<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>高可用篇 | FettersLoveの博客</title><meta name="author" content="FettersLove"><meta name="copyright" content="FettersLove"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="高可用篇">
<meta property="og:type" content="article">
<meta property="og:title" content="高可用篇">
<meta property="og:url" content="http://fetterslove.github.io/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/index.html">
<meta property="og:site_name" content="FettersLoveの博客">
<meta property="og:description" content="高可用篇">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg">
<meta property="article:published_time" content="2022-08-08T16:00:00.000Z">
<meta property="article:modified_time" content="2022-11-13T14:28:05.683Z">
<meta property="article:author" content="FettersLove">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://fetterslove.github.io/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/Free" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: FettersLove","link":"链接: ","source":"来源: FettersLoveの博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '高可用篇',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-13 22:28:05'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/ethan4116-blog/lib/css/plane_v2.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/xxx.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/QQ%E5%9B%BE%E7%89%8720221110180115.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-book"></i><span> 程序生涯</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-face-smile"></i><span> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/story/"><i class="fa-fw fas fa-star"></i><span> story</span></a></li><li><a class="site-page child" href="/perception/"><i class="fa-fw fas fa-paper-plane"></i><span> 感悟</span></a></li><li><a class="site-page child" href="/cover/"><i class="fa-fw fas fa-headphones"></i><span> 翻唱音乐</span></a></li><li><a class="site-page child" href="/warmBlood/"><i class="fa-fw fas fa-fire"></i><span> 热血</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">FettersLoveの博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-book"></i><span> 程序生涯</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-face-smile"></i><span> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/story/"><i class="fa-fw fas fa-star"></i><span> story</span></a></li><li><a class="site-page child" href="/perception/"><i class="fa-fw fas fa-paper-plane"></i><span> 感悟</span></a></li><li><a class="site-page child" href="/cover/"><i class="fa-fw fas fa-headphones"></i><span> 翻唱音乐</span></a></li><li><a class="site-page child" href="/warmBlood/"><i class="fa-fw fas fa-fire"></i><span> 热血</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">高可用篇</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-13T14:28:05.683Z" title="更新于 2022-11-13 22:28:05">2022-11-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/redis/">redis</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="高可用篇"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="redis的三种集群模型"><a href="#redis的三种集群模型" class="headerlink" title="redis的三种集群模型"></a>redis的三种集群模型</h2><h3 id="Ⅰ主从复制是怎么实现的？"><a href="#Ⅰ主从复制是怎么实现的？" class="headerlink" title="Ⅰ主从复制是怎么实现的？"></a>Ⅰ主从复制是怎么实现的？</h3><p>AOF 和 RDB，这两个持久化技术保证了即使在服务器重启的情况下也不会丢失数据（或少量损失）。<br>不过，由于数据都是存储在一台服务器上，如果出事就完犊子了，比如：</p>
<ul>
<li>如果服务器发生了宕机，由于数据恢复是需要点时间，那么这个期间是无法服务新的请求的；</li>
<li>如果这台服务器的硬盘出现了故障，可能数据就都丢失了。</li>
</ul>
<p>要避免这种单点故障，最好的办法是将数据备份到其他服务器上，让这些服务器也可以对外提供服务，这样即使有一台服务器出现了故障，其他服务器依然可以继续提供服务。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080221-b4c14623-7658-4b9c-8d41-250a88a8045e.png#averageHue=%23faf9f8&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=343&amp;id=u85e7973a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=661&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=91068&amp;status=done&amp;style=none&amp;taskId=u85a8384f-ed55-4d5e-a913-dfb1cfc82bf&amp;title=&amp;width=560.0000610351562" alt="image.png"><br>多台服务器要保存同一份数据，这里问题就来了。<br>这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？</p>
<p>Redis 提供了<strong>主从复制模式</strong>，来避免上述的问题。<br>这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是<strong>「读写分离」</strong>的方式。<br>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080191-76100d8b-81bb-4a41-ad95-e03c112f8062.png#averageHue=%23f9f6f5&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2b694aaa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=422&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49243&amp;status=done&amp;style=none&amp;taskId=ud960accc-5eeb-454b-bc5a-6eb3a1e0aee&amp;title=" alt="image.png"><br>也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。<br>同步这两个字说的简单，但是这个同步过程并没有想象中那么简单，要考虑的事情不是一两个。<br><strong>主从服务器</strong>间的第一次同步是如何工作的？#### ①第一次同步<br>多台服务器之间要通过什么方式来确定谁是主服务器，或者谁是从服务器呢？<br>我们可以使用 <strong>replicaof</strong>（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。<br>比如，现在有服务器 A 和 服务器 B，我们在服务器 B 上执行下面这条命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 服务器 B 执行这条命令</span><br><span class="line">replicaof &lt;服务器 A 的 IP 地址&gt; &lt;服务器 A 的 Redis 端口号&gt;</span><br></pre></td></tr></table></figure><br>接着，服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。<br><strong>主从服务器间的第一次同步的过程可分为三个阶段：</strong></p>
<ul>
<li><strong>第一阶段是建立链接、协商同步；</strong></li>
<li><strong>第二阶段是主服务器同步数据给从服务器；</strong></li>
<li><strong>第三阶段是主服务器发送新写操作命令给从服务器。</strong></li>
</ul>
<p>为了让你更清楚了解这三个阶段，我画了一张图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080280-933601dd-4609-41b7-a8fc-7827866550d9.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=315&amp;id=TSgEY&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=555&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=143619&amp;status=done&amp;style=none&amp;taskId=u4f1547a5-d0e6-4657-b954-71815208666&amp;title=&amp;width=613.0000610351562" alt="image.png"><br>接下来，我在具体介绍每一个阶段都做了什么。<br><em>第一阶段：建立链接、协商同步</em><br>执行了 replicaof 命令后，从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。<br>psync 命令包含两个参数，分别是<strong>主服务器的 runID</strong> 和<strong>复制进度 offset</strong>。</p>
<ul>
<li>runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 “?”。</li>
<li>offset，表示复制的进度，第一次同步时，其值为 -1。</li>
</ul>
<p>主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。<br>并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。<br>FULLRESYNC 响应命令的意图是采用<strong>全量复制</strong>的方式，也就是主服务器会把所有的数据都同步给从服务器。<br>所以，第一阶段的工作时为了全量复制做准备。<br>那具体怎么全量同步呀呢？我们可以往下看第二阶段。<br><em>第二阶段：主服务器同步数据给从服务器</em><br>接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。<br>从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。</p>
<p>这里有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。</p>
<p>但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。那么为了保证主从服务器的数据一致性，<strong>主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里。</strong></p>
<ul>
<li>主服务器生成 RDB 文件期间；</li>
<li>主服务器发送 RDB 文件给从服务器期间；</li>
<li>「从服务器」加载 RDB 文件期间；</li>
</ul>
<p><em>第三阶段：主服务器发送新写操作命令给从服务器</em><br>在主服务器生成的 RDB 文件发送完，从服务器加载完 RDB 文件后，然后将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，然后「从服务器」重新执行这些操作，至此主从服务器的数据就一致了。<br>至此，主从服务器的第一次同步的工作就完成了。</p>
<h4 id="②命令传播"><a href="#②命令传播" class="headerlink" title="②命令传播"></a>②命令传播</h4><p>主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080087-dad54cf0-ce53-4636-8f39-32fe8f9c8754.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=345&amp;id=bGuU5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=602&amp;originWidth=842&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=53580&amp;status=done&amp;style=none&amp;taskId=u89402ee2-1d1e-47bf-8110-9cd31080215&amp;title=&amp;width=482" alt="image.png"><br>后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。<br>而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。<br>上面的这个过程被称为<strong>基于长连接的命令传播</strong>，通过这种方式来保证第一次同步后的主从服务器的数据一致性。</p>
<h4 id="③分摊主服务器的压力"><a href="#③分摊主服务器的压力" class="headerlink" title="③分摊主服务器的压力"></a>③分摊主服务器的压力</h4><p>在前面的分析中，我们可以知道主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。<br>主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：</p>
<ul>
<li>由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；</li>
<li>传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。<blockquote>
<p>这种情况就好像，刚创业的公司，由于人不多，所以员工都归老板一个人管，但是随着公司的发展，人员的扩充，老板慢慢就无法承担全部员工的管理工作了。<br>要解决这个问题，老板就需要设立经理职位，由经理管理多名普通员工，然后老板只需要管理经理就好。<br>Redis 也是一样的，从服务器可以有自己的从服务器，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器，组织形式如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080224-708cc951-807d-4784-90ec-6a110ad0f19e.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=335&amp;id=RFwwh&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=632&amp;originWidth=1052&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=88698&amp;status=done&amp;style=none&amp;taskId=u9d65afcc-8ff9-4513-8ef1-5fdd1bdbfed&amp;title=&amp;width=557.0000610351562" alt="image.png"></p>
</blockquote>
</li>
</ul>
<p>通过这种方式，<strong>主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器</strong>。<br>那具体怎么做到的呢？<br>其实很简单，我们在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof &lt;目标服务器的IP&gt; <span class="number">6379</span></span><br></pre></td></tr></table></figure><br>此时如果目标服务器本身也是「从服务器」，那么该目标服务器就会成为「经理」的角色，不仅可以接受主服务器同步的数据，也会把数据同步给自己旗下的从服务器，从而减轻主服务器的负担。</p>
<h4 id="④增量复制"><a href="#④增量复制" class="headerlink" title="④增量复制"></a>④增量复制</h4><p>主从服务器在完成第一次同步后，就会基于长连接进行命令传播。<br>可是，网络总是不按套路出牌的嘛，说延迟就延迟，说断开就断开。<br>如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081879-6a81191c-bb03-4c06-b96a-0085938bc72a.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=556&amp;id=CnjPy&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=812&amp;originWidth=834&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72549&amp;status=done&amp;style=none&amp;taskId=u8f9ec897-bf7c-49dd-8d7f-1bd71942c33&amp;title=&amp;width=571.0000610351562" alt="image.png"><br>那么问题来了，如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？</p>
<p>在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。<br>所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用<strong>增量复制</strong>的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。<br>网络恢复后的增量复制过程如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081795-099fb740-5694-41c8-ac30-7492ead59862.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=508&amp;id=tWwsX&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=617&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54774&amp;status=done&amp;style=none&amp;taskId=u4cbc26bf-835d-4c94-99c3-3b000c5115f&amp;title=&amp;width=582.0000610351562" alt="image.png"><br>主要有三个步骤：</p>
<ul>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li>
<li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li>
</ul>
<p>那么关键的问题来了，<strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong><br>答案藏在这两个东西里：</p>
<ul>
<li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li>
<li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master<em>repl_offset 来记录自己「</em>写<em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「</em>读_」到的位置。</li>
</ul>
<p>那repl_backlog_buffer 缓冲区是什么时候写入的呢？<br>在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。<br>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：</p>
<ul>
<li>如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>增量同步</strong>的方式；</li>
<li>相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>全量同步</strong>的方式。</li>
</ul>
<p>当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081917-c00abe06-1988-459c-acf3-ba56fd6db733.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=eKHr9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84591&amp;status=done&amp;style=none&amp;taskId=u399d5ce3-13bc-4399-9fd5-20d4685e5cb&amp;title=" alt="image.png"><br>repl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。<br>因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。<br>那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。<br>因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。</p>
<blockquote>
<p>那 repl_backlog_buffer 缓冲区具体要调整到多大呢？<br>repl_backlog_buffer 最小的大小可以根据这面这个公式估算。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081859-ec1c2425-f51e-4f78-a920-36dedb13d7ab.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PyRXc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=121&amp;originWidth=361&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6215&amp;status=done&amp;style=none&amp;taskId=u819284f4-c9cd-4bbb-a75e-42b53aab762&amp;title=" alt="image.png"><br>我来解释下这个公式的意思：</p>
<ul>
<li>second 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。</li>
<li>write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。</li>
</ul>
<p>举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。<br>那么 repl_backlog_buffer 大小就不能低于 5 MB，否则新写地命令就会覆盖旧数据了。<br>当然，为了应对一些突发的情况，可以将 repl_backlog_buffer 的大小设置为此基础上的 2 倍，也就是 10 MB。<br>关于 repl_backlog_buffer 大小修改的方法，只需要修改配置文件里下面这个参数项的值就可以。</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">repl-backlog-size <span class="number">1</span>mb</span><br></pre></td></tr></table></figure>
<h4 id="总结★（记熟悉）"><a href="#总结★（记熟悉）" class="headerlink" title="总结★（记熟悉）"></a>总结★（记熟悉）</h4><p>主从复制共有三种模式：<strong>全量复制、基于长连接的命令传播、增量复制</strong>。</p>
<ul>
<li>主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。</li>
<li>第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。</li>
<li>如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。</li>
</ul>
<p>如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。</p>
<h4 id="集群产生脑裂数据丢失"><a href="#集群产生脑裂数据丢失" class="headerlink" title="集群产生脑裂数据丢失"></a>集群产生脑裂数据丢失</h4><p>先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？<br>那么在 redis 中，集群脑裂产生数据丢失的现象是怎样的呢？<br>在 redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。<br>如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。<br>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。<br>这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。<br>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。<br><strong>解决方案：</strong><br>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p>
<p>在 redis 的配置文件中有两个参数我们可以设置：</p>
<ul>
<li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li>
<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li>
</ul>
<p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p>
<p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。<br>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。<br><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。我再来给你举个例子。</strong><br>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p>
<h4 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h4><h5 id="redis主从节点时长连接还是短链接？"><a href="#redis主从节点时长连接还是短链接？" class="headerlink" title="redis主从节点时长连接还是短链接？"></a>redis主从节点时长连接还是短链接？</h5><p>长连接</p>
<h5 id="怎么判断-redis-某个节点是否正常工作？"><a href="#怎么判断-redis-某个节点是否正常工作？" class="headerlink" title="怎么判断 redis 某个节点是否正常工作？"></a>怎么判断 redis 某个节点是否正常工作？</h5><p>redis 判断接点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。<br>redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：</p>
<ul>
<li>redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。</li>
<li><p>redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：</p>
<ul>
<li>实时监测主从节点网络状态；</li>
<li>上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。<h5 id="主从复制架构中，过期key如何处理？"><a href="#主从复制架构中，过期key如何处理？" class="headerlink" title="主从复制架构中，过期key如何处理？"></a>主从复制架构中，过期key如何处理？</h5>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。<h5 id="redis-是同步复制还是异步复制？"><a href="#redis-是同步复制还是异步复制？" class="headerlink" title="redis 是同步复制还是异步复制？"></a>redis 是同步复制还是异步复制？</h5>redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。<h5 id="主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><a href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？" class="headerlink" title="主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？"></a>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</h5>replication buffer 、repl backlog buffer 区别如下：</li>
</ul>
</li>
<li><p>replication buffer 是在全量复制阶段会出现，<strong>主库会给每个新连接的从库，分配一个</strong> replication buffer；repl backlog buffer 是在增量复制阶段出现，<strong>一个主库只分配一个</strong>repl backlog buffer；</p>
</li>
<li><p>这两个 Buffer 都有大小限制的，当缓冲区满了之后。repl backlog buffer，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>，replication buffer则会导致连接断开，删除缓存，从库重新连接，<strong>重新开始全量复制</strong>。</p>
<h5 id="redis-主从切换如何减少数据丢失？"><a href="#redis-主从切换如何减少数据丢失？" class="headerlink" title="redis 主从切换如何减少数据丢失？"></a>redis 主从切换如何减少数据丢失？</h5><h6 id="异步复制同步丢失"><a href="#异步复制同步丢失" class="headerlink" title="异步复制同步丢失"></a>异步复制同步丢失</h6><p>对于 redis 主节点与从节点之间的数据复制，时异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。<br><strong>可以有 2 种解决方案：</strong></p>
</li>
<li><p>第一种：客户端将数据暂时写入本地缓存和磁盘中，在一段时间后将本地缓存或者磁盘的数据发送给主节点，来保证数据不丢失；</p>
</li>
<li>第二种：客户端将数据写入到消息队列中，发送一个延时消费消息，比如10分钟后再消费消息队列中的数据，然后再写到主节点。</li>
</ul>
<h5 id="redis-主从如何做到故障自动切换？"><a href="#redis-主从如何做到故障自动切换？" class="headerlink" title="redis 主从如何做到故障自动切换？"></a>redis 主从如何做到故障自动切换？</h5><p>主节点挂了 ，从节点是无法自动升级为主节点的，这个过程需要人工处理，在此期间 redis 无法对外提供写操作。<br>此时，redis 哨兵机制就登场了，哨兵在发现主节点出现故障时，由哨兵自动完成故障发现和故障转移，并通知给应用方，从而实现高可用性。</p>
<h3 id="Ⅱ为什么要有哨兵？"><a href="#Ⅱ为什么要有哨兵？" class="headerlink" title="Ⅱ为什么要有哨兵？"></a>Ⅱ为什么要有哨兵？</h3><p>这次聊聊，Redis 的哨兵机制。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992525-e378da71-0cf2-424d-b9f4-f8ca54fc8df5.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=471&amp;id=u7e4c967c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1404&amp;originWidth=1814&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=666006&amp;status=done&amp;style=none&amp;taskId=u0387f134-ceb4-4da1-9d88-286629f0d6e&amp;title=&amp;width=609.0000610351562" alt="image.png"></p>
<h4 id="①为什么要有哨兵机制？"><a href="#①为什么要有哨兵机制？" class="headerlink" title="①为什么要有哨兵机制？"></a>①为什么要有哨兵机制？</h4><ul>
<li>在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992237-60e4b944-b02d-4823-ba9b-0c5014b85d16.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=226&amp;id=ub7210b00&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1008&amp;originWidth=2082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=278739&amp;status=done&amp;style=none&amp;taskId=u9f0157a6-7bee-4e7c-86b6-de0b3a7f670&amp;title=&amp;width=466.00006103515625" alt="image.png"></p>
<ul>
<li>这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。</li>
<li>这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了 ，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！</li>
</ul>
<p>Redis 在 2.8 版本以后提供的<strong>哨兵（<em>Sentinel</em>）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p>
<h4 id="②哨兵机制是如何工作的？"><a href="#②哨兵机制是如何工作的？" class="headerlink" title="②哨兵机制是如何工作的？"></a>②哨兵机制是如何工作的？</h4><p>哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。<br>当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。<br>哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991701-eaa465bd-18aa-41fe-95bf-bfd0794de6ac.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e7aea3f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=326&amp;originWidth=912&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29102&amp;status=done&amp;style=none&amp;taskId=uaa5caac2-ea08-4000-853e-58cf208180f&amp;title=" alt="image.png"><br>所以，我们重点要学习这三件事情：</p>
<ul>
<li>哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？</li>
<li>根据什么规则选择一个从节点切换为主节点？</li>
<li><p>怎么把新主节点的相关信息通知给从节点和客户端呢？</p>
<h4 id="③如何判断主节点真的故障了？"><a href="#③如何判断主节点真的故障了？" class="headerlink" title="③如何判断主节点真的故障了？"></a>③如何判断主节点真的故障了？</h4><p>哨兵会每隔 1 秒给<strong>所有主从节点</strong>发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991918-2f292a86-232a-4324-8734-694e1e6dbfb8.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=341&amp;id=u6488a21b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=560&amp;originWidth=982&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61368&amp;status=done&amp;style=none&amp;taskId=uc67498ae-7a3b-446a-8c5c-e470b2e4b12&amp;title=&amp;width=598.0000610351562" alt="image.png"><br>如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「<strong>主观下线</strong>」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。<br>主观下线？难道还有客观下线？<br>是的没错，<strong>客观下线只适用于主节点。</strong></p>
</li>
<li><p>之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。</p>
</li>
<li>所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成<strong>哨兵集群</strong>（<em>最少需要三台机器来部署哨兵集群</em>），<strong>通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况</strong>。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</li>
</ul>
<p><strong>具体是怎么判定主节点为「客观下线」的呢？</strong><br>当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991919-3b23464f-6552-4e7f-b54d-088539b160d2.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub2273e1c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=686&amp;originWidth=1066&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=86410&amp;status=done&amp;style=none&amp;taskId=ud7a35611-a0b0-4bce-9343-186bae91985&amp;title=" alt="image.png"><br>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。<br>例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。<br>PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。<br>哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。</p>
<h4 id="④由哪个哨兵进行主从故障转移？"><a href="#④由哪个哨兵进行主从故障转移？" class="headerlink" title="④由哪个哨兵进行主从故障转移？"></a>④由哪个哨兵进行主从故障转移？</h4><p>前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以<strong>哨兵是以哨兵集群的方式存在的</strong>。<br><strong>问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？</strong><br>所以这时候，还需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。<br>选举 leader 的过程其实是一个投票的过程，在投票开始前，肯定得有个「候选者」。<br>那谁来作为候选者呢？<br>哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。<br>举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992714-d498bfdb-a0f8-40a5-8b54-423c285d1621.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=498&amp;id=u32b91fc8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=988&amp;originWidth=1124&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=125820&amp;status=done&amp;style=none&amp;taskId=ub0393f24-a234-41af-a7f8-61bd2deb28d&amp;title=&amp;width=566.0000610351562" alt="image.png"><br>当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。<br>候选者如何选举成为 Leader？<br>候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。<br>每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。<br>那么在投票过程中，任何一个「候选者」，要满足两个条件：</p>
<ul>
<li>第一，拿到半数以上的赞成票；</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
<p>举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。<br>这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？<br>每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。<br>为什么哨兵节点至少要有 3 个？<br>如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。<br>所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。<br>因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。<br>当然，你要问，如果 3 个哨兵节点，挂了 2 个怎么办？这个时候得人为介入了，或者增加多一点哨兵节点。<br>再说一个问题，Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？</p>
<ul>
<li><strong>哨兵集群可以判定主节点“客观下线”</strong>。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。</li>
<li><strong>哨兵集群可以完成主从切换</strong>。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。</li>
</ul>
<p>如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。<br>如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。<br>可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。<br>所以，<strong>quorum 的值建议设置为哨兵个数的二分之一加1</strong>，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且<strong>哨兵节点的数量应该是奇数</strong>。</p>
<h4 id="⑤主从故障转移的过程是怎样的？"><a href="#⑤主从故障转移的过程是怎样的？" class="headerlink" title="⑤主从故障转移的过程是怎样的？"></a>⑤主从故障转移的过程是怎样的？</h4><p>在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645993557-963b926e-a3fb-4cbe-ab5f-acaffb8e4aa2.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3e967b7f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=701&amp;originWidth=2510&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=430642&amp;status=done&amp;style=none&amp;taskId=uad4c2133-9e3c-4c10-b131-187a6e14c2c&amp;title=" alt="image.png"><br>主从故障转移操作包含以下四个步骤：</p>
<ul>
<li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。</li>
<li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li>
<li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li>
<li><p>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；<br>详细步骤#### 步骤一：选出新主节点<br>故障转移操作第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」。<br><strong>那么多「从节点」，到底选择哪个从节点作为新主节点的？</strong></p>
</li>
<li><p>随机的方式好吗？随机的方式，实现起来很简单，但是如果选到一个网络状态不好的从节点作为新主节点，那么可能在将来不久又要做一次主从故障迁移。</p>
</li>
<li>所以，我们首先要把网络状态不好的从节点给过滤掉。首先把已经下线的从节点过滤掉，然后把以往网络连接状态不好的从节点也给过滤掉。</li>
</ul>
<p>怎么判断从节点之前的网络连接状态不好呢？<br>Redis 有个叫 down-after-milliseconds <em> 10 配置项，其down-after-milliseconds 是主从节点断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。<br>至此，我们就把网络状态不好的从节点过滤掉了，接下来要对所有从节点进行三轮考察：<em>*优先级、复制进度、ID 号</em></em>。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点。</p>
<ul>
<li>第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，</li>
<li>第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。</li>
<li><p>第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。</p>
<h5 id="第一轮考察：优先级最高的从节点胜出"><a href="#第一轮考察：优先级最高的从节点胜出" class="headerlink" title="第一轮考察：优先级最高的从节点胜出"></a>第一轮考察：优先级最高的从节点胜出</h5><p>Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。<br>每一台从节点的服务器配置不一定是相同的，我们可以根据服务器性能配置来设置从节点的优先级。<br>比如，如果 「 A 从节点」的物理内存是所有从节点中最大的， 那么我们可以把「 A 从节点」的优先级设置成最高。这样当哨兵进行第一轮考虑的时候，优先级最高的 A 从节点就会优先胜出，于是就会成为新主节点。</p>
<h5 id="第二轮考察：复制进度最靠前的从节点胜出"><a href="#第二轮考察：复制进度最靠前的从节点胜出" class="headerlink" title="第二轮考察：复制进度最靠前的从节点胜出"></a>第二轮考察：复制进度最靠前的从节点胜出</h5><p>如果在第一轮考察中，发现优先级最高的从节点有两个，那么就会进行第二轮考察，比较两个从节点哪个复制进度。<br>什么是复制进度？主从架构中，主节点会将写操作同步给从节点，在这个过程中，主节点会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置（如下图中的「主服务器已经写入的数据」的位置），而从节点会用 slave_repl_offset 这个值记录当前的复制进度（如下图中的「从服务器要读的位置」的位置）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645993347-fe1b7396-557e-44c4-a75d-be051bae531d.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tED3r&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84591&amp;status=done&amp;style=none&amp;taskId=u5c058a76-fd9d-47ef-9ea6-86791605b92&amp;title=" alt="image.png"><br>如果某个从节点的 slave_repl_offset 最接近 master_repl_offset，说明它的复制进度是最靠前的，于是就可以将它选为新主节点。</p>
<h5 id="第三轮考察：ID-号小的从节点胜出"><a href="#第三轮考察：ID-号小的从节点胜出" class="headerlink" title="第三轮考察：ID 号小的从节点胜出"></a>第三轮考察：ID 号小的从节点胜出</h5><p>如果在第二轮考察中，发现有两个从节点优先级和复制进度都是一样的，那么就会进行第三轮考察，比较两个从节点的 ID 号，ID 号小的从节点胜出。<br>什么是 ID 号？每个从节点都有一个编号，这个编号就是 ID 号，是用来唯一标识从节点的。<br>到这里，选主的事情终于结束了。简单给大家总结下：<br><img src="https://cdn.nlark.com/yuque/0/2022/webp/21371548/1658645993451-7cf5e318-e918-410a-9b8b-8188c84a21e9.webp#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Vm5go&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1027&amp;originWidth=879&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u96c37ec3-8121-4af1-98be-87f513cca7a&amp;title=" alt=""><br>在选举出从节点后，哨兵 leader 向被选中的从节点发送 SLAVEOF no one 命令，让这个从节点解除从节点的身份，将其变为新主节点。<br>如下图，哨兵 leader 向被选中的从节点 server2 发送 SLAVEOF no one 命令，将该从节点升级为新主节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995437-b08f67fd-2503-4643-8840-927a656d4ce0.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=skIkx&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1140&amp;originWidth=1830&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=601992&amp;status=done&amp;style=none&amp;taskId=u25596e48-fb8b-43df-b457-d23ab800786&amp;title=" alt="image.png"><br>在发送 SLAVEOF no one 命令之后，哨兵 leader 会以每秒一次的频率向被升级的从节点发送 INFO 命令（没进行故障转移之前，INFO 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。<br>如下图，选中的从节点 server2 升级成了新主节点：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995352-534e7c2e-3b41-48eb-b549-f4183aba9155.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=x8OY8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1070&amp;originWidth=1492&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=503409&amp;status=done&amp;style=none&amp;taskId=u9f0602ff-a450-4cb0-8469-8d3f78887fc&amp;title=" alt="image.png"></p>
<h4 id="步骤二：将从节点指向新主节点"><a href="#步骤二：将从节点指向新主节点" class="headerlink" title="步骤二：将从节点指向新主节点"></a>步骤二：将从节点指向新主节点</h4><p>当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 SLAVEOF 命令来实现。<br>如下图，哨兵 leader 向所有从节点（server3和server4）发送 SLAVEOF ，让它们成为新主节点的从节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995516-a02f6388-668e-47d2-971f-cb19cc08689e.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=AzQsa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=928&amp;originWidth=1720&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=542845&amp;status=done&amp;style=none&amp;taskId=u81cc2c62-f837-4abb-a088-5a146b4bab1&amp;title=" alt="image.png"><br>所有从节点指向新主节点后的拓扑图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995548-d735ebab-f4b1-4b9d-a298-2a129f75376b.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Fypeq&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1246&amp;originWidth=1630&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=559528&amp;status=done&amp;style=none&amp;taskId=uc247425f-b83b-4da6-a616-e49febb0df1&amp;title=" alt="image.png"></p>
<h4 id="步骤三：通知客户的主节点已更换"><a href="#步骤三：通知客户的主节点已更换" class="headerlink" title="步骤三：通知客户的主节点已更换"></a>步骤三：通知客户的主节点已更换</h4><p>经过前面一系列的操作后，哨兵集群终于完成主从切换的工作，那么新主节点的信息要如何通知给客户端呢？<br>这主要<strong>通过 Redis 的发布者/订阅者机制来实现</strong>的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。<br>哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件，几个常见的事件如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/webp/21371548/1658645995083-3883a2f6-347d-4393-a2cb-37cdb64a0988.webp#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=liKxB&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1738&amp;originWidth=2856&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8128f5e1-3cb7-419a-98d8-a20ba22fc7c&amp;title=" alt=""><br>客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。<strong>主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了</strong>。<br>通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p>
<h4 id="步骤四：将旧主节点变为从节点"><a href="#步骤四：将旧主节点变为从节点" class="headerlink" title="步骤四：将旧主节点变为从节点"></a>步骤四：将旧主节点变为从节点</h4><p>故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新主节点的从节点，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645996970-36b708d2-92e1-442a-badb-17d336d4afa4.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=xqrVM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1120&amp;originWidth=1392&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=531342&amp;status=done&amp;style=none&amp;taskId=u13359704-0f85-46ec-b273-fb8d90809af&amp;title=" alt="image.png"><br>至此，整个主从节点的故障转移的工作结束。</p>
<h4 id="哨兵集群是如何组成的？"><a href="#哨兵集群是如何组成的？" class="headerlink" title="哨兵集群是如何组成的？"></a>哨兵集群是如何组成的？</h4><p>前面提到了 Redis 的发布者/订阅者机制，那就不得不提一下哨兵集群的组成方式，因为它也用到了这个技术。<br>在我第一次搭建哨兵集群的时候，当时觉得很诧异。因为在配置哨兵的信息时，竟然只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。<br>sentinel monitor <master-name> <ip> <redis-port> <quorum><br>不需要填其他哨兵节点的信息，我就好奇它们是如何感知对方的，又是如何组成哨兵集群的？<br>后面才了解到，<strong>哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的</strong>。<br>在主从集群中，主节点上有一个名为<strong>sentinel</strong>:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。<br>在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到<strong>sentinel</strong>:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645997027-58d69efe-ed36-44f1-988e-797fa1b220d0.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e2d289d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1152&amp;originWidth=1290&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=158491&amp;status=done&amp;style=none&amp;taskId=uc687137e-9105-4e08-8586-65ba1043c99&amp;title=" alt="image.png"><br>通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。<br>哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？<br>主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。<br>如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645997128-8aa9cbd7-9342-42be-9436-9e1656158851.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u420cccac&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1396&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=100621&amp;status=done&amp;style=none&amp;taskId=ufd1d7e66-9d30-482e-952a-739cf396e18&amp;title=" alt="image.png"><br>正式通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Redis 在 2.8 版本以后提供的<strong>哨兵（<em>Sentinel</em>）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。<br>哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：<strong>监控、选主、通知</strong>。<br>哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。<br><em>1、第一轮投票：判断主节点下线</em><br>当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。<br>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。<br><em>2、第二轮投票：选出哨兵leader</em><br>某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：</p>
</li>
<li><p>第一，拿到半数以上的赞成票；</p>
</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
<p><em>3、由哨兵 leader 进行主从故障转移</em><br>选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：</p>
<ul>
<li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：<ul>
<li>过滤掉已经离线的从节点；</li>
<li>过滤掉历史网络连接状态不好的从节点；</li>
<li>将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。</li>
</ul>
</li>
<li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li>
<li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li>
<li>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li>
</ul>
<p>完！</p>
<h3 id="Ⅲ集群"><a href="#Ⅲ集群" class="headerlink" title="Ⅲ集群"></a>Ⅲ集群</h3><h4 id="①Redis集群介绍："><a href="#①Redis集群介绍：" class="headerlink" title="①Redis集群介绍："></a>①Redis集群介绍：</h4><p>1、为什么需要Redis集群？<br>        在讲Redis集群架构之前，我们先简单讲下Redis单实例的架构，从最开始的一主N从，到读写分离，再到Sentinel哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667463929934-e9841e49-66a5-49fb-9970-244d86c251d5.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=208&amp;id=u9129082b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=422&amp;originWidth=494&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=104687&amp;status=done&amp;style=none&amp;taskId=u86f87354-d209-4370-abf5-341d2c67be6&amp;title=&amp;width=243.28573608398438" alt="image.png"></p>
<p>但是，在某些场景下，单实例存Redis缓存会存在的几个问题：</p>
<p>（1）写并发：<br>        Redis单实例读写分离可以解决读操作的负载均衡，但对于写操作，仍然是全部落在了master节点上面，在海量数据高并发场景，一个节点写数据容易出现瓶颈，造成master节点的压力上升。</p>
<p>（2）海量数据的存储压力：<br>        单实例Redis本质上只有一台Master作为存储，如果面对海量数据的存储，一台Redis的服务器就应付不过来了，而且数据量太大意味着持久化成本高，严重时可能会阻塞服务器，造成服务请求成功率下降，降低服务的稳定性。</p>
<p>针对以上的问题，Redis集群提供了较为完善的方案，解决了存储能力受到单机限制，写操作无法负载均衡的问题。</p>
<p>2、什么是Redis集群？</p>
<pre><code>    Redis3.0加入了Redis的集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的master节点上面，从而解决了海量数据的存储问题。

    Redis集群采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。

    Redis也内置了高可用机制，支持N个master节点，每个master节点都可以挂载多个slave节点，当master节点挂掉时，集群会提升它的某个slave节点作为新的master节点。
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667463969408-e0330455-e5ce-4fbd-ab69-f15e96aaf04d.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=257&amp;id=uddd4dd13&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=404&amp;originWidth=720&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57980&amp;status=done&amp;style=none&amp;taskId=u4863c4ba-0e7f-4322-8312-21a3efea908&amp;title=&amp;width=458.2857666015625" alt="image.png"></p>
<pre><code>    如上图所示，Redis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点（其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用）
</code></pre><h4 id="②Redis集群的数据分布算法：哈希槽算法"><a href="#②Redis集群的数据分布算法：哈希槽算法" class="headerlink" title="②Redis集群的数据分布算法：哈希槽算法"></a>②Redis集群的数据分布算法：哈希槽算法</h4><p>1、什么是哈希槽算法？</p>
<pre><code>    前面讲到，Redis集群通过分布式存储的方式解决了单节点的海量数据存储的问题，对于分布式存储，需要考虑的重点就是如何将数据进行拆分到不同的Redis服务器上。常见的分区算法有hash算法、一致性hash算法，关于这些算法这里就不多介绍。
</code></pre><ul>
<li>普通hash算法：将key使用hash算法计算之后，按照节点数量来取余，即hash(key)%N。优点就是比较简单，但是扩容或者摘除节点时需要重新根据映射关系计算，会导致数据重新迁移。</li>
<li><p>一致性hash算法：为每一个节点分配一个token，构成一个哈希环；查找时先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。优点是在加入和删除节点时只影响相邻的两个节点，缺点是加减节点会造成部分数据无法命中，所以一般用于缓存，而且用于节点量大的情况下，扩容一般增加一倍节点保障数据负载均衡。</p>
<pre><code>  Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作。

  使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；哈希槽数据分区算法具有以下几种特点：
</code></pre></li>
<li><p>解耦数据和节点之间的关系，简化了扩容和收缩难度；</p>
</li>
<li>节点自身维护槽的映射关系，不需要客户端代理服务维护槽分区元数据</li>
<li>支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景<blockquote>
<p>槽的迁移与指派命令：CLUSTER ADDSLOTS 0 1 2 3 4 … 5000 </p>
</blockquote>
</li>
</ul>
<pre><code>    默认情况下，redis集群的读和写都是到master上去执行的，不支持slave节点读和写，跟Redis主从复制下读写分离不一样，因为redis集群的核心的理念，主要是使用slave做数据的热备，以及master故障时的主备切换，实现高可用的。Redis的读写分离，是为了横向任意扩展slave节点去支撑更大的读吞吐量。而redis集群架构下，本身master就是可以任意扩展的，如果想要支撑更大的读或写的吞吐量，都可以直接对master进行横向扩展。
</code></pre><p>2、Redis中哈希槽相关的数据结构：</p>
<p>（1）clusterNode数据结构：保存节点的当前状态，比如节点的创建时间，节点的名字，节点当前的配置纪元，节点的IP和地址，等等。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464136892-fdd95171-98fa-4024-8742-6ee58df1812f.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=661&amp;id=u2679d634&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=823&amp;originWidth=730&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=159857&amp;status=done&amp;style=none&amp;taskId=u9691a89f-2076-4fcf-aa16-6b3c79193cd&amp;title=&amp;width=586.2857666015625" alt="image.png"><br>（2）clusterState数据结构：记录当前节点所认为的集群目前所处的状态。</p>
<p>（3）节点的槽指派信息：</p>
<pre><code>    clusterNode数据结构的slots属性和numslot属性记录了节点负责处理那些槽：slots属性是一个二进制位数组(bit array)，这个数组的长度为16384/8=2048个字节，共包含16384个二进制位。Master节点用bit来标识对于某个槽自己是否拥有，时间复杂度为O(1)
</code></pre><p>（4）集群所有槽的指派信息：</p>
<pre><code>    当收到集群中其他节点发送的信息时，通过将节点槽的指派信息保存在本地的clusterState.slots数组里面，程序要检查槽i是否已经被指派，又或者取得负责处理槽i的节点，只需要访问clusterState.slots[i]的值即可，时间复杂度仅为O(1)



    如上图所示，ClusterState 中保存的 Slots 数组中每个下标对应一个槽，每个槽信息中对应一个 clusterNode 也就是缓存的节点。这些节点会对应一个实际存在的 Redis 缓存服务，包括 IP 和 Port 的信息。Redis Cluster 的通讯机制实际上保证了每个节点都有其他节点和槽数据的对应关系。无论Redis 的客户端访问集群中的哪个节点都可以路由到对应的节点上，因为每个节点都有一份 ClusterState，它记录了所有槽和节点的对应关系。
</code></pre><h4 id="③集群的请求重定向："><a href="#③集群的请求重定向：" class="headerlink" title="③集群的请求重定向："></a>③集群的请求重定向：</h4><pre><code>    前面讲到，Redis集群在客户端层面没有采用代理，并且无论Redis 的客户端访问集群中的哪个节点都可以路由到对应的节点上，下面来看看 Redis 客户端是如何通过路由来调用缓存节点的：
</code></pre><p>（1）MOVED请求：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464279693-c6577c2a-3a9d-45f3-870c-5e23ebf156f0.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=365&amp;id=u3d157440&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=548&amp;originWidth=808&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=125945&amp;status=done&amp;style=none&amp;taskId=u8806bf71-7d2a-4e65-842d-61a0578d0b0&amp;title=&amp;width=538.2857666015625" alt="image.png"></p>
<pre><code>    如上图所示，Redis 客户端通过 CRC16(key)%16383 计算出 Slot 的值，发现需要找“缓存节点1”进行数据操作，但是由于缓存数据迁移或者其他原因导致这个对应的 Slot 的数据被迁移到了“缓存节点2”上面。那么这个时候 Redis 客户端就无法从“缓存节点1”中获取数据了。但是由于“缓存节点1”中保存了所有集群中缓存节点的信息，因此它知道这个 Slot 的数据在“缓存节点2”中保存，因此向 Redis 客户端发送了一个 MOVED 的重定向请求。这个请求告诉其应该访问的“缓存节点2”的地址。Redis 客户端拿到这个地址，继续访问“缓存节点2”并且拿到数据。
</code></pre><p>（2）ASK请求：<br>        上面的例子说明了，数据 Slot 从“缓存节点1”已经迁移到“缓存节点2”了，那么客户端可以直接找“缓存节点2”要数据。那么如果两个缓存节点正在做节点的数据迁移，此时客户端请求会如何处理呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464287335-8c6ea7e5-e44a-4572-8e3b-68c635a6c031.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=332&amp;id=u69b85d6d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=478&amp;originWidth=817&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=123812&amp;status=done&amp;style=none&amp;taskId=uc5e5b594-542f-4c64-bd24-7cf6ebd670d&amp;title=&amp;width=568.2857666015625" alt="image.png"></p>
<pre><code>    Redis 客户端向“缓存节点1”发出请求，此时“缓存节点1”正向“缓存节点 2”迁移数据，如果没有命中对应的 Slot，它会返回客户端一个 ASK 重定向请求并且告诉“缓存节点2”的地址。客户端向“缓存节点2”发送 Asking 命令，询问需要的数据是否在“缓存节点2”上，“缓存节点2”接到消息以后返回数据是否存在的结果。
</code></pre><p>（3）频繁重定向造成的网络开销的处理：smart客户端</p>
<p>① 什么是 smart客户端：<br>        在大部分情况下，可能都会出现一次请求重定向才能找到正确的节点，这个重定向过程显然会增加集群的网络负担和单次请求耗时。所以大部分的客户端都是smart的。所谓 smart客户端，就是指客户端本地维护一份hashslot =&gt; node的映射表缓存，大部分情况下，直接走本地缓存就可以找到hashslot =&gt; node，不需要通过节点进行moved重定向，</p>
<p>② JedisCluster的工作原理：</p>
<ul>
<li>在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot =&gt; node映射表，同时为每个节点创建一个JedisPool连接池。</li>
<li>每次基于JedisCluster执行操作时，首先会在本地计算key的hashslot，然后在本地映射表找到对应的节点node。</li>
<li>如果那个node正好还是持有那个hashslot，那么就ok；如果进行了reshard操作，可能hashslot已经不在那个node上了，就会返回moved。</li>
<li>如果JedisCluter API发现对应的节点返回moved，那么利用该节点返回的元数据，更新本地的hashslot =&gt; node映射表缓存</li>
<li>重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException</li>
</ul>
<p>③ hashslot迁移和ask重定向：</p>
<pre><code>    如果hashslot正在迁移，那么会返回ask重定向给客户端。客户端接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hashslot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存。

    虽然ASK与MOVED都是对客户端的重定向控制，但是有本质区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道迁移什么时候完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，客户端需要更新slots缓存。
</code></pre><h4 id="④Redis集群中节点的通信机制：goosip协议"><a href="#④Redis集群中节点的通信机制：goosip协议" class="headerlink" title="④Redis集群中节点的通信机制：goosip协议"></a>④Redis集群中节点的通信机制：goosip协议</h4><pre><code>    redis集群的哈希槽算法解决的是数据的存取问题，不同的哈希槽位于不同的节点上，而不同的节点维护着一份它所认为的当前集群的状态，同时，Redis集群是去中心化的架构。那么，当集群的状态发生变化时，比如新节点加入、slot迁移、节点宕机、slave提升为新Master等等，我们希望这些变化尽快被其他节点发现，Redis是如何进行处理的呢？也就是说，Redis不同节点之间是如何进行通信进行维护集群的同步状态呢？

    在Redis集群中，不同的节点之间采用gossip协议进行通信，节点之间通讯的目的是为了维护节点之间的元数据信息。这些元数据就是每个节点包含哪些数据，是否出现故障，通过gossip协议，达到最终数据的一致性。
</code></pre><blockquote>
<p>gossip协议，是基于流行病传播方式的节点或者进程之间信息交换的协议。原理就是在不同的节点间不断地通信交换信息，一段时间后，所有的节点就都有了整个集群的完整信息，并且所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，但只要这些节可以通过网络连通，最终他们的状态就会是一致的。Gossip协议最大的好处在于，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。</p>
</blockquote>
<p>Redis集群中节点的通信过程如下：</p>
<blockquote>
<ul>
<li>集群中每个节点都会单独开一个TCP通道，用于节点间彼此通信。</li>
<li>每个节点在固定周期内通过待定的规则选择几个节点发送ping消息</li>
<li>接收到ping消息的节点用pong消息作为响应</li>
</ul>
</blockquote>
<pre><code>    使用gossip协议的优点在于将元数据的更新分散在不同的节点上面，降低了压力；但是缺点就是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。另外，由于 gossip 协议对服务器时间的要求较高，时间戳不准确会影响节点判断消息的有效性。而且节点数量增多后的网络开销也会对服务器产生压力，同时结点数太多，意味着达到最终一致性的时间也相对变长，因此官方推荐最大节点数为1000左右。
</code></pre><blockquote>
<p>redis cluster架构下的每个redis都要开放两个端口号，比如一个是6379，另一个就是加1w的端口号16379。</p>
<ul>
<li>6379端口号就是redis服务器入口。</li>
<li>16379端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用的是一种叫gossip 协议的二进制协议</li>
</ul>
</blockquote>
<p>1、gossip协议的常见类型：</p>
<p>gossip协议常见的消息类型包含： ping、pong、meet、fail等等。</p>
<p>（1）meet：主要用于通知新节点加入到集群中，通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。</p>
<p>（2）ping：用于交换节点的元数据。每个节点每秒会向集群中其他节点发送 ping 消息，消息中封装了自身节点状态还有其他部分节点的状态数据，也包括自身所管理的槽信息等等。</p>
<p>因为发送ping命令时要携带一些元数据，如果很频繁，可能会加重网络负担。因此，一般每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。<br>如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长导致信息严重滞后。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。<br>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 （总节点数 - 2）个其它节点的信息。<br>（3）pong：ping和meet消息的响应，同样包含了自身节点的状态和集群元数据信息。</p>
<p>（4）fail：某个节点判断另一个节点 fail 之后，向集群所有节点广播该节点挂掉的消息，其他节点收到消息后标记已下线。</p>
<p>由于Redis集群的去中心化以及gossip通信机制，Redis集群中的节点只能保证最终一致性。例如当加入新节点时(meet)，只有邀请节点和被邀请节点知道这件事，其余节点要等待 ping 消息一层一层扩散。除了 Fail 是立即全网通知的，其他诸如新节点、节点重上线、从节点选举成为主节点、槽变化等，都需要等待被通知到，也就是Gossip协议是最终一致性的协议。</p>
<p>2、meet命令的实现：</p>
<p>（1）节点A会为节点B创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。</p>
<p>（2）节点A根据CLUSTER MEET命令给定的IP地址和端口号，向节点B发送一条MEET消息。</p>
<p>（3）节点B接收到节点A发送的MEET消息，节点B会为节点A创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。</p>
<p>（4）节点B向节点A返回一条PONG消息。</p>
<p>（5）节点A将受到节点B返回的PONG消息，通过这条PONG消息，节点A可以知道节点B已经成功的接收了自己发送的MEET消息。</p>
<p>（6）之后，节点A将向节点B返回一条PING消息。</p>
<p>（7）节点B将接收到的节点A返回的PING消息，通过这条PING消息节点B可以知道节点A已经成功的接收到了自己返回的PONG消息，握手完成。</p>
<p>（8）之后，节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间后，节点B会被集群中的所有节点认识。</p>
<p>四、集群的扩容与收缩：<br>        作为分布式部署的缓存节点总会遇到缓存扩容和缓存故障的问题。这就会导致缓存节点的上线和下线的问题。由于每个节点中保存着槽数据，因此当缓存节点数出现变动时，这些槽数据会根据对应的虚拟槽算法被迁移到其他的缓存节点上。所以对于redis集群，集群伸缩主要在于槽和数据在节点之间移动。</p>
<p>1、扩容：</p>
<p>（1）启动新节点<br>（2）使用cluster meet命令将新节点加入到集群<br>（3）迁移槽和数据：添加新节点后，需要将一些槽和数据从旧节点迁移到新节点</p>
<pre><code>    如上图所示，集群中本来存在“缓存节点1”和“缓存节点2”，此时“缓存节点3”上线了并且加入到集群中。此时根据虚拟槽的算法，“缓存节点1”和“缓存节点2”中对应槽的数据会应该新节点的加入被迁移到“缓存节点3”上面。

    新节点加入到集群的时候，作为孤儿节点是没有和其他节点进行通讯的。因此需要在集群中任意节点执行 cluster meet 命令让新节点加入进来。假设新节点是 192.168.1.1 5002，老节点是 192.168.1.1 5003，那么运行以下命令将新节点加入到集群中。
</code></pre><p>192.168.1.1 5003&gt; cluster meet 192.168.1.1 5002</p>
<pre><code>    这个是由老节点发起的，有点老成员欢迎新成员加入的意思。新节点刚刚建立没有建立槽对应的数据，也就是说没有缓存任何数据。如果这个节点是主节点，需要对其进行槽数据的扩容；如果这个节点是从节点，就需要同步主节点上的数据。总之就是要同步数据。
</code></pre><p>如上图所示，由客户端发起节点之间的槽数据迁移，数据从源节点往目标节点迁移。</p>
<p>（1）客户端对目标节点发起准备导入槽数据的命令，让目标节点准备好导入槽数据。使用命令：cluster setslot {slot} importing {sourceNodeId}<br>（2）之后对源节点发起送命令，让源节点准备迁出对应的槽数据。使用命令：cluster setslot {slot} migrating {targetNodeId}<br>（3）此时源节点准备迁移数据了，在迁移之前把要迁移的数据获取出来。通过命令 cluster getkeysinslot {slot} {count}。Count 表示迁移的 Slot 的个数。<br>（4）然后在源节点上执行，migrate {targetIP} {targetPort} “” 0 {timeout} keys {keys} 命令，把获取的键通过流水线批量迁移到目标节点。<br>（5）重复 3 和 4 两步不断将数据迁移到目标节点。<br>（6）完成数据迁移到目标节点以后，通过 cluster setslot {slot} node {targetNodeId} 命令通知对应的槽被分配到目标节点，并且广播这个信息给全网的其他主节点，更新自身的槽节点对应表。<br>2、收缩：</p>
<p>迁移槽。<br>忘记节点。通过命令 cluster forget {downNodeId} 通知其他的节点</p>
<pre><code>    为了安全删除节点，Redis集群只能下线没有负责槽的节点。因此如果要下线有负责槽的master节点，则需要先将它负责的槽迁移到其他节点。迁移的过程也与上线操作类似，不同的是下线的时候需要通知全网的其他节点忘记自己，此时通过命令 cluster forget &#123;downNodeId&#125; 通知其他的节点。
</code></pre><p>五、集群的故障检测与故障转恢复机制：<br>1、集群的故障检测：</p>
<pre><code>    Redis集群的故障检测是基于gossip协议的，集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。
</code></pre><p>（1）主观下线（pfail）：当节点A检测到与节点B的通讯时间超过了cluster-node-timeout 的时候，就会更新本地节点状态，把节点B更新为主观下线。</p>
<p>主观下线并不能代表某个节点真的下线了，有可能是节点A与节点B之间的网络断开了，但是其他的节点依旧可以和节点B进行通讯。</p>
<p>（2）客观下线：</p>
<pre><code>    由于集群内的节点会不断地与其他节点进行通讯，下线信息也会通过 Gossip 消息传遍所有节点，因此集群内的节点会不断收到下线报告。

    当半数以上的主节点标记了节点B是主观下线时，便会触发客观下线的流程（该流程只针对主节点，如果是从节点就会忽略）。将主观下线的报告保存到本地的 ClusterNode 的结构fail_reports链表中，并且对主观下线报告的时效性进行检查，如果超过 cluster-node-timeout*2 的时间，就忽略这个报告，否则就记录报告内容，将其标记为客观下线。

    接着向集群广播一条主节点B的Fail 消息，所有收到消息的节点都会标记节点B为客观下线。
</code></pre><p>2、集群地故障恢复：</p>
<pre><code>    当故障节点下线后，如果是持有槽的主节点则需要在其从节点中找出一个替换它，从而保证高可用。此时下线主节点的所有从节点都担负着恢复义务，这些从节点会定时监测主节点是否进入客观下线状态，如果是，则触发故障恢复流程。故障恢复也就是选举一个节点充当新的master，选举的过程是基于Raft协议选举方式来实现的。
</code></pre><p>2.1、从节点过滤：</p>
<pre><code>    检查每个slave节点与master节点断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master
</code></pre><p>2.2、投票选举：</p>
<p>（1）节点排序：</p>
<pre><code>    对通过过滤条件的所有从节点进行排序，按照priority、offset、run id排序，排序越靠前的节点，越优先进行选举。
</code></pre><p>priority的值越低，优先级越高<br>offset越大，表示从master节点复制的数据越多，选举时间越靠前，优先进行选举<br>如果offset相同，run id越小，优先级越高<br>（2）更新配置纪元：</p>
<pre><code>    每个主节点会去更新配置纪元（clusterNode.configEpoch），这个值是不断增加的整数。这个值记录了每个节点的版本和整个集群的版本。每当发生重要事情的时候（例如：出现新节点，从节点精选）都会增加全局的配置纪元并且赋给相关的主节点，用来记录这个事件。更新这个值目的是，保证所有主节点对这件“大事”保持一致，大家都统一成一个配置纪元，表示大家都知道这个“大事”了。
</code></pre><p>（3）发起选举：</p>
<pre><code>    更新完配置纪元以后，从节点会向集群发起广播选举的消息（CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST），要求所有收到这条消息，并且具有投票权的主节点进行投票。每个从节点在一个纪元中只能发起一次选举。
</code></pre><p>（4）选举投票：</p>
<pre><code>    如果一个主节点具有投票权，并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点。每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。

    如果超过(N/2 + 1)数量的master节点都投票给了某个从节点，那么选举通过，这个从节点可以切换成master，如果在 cluster-node-timeout*2 的时间内从节点没有获得足够数量的票数，本次选举作废，更新配置纪元，并进行第二轮选举，直到选出新的主节点为止。
</code></pre><p>在第(1)步排序领先的从节点通常会获得更多的票，因为它触发选举的时间更早一些，获得票的机会更大</p>
<p>2.3、替换主节点：</p>
<pre><code>    当满足投票条件的从节点被选出来以后，会触发替换主节点的操作。删除原主节点负责的槽数据，把这些槽数据添加到自己节点上，并且广播让其他的节点都知道这件事情，新的主节点诞生了。
</code></pre><p>（1）被选中的从节点执行SLAVEOF NO ONE命令，使其成为新的主节点</p>
<p>（2）新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己</p>
<p>（3）新的主节点对集群进行广播PONG消息，告知其他节点已经成为新的主节点</p>
<p>（4）新的主节点开始接收和处理槽相关的请求</p>
<p>备注：如果集群中某个节点的master和slave节点都宕机了，那么集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。</p>
<p>六、Redis集群的搭建：<br>该部分可以参考这篇文章：<a target="_blank" rel="noopener" href="https://juejin.cn/post/6922690589347545102#heading-1">https://juejin.cn/post/6922690589347545102#heading-1</a></p>
<p>Redis集群的搭建可以分为以下几个部分：</p>
<p>1、启动节点：将节点以集群模式启动，读取或者生成集群配置文件，此时节点是独立的。</p>
<p>2、节点握手：节点通过gossip协议通信，将独立的节点连成网络，主要使用meet命令。</p>
<p>3、槽指派：将16384个槽位分配给主节点，以达到分片保存数据库键值对的效果。</p>
<p>七、Redis集群的运维：<br>1、数据迁移问题：</p>
<p>Redis集群可以进行节点的动态扩容缩容，这一过程目前还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。而 Redis为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦Key的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。</p>
<p>2、带宽消耗问题：</p>
<p>Redis集群是无中心节点的集群架构，依靠Gossip协议协同自动化修复集群的状态，但goosip有消息延时和消息冗余的问题，在集群节点数量过多的时候，goosip协议通信会消耗大量的带宽，主要体现在以下几个方面：</p>
<p>消息发送频率：跟cluster-node-timeout密切相关，当节点发现与其他节点的最后通信时间超过 cluster-node-timeout/2时会直接发送ping消息<br>消息数据量：每个消息主要的数据占用包含：slots槽数组（2kb）和整个集群1/10的状态数据<br>节点部署的机器规模：机器的带宽上限是固定的，因此相同规模的集群分布的机器越多，每台机器划分的节点越均匀，则整个集群内整体的可用带宽越高<br>集群带宽消耗主要分为：读写命令消耗+Gossip消息消耗，因此搭建Redis集群需要根据业务数据规模和消息通信成本做出合理规划：</p>
<p>在满足业务需求的情况下尽量避免大集群，同一个系统可以针对不同业务场景拆分使用若干个集群。<br>适度提供cluster-node-timeout降低消息发送频率，但是cluster-node-timeout还影响故障转移的速度，因此需要根据自身业务场景兼顾二者平衡<br>如果条件允许尽量均匀部署在更多机器上，避免集中部署。如果有60个节点的集群部署在3台机器上每台20个节点，这是机器的带宽消耗将非常严重<br>3、Pub/Sub广播问题：</p>
<p>集群模式下内部对所有publish命令都会向所有节点进行广播，加重带宽负担，所以集群应该避免频繁使用Pub/sub功能</p>
<p>4、集群倾斜：</p>
<p>集群倾斜是指不同节点之间数据量和请求量出现明显差异，这种情况将加大负载均衡和开发运维的难度。因此需要理解集群倾斜的原因</p>
<p>（1）数据倾斜：</p>
<p>节点和槽分配不均<br>不同槽对应键数量差异过大<br>集合对象包含大量元素<br>内存相关配置不一致<br>（2）请求倾斜：</p>
<p>合理设计键，热点大集合对象做拆分或者使用hmget代替hgetall避免整体读取</p>
<p>5、集群读写分离：</p>
<p>集群模式下读写分离成本比较高，直接扩展主节点数量来提高集群性能是更好的选择。<br>————————————————<br>版权声明：本文为CSDN博主「张维鹏」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/a745233700/article/details/112691126">https://blog.csdn.net/a745233700/article/details/112691126</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://fetterslove.github.io">FettersLove</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://fetterslove.github.io/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/">http://fetterslove.github.io/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://fetterslove.github.io" target="_blank">FettersLoveの博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/QQ%E5%9B%BE%E7%89%8720221110180115.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">FettersLove</div><div class="author-info__description">从来没憎恨过谁，只是想成为最强的</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/FettersLove"><i></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/fetterslove-blog" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:fetterslove2y@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis%E7%9A%84%E4%B8%89%E7%A7%8D%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%9E%8B"><span class="toc-text">redis的三种集群模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%85%A0%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-text">Ⅰ主从复制是怎么实现的？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1%E5%91%BD%E4%BB%A4%E4%BC%A0%E6%92%AD"><span class="toc-text">②命令传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A2%E5%88%86%E6%91%8A%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%8E%8B%E5%8A%9B"><span class="toc-text">③分摊主服务器的压力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A3%E5%A2%9E%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="toc-text">④增量复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E2%98%85%EF%BC%88%E8%AE%B0%E7%86%9F%E6%82%89%EF%BC%89"><span class="toc-text">总结★（记熟悉）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E4%BA%A7%E7%94%9F%E8%84%91%E8%A3%82%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1"><span class="toc-text">集群产生脑裂数据丢失</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-text">面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#redis%E4%B8%BB%E4%BB%8E%E8%8A%82%E7%82%B9%E6%97%B6%E9%95%BF%E8%BF%9E%E6%8E%A5%E8%BF%98%E6%98%AF%E7%9F%AD%E9%93%BE%E6%8E%A5%EF%BC%9F"><span class="toc-text">redis主从节点时长连接还是短链接？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%88%A4%E6%96%AD-redis-%E6%9F%90%E4%B8%AA%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8%E5%B7%A5%E4%BD%9C%EF%BC%9F"><span class="toc-text">怎么判断 redis 某个节点是否正常工作？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%E4%B8%AD%EF%BC%8C%E8%BF%87%E6%9C%9Fkey%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-text">主从复制架构中，过期key如何处理？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#redis-%E6%98%AF%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6%E8%BF%98%E6%98%AF%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6%EF%BC%9F"><span class="toc-text">redis 是同步复制还是异步复制？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%AD%E4%B8%A4%E4%B8%AA-Buffer-replication-buffer-%E3%80%81repl-backlog-buffer-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-text">主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#redis-%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-text">redis 主从切换如何减少数据丢失？</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6%E5%90%8C%E6%AD%A5%E4%B8%A2%E5%A4%B1"><span class="toc-text">异步复制同步丢失</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#redis-%E4%B8%BB%E4%BB%8E%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E6%95%85%E9%9A%9C%E8%87%AA%E5%8A%A8%E5%88%87%E6%8D%A2%EF%BC%9F"><span class="toc-text">redis 主从如何做到故障自动切换？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%85%A1%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E5%93%A8%E5%85%B5%EF%BC%9F"><span class="toc-text">Ⅱ为什么要有哨兵？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%EF%BC%9F"><span class="toc-text">①为什么要有哨兵机制？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="toc-text">②哨兵机制是如何工作的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A2%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%BB%E8%8A%82%E7%82%B9%E7%9C%9F%E7%9A%84%E6%95%85%E9%9A%9C%E4%BA%86%EF%BC%9F"><span class="toc-text">③如何判断主节点真的故障了？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A3%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%EF%BC%9F"><span class="toc-text">④由哪个哨兵进行主从故障转移？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A4%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-text">⑤主从故障转移的过程是怎样的？</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%BD%AE%E8%80%83%E5%AF%9F%EF%BC%9A%E4%BC%98%E5%85%88%E7%BA%A7%E6%9C%80%E9%AB%98%E7%9A%84%E4%BB%8E%E8%8A%82%E7%82%B9%E8%83%9C%E5%87%BA"><span class="toc-text">第一轮考察：优先级最高的从节点胜出</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%BD%AE%E8%80%83%E5%AF%9F%EF%BC%9A%E5%A4%8D%E5%88%B6%E8%BF%9B%E5%BA%A6%E6%9C%80%E9%9D%A0%E5%89%8D%E7%9A%84%E4%BB%8E%E8%8A%82%E7%82%B9%E8%83%9C%E5%87%BA"><span class="toc-text">第二轮考察：复制进度最靠前的从节点胜出</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E8%BD%AE%E8%80%83%E5%AF%9F%EF%BC%9AID-%E5%8F%B7%E5%B0%8F%E7%9A%84%E4%BB%8E%E8%8A%82%E7%82%B9%E8%83%9C%E5%87%BA"><span class="toc-text">第三轮考察：ID 号小的从节点胜出</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%B0%86%E4%BB%8E%E8%8A%82%E7%82%B9%E6%8C%87%E5%90%91%E6%96%B0%E4%B8%BB%E8%8A%82%E7%82%B9"><span class="toc-text">步骤二：将从节点指向新主节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E9%80%9A%E7%9F%A5%E5%AE%A2%E6%88%B7%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9%E5%B7%B2%E6%9B%B4%E6%8D%A2"><span class="toc-text">步骤三：通知客户的主节点已更换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E5%B0%86%E6%97%A7%E4%B8%BB%E8%8A%82%E7%82%B9%E5%8F%98%E4%B8%BA%E4%BB%8E%E8%8A%82%E7%82%B9"><span class="toc-text">步骤四：将旧主节点变为从节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%84%E6%88%90%E7%9A%84%EF%BC%9F"><span class="toc-text">哨兵集群是如何组成的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%85%A2%E9%9B%86%E7%BE%A4"><span class="toc-text">Ⅲ集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0Redis%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%EF%BC%9A"><span class="toc-text">①Redis集群介绍：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1Redis%E9%9B%86%E7%BE%A4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%AE%97%E6%B3%95%EF%BC%9A%E5%93%88%E5%B8%8C%E6%A7%BD%E7%AE%97%E6%B3%95"><span class="toc-text">②Redis集群的数据分布算法：哈希槽算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A2%E9%9B%86%E7%BE%A4%E7%9A%84%E8%AF%B7%E6%B1%82%E9%87%8D%E5%AE%9A%E5%90%91%EF%BC%9A"><span class="toc-text">③集群的请求重定向：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A3Redis%E9%9B%86%E7%BE%A4%E4%B8%AD%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%EF%BC%9Agoosip%E5%8D%8F%E8%AE%AE"><span class="toc-text">④Redis集群中节点的通信机制：goosip协议</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/09/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%AF%87/" title="存储引擎篇"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="存储引擎篇"/></a><div class="content"><a class="title" href="/2022/08/09/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%AF%87/" title="存储引擎篇">存储引擎篇</a><time datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/09/cover/cover/" title="翻唱"><img src="/1" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="翻唱"/></a><div class="content"><a class="title" href="/2022/08/09/cover/cover/" title="翻唱">翻唱</a><time datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/09/java/Java%E5%9F%BA%E7%A1%80/" title="Java基础"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180059.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java基础"/></a><div class="content"><a class="title" href="/2022/08/09/java/Java%E5%9F%BA%E7%A1%80/" title="Java基础">Java基础</a><time datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/09/redis/%E5%9F%BA%E7%A1%80%E7%AF%87/" title="基础篇"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基础篇"/></a><div class="content"><a class="title" href="/2022/08/09/redis/%E5%9F%BA%E7%A1%80%E7%AF%87/" title="基础篇">基础篇</a><time datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/09/redis/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/" title="线程模型篇"><img src="https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="线程模型篇"/></a><div class="content"><a class="title" href="/2022/08/09/redis/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/" title="线程模型篇">线程模型篇</a><time datetime="2022-08-08T16:00:00.000Z" title="发表于 2022-08-09 00:00:00">2022-08-09</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/cover/QQ%E5%9B%BE%E7%89%8720221113180052.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 By FettersLove</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="1976848374" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-lrctype="1" data-preload="none" data-autoplay="false" muted></div><script defer src="/js/light.js"></script><script async src="//at.alicdn.com/t/c/xxx.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://fetterslove.github.io/categories/java/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 java (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://fetterslove.github.io/categories/MySQL/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 MySQL (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://fetterslove.github.io/categories/redis/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 redis (8)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://fetterslove.github.io/categories/计算机网络/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 计算机网络 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://fetterslove.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 190px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 160px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://edu-fly.oss-cn-beijing.aliyuncs.com/QQ%E5%9B%BE%E7%89%8720221110175517.jpg);"> <a class="categoryBar-list-link" href="categories/MySQL/">MySQL</a><span class="categoryBar-list-count">6</span><span class="categoryBar-list-descr">java</span></li><li class="categoryBar-list-item" style="background:url(https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/categories/QQ%E5%9B%BE%E7%89%8720221113223040.jpg);"> <a class="categoryBar-list-link" href="categories/java/">java</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">MySQL</span></li><li class="categoryBar-list-item" style="background:url(https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/categories/QQ%E5%9B%BE%E7%89%8720221113223046.jpg);"> <a class="categoryBar-list-link" href="categories/redis/">redis</a><span class="categoryBar-list-count">8</span><span class="categoryBar-list-descr">计算机网络</span></li><li class="categoryBar-list-item" style="background:url(https://edu-fly.oss-cn-beijing.aliyuncs.com/hexo-blog/categories/QQ%E5%9B%BE%E7%89%8720221113223049.jpg);"> <a class="categoryBar-list-link" href="categories/计算机网络/">计算机网络</a><span class="categoryBar-list-count">3</span><span class="categoryBar-list-descr">redis</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>