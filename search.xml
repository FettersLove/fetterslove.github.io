<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Java基础</title>
      <link href="/2022/08/09/java/Java%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/08/09/java/Java%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="1-IO流分为什么"><a href="#1-IO流分为什么" class="headerlink" title="1.IO流分为什么"></a>1.IO流分为什么</h1><p>IO流的分类可以分为以下三种：<br><strong>第一种：输入流和输出流</strong><br>按照流的流向来分，可以分为输入流和输出流。输入，输出都是从程序运行所在内存的角度来划分的。<br>输入流：只能从中读取数据，而不能向其写入数据，由InputStream和Reader作为基类。<br>输出流：只能向其写入数据，而不能从中读取数据。由OutputStream和Writer作为基类<br><strong>第二种：字节流和字符流</strong><br>字节流和字符流的用法几乎完全一样，区别在于字节流和字符流所操作的数据单元不同。<br>字节流操作的数据单元是8位字节，由InputStream和OutputStream作为基类。<br>字符流操作的数据单元是16为的字符，由Reader和Writer作为基类<br><strong>第三种：节点流和处理流</strong><br>按照流的角色来分，可以分为节点流和处理流。<br>节点流：可以从向一个特定的IO设备（如磁盘、网络）读/写数据的流。也被称为低级流。<br>处理流：用于对一个已存在的流进行连接或封装，通过封装后的流来实现数据读/写功能。也称为高级流</p><p>1、字节流 ：字节读写，  字节流(ASCII)处理二进制文件。<br>       可以传输音频，视频，图片，文本等，传输数据的基本单位为字节。<br>         InputStream OutputStream<br>2、字符流：快读写 ，字符流(Unicode)处理文本文件。<br>     只能传输纯文本， 传输数据的基本单位为字符 。<br>      FileWriter FileReader 一个字符等于2个字节</p><h1 id="2-抽象类和接口区别"><a href="#2-抽象类和接口区别" class="headerlink" title="2.抽象类和接口区别"></a>2.抽象类和接口区别</h1><p>先去看OneNote看抽象类和接口的知识点</p><ul><li>构造器不同：<ul><li>抽象类可以有构造方法，接口中不能有构造方法。</li></ul></li><li>属性区别：   普通成员变量—静态成员变量<ul><li>抽象类中可以有普通成员变量，接口中没有普通成员变量，抽象类和接口中都可以包含静态成员变量。</li><li>抽象类中的静态成员变量的访问类型可以任意，但接口中定义的变量只能是 public static final 类型，并且默认即为 public static final 类型。</li></ul></li><li>方法区别：    普通方法—访问类型—静态方法<ul><li>抽象类中可以包含非抽象的普通方法，接口中的所有方法必须都是抽象的，不能有非抽象的普通方法。</li><li>抽象类中的抽象方法的访问类型可以是 public，protected和（默认类型），但接口中的抽象方法只能是 public 类型的，并且默认即为 public abstract 类型。</li><li>抽象类中可以包含静态方法，接口中不能包含静态方法（JAVA8的新特性：接口可以有静态方法和默认方法）</li></ul></li><li><p>一个类可以实现多个接口，但只能继承一个抽象类。</p><h1 id="3-接口和抽象类的异同及适用场景"><a href="#3-接口和抽象类的异同及适用场景" class="headerlink" title="3. 接口和抽象类的异同及适用场景"></a>3. 接口和抽象类的异同及适用场景</h1><p><strong>不同点</strong></p></li><li><p>语法上的不同，对接口的使用是通过关键字implements，定义是使用关键字interface；对抽象类的使用是通过关键字extends（当然接口也可以通过关键字extends继承），定义是使用关键字abstract class。</p></li><li>接口只有常量和方法，抽象类则包含普通类中的一切结构。</li><li>接口中的方法都必须是public类型的，而抽象类则不受限制。</li><li>一个类可以同时实现多个接口，但一个类只能继承一个抽象类。</li><li>抽象类中可以定义普通的带有方法体的方法，而接口不行</li></ul><p><strong>相同点</strong></p><ul><li>接口中的方法和抽象类中的抽象方法都不能有方法体，并且在其子类中都必须被实现</li><li>都可以被继承但不能被实例化</li></ul><p><strong>适用场景</strong><br>如果要创建一个模型，这个模型将由一些紧密相关的对象采用，就可以使用抽象类。如果要创建将由一些不相关对象采用的功能，就使用接口。<br>如果必须从多个来源继承行为，就使用接口。<br>如果知道所有类都会共享一个公共的行为实现，就使用抽象类，并在其中实现该行为。</p><h1 id="4-谈谈面向对象的理解"><a href="#4-谈谈面向对象的理解" class="headerlink" title="4.谈谈面向对象的理解"></a>4.谈谈面向对象的理解</h1><p><strong>面向过程</strong>：一件事该怎么做，注重实现过程，以过程为中心<br><strong>面向对象</strong>：实现对象是谁，只关心怎样使用，不关心具体实现（有封装、继承、多态三 大特性） </p><p><strong>封装</strong>：将一类属性和行为抽象成一个类，使其属性私有化，行为公开化，提高属性的安全性的同 时，也可以使代码模块化，这样做使代码的复用性更高。可以不用关心内部实现,具体构造,只需知道怎么操作它就是，比如电视，手机，将内部封装起来，直接使用<br><strong>继承</strong>：将几个类共有的属性和行为抽象成一个父 类，每个子类都有父类的属性和行为，也有自己的属性和行为，这样做，扩展了已存在的代码，进一步提高了代码的复用性，但是继承是耦合度很高的一种关系，父类代码修改，子类行为也会改变，如果过度使用继承会起到反效果。比如有学生教师，他们都有一些公用方法与属性，可以将其抽取出来定义为父类， 再去继承它，复用代码，减少冗余，易于扩展<br><strong>多态</strong>： 同一个方法调用，由于对象不同可能会有不同的行为。比如都是休息，张三是睡觉，李四是爬山等；或则具体场景中，我不知道现在具体传进来的对象是student,还是teacher，那么可以用pepole去接收它。 多态的存在要有3个必要条件：继承，方法重写，父类引用指向子类对象。父类引用指向子类对象后，用该父 类引用调用子类重写的方法，此时多态就出现了 </p><p>面向对象是一种编程思想，早期的面向过程的思想就是一件事该怎么做，而面向对象就是一件事该由谁来做， 它怎么做的我不管，我只需要调用就行。</p><p><strong>深入理解：</strong><br>比如项目中的redis模块中的驱逐策略，因为有fifo策略，lru策略，lfu策略，他们都有一个驱除方法，所以就可以实现一个父类，将驱逐策略抽象为一个类并定义一个驱逐方法，子类去继承他，重写该方法。</p><p>多态的底层实现是动态绑定，即在运行时才把方法调用与方法实现关联起来。也就是分派<br>分派有两种：一种是在编译期确定，被称为静态分派，比如方法的重载；一种是在运行时确定，被称为动态分派，比如方法的覆盖。对象方法基本上都是虚方法。</p><blockquote><p>这里需要特别说明的是，final 方法由于不能被覆盖，可以唯一确定，因此 Java 语言规范规定 final 方法属于非虚方法，但仍然使用 invokevirtual 指令调用。静态绑定、动态绑定的概念和虚方法、非虚方法的概念是两个不同的概念。</p></blockquote><p>它是通过invokevirtual方法调用指令直线的</p><blockquote><p>静态绑定与动态绑定<br>JVM 的方法调用指令有五个，分别是：<br>invokestatic：调用静态方法；<br>invokespecial：调用实例构造器<br>方法、私有方法和父类方法；<br>invokevirtual：调用虚方法；<br>invokeinterface：调用接口方法，运行时确定具体实现；<br>invokedynamic：运行时动态解析所引用的方法，然后再执行，用于支持动态类型语言。<br>其中，invokestatic 和 invokespecial 用于静态绑定，invokevirtual 和 invokeinterface 用于动态绑定。可以看出，动态绑定主要应用于虚方法和接口方法。<br>静态绑定在编译期就已经确定，这是因为静态方法、构造器方法、私有方法和父类方法可以唯一确定。这些方法的符号引用在类加载的解析阶段就会解析成直接引用。因此这些方法也被称为非虚方法，与之相对的便是虚方法。</p></blockquote><p><strong>多态的实现</strong></p><blockquote><p>虚拟机栈中会存放当前方法调用的栈帧，在栈帧中，存储着局部变量表、操作栈、动态连接 、返回地址和其他附加信息。</p></blockquote><p>多态的实现过程，就是方法调用动态分派的过程，通过栈帧的信息去找到被调用方法的具体实现，然后使用这个具体实现的直接引用完成方法调用。<br>以 invokevirtual 指令为例，在执行时，大致可以分为以下几步：<br>1、先从操作栈中找到对象的实际类型 class；<br>2、找到 class 中与被调用方法签名相同的方法，如果有访问权限就返回这个方法的直接引用，如果没有访问权限就报错 java.lang.IllegalAccessError ；<br>3、如果第 2 步找不到相符的方法，就去搜索 class 的父类，按照继承关系自下而上依次执行第 2 步的操作；<br>4、如果第 3 步找不到相符的方法，就报错 java.lang.AbstractMethodError ；<br>可以看到，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。</p><blockquote><p>实际上，商用虚拟机为了保证性能，通常会使用虚方法表和接口方法表，而不是每次都执行一遍上面的步骤。以虚方法表为例，虚方法表在类加载的解析阶段填充完成，其中存储了所有方法的直接引用。也就是说，动态分派在填充虚方法表的时候就已经完成了。<br>在子类的虚方法表中，如果子类覆盖了父类的某个方法，则这个方法的直接引用指向子类的实现；而子类没有覆盖的那些方法，比如 Object 的方法，直接引用指向父类或 Object 的实现。</p></blockquote><h1 id="equals区别"><a href="#equals区别" class="headerlink" title="== equals区别"></a>== equals区别</h1><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649814332085-82aa1b59-2e77-474a-b5e9-23a6f8268ab1.png#clientId=ud356de06-7455-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=82&amp;id=u698b8acf&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=103&amp;originWidth=986&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=20345&amp;status=done&amp;style=none&amp;taskId=u79b0e729-2cd1-45e1-9e9d-767cbe01782&amp;title=&amp;width=788.8" alt="image.png"></p><h1 id="重写equals为什么要重写hashcode（）"><a href="#重写equals为什么要重写hashcode（）" class="headerlink" title="重写equals为什么要重写hashcode（）"></a>重写equals为什么要重写hashcode（）</h1><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649814495576-23cc205b-6111-4ee4-8aa2-8cc328a44e4f.png#clientId=ud356de06-7455-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=172&amp;id=u8df975bb&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=215&amp;originWidth=992&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=52603&amp;status=done&amp;style=none&amp;taskId=uece3d6d2-27c8-442c-a8a8-e1e48c70e60&amp;title=&amp;width=793.6" alt="image.png"></p><h1 id="String、StringBuilder、StringBuffer有什么区别？"><a href="#String、StringBuilder、StringBuffer有什么区别？" class="headerlink" title="String、StringBuilder、StringBuffer有什么区别？"></a>String、StringBuilder、StringBuffer有什么区别？</h1><p>三者共同之处:都是final类,不允许被继承，主要是从性能和安全性上考虑的，因为这几个类都是经常被使用着，且考虑到防止其中的参数被参数修改影响到其他的应用。<br>StringBuffer是线程安全，可以不需要额外的同步用于多线程中;<br>StringBuilder是非同步,运行于多线程中就需要使用着单独同步处理，但是速度就比StringBuffer快多了;<br>StringBuffer与StringBuilder两者共同之处:可以通过append、indert进行字符串的操作。</p><h2 id="这三个类之间的区别主要是在两个方面，即运行速度和线程安全这两方面。"><a href="#这三个类之间的区别主要是在两个方面，即运行速度和线程安全这两方面。" class="headerlink" title="这三个类之间的区别主要是在两个方面，即运行速度和线程安全这两方面。"></a>这三个类之间的区别主要是在两个方面，即运行速度和线程安全这两方面。</h2><h3 id="1、首先说运行速度，或者说是执行速度，在这方面运行速度快慢为：StringBuilder-gt-StringBuffer-gt-String"><a href="#1、首先说运行速度，或者说是执行速度，在这方面运行速度快慢为：StringBuilder-gt-StringBuffer-gt-String" class="headerlink" title="1、首先说运行速度，或者说是执行速度，在这方面运行速度快慢为：StringBuilder &gt; StringBuffer &gt; String"></a>1、首先说运行速度，或者说是执行速度，在这方面运行速度快慢为：StringBuilder &gt; StringBuffer &gt; String</h3><p><strong>String最慢的原因：</strong>String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的。<strong>以下面一段代码为例：</strong><br>1 String str=”abc”; 2 System.out.println(str); 3 str=str+”de”; 4 System.out.println(str);<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648951391262-57fcbf3f-d73f-4ec1-8e52-5fb2da8a3654.png#clientId=u566f4794-187d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub324570c&amp;margin=%5Bobject%20Object%5D&amp;originHeight=340&amp;originWidth=995&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u6e1b970c-5d1c-4404-afd5-35adf878c10&amp;title=" alt=""><br>运行这段代码会发现先输出“abc”，然后又输出“abcde”，好像是str这个对象被更改了，其实，这只是一种假象罢了，JVM对于这几行代码是这样处理的，首先创建一个String对象str，并把“abc”赋值给str，然后在第三行中，其实JVM又创建了一个新的对象也名为str，然后再把原来的str的值和“de”加起来再赋值给新的str，而原来的str就会被JVM的垃圾回收机制（GC）给回收掉了，所以，str实际上并没有被更改，也就是前面说的String对象一旦创建之后就不可更改了。所以，Java中对String对象进行的操作实际上是一个不断创建新的对象并且将旧的对象回收的一个过程，所以执行速度很慢。<br>而StringBuilder和StringBuffer的对象是变量，对变量进行操作就是直接对该对象进行更改，而不进行创建和回收的操作，所以速度要比String快很多。<br>另外，有时候我们会这样对字符串进行赋值<br>1 String str=”abc”+”de”; 2 StringBuilder stringBuilder=new StringBuilder().append(“abc”).append(“de”); 3 System.out.println(str); 4 System.out.println(stringBuilder.toString());<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648951391238-8206b46d-376f-49d5-9f22-6207c77c072c.png#clientId=u566f4794-187d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ubdcfb168&amp;margin=%5Bobject%20Object%5D&amp;originHeight=306&amp;originWidth=1099&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ud72b21f4-3cd9-4ab0-8876-168d4df40a2&amp;title=" alt=""><br>这样输出结果也是“abcde”和“abcde”，但是String的速度却比StringBuilder的反应速度要快很多，这是因为第1行中的操作和String str=”abcde”;是完全一样的，所以会很快，而如果写成下面这种形式<br>1 String str1=”abc”; 2 String str2=”de”; 3 String str=str1+str2;</p><h3 id="2-再来说线程安全"><a href="#2-再来说线程安全" class="headerlink" title="2. 再来说线程安全"></a>2. 再来说线程安全</h3><p><strong>在线程安全上，StringBuilder是线程不安全的，而StringBuffer是线程安全的</strong><br>如果一个StringBuffer对象在字符串缓冲区被多个线程使用时，StringBuffer中很多方法可以带有synchronized关键字，所以可以保证线程是安全的，但StringBuilder的方法则没有该关键字，所以不能保证线程安全，有可能会出现一些错误的操作。所以如果要进行的操作是多线程的，那么就要使用StringBuffer，但是在单线程的情况下，还是建议使用速度比较快的StringBuilder。<br>（一个线程访问一个对象中的<a href="https://www.cnblogs.com/weibanggang/p/9470718.html">synchronized</a>(this)同步代码块时，其他试图访问该对象的线程将被阻塞）</p><h3 id="3-总结一下"><a href="#3-总结一下" class="headerlink" title="3. 总结一下"></a>3. 总结一下</h3><p><strong>String：适用于少量的字符串操作的情况</strong><br><strong>StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况</strong><br><strong>StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况</strong></p><h2 id="静态代理和动态代理的区别"><a href="#静态代理和动态代理的区别" class="headerlink" title="静态代理和动态代理的区别"></a>静态代理和动态代理的区别</h2><h1 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h1>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>存储引擎篇</title>
      <link href="/2022/08/09/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h1 id="常见的存储引擎有哪些？"><a href="#常见的存储引擎有哪些？" class="headerlink" title="常见的存储引擎有哪些？"></a>常见的存储引擎有哪些？</h1><p>MySQL中常用的四种存储引擎分别是： <strong>MyISAM</strong>、<strong>InnoDB</strong>、<strong>MEMORY</strong>、<strong>ARCHIVE</strong>。MySQL 5.5版本后默认的存储引擎为InnoDB。</p><h2 id="InnoDB存储引擎"><a href="#InnoDB存储引擎" class="headerlink" title="InnoDB存储引擎"></a>InnoDB存储引擎</h2><p>InnoDB是MySQL<strong>默认的事务型存储引擎</strong>，使用最广泛，基于聚簇索引建立的。InnoDB内部做了很多优化，如能够自动在内存中创建自适应hash索引，以加速读操作。<br><strong>优点</strong>：支持事务和崩溃修复能力；引入了行级锁和外键约束。<br><strong>缺点</strong>：占用的数据空间相对较大。<br><strong>适用场景</strong>：需要事务支持，并且有较高的并发读写频率。</p><h2 id="MyISAM存储引擎"><a href="#MyISAM存储引擎" class="headerlink" title="MyISAM存储引擎"></a>MyISAM存储引擎</h2><p>数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，可以使用MyISAM引擎。MyISAM会将表存储在两个文件中，数据文件.MYD和索引文件.MYI。<br><strong>优点</strong>：访问速度快。<br><strong>缺点</strong>：MyISAM不支持事务和行级锁，不支持崩溃后的安全恢复，也不支持外键。<br><strong>适用场景</strong>：对事务完整性没有要求；表的数据都会只读的。<br><strong>MEMORY存储引擎</strong><br>MEMORY引擎将数据全部放在内存中，访问速度较快，但是一旦系统奔溃的话，数据都会丢失。<br>MEMORY引擎默认使用哈希索引，将键的哈希值和指向数据行的指针保存在哈希索引中。<br><strong>优点</strong>：访问速度较快。<br><strong>缺点</strong>：</p><ol><li>哈希索引数据不是按照索引值顺序存储，无法用于<a href="/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>。 </li><li>不支持部分索引匹配查找，因为哈希索引是使用索引列的全部内容来计算哈希值的。 </li><li>只支持等值比较，不支持范围查询。 </li><li>当出现哈希冲突时，存储引擎需要遍历<a href="/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8">链表</a>中所有的行指针，逐行进行比较，直到找到符合条件的行。 </li></ol><p><strong>ARCHIVE存储引擎</strong><br>ARCHIVE存储引擎非常适合存储大量独立的、作为历史记录的数据。ARCHIVE提供了压缩功能，拥有高效的插入速度，但是这种引擎不支持索引，所以查询性能较差。</p><h3 id="MyISAM和InnoDB的区别？"><a href="#MyISAM和InnoDB的区别？" class="headerlink" title="MyISAM和InnoDB的区别？"></a>MyISAM和InnoDB的区别？</h3><ol><li><strong>是否支持行级锁</strong> : MyISAM 只有表级锁，而InnoDB 支持行级锁和表级锁，默认为行级锁。</li><li><strong>是否支持事务和崩溃后的安全恢复</strong>： MyISAM 不提供事务支持。而InnoDB提供事务支持，具有事务、回滚和崩溃修复能力。</li><li><strong>是否支持外键：</strong>MyISAM不支持，而InnoDB支持。</li><li><strong>是否支持MVCC</strong> ：MyISAM不支持，InnoDB支持。应对高并发事务，MVCC比单纯的加锁更高效。</li><li>MyISAM不支持聚集索引，InnoDB支持聚集索引。</li></ol>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基础篇</title>
      <link href="/2022/08/09/redis/%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2022/08/09/redis/%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="①简单介绍一下-Redis-呗"><a href="#①简单介绍一下-Redis-呗" class="headerlink" title="①简单介绍一下 Redis 呗!"></a>①简单介绍一下 Redis 呗!</h3><ul><li>Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。</li><li>Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题。</li><li>除此之外，Redis 还支持<strong>事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制</strong>等等。<h3 id="②redis优缺点"><a href="#②redis优缺点" class="headerlink" title="②redis优缺点"></a>②redis优缺点</h3>优点：</li></ul><ol><li>数据存储在内存， 读写速度快，性能优异</li><li>支持数据持久化，便于数据备份、恢复</li><li>支持简单的事务，操作满足原子性</li><li>支持String、List、Hash、Set、Zset五种数据类型，满足多场景需求</li><li>支持主从复制，实现读写分离，分担读的压力</li><li>支持哨兵机制，实现自动故障转移</li></ol><p>缺点：</p><ol><li>数据存储在内存，主机断电则数据丢失</li><li>存储容量受到物理内存的限制，只能用于小数据量的高性能操作</li><li>在线扩容比较困难，系统上线时必须确保有足够的空间</li><li><p>用于缓存时，易出现’缓存雪崩‘，’缓存击穿‘等问题</p><h3 id="③Redis-和-Memcached-有什么区别？"><a href="#③Redis-和-Memcached-有什么区别？" class="headerlink" title="③Redis 和 Memcached 有什么区别？"></a>③Redis 和 Memcached 有什么区别？</h3><p>很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。 Redis 与 Memcached <strong>共同点</strong>：</p></li><li><p>都是基于内存的数据库，一般都用来当做缓存使用。</p></li><li>都有过期策略。</li><li>两者的性能都非常高。</li></ol><p>Redis 与 Memcached <strong>区别</strong>：</p><ul><li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li><li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li><li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li><li><p>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</p><h3 id="④Redis-与其他key-value-存储有什么不同？"><a href="#④Redis-与其他key-value-存储有什么不同？" class="headerlink" title="④Redis 与其他key-value 存储有什么不同？"></a>④Redis 与其他key-value 存储有什么不同？</h3><p>Redis 与其他key - value 缓存产品有以下三个特点：</p></li><li><p>Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</p></li><li>Redis 不仅仅支持简单的key-value 类型的数据， 同时还提供list，set，zset，hash 等数据结构的存储。Redis 有着更为复杂的数据结构并且提供对他们的原子性操作</li><li><p>Redis 支持数据的备份， 即master-slave 模式的数据备份。</p><h3 id="⑤redis-优势"><a href="#⑤redis-优势" class="headerlink" title="⑤redis 优势"></a>⑤redis 优势</h3></li><li><p>性能极高– Redis 能读的速度是110000 次/s,写的速度是81000 次/s 。</p></li><li>丰富的数据类型– Redis 支持二进制案例的Strings, Lists, Hashes, Sets 及Ordered Sets 数据类型操作。</li><li>原子– Redis 的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI 和EXEC指令包起来。</li><li>丰富的特性– Redis 还支持publish/subscribe, 通知, key 过期等等特性。<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3></li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>线程模型篇</title>
      <link href="/2022/08/09/redis/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
      <url>/2022/08/09/redis/%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="ⅠRedis-是单线程吗？"><a href="#ⅠRedis-是单线程吗？" class="headerlink" title="ⅠRedis 是单线程吗？"></a>ⅠRedis 是单线程吗？</h2><p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发生数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p><p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程（BIO）</strong>的：</p><ul><li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</li><li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。<blockquote><p>例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执        行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命        令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink         命令来异步删除大key。</p></blockquote></li></ul><p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p><blockquote><p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658045435445-a0d71b2b-c99d-43b0-9039-c65d0a37fa78.png#averageHue=%23efe5e2&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=297&amp;id=u07828d2f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=834&amp;originWidth=1282&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=271059&amp;status=done&amp;style=none&amp;taskId=ud744440e-469d-4557-abd2-aa6ec34ab5f&amp;title=&amp;width=456.00006103515625" alt="image.png"><br>关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：</p><ul><li>BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；</li><li>BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，</li><li>BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；</li></ul></blockquote><h2 id="👌ⅡRedis-单线程模式是怎样的？"><a href="#👌ⅡRedis-单线程模式是怎样的？" class="headerlink" title="👌ⅡRedis 单线程模式是怎样的？"></a>👌ⅡRedis 单线程模式是怎样的？</h2><p>Redis 6.0 版本之前的单线模式如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658045435932-c3f66a41-33f3-4ece-9368-3c0bfbef21ef.png#averageHue=%2390bc84&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=546&amp;id=u762de5e0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1547&amp;originWidth=1622&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=863697&amp;status=done&amp;style=none&amp;taskId=uf6a3ffe5-db91-4157-968b-b10aea9d9ff&amp;title=&amp;width=572.0000610351562" alt="image.png"><br>图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。 Redis 初始化的时候，会做下面这几年事情：</p><ul><li>首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 一个服务端 socket</li><li>然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；</li><li>然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。</li></ul><p>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：</p><ul><li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发生完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li><li>接着，调用 epoll_wait 函数等待事件的到来：<ul><li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctr 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li><li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li><li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发生完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li></ul></li></ul><p>以上就是 Redis 单线模式的工作方式，如果你想看源码解析，可以参考这一篇：<a href="https://mp.weixin.qq.com/s/oeOfsgF-9IOoT5eQt5ieyw">为什么单线程的 Redis 如何做到每秒数万 QPS ？(opens new window)</a></p><h2 id="ⅢRedis-采用单线程为什么还这么快？"><a href="#ⅢRedis-采用单线程为什么还这么快？" class="headerlink" title="ⅢRedis 采用单线程为什么还这么快？"></a>ⅢRedis 采用单线程为什么还这么快？</h2><p>官方使用基准测试的结果是，<strong>单线程的 Redis 吞吐量可以达到 10W/每秒</strong>，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658045435398-51520716-c4bb-4c8f-929c-915a7c474320.png#averageHue=%23f4f4f4&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=364&amp;id=ubf9e87fb&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=453&amp;originWidth=754&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=69857&amp;status=done&amp;style=none&amp;taskId=u53550676-e168-4bfd-a9a0-6e129f8ec99&amp;title=&amp;width=606.0000610351562" alt="image.png"><br>之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：</p><ul><li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU(多核)，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li><li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li><li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。<blockquote><p>Redis的IO多路复用<br>Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，一次放到文件事件分派器，事件分派器将事件分发给事件处理器。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648210784122-86ed8ab8-b4f8-492f-abf4-76dd1a4e5a78.png#clientId=ud0ba0578-c194-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=282&amp;id=rMgf9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=353&amp;originWidth=1153&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=97585&amp;status=done&amp;style=none&amp;taskId=u7c82dc5e-07b8-491a-a9a0-9ad766a889f&amp;title=&amp;width=922.4" alt="image.png"></p></blockquote></li></ul><blockquote><p>Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现</p><p>所谓 I/O 多路复用机制，就是说通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。这种机制的使用需要 select 、 poll 、 epoll 来配合。多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。</p><p>Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）<br>Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：<br>多个套接字、<br>IO多路复用程序、<br>文件事件分派器、<br>事件处理器。<br>因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型</p><p>单线程又避免了上下文的切换开销</p></blockquote><h2 id="ⅣRedis-6-0-之前为什么使用单线程？"><a href="#ⅣRedis-6-0-之前为什么使用单线程？" class="headerlink" title="ⅣRedis 6.0 之前为什么使用单线程？"></a>ⅣRedis 6.0 之前为什么使用单线程？</h2><blockquote><p>我们都知道单线程的程序是无法利用服务器的多核 CPU 的，那么早期 Redis 版本的主要工作（网络 I/O 和执行命令）为什么还要使用单线程呢？我们不妨先看一下Redis官方给出的<a href="https://link.juejin.cn/?target=https%3A%2F%2Fredis.io%2Ftopics%2Ffaq">FAQ(opens new window)</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658045435759-eb90e475-bdbd-426c-a1f5-81c919dfa16f.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ufe11b7d9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=748&amp;originWidth=1492&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=570283&amp;status=done&amp;style=none&amp;taskId=uc671e657-7bc8-4f2b-9e2c-5842a437d4d&amp;title=" alt="image.png"></p></blockquote><p>核心意思是：CPU 并不是制约 Redis 性能表现的瓶颈所在，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。</p><p>除了上面的官方回答，选择单线程的原因也有下面的考虑。</p><p>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，<strong>带来了并发读写的一系列问题</strong>，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</p><h2 id="ⅤRedis-6-0-之后为什么引入了多线程？"><a href="#ⅤRedis-6-0-之后为什么引入了多线程？" class="headerlink" title="ⅤRedis 6.0 之后为什么引入了多线程？"></a>ⅤRedis 6.0 之后为什么引入了多线程？</h2><ul><li>虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</li><li><p>所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。<strong>但是对于读写命令，Redis 仍然使用单线程来处理，所以大家不要误解</strong> Redis 有多线程同时执行命令。<br>补充Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。<br>Redis 6.0 版本支持的 I/O 多线程特性，默认是 I/O 多线程只处理写操作（write client socket），并不会以多线程的方式处理读操作（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读请求也使用io多线程</span></span><br><span class="line">io-threads-<span class="keyword">do</span>-reads yes </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）</span></span><br><span class="line">io-threads <span class="number">4</span> </span><br></pre></td></tr></table></figure><p>关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。 因此， <strong>Redis 6.0 版本之后，</strong>Redis 在启动的时候，默认情况下会有 6 个线程：</p></li><li><p>Redis-server ： Redis的主线程，主要负责执行命令；</p></li><li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li><li>io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>过期删除策略与内存淘汰篇</title>
      <link href="/2022/08/09/redis/%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0/"/>
      <url>/2022/08/09/redis/%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ过期删除策略"><a href="#Ⅰ过期删除策略" class="headerlink" title="Ⅰ过期删除策略"></a>Ⅰ过期删除策略</h2><h3 id="①Redis-使用的过期删除策略是什么？"><a href="#①Redis-使用的过期删除策略是什么？" class="headerlink" title="①Redis 使用的过期删除策略是什么？"></a>①Redis 使用的过期删除策略是什么？</h3><p>Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。<br>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。<br>当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p><ul><li>如果不在，则正常读取键值；</li><li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li></ul><p>Redis 使用的过期删除策略是<strong>「惰性删除+定期删除」这两种策略配和使用。</strong></p><h4 id="1-什么是惰性删除策略？"><a href="#1-什么是惰性删除策略？" class="headerlink" title="1. 什么是惰性删除策略？"></a>1. 什么是惰性删除策略？</h4><p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></p><p>惰性删除策略的<strong>优点</strong>：</p><ul><li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</li></ul><p>惰性删除策略的<strong>缺点</strong>：</p><ul><li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。<h4 id="2-什么是定期删除策略？"><a href="#2-什么是定期删除策略？" class="headerlink" title="2. 什么是定期删除策略？"></a>2. 什么是定期删除策略？</h4>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong><blockquote><p>Redis 的定期删除的流程：</p><ol><li>从过期字典中随机抽取 20 个 key；</li><li>检查这 20 个 key 是否过期，并删除已过期的 key；</li><li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li></ol><p>可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p></blockquote></li></ul><p>定期删除策略的<strong>优点</strong>：</p><ul><li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li></ul><p>定期删除策略的<strong>缺点</strong>：</p><ul><li>难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li></ul><p>可以看到，惰性删除策略和定期删除策略都有各自的优点，所以 <strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。<br><a href="https://xiaolincoding.com/redis/module/strategy.html"></a></p><h3 id="②Redis-持久化时，对过期键会如何处理的？"><a href="#②Redis-持久化时，对过期键会如何处理的？" class="headerlink" title="②Redis 持久化时，对过期键会如何处理的？"></a>②Redis 持久化时，对过期键会如何处理的？</h3><p>Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。<br>RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。</p><ul><li><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li><li><strong>RDB 加载阶段</strong>：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：<ul><li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li><li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li></ul></li></ul><p>AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。</p><ul><li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li><li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。<h3 id="③Redis-主从模式中，对过期键会如何处理？"><a href="#③Redis-主从模式中，对过期键会如何处理？" class="headerlink" title="③Redis 主从模式中，对过期键会如何处理？"></a>③Redis 主从模式中，对过期键会如何处理？</h3>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</li></ul><p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p><h2 id="Ⅱ内存淘汰策略"><a href="#Ⅱ内存淘汰策略" class="headerlink" title="Ⅱ内存淘汰策略"></a>Ⅱ内存淘汰策略</h2><h3 id="①Redis-内存满了，会发生什么？"><a href="#①Redis-内存满了，会发生什么？" class="headerlink" title="①Redis 内存满了，会发生什么？"></a>①Redis 内存满了，会发生什么？</h3><p>在 Redis 的运行内存达到了某个阀值，就会触发<strong>内存淘汰机制</strong>，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。</p><h3 id="②Redis-内存淘汰策略有哪些？"><a href="#②Redis-内存淘汰策略有哪些？" class="headerlink" title="②Redis 内存淘汰策略有哪些？"></a>②Redis 内存淘汰策略有哪些？</h3><p>Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。<br><em><strong>1、不进行数据淘汰的策略</strong></em><br><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。<br><em><strong>2、进行数据淘汰的策略</strong></em><br>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 在设置了过期时间的数据中进行淘汰：</p><ul><li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li><li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li><li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li><li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li></ul><p>在所有数据范围内进行淘汰：</p><ul><li><strong>allkeys-random</strong>：随机淘汰任意键值;</li><li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li><li><p><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</p><h3 id="③LRU-算法和-LFU-算法有什么区别？👌"><a href="#③LRU-算法和-LFU-算法有什么区别？👌" class="headerlink" title="③LRU 算法和 LFU 算法有什么区别？👌"></a>③LRU 算法和 LFU 算法有什么区别？👌</h3><p>详细内容LFU 内存淘汰算法是 Redis 4.0 之后新增内存淘汰策略，那为什么要新增这个算法？那肯定是为了解决 LRU 算法的问题。<br>接下来，就看看这两个算法有什么区别？Redis 又是如何实现这两个算法的？<br>什么是 LRU 算法？<br><strong>LRU</strong> 全称是 Least Recently Used 翻译为<strong>最近最少使用</strong>，会选择淘汰最近最少使用的数据。<br>传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。<br>Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：</p></li><li><p>需要用链表管理所有的缓存数据，这会带来额外的空间开销；</p></li><li>当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</li></ul><p>Redis 是如何实现 LRU 算法的？<br>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。<br>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。<br>Redis 实现的 LRU 算法的优点：</p><ul><li>不用为所有的数据维护一个大链表，节省了空间占用；</li><li>不用在每次数据访问时都移动链表项，提升了缓存的性能；</li></ul><p>但是 LRU 算法有一个问题，<strong>无法解决缓存污染问题</strong>，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。<br>因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。<br>什么是 LFU 算法？<br>LFU 全称是 Least Frequently Used 翻译为<strong>最近最不常用的，</strong>LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。<br>所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。<br>Redis 是如何实现 LFU 算法的？<br>LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line">      </span><br><span class="line">    <span class="comment">// 24 bits，用于记录对象的访问信息</span></span><br><span class="line">    <span class="type">unsigned</span> lru:<span class="number">24</span>;  </span><br><span class="line">    ...</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure><br>Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。<br><strong>在 LRU 算法中</strong>，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。<br><strong>在 LFU 算法中</strong>，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658047541250-2cbbaae9-f654-40d2-8069-5a1663807d30.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Q86Jl&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=324&amp;originWidth=1578&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62609&amp;status=done&amp;style=none&amp;taskId=u20896737-27a2-4170-b135-b697c5de8e9&amp;title=" alt="image.png"></p><ul><li>ldt 是用来记录 key 的访问时间戳；</li><li>logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。</li></ul><p>注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 <strong>logc 会随时间推移而衰减的</strong>。<br>在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据<strong>访问频率</strong>来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。<br>对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。<br>所以，Redis 在访问 key 时，对于 logc 是这样变化的：</p><ol><li>先按照上次访问距离当前的时长，来对 logc 进行衰减；</li><li>然后，再按照一定概率增加 logc 的值</li></ol><p>redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：</p><ul><li>lfu-decay-time 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；</li><li>lfu-log-factor 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>索引篇</title>
      <link href="/2022/08/09/MySQL/%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ执行一条-select-语句，期间发生了什么？"><a href="#Ⅰ执行一条-select-语句，期间发生了什么？" class="headerlink" title="Ⅰ执行一条 select     语句，期间发生了什么？"></a>Ⅰ执行一条 select     语句，期间发生了什么？</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649380179438-d0a0a0bc-9a9d-4097-89c2-1389ebbf6425.png#averageHue=%23ebeee2&amp;clientId=u4d9624a2-11c5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=395&amp;id=gDXHk&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=648&amp;originWidth=858&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=205130&amp;status=done&amp;style=none&amp;taskId=u97450cf1-9480-4153-ba76-c1edcccbceb&amp;title=&amp;width=523.3928833007812" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659836764704-dddc5631-f9e7-478d-b00f-d4d7736ffe58.png#averageHue=%23f2eee7&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=312&amp;id=H8hw0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=721&amp;originWidth=1261&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=265426&amp;status=done&amp;style=none&amp;taskId=u4a1f03af-30d9-4060-9813-759e25c4a41&amp;title=&amp;width=546.2857666015625" alt="image.png"><br>可以看到， MySQL 的架构共分为两层：<strong>Server 层和存储引擎层</strong>，</p><ul><li><strong>Server 层负责建立连接、分析和执行 SQL</strong>。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。</li><li><strong>存储引擎层负责数据的存储和提取</strong>。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。</li></ul><p>好了，现在我们对 Server 层和存储引擎层有了一个简单认识，接下来，就详细说一条 SQL 查询语句的执行流程，依次看看每一个功能模块的作用。<br>详细内容### 第一步：连接器</p><ul><li>与客户端进行 TCP 三次握手建立连接；</li><li>校验客户端的用户名和密码，如果用户名或密码不对，则会报错；</li><li><p>如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；</p><h3 id="第二步：查询缓存"><a href="#第二步：查询缓存" class="headerlink" title="第二步：查询缓存"></a>第二步：查询缓存</h3></li><li><p>连接器的工作完成后，客户端就可以向 MySQL 服务发送 SQL 语句了，MySQL 服务收到 SQL 语句后，就会解析出 SQL 语句的第一个字段，看看是什么类型的语句。</p><ul><li>如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。<ul><li>如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。</li></ul></li></ul></li></ul><p>这么看，查询缓存还挺有用，但是其实<strong>查询缓存挺鸡肋</strong>的。</p><ul><li>对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。</li><li>所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。</li><li>对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。</li></ul><p><strong>TIP</strong><br>这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer poll。</p><h3 id="第三步：解析-SQL"><a href="#第三步：解析-SQL" class="headerlink" title="第三步：解析 SQL"></a>第三步：解析 SQL</h3><p>在正式执行 SQL 查询语句之前， MySQL 会先对 SQL 语句做解析，这个工作交由由「解析器」来完成。</p><h4 id="解析器"><a href="#解析器" class="headerlink" title="解析器"></a>解析器</h4><p>解析器会做如下两件事情。<br>第一件事情，<strong>词法分析</strong>。MySQL 会根据你输入的字符串识别出关键字出来，构建出 SQL 语法树，这样方面后面模块获取 SQL 类型、表名、字段名、 where 条件等等。<br>第二件事情，<strong>语法分析</strong>。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。<br>如果我们输入的 SQL 语句语法不对，就会在解析器这个阶段报错。比如，我下面这条查询语句，把 from 写成了 form，这时 MySQL 解析器就会给报错。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837237167-34ffc81e-89e1-4a59-9936-7d87acc2b9f6.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=n8SPn&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=226&amp;originWidth=1244&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=179547&amp;status=done&amp;style=none&amp;taskId=uac712958-cfb9-47cf-8414-45abaa0480b&amp;title=" alt="image.png"><br>但是注意，表不存在或者字段不存在，并不是在解析器里做的，《MySQL 45 讲》说是在解析器做的，但是经过我和朋友看 MySQL 源码（5.7和8.0）得出结论是解析器只负责构建语法树和检查语法，但是不会去查表或者字段存不存在。<br>那到底谁来做检测表和字段是否存在的工作呢？别急，接下来就是了。</p><h3 id="第四步：执行-SQL"><a href="#第四步：执行-SQL" class="headerlink" title="第四步：执行 SQL"></a>第四步：执行 SQL</h3><p>经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段：</p><ul><li>prepare 阶段，也就是预处理阶段；</li><li>optimize 阶段，也就是优化阶段；</li><li><p>execute 阶段，也就是执行阶段；</p><h4 id="预处理器"><a href="#预处理器" class="headerlink" title="预处理器"></a>预处理器</h4><p>我们先来说说预处理阶段做了什么事情。</p></li><li><p>检查 SQL 查询语句中的表或者字段是否存在；</p></li><li>将 select <em> 中的 </em> 符号，扩展为表上的所有列；<blockquote><p>我下面这条查询语句，test 这张表是不存在的，这时 MySQL 就会在执行 SQL 查询语句的 prepare 阶段中报错。<br>mysql&gt; select * from test; ERROR 1146 (42S02): Table ‘mysql.test’ doesn’t exist<br>这里贴个 MySQL 8.0 源码来证明表或字段是否存在的判断，不是在解析器里做的，而是在 prepare 阶段。（<em>PS：下图是公众号「一树一溪」老哥帮我分析的，这位老哥专门写 MySQL 源码文章，感兴趣的朋友，可以微信搜索关注</em>）<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837237905-72ddeb07-ecd8-4417-96e0-91e0cfe1ec17.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Intjl&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=786&amp;originWidth=1863&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1170616&amp;status=done&amp;style=none&amp;taskId=u3502c107-c910-4652-8dc5-2b288a1d504&amp;title=" alt="image.png"><br>上面的中间部分是 MySQL 报错表不存在时的函数调用栈，可以看到表不存在的错误是在get_table_share() 函数里报错的，而这个函数是在 prepare 阶段调用的。<br>不过，对于 MySQL 5.7 判断表或字段是否存在的工作，是在词法分析&amp;语法分析之后，prepare 阶段之前做的。结论都一样，不是在解析器里做的。代码我就不放了，正因为 MySQL 5.7 代码结构不好，所以 MySQL 8.0 代码结构变化很大，后来判断表或字段是否存在的工作就被放入到 prepare 阶段做了。</p></blockquote></li></ul><h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>经过预处理阶段后，还需要为 SQL 查询语句先制定一个执行计划，这个工作交由「优化器」来完成的。<br><strong>优化器主要负责将 SQL 查询语句的执行方案确定下来</strong>，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。</p><blockquote><p>当然，我们本次的查询语句（select <em> from product where id = 1）很简单，就是选择使用主键索引。<br>要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引，比如下图的 key 为 PRIMARY 就是使用了主键索引。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837237134-b9f70648-8dea-4500-91af-1bf78504ab03.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=yHwwB&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=346&amp;originWidth=1840&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=105917&amp;status=done&amp;style=none&amp;taskId=u09b1828e-9a1f-45c8-b359-659ffa89ed6&amp;title=" alt="image.png"><br>如果查询语句的执行计划里的 key 为 null 说明没有使用索引，那就会全表扫描（type = ALL），这种查询扫描的方式是效率最低档次的，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837237159-af233307-5ff3-4db9-a5db-feb1b17cd291.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PSMPC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=302&amp;originWidth=1752&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=98203&amp;status=done&amp;style=none&amp;taskId=u52f234f1-5e97-483f-a6ae-cfed207e4f6&amp;title=" alt="image.png"><br>这张 product 表只有一个索引就是主键，现在我在表中将 name 设置为普通索引（二级索引）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837237119-e56c7532-1f39-42b3-9f7e-b4c910aa73e6.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=FlZy0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=438&amp;originWidth=660&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=86376&amp;status=done&amp;style=none&amp;taskId=ua2232d15-5ab9-4d65-ace6-fb18a3fc14f&amp;title=" alt="image.png"><br>这时 product 表就有主键索引（id）和普通索引（name）。假设执行了这条查询语句：<br>select id from product where id &gt; 1  and name like ‘i%’;<br>这条查询语句的结果既可以使用主键索引，也可以使用普通索引，但是执行的效率会不同。这时，就需要优化器来决定使用哪个索引了。<br>很显然这条查询语句是<em>*覆盖索引</em></em>，直接在二级索引就能查找到结果（因为二级索引的 B+ 树的叶子节点的数据存储的是主键值），就没必要在主键索引查找了，因为查询主键索引的 B+ 树的成本会比查询二级索引的 B+ 的成本大，优化器基于查询成本的考虑，会选择查询代价小的普通索引。<br>在下图中执行计划，我们可以看到，执行过程中使用了普通索引（name），Exta 为 Using index，这就是表明使用了覆盖索引优化。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837239137-1ae3db33-8b98-48a6-bc36-8a6945bea8f4.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=sro5s&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=428&amp;originWidth=2106&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=158871&amp;status=done&amp;style=none&amp;taskId=u7bba16a6-26d1-4c86-a80b-a042a20c67c&amp;title=" alt="image.png"></p></blockquote><h4 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h4><p>经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。<br>接下来，用三种方式执行过程，跟大家说一下执行器和存储引擎的交互过程（PS ：为了写好这一部分，特地去看 MySQL 源码，也是第一次看哈哈）。</p><ul><li>主键索引查询</li><li>全表扫描</li><li>索引下推</li></ul><p>执行一条 SQL 查询语句，期间发生了什么？</p><ul><li><strong>连接器</strong>：建立连接，管理连接、校验用户身份；</li><li><strong>查询缓存</strong>：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；<br>这么看，查询缓存还挺有用，但是其实<strong>查询缓存挺鸡肋</strong>的。</li><li>对于更新比较频繁的表，查询缓存的命中率很低的，<strong>因为只要一个表有更新操作，那么这个表的查询缓存就会被清空</strong>。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。</li><li>所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。</li><li>对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。</li><li><strong>解析器</strong>会解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</li><li>执行 SQL：执行 SQL 共有三个阶段：<ul><li><strong>预处理器</strong>，预处理阶段：检查表或字段是否存在；将 select <em> 中的 </em> 符号扩展为表上的所有列。</li><li><strong>优化器</strong>进行优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li><li><strong>执行器</strong>进行执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；<h2 id="Ⅱ-数据库的三大范式"><a href="#Ⅱ-数据库的三大范式" class="headerlink" title="Ⅱ 数据库的三大范式"></a>Ⅱ 数据库的三大范式</h2></li></ul></li></ul><p><strong>第一范式1NF</strong><br>确保数据库表字段的原子性。<br>比如字段 userInfo: 广东省 10086’ ，依照第一范式必须拆分成 userInfo: 广东省userTel:10086两个字段。<br><strong>第二范式2NF</strong><br>首先要满足第一范式，另外包含两部分内容：</p><ul><li>一是表必须有一个主键；</li><li>二是非主键列必须完全依赖于主键，而不能只依赖于主键的一部分。<blockquote><p>举个例子。假定选课关系表为student_course(student_no, student_name, age, course_name, grade, credit)，主键为(student_no, course_name)。其中学分完全依赖于课程名称，姓名年龄完全依赖学号，不符合第二范式，会导致数据冗余（学生选n门课，姓名年龄有n条记录）、插入异常（插入一门新课，因为没有学号，无法保存新课记录）等问题。<br>可以拆分成三个表：学生：student(stuent_no, student_name, 年龄)；课程：course(course_name, credit)；选课关系：student_course_relation(student_no, course_name, grade)。</p></blockquote></li></ul><p><strong>第三范式3NF</strong><br>首先要满足第二范式，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。</p><blockquote><p>假定学生关系表为Student(student_no, student_name, age, academy_id, academy_telephone)，主键为”学号”，其中学院id依赖于学号，而学院地点和学院电话依赖于学院id，存在传递依赖，不符合第三范式。<br>可以把学生关系表分为如下两个表：学生：(student_no, student_name, age, academy_id)；学院：(academy_id, academy_telephone)。</p></blockquote><p><strong>2NF和3NF的区别？</strong></p><ul><li>2NF依据是非主键列是否完全依赖于主键，还是依赖于主键的一部分。 </li><li><p>3NF依据是非主键列是直接依赖于主键，还是直接依赖于非主键。 </p><h2 id="Ⅲ原本可以执行得很快的-SQL-语句，执行速度却比预期的慢很多，原因是什么？如何解决？"><a href="#Ⅲ原本可以执行得很快的-SQL-语句，执行速度却比预期的慢很多，原因是什么？如何解决？" class="headerlink" title="Ⅲ原本可以执行得很快的 SQL 语句，执行速度却比预期的慢很多，原因是什么？如何解决？"></a>Ⅲ原本可以执行得很快的 SQL 语句，执行速度却比预期的慢很多，原因是什么？如何解决？</h2><p>原因：从大到小可分为四种情况</p></li><li><p>MySQL 数据库本身被堵住了，比如：系统或网络资源不够。</p></li><li>SQL 语句被堵住了，比如：表锁，行锁等，导致存储引擎不执行对应的 SQL 语句。</li><li>索引使用不当，没有走索引。</li><li>表中数据的特点导致的，走了索引，但回表次数庞大。</li></ul><p>解决：</p><ul><li>考虑采用 force index 强行选择一个索引</li><li>考虑修改语句，引导 MySQL 使用我们期望的索引。比如把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</li><li>第三种方法是，在有些场景下，可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</li><li>如果确定是索引根本没必要，可以考虑删除索引。</li></ul>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>事务篇</title>
      <link href="/2022/08/09/MySQL/%E4%BA%8B%E5%8A%A1%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E4%BA%8B%E5%8A%A1%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<p>事务：一系列操作组成，要么操作全部成功，要么操作全部失败</p><h2 id="①事务的四大特性？"><a href="#①事务的四大特性？" class="headerlink" title="①事务的四大特性？"></a>①事务的四大特性？</h2><ul><li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。 </li><li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 </li><li><strong>一致性（Consistency）</strong>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如a与b账户共有1000块，两人之间转账之后无论成功还是失败，它们的账户总和还是1000。 </li></ul><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p><ul><li>持久性是通过 redo log （重做日志）来保证的；</li><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；<h2 id="②并发事务会引发什么问题？"><a href="#②并发事务会引发什么问题？" class="headerlink" title="②并发事务会引发什么问题？"></a>②并发事务会引发什么问题？</h2></li></ul><p>当数据库上有多个事务同时执行的时候，就会出现并发问题。<br>1.脏读：读到了另一个事务未提交的数据<br>2.不可重复读：一个事务下，两次读取的数据不一致。<br>3.幻读：事务A 按照一定条件进行数据读取， 期间事务B 插入了相同搜索条件的新数据，事务A再次按照原先条件进行读取时，发现了事务B 新插入的数据 称为幻读。</p><h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p><strong>如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。</strong></p><blockquote><p>举个栗子。<br>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659852498118-7c962a35-11de-4941-9972-6823b507ab5e.png#averageHue=%23f9f6f1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=218&amp;id=u713f8a2e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=420&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=94071&amp;status=done&amp;style=none&amp;taskId=u8b179135-222e-4dac-bc6a-8671a94553a&amp;title=&amp;width=561.0000610351562" alt="image.png"></p></blockquote><p>因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，<strong>如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。</strong></p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p><strong>在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</strong></p><blockquote><p>举个栗子。<br>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，<strong>在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659852498128-6821850d-6429-4fe4-aee1-90d2a2bb5dde.png#averageHue=%23f9f7f0&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=231&amp;id=u0092c86b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=486&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=114245&amp;status=done&amp;style=none&amp;taskId=ue9dfae9a-3dba-4c98-919c-15e4b25e218&amp;title=&amp;width=513.2857666015625" alt="image.png"></p></blockquote><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>事务A 按照一定条件进行数据读取， 期间事务B 插入了相同搜索条件的新数据，事务A再次按照原先条件进行读取时，发现了事务B 新插入的数据 称为幻读。</p><blockquote><p>举个栗子。<br>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659852498155-db10dac0-0248-43fd-a91b-5c7449709f34.png#averageHue=%23f8f5ef&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7a151413&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=312&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=104238&amp;status=done&amp;style=none&amp;taskId=ud5d6b6ca-3dc2-433e-b98d-eab1dc1832e&amp;title=" alt="image.png"><br>接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。<br>然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，<strong>发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读</strong></p></blockquote><h2 id="③隔离级别原理及解决问题分析"><a href="#③隔离级别原理及解决问题分析" class="headerlink" title="③隔离级别原理及解决问题分析"></a>③隔离级别原理及解决问题分析</h2><ul><li><strong>读未提交（<em>read uncommitted</em>）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；直接读取数据，不能解决任何并发的问题。</li><li><strong>读提交（<em>read committed</em>）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；读操作不加锁，写操作加排他锁，解决了脏读。原理：利用mvcc实现，每一句语句执行前都会生成ReadView。</li><li><strong>可重复读（<em>repeatable read</em>）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；MVCC实现，只有事务开始时才会创建ReadView，之后事务里的其他查询语句都用这个ReadView。解决了脏读不可重复读。<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667466208556-58ce5295-d9b4-4ce8-ab8c-6574eefd67a1.png#averageHue=%23f5f2ee&amp;clientId=u43b03e35-250b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=71&amp;id=u569b2700&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=124&amp;originWidth=1163&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=91569&amp;status=done&amp;style=none&amp;taskId=u6ed208d7-8232-436b-a57c-0bb2eee2cba&amp;title=&amp;width=664.5714285714286" alt="image.png"></li><li><strong>串行化（<em>serializable</em> ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；原理：使用锁，读加共享锁，写加排他锁，串行执行。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667466186336-4d764e0f-6573-444a-afc2-2ece74143e3c.png#averageHue=%23f5f2f0&amp;clientId=u43b03e35-250b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=54&amp;id=ue636552a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=95&amp;originWidth=1224&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=76262&amp;status=done&amp;style=none&amp;taskId=u2587abbd-28ad-4df0-8a1c-9685e9cc0d2&amp;title=&amp;width=699.4285714285714" alt="image.png"></p><h2 id="④MVCC原理"><a href="#④MVCC原理" class="headerlink" title="④MVCC原理"></a>④MVCC原理</h2><p>多版本并发控制，同一份数据保留多版本的一种方式<br><strong>原理</strong>：使用版本链和readView<br><strong>版本链</strong>：<strong>同一行数据可能有多个版本</strong><br>innodb数据表每行数据记录会有几个隐藏字段，row_id,事务ID,回滚指针。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647690425328-f81b7c50-45d3-425e-a90a-0bc5317a60a5.png#averageHue=%23f4f1ee&amp;clientId=u85fe28fb-6d3c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=150&amp;id=PnEoi&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=187&amp;originWidth=970&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=41151&amp;status=done&amp;style=none&amp;taskId=uc15ff453-824e-4daa-b498-8210e8cc4c7&amp;title=&amp;width=776" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2021/png/21967782/1625902802350-affa5da1-f775-4489-978e-614b4b45d099.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_16%2Ctext_5b6u5L-h5YWs5LyX5Y-377ya5bCP6b6ZY29kaW5n%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10#averageHue=%23f5ebe7&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=url&amp;height=249&amp;id=WEThO&amp;margin=%5Bobject%20Object%5D&amp;originHeight=299&amp;originWidth=563&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=&amp;width=469" alt=""><br><strong>ReadView</strong><br>那 Read View 到底是个什么东西？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659852784431-9f1b701f-c659-4427-9044-6a10a04fae91.png#averageHue=%23c1ceb9&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=253&amp;id=tl5DD&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=437&amp;originWidth=900&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=237940&amp;status=done&amp;style=none&amp;taskId=u7a1c9b2c-a413-4060-ab30-462934714a7&amp;title=&amp;width=521.2857666015625" alt="image.png"><br>Read View 有四个重要的字段：</p><ul><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li></ul><p>在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659852784349-3ccd92ff-6cec-44c5-9603-2272ea5a02f8.png#averageHue=%23eeb464&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=233&amp;id=aqVoQ&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=332&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=107330&amp;status=done&amp;style=none&amp;taskId=u1a8358a0-52f4-4fd4-9ee9-e727e1555c2&amp;title=&amp;width=497.00006103515625" alt="image.png"><br>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p><ul><li>如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View <strong>前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</li><li>如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View <strong>后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：<ul><li>如果记录的 trx_id <strong>在</strong> m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id <strong>不在</strong> m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务<strong>可见</strong>。</li></ul></li></ul><p><strong>这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。</strong></p><h2 id="⑤可重复读是如何工作的？"><a href="#⑤可重复读是如何工作的？" class="headerlink" title="⑤可重复读是如何工作的？"></a>⑤可重复读是如何工作的？</h2><p><strong>可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</strong>。<br>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659853192612-a0ff8d3a-5888-4791-ad36-ac5e13dbd291.png#averageHue=%23f2f1e6&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=343&amp;id=u344cd5da&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=854&amp;originWidth=849&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=225333&amp;status=done&amp;style=none&amp;taskId=u2012d0f0-5bf0-4146-9fb9-4b54a1532ce&amp;title=&amp;width=341.2857666015625" alt="image.png"><br>事务 A 和 事务 B 的 Read View 具体内容如下：</p><ul><li>在事务 A 的 Read View 中，它的事务 id 是 51，由于它是第一个启动的事务，所以此时活跃事务的事务 id 列表就只有 51，活跃事务的事务 id 列表中最小的事务 id 是事务 A 本身，下一个事务 id 则是 52。</li><li>在事务 B 的 Read View 中，它的事务 id 是 52，由于事务 A 是活跃的，所以此时活跃事务的事务 id 列表是 51 和 52，<strong>活跃的事务 id 中最小的事务 id 是事务 A</strong>，下一个事务 id 应该是 53。</li></ul><p>接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作：</p><ul><li>事务 B 读取小林的账户余额记录，读到余额是 100 万；</li><li>事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额还是 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额依然还是 100 万；</li></ul><p>接下来，跟大家具体分析下。<br>事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时<strong>发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的</strong>，也就是事务 B 可以获取到这条记录。<br>接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成<strong>版本链</strong>，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659853192662-899a57e4-455b-476c-b384-63d4e39ed220.png#averageHue=%23f1f0e4&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=547&amp;id=u51cc1274&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=914&amp;originWidth=849&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=266410&amp;status=done&amp;style=none&amp;taskId=u5da79f6a-44b3-432f-b998-4cbdd28f655&amp;title=&amp;width=508.2857666015625" alt="image.png"><br>你可以在上图的「记录的字段」看到，由于事务 A 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 A 的事务 id（trx_id = 51）。<br>然后事务 B 第二次去读取该记录，<strong>发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录</strong>，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。<br>最后，当事物 A 提交事务后，<strong>由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录</strong>。<br>就是通过这样的方式实现了，「可重复读」隔离级别下在事务期间读到的记录都是事务启动前的记录。</p><h2 id="⑥读提交是如何工作的？"><a href="#⑥读提交是如何工作的？" class="headerlink" title="⑥读提交是如何工作的？"></a>⑥读提交是如何工作的？</h2><p><strong>读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View</strong>。<br>也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。<br>那读提交隔离级别是怎么工作呢？我们还是以前面的例子来聊聊。<br>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作：</p><ul><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 200 万；</li></ul><p>那具体怎么做到的呢？我们重点看事务 B 每次读取数据时创建的 Read View。前两次 事务 B 读取数据时创建的 Read View 如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659853192711-5c973519-b01f-438e-a991-d2d6f88c2080.png#averageHue=%23f7f5f1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=1040&amp;id=u1ad6e270&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1809&amp;originWidth=959&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=349222&amp;status=done&amp;style=none&amp;taskId=u16249a9a-856b-4134-9c5c-9ba604cab3a&amp;title=&amp;width=551.2857666015625" alt="image.png"><br>我们来分析下为什么事务 B 第二次读数据时，读不到事务 A （还未提交事务）修改的数据？<br>事务 B 在找到小林这条记录时，会看这条记录的 trx_id 是 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，接下来需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明<strong>这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录</strong>。而是，沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。<br>我们来分析下为什么事务 A 提交后，事务 B 就可以读到事务 A 修改的数据？<br>在事务 A 提交后，<strong>由于隔离级别是「读提交」，所以事务 B 在每次读数据的时候，会重新创建 Read View</strong>，此时事务 B 第三次读取数据时创建的 Read View 如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659853192644-03ba2786-f62c-4cbc-ad81-25f3410a08fa.png#averageHue=%23f2ede1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uddd014f0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=504&amp;originWidth=1359&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=236738&amp;status=done&amp;style=none&amp;taskId=u76749b94-62ce-448c-8b50-be5e668791b&amp;title=" alt="image.png"><br>事务 B 在找到小林这条记录时，<strong>会发现这条记录的 trx_id 是 51，比事务 B 的 Read View 中的 min_trx_id 值（52）还小，这意味着修改这条记录的事务早就在创建 Read View 前提交过了，所以该版本的记录对事务 B 是可见的</strong>。<br>正是因为在读提交隔离级别下，事务每次读数据时都重新创建 Read View，那么在事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p><h2 id="幻读问题详解"><a href="#幻读问题详解" class="headerlink" title="幻读问题详解"></a>幻读问题详解</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647690149070-e3c1b7c8-a7c6-4905-be9a-356bd0520826.png#averageHue=%23f9f9f8&amp;clientId=u85fe28fb-6d3c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=414&amp;id=nLjER&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=518&amp;originWidth=971&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=40994&amp;status=done&amp;style=none&amp;taskId=ufddebbd7-3d66-49a9-8932-fec615a16a0&amp;title=&amp;width=776.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647690162693-7f577e5a-54ec-4392-af7d-ce06e3f7d8f4.png#averageHue=%233a3737&amp;clientId=u85fe28fb-6d3c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=426&amp;id=va2b9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=532&amp;originWidth=959&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=272199&amp;status=done&amp;style=none&amp;taskId=u312baa42-bd47-45fa-8ee1-58965a85be5&amp;title=&amp;width=767.2" alt="image.png"></p><h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647690175576-fa3b55cf-f4bb-4e83-a3e0-fc6403adc2c4.png#averageHue=%23f5f2ee&amp;clientId=u85fe28fb-6d3c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=405&amp;id=ddfv9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=506&amp;originWidth=982&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=180447&amp;status=done&amp;style=none&amp;taskId=ud28f7b03-4f92-4f5f-937b-3a120f0cfcb&amp;title=&amp;width=785.6" alt="image.png"></h2>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>缓存篇</title>
      <link href="/2022/08/09/redis/%E7%BC%93%E5%AD%98/"/>
      <url>/2022/08/09/redis/%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ缓存雪崩-缓存穿透-缓存击穿"><a href="#Ⅰ缓存雪崩-缓存穿透-缓存击穿" class="headerlink" title="Ⅰ缓存雪崩+缓存穿透+缓存击穿"></a>Ⅰ缓存雪崩+缓存穿透+缓存击穿</h2><h3 id="①缓存雪崩"><a href="#①缓存雪崩" class="headerlink" title="①缓存雪崩"></a>①缓存雪崩</h3><p><strong>第一个原因是：缓存中有大量数据同时过期或者redis宕机，导致大量请求无法得到处理。</strong><br>可以看到，发生缓存雪崩有两个原因：</p><ul><li>大量数据同时过期；</li><li>Redis 故障宕机；</li></ul><p>不同的诱因，应对的策略也会不同。</p><h4 id="大量数据同时过期"><a href="#大量数据同时过期" class="headerlink" title="大量数据同时过期"></a>大量数据同时过期</h4><p>针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种：</p><ul><li>均匀设置过期时间；</li><li>互斥锁；</li><li>双 key 策略；</li><li>后台更新缓存；</li></ul><p><em>1. 均匀设置过期时间</em><br>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。<br><em>2. 互斥锁</em><br>多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。<br><em>3. 双 key 策略</em><br>我们对缓存数据可以使用两个 key，一个是<strong>主 key，会设置过期时间</strong>，一个是<strong>备 key，不会设置过期</strong>，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。<br>当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，<strong>同时更新「主 key 」和「备 key 」的数据。</strong></p><h4 id="Redis-故障宕机"><a href="#Redis-故障宕机" class="headerlink" title="Redis 故障宕机"></a>Redis 故障宕机</h4><p>针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种：</p><ul><li>服务熔断或请求限流机制；</li><li>构建 Redis 缓存高可靠集群；</li></ul><p><em>1. 服务熔断或请求限流机制</em></p><ul><li>因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动<strong>服务熔断</strong>机制，<strong>暂停业务应用对缓存服务的访问，直接返回错误</strong>，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。</li><li>服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作</li><li>为了减少对业务的影响，我们可以启用<strong>请求限流</strong>机制，<strong>只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</strong>，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。</li></ul><p><em>2. 构建 Redis 缓存高可靠集群</em><br>服务熔断或请求限流机制是缓存雪崩发生后的应对方案，我们最好通过<strong>主从节点的方式构建 Redis 缓存高可靠集群</strong>。<br>如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。</p><h3 id="②缓存穿透"><a href="#②缓存穿透" class="headerlink" title="②缓存穿透"></a>②缓存穿透</h3><p>先redis后mysql都查询不到数据，但每次请求都会打到数据库上面去，导致数据库压力骤增</p><p>那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况。<br>业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；<br>恶意攻击：专门访问数据库中没有的数据。</p><p>缓存穿透的发生一般有这两种情况：</p><ul><li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li><li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务；</li></ul><p>应对缓存穿透的方案，常见的方案有三种。</p><ul><li>第一种方案，非法请求的限制；</li><li>第二种方案，缓存空值或者默认值；</li><li>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；</li></ul><p><strong>第一种方案，非法请求的限制</strong><br>当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。<br><strong>第二种方案，缓存空值或者默认值</strong><br>当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。<br><em>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。</em><br>我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。<br>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。<br>那问题来了，布隆过滤器是如何工作的呢？接下来，我介绍下。<br>布隆过滤器是如何工作布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。<br>布隆过滤器会通过 3 个操作完成标记：</p><ul><li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li><li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li><li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li></ul><p>举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048244118-deee2785-55b4-4513-9863-71b4b5c9fe7c.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=FTsZk&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=287&amp;originWidth=977&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=45334&amp;status=done&amp;style=none&amp;taskId=u6b1f2d4b-6ec5-40cd-acd7-61875a3c950&amp;title=" alt="image.png"><br>在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。<strong>当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中</strong>。<br>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong>，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。<br>所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据</strong>。</p><h3 id="③缓存击穿"><a href="#③缓存击穿" class="headerlink" title="③缓存击穿"></a>③缓存击穿</h3><p>大量的请求同时查询一个 key 时，<br>此时这个key正好失效了，就会导致大量的请求都打到数据库上面去<br>方案1：对于频繁访问的key，干脆就不设置过期时间。<br>方案2：<strong>互斥更新</strong>，开辟两块缓存，主A从B,更新时先更新B再更新A,查询时主A从B<br>方案3：互斥独占锁防止击穿，多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。[</p><p>](<a href="https://blog.csdn.net/weixin_43064185/article/details/122035596">https://blog.csdn.net/weixin_43064185/article/details/122035596</a>)</p><h2 id="Ⅱ说说常见的缓存更新策略？"><a href="#Ⅱ说说常见的缓存更新策略？" class="headerlink" title="Ⅱ说说常见的缓存更新策略？"></a>Ⅱ说说常见的缓存更新策略？</h2><p>常见的缓存更新策略共有3种：</p><ul><li>Cache Aside（旁路缓存）策略；</li><li>Read/Write Through（读穿 / 写穿）策略；</li><li>Write Back（写回）策略；</li></ul><p>实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。<br>Cache Aside（旁路缓存）策略<br>Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658049137593-140a1353-a4dd-4420-bdd6-116aaf3c1fdd.png#averageHue=%23f8f4ee&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7fd3e624&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=731&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=52333&amp;status=done&amp;style=none&amp;taskId=ucbff1632-a915-42ef-aa1e-619325bb6ef&amp;title=" alt="image.png"><br><strong>写策略的步骤：</strong></p><ul><li>先更新数据库中的数据，再删除缓存中的数据。</li></ul><p><strong>读策略的步骤：</strong></p><ul><li>如果读取的数据命中了缓存，则直接返回数据；</li><li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li></ul><p>注意，写策略的步骤的顺序顺序不能倒过来，即<strong>不能先删除缓存再更新数据库</strong>，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。</p><p>举个例子，假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658049137636-569f8571-389f-4084-bc1b-b1663d566d1c.png#averageHue=%23f9f4f1&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=361&amp;id=u224f3a8e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=903&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59278&amp;status=done&amp;style=none&amp;taskId=u9a1526dd-1935-44fa-8937-e70314bc70d&amp;title=&amp;width=528.0000610351562" alt="image.png"><br>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。<br><strong>为什么「先更新数据库再删除缓存」不会有数据不一致的问题？</strong><br>继续用「读 + 写」请求的并发的场景来分析。</p><p>假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658049137632-5a27e9bb-408d-4993-8947-2f3c3ecf1b34.png#averageHue=%23f9f5f1&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=367&amp;id=u108d43eb&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=56539&amp;status=done&amp;style=none&amp;taskId=u11c331fd-5ce8-4a8f-97bd-8f94c932950&amp;title=&amp;width=535.0000610351562" alt="image.png"><br>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。 从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。</p><p><strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。</p><p><strong>Cache Aside 策略适合读多写少的场景，不适合写多的场景</strong>，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：</p><ul><li>一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；</li><li>另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。</li></ul><p>Read/Write Through（读穿 / 写穿）策略<br>Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。<br><em><strong>1、Read Through 策略</strong></em><br>先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。<br><em><strong>2、Write Through 策略</strong></em><br>当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：</p><ul><li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li><li>如果缓存中数据不存在，直接更新数据库，然后返回；</li></ul><p>下面是 Read Through/Write Through 策略的示意图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658049137864-bb78aaf7-91cd-4897-b2ea-2b3d83cba589.png#averageHue=%23fbfaf9&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=719&amp;id=ueb7063ee&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1601&amp;originWidth=1242&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=320419&amp;status=done&amp;style=none&amp;taskId=ue91ad714-5a00-4129-80ce-dd37cb77dbe&amp;title=&amp;width=558.0000610351562" alt="image.png"><br>Read Through/Write Through 策略的特点是由缓存节点而非应用程序来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库和自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略。<br>Write Back（写回）策略<br>Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。<br>实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 Redis 并没有异步更新数据库的功能。<br>Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。<br><strong>Write Back 策略特别适合写多的场景</strong>，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。<br><strong>但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险</strong>，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。<br>这里贴一张 CPU 缓存与内存使用 Write Back 策略的流程图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658049137791-7bd9f54a-fea6-4bcb-a6ae-2c9689a0678a.png#averageHue=%230c0c05&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=661&amp;id=uf90245cc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=820&amp;originWidth=640&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=153927&amp;status=done&amp;style=none&amp;taskId=u08dc400e-5079-4f9b-bf0d-26f4ceab5a8&amp;title=&amp;width=516" alt="image.png"><br>有没有觉得这个流程很熟悉？因为我在写 <a href="https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#%E5%86%99%E5%9B%9E">CPU 缓存文章(opens new window)</a>的时候提到过。</p><h2 id="Ⅲ数据库和缓存如何保证一致性？"><a href="#Ⅲ数据库和缓存如何保证一致性？" class="headerlink" title="Ⅲ数据库和缓存如何保证一致性？"></a>Ⅲ数据库和缓存如何保证一致性？</h2><h3 id="①先更新数据库，还是先更新缓存？"><a href="#①先更新数据库，还是先更新缓存？" class="headerlink" title="①先更新数据库，还是先更新缓存？"></a>①先更新数据库，还是先更新缓存？</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048401833-cc606235-55d1-420b-9494-61e55b1e85f4.png#averageHue=%23f9c897&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=216&amp;id=u58e934b0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=272&amp;originWidth=572&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=15767&amp;status=done&amp;style=none&amp;taskId=uc148a0de-4307-45d6-bdd9-38632e11a67&amp;title=&amp;width=454" alt="image.png"><br><strong>由于引入了缓存，那么在数据更新时，不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题</strong>：</p><ul><li>先更新数据库，再更新缓存；</li><li>先更新缓存，再更新数据库；</li></ul><p>造成缓存和数据库的数据不一致的现象，是因为<strong>并发问题</strong>！</p><h4 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h4><p>举个例子，比如「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048401892-93177ed1-80c2-4c04-bfa1-51ce888c765e.png#averageHue=%23faf6f3&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=336&amp;id=u2e8737bd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=893&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=65879&amp;status=done&amp;style=none&amp;taskId=u7112a73f-9b13-4ecd-a3c6-7478d9fdc2a&amp;title=&amp;width=486.00006103515625" alt="image.png"><br>A 请求先将数据库的数据更新为 1，然后在更新缓存前，请求 B 将数据库的数据更新为 2，紧接着也把缓存更新为 2，然后 A 请求更新缓存为 1。<br>此时，数据库中的数据是 2，而缓存中的数据却是 1，<strong>出现了缓存和数据库中的数据不一致的现象</strong>。</p><h4 id="先更新缓存，再更新数据库"><a href="#先更新缓存，再更新数据库" class="headerlink" title="先更新缓存，再更新数据库"></a>先更新缓存，再更新数据库</h4><p>那换成「<strong>先更新缓存，再更新数据库</strong>」这个方案，还会有问题吗？<br>依然还是存在并发的问题，分析思路也是一样。<br>假设「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048401901-3a930743-97c8-43cc-bd20-4048fd50cb15.png#averageHue=%23f9f4f0&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=298&amp;id=u883c364d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=498&amp;originWidth=903&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60943&amp;status=done&amp;style=none&amp;taskId=u7d299ba2-91d9-42ce-9edb-d7a65b34e50&amp;title=&amp;width=540.0000610351562" alt="image.png"><br>A 请求先将缓存的数据更新为 1，然后在更新数据库前，B 请求来了， 将缓存的数据更新为 2，紧接着把数据库更新为 2，然后 A 请求将数据库的数据更新为 1。</p><p>此时，数据库中的数据是 1，而缓存中的数据却是 2，<strong>出现了缓存和数据库中的数据不一致的现象</strong>。<br>所以，<strong>无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong>。</p><h3 id="②先更新数据库，还是先删除缓存？"><a href="#②先更新数据库，还是先删除缓存？" class="headerlink" title="②先更新数据库，还是先删除缓存？"></a>②先更新数据库，还是先删除缓存？</h3><p>在更新数据时，<strong>不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。</strong><br>这个策略是有名字的，是叫 <strong>Cache Aside 策略</strong>，中文是叫旁路缓存策略。<br>该策略又可以细分为「读策略」和「写策略」。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048401883-e708111b-3173-4b57-bd3c-3c0df0016eed.png#averageHue=%23f8f4ee&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=456&amp;id=uc36ecc06&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=731&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=52333&amp;status=done&amp;style=none&amp;taskId=u31931878-d947-445d-9e93-efd0e681696&amp;title=&amp;width=539.0000610351562" alt="image.png"><br><strong>写策略的步骤：</strong></p><ul><li>更新数据库中的数据；</li><li>删除缓存中的数据。</li></ul><p><strong>读策略的步骤：</strong></p><ul><li>如果读取的数据命中了缓存，则直接返回数据；</li><li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li></ul><p>「写策略」的时候，到底该选择哪种顺序呢？</p><ul><li>先删除缓存，再更新数据库；</li><li>先更新数据库，再删除缓存。<h4 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h4>阿旺还是以用户表的场景来分析。<br>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048403571-2fab9040-7836-47e6-922b-73a9b0206e57.png#averageHue=%23f9f4f1&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=370&amp;id=u18dce6e2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=903&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59278&amp;status=done&amp;style=none&amp;taskId=u4c977828-fad0-425c-a444-a4d6986d15b&amp;title=&amp;width=541.0000610351562" alt="image.png"><br>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。<br>可以看到，<strong>先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题</strong>。<h4 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h4>继续用「读 + 写」请求的并发的场景来分析。<br>假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048403582-1976597e-758b-449c-96e6-478fa6d4c0b6.png#averageHue=%23f9f5f1&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=372&amp;id=u5218b060&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=618&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=56539&amp;status=done&amp;style=none&amp;taskId=u9952a21e-6d75-461d-a6e5-55a49b50018&amp;title=&amp;width=543.0000610351562" alt="image.png"><br>最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。<br>从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。<br><strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。<br>而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。<br>所以，<strong>「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的</strong>。<br>而且阿旺为了确保万无一失，还给缓存数据加上了「<strong>过期时间</strong>」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。</li></ul><p>「先更新数据库， 再删除缓存」其实是两个操作，前面的所有分析都是建立在这两个操作都能同时执行成功，而这次客户投诉的问题就在于，<strong>在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值</strong>。<br>好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。<br>所以新的问题来了，<strong>如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？</strong></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。<br>所以，<strong>如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况</strong>。<br>但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，就会因为写入顺序的不同造成数据的不一致。<br>所以我们得增加一些手段来解决这个问题，这里提供两种做法：</p><ul><li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li><li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</li></ul><p>对了，针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「<strong>延迟双删</strong>」。<br>延迟双删实现的伪代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#删除缓存</span><br><span class="line">redis.delKey(X)</span><br><span class="line">#更新数据库</span><br><span class="line">db.update(X)</span><br><span class="line">#睡眠</span><br><span class="line">Thread.sleep(N)</span><br><span class="line">#再删除缓存</span><br><span class="line">redis.delKey(X)</span><br></pre></td></tr></table></figure><br>加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。</p><p>所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。<br>但是具体睡眠多久其实是个<strong>玄学</strong>，很难评估出来，所以这个方案也只是<strong>尽可能</strong>保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。<br>因此，还是比较建议用「先更新数据库，再删除缓存」的方案。</p><hr><h3 id="前情回顾"><a href="#前情回顾" class="headerlink" title="前情回顾"></a>前情回顾</h3><p>上回程序员阿旺为了提升数据访问的性能，引入 Redis 作为 MySQL 缓存层，但是这件事情并不是那么简单，因为还要考虑 Redis 和 MySQL 双写一致性的问题。<br>阿旺经过一番周折，最终选用了「<strong>先更新数据库，再删缓存</strong>」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。<br>聪明的阿旺还搞了个兜底的方案，就是给缓存加上了过期时间。</p><p>「先更新数据库， 再删除缓存」其实是两个操作，这次客户投诉的问题就在于，<strong>在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值</strong>。<br>好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。<br>所以新的问题来了，<strong>如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？</strong></p><h3 id="如何保证两个操作都能执行成功？"><a href="#如何保证两个操作都能执行成功？" class="headerlink" title="如何保证两个操作都能执行成功？"></a>如何保证两个操作都能执行成功？</h3><p>这次用户的投诉是因为在删除缓存（第二个操作）的时候失败了，导致缓存还是旧值，而数据库是最新值，造成数据库和缓存数据不一致的问题，会对敏感业务造成影响。<br>举个例子，来说明下。<br>应用要把数据 X 的值从 1 更新为 2，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候数据库中 X 的新值为 2，Redis 中的 X 的缓存值为 1，出现了数据库和缓存数据不一致的问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048403660-03a28ca1-d85d-40ac-a2c1-71691f561be8.png#averageHue=%23faf8f3&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=263&amp;id=u60575151&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=504&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=103501&amp;status=done&amp;style=none&amp;taskId=u57fd60e9-7240-46e6-90b8-78841fea433&amp;title=&amp;width=564.0000610351562" alt="image.png"><br>那么，后续有访问数据 X 的请求，会先在 Redis 中查询，因为缓存并没有 诶删除，所以会缓存命中，但是读到的却是旧值 1。<br>其实不管是先操作数据库，还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。<br>问题原因知道了，该怎么解决呢？有两种方法：</p><ul><li>重试机制。</li><li>订阅 MySQL binlog，再操作缓存。</li></ul><p>先来说第一种。<br><strong>重试机制</strong><br>我们可以引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</p><ul><li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li><li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</li></ul><p>举个例子，来说明重试机制的过程。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048404181-b4cf7ff3-f6c3-430f-9691-193eaf49368e.png#averageHue=%23fbfaf8&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7a5a5bcc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=462&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=78821&amp;status=done&amp;style=none&amp;taskId=u9f4a9b1e-5201-4c55-8372-e5bea7ed8f6&amp;title=" alt="image.png"><br><strong>订阅 MySQL binlog，再操作缓存</strong><br>「<strong>先更新数据库，再删缓存</strong>」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。<br>于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。<br>Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。<br>下图是 Canal 的工作原理：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658048405735-ac7fe58f-ae61-49ea-8cef-3c990125baa4.png#averageHue=%23f7f6f4&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9f0f8245&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=332&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28059&amp;status=done&amp;style=none&amp;taskId=ub3d5c5c8-bfa2-44f0-8fa4-5517fbc7874&amp;title=" alt="image.png"><br>所以，<strong>如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。</strong></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分布式锁篇</title>
      <link href="/2022/08/09/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2022/08/09/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h2 id="如何用-Redis-实现分布式锁的？"><a href="#如何用-Redis-实现分布式锁的？" class="headerlink" title="如何用 Redis 实现分布式锁的？"></a>如何用 Redis 实现分布式锁的？</h2><p>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658646467551-ed3bd458-d969-4327-903e-6c3de256134e.png#averageHue=%23faf9f9&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=276&amp;id=k40Bl&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=674&amp;originWidth=1454&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=191505&amp;status=done&amp;style=none&amp;taskId=ud4e2bd3d-3bf2-4c4d-9d5c-f0aaaa7342e&amp;title=&amp;width=596.0000610351562" alt="image.png"><br>Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。<br>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p><ul><li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li><li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li></ul><p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p><ul><li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li><li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li><li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；</li></ul><p>满足这三个条件的分布式命令如下：<br>SET lock_key unique_value NX PX 10000  </p><ul><li>lock_key 就是 key 键；</li><li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li><li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li><li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</li></ul><p>而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。<br>可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] then</span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><br>这样一来，就通过使用 SET 命令和 Lua 脚本在 <strong>Redis 单节点</strong>上完成了分布式锁的加锁和解锁。<br>基于 Redis 实现分布式锁有什么优缺点？<br>基于 Redis 实现分布式锁的<strong>优点</strong>：</p><ol><li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li><li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li><li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li></ol><p>基于 Redis 实现分布式锁的<strong>缺点</strong>：</p><ul><li><strong>超时时间不好设置</strong>。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。<ul><li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li></ul></li><li><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</li></ul><p>Redis 如何解决集群情况下分布式锁的可靠性？<br>为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。<br>它是基于多个 Redis 节点的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。<br>Redlock 算法的基本思路，<strong>是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败</strong>。<br>这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。<br>Redlock 算法加锁三个过程：</p><ul><li>第一步是，客户端获取当前时间。</li><li>第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：<ul><li>加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。</li><li>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间）。</li></ul></li><li>第三步是，一旦客户端完成了和所有 Redis 节点的加锁操作，客户端就要计算整个加锁过程的总耗时（t1）。</li></ul><p>加锁成功要同时满足两个条件（<em>简述：如果有超过半数的 Redis 节点成功的获取到了锁，并且总耗时没有超过锁的有效时间，那么就是加锁成功</em>）：</p><ul><li>条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁；</li><li>条件二：客户端获取锁的总耗时（t1）没有超过锁的有效时间。</li></ul><p>加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁的最初有效时间」减去「客户端为获取锁的总耗时（t1）」。<br>加锁失败后，客户端向所有 Redis 节点发起释放锁的操作，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。</p><h3 id="Redisson源码解析"><a href="#Redisson源码解析" class="headerlink" title="Redisson源码解析"></a>Redisson源码解析</h3><p>在获取锁成功后，给锁加一个 watchdog，watchdog 会起一个定时任务，在锁没有被释放且快要过期的时候会续期</p><ul><li>缓存续命<ul><li>通过redisson新建出来的锁key，默认是30秒</li></ul></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713306349-ef8723f7-e830-4bdc-a5cd-2e346dfe58b1.png#averageHue=%23faf7f5&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=310&amp;id=jZQCh&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=387&amp;originWidth=634&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29984&amp;status=done&amp;style=none&amp;taskId=u56f6a589-1f06-4b8e-82e8-9d4c719ab93&amp;title=&amp;width=507.2" alt="image.png"></p><ul><li>加锁的逻辑会进入到scheduleExpirationRenewal</li><li>这里面初始化了一个定时器，dely 的时间是 internalLockLeaseTime/3。</li></ul><p>在 Redisson 中，internalLockLeaseTime 是 30s，也就是每隔 10s 续期一次，每次 30s。</p><ul><li>客户端A加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间，默认每次续命又从30秒新开始</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713570512-88b8e39e-f86c-46ac-bbc0-d4acfd1ffa4e.png#averageHue=%23fcf6f5&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=294&amp;id=Wsu1V&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=367&amp;originWidth=814&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=24478&amp;status=done&amp;style=none&amp;taskId=u3dc5952d-8c06-4e68-a6e2-91bbf647bed&amp;title=&amp;width=651.2" alt="image.png"></p><ul><li>加锁流程解释</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713775568-53ffa92c-70f0-425b-88cd-fff5b19893b0.png#averageHue=%23fdf9f7&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=340&amp;id=jSWPo&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=425&amp;originWidth=1110&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=119076&amp;status=done&amp;style=none&amp;taskId=u73d926f3-ffc3-4dd0-bc56-2ffcc8a6406&amp;title=&amp;width=888" alt="image.png"></p><ul><li>通过exists判断，如果锁不存在，则设置值和过期时间，加锁成功</li><li>通过hexists判断，如果锁已存在，并且锁的是当前线程，则证明是重入锁，加锁成功</li><li>如果锁已存在，但锁的不是当前线程，则证明有其他线程持有锁。</li></ul><p>返回当前锁的过期时间(代表了lockzzyy这个锁key的剩余生存时间)，加锁失败<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713831802-1634b987-6608-4eed-bbc8-59d40c840e40.png#averageHue=%23fbf5f4&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=170&amp;id=fi04U&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=212&amp;originWidth=553&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18432&amp;status=done&amp;style=none&amp;taskId=u76e6d89e-215e-4345-bbca-9fc0590683b&amp;title=&amp;width=442.4" alt="image.png"></p><h1 id="九、redis实现分布式锁"><a href="#九、redis实现分布式锁" class="headerlink" title="九、redis实现分布式锁"></a>九、redis实现分布式锁</h1><h2 id="演变过程："><a href="#演变过程：" class="headerlink" title="演变过程："></a>演变过程：</h2><ol><li><strong>使用synchronized或加ReentrantLock</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712058090-1631135e-b073-4c7e-8404-76b4e4530059.png#averageHue=%23fdfcfb&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=313&amp;id=yBfjG&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=391&amp;originWidth=860&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=24793&amp;status=done&amp;style=none&amp;taskId=u46bf712f-d22f-4234-810a-35feb0ba62f&amp;title=&amp;width=688" alt="image.png"><br>问题：在单机环境下，可以使用synchronized或Lock来实现。<br>但是在分布式系统中，因为竞争的线程可能不在同一个节点上（同一个jvm中），<br>所以需要一个让所有进程都能访问到的锁来实现(比如redis或者zookeeper来构建)<br>不同进程jvm层面的锁就不管用了，那么可以利用第三方的一个组件，来获取锁，未获取到锁，则阻塞当前想要运行的线程<br><strong>基于单个 Redis 节点实现分布式锁</strong></p><ol><li><strong>redis setnx</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712190688-2b8a55f7-b1ad-4d59-a0f6-88af403ddc62.png#averageHue=%23fdfaf9&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=430&amp;id=RQgTz&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=538&amp;originWidth=942&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=47854&amp;status=done&amp;style=none&amp;taskId=u884e00f1-85b2-43e7-ae22-2a524ddf4af&amp;title=&amp;width=753.6" alt="image.png"><br>问题：出异常的话，可能无法释放锁，必须要在代码层面finally释放锁</p><ol><li><strong>加锁解锁，lock/unlock必须同时出现并保证调用</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712248798-b963de90-837c-48a9-b19a-16edc1208f1f.png#averageHue=%23fef5f4&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=60&amp;id=nuCrG&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=75&amp;originWidth=398&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=2898&amp;status=done&amp;style=none&amp;taskId=udd64085e-e5a0-481f-a7bb-fd53b70ca6d&amp;title=&amp;width=318.4" alt="image.png"></p><ol><li><strong>部署了微服务jar包的机器挂了，代码层面根本没有走到finally这块，</strong></li></ol><p><strong>没办法保证解锁，这个key没有被删除，需要加入一个过期时间限定key</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712273024-25bfa158-235f-4455-9361-a80cb0d2efdb.png#averageHue=%23fef5f4&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=81&amp;id=m1Glp&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=101&amp;originWidth=752&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=7012&amp;status=done&amp;style=none&amp;taskId=uc7cedbed-9fb8-4528-aaff-2259b3cfafe&amp;title=&amp;width=601.6" alt="image.png"></p><ol><li><strong>设置key+过期时间分开了，必须要合并成一行具备原子性</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712296119-5e7f7cba-6f57-4145-83d0-e2b9e6e1175e.png#averageHue=%23fef7f5&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=65&amp;id=XBy0V&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=81&amp;originWidth=809&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=5637&amp;status=done&amp;style=none&amp;taskId=u19a0991c-3eba-4039-bc67-c7fff9831f0&amp;title=&amp;width=647.2" alt="image.png"></p><ol><li><strong>张冠李戴，删除了别人的锁</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712323105-ab84a647-4418-4b22-9a8a-62b0664be8cd.png#averageHue=%23fef7f6&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=86&amp;id=JI4wh&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=107&amp;originWidth=695&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6117&amp;status=done&amp;style=none&amp;taskId=u7416e73c-288a-4291-ae8e-bd2195e0666&amp;title=&amp;width=556" alt="image.png"></p><ol><li><strong>finally块的判断+del删除操作不是原子性的，Redis调用Lua脚本通过eval命令保证代码执行的原子性</strong></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712360995-a32d9417-36b0-464b-8e2e-d9aeebd56241.png#averageHue=%23fef9f8&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=387&amp;id=QXsxB&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=484&amp;originWidth=795&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=25311&amp;status=done&amp;style=none&amp;taskId=u4e082b19-1617-4713-8357-f1bb2dbe4c5&amp;title=&amp;width=636" alt="image.png"><br>截止到这里，基于单个Redis节点实现分布式锁</p><h2 id="Redis分布式锁-Redlock算法"><a href="#Redis分布式锁-Redlock算法" class="headerlink" title="Redis分布式锁-Redlock算法"></a>Redis分布式锁-Redlock算法</h2><p>Redisson是java的redis客户端之一，提供了一些api方便操作redis<br>多机案例：<br><strong>1. 基于setnx的分布式锁有什么缺点？</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648712578588-08416c50-53e9-4e4c-b3dc-e50fa17840ad.png#averageHue=%23f6f3df&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=306&amp;id=jb67Y&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=383&amp;originWidth=982&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61747&amp;status=done&amp;style=none&amp;taskId=ub640ef54-cb85-4368-811a-cace3a5bb54&amp;title=&amp;width=785.6" alt="image.png"></p><p>线程 1 首先获取锁成功，将键值对写入 redis 的 master 节点；<br>在 redis 将该键值对同步到 slave 节点之前，master 发生了故障；<br>redis 触发故障转移，其中一个 slave 升级为新的 master；<br>此时新的 master 并不包含线程 1 写入的键值对，因此线程 2 尝试获取锁也可以成功拿到锁；<br>此时相当于有两个线程获取到了锁，可能会导致各种预期之外的情况发生，例如最常见的脏数据。<br> 我们加的是排它独占锁，同一时间只能有一个建redis锁成功并持有锁，严禁出现2个以上的请求线程拿到锁。危险的</p><p><strong>redis之父提出了Redlock算法解决这个问题：</strong><br>Redis也提供了Redlock算法，用来实现基于多个实例的分布式锁。<br>锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。Redlock算法是实现高可靠分布式锁的一种有效解决方案，可以在实际开发中使用。<br><strong>2. Redlock算法设计理念</strong><br><strong>设计理念</strong>：该方案也是基于（set 加锁、Lua 脚本解锁）进行改良的，所以redis之父antirez 只描述了差异的地方，大致方案如下。<br>假设我们有N个Redis主节点，例如 N = 5这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统，<br>为了取到锁客户端执行以下操作：</p><ol><li>获取当前时间，以毫秒为单位；</li><li>依次尝试从5个实例，使用相同的 key 和随机值（例如 UUID）获取锁。当向Redis 请求获取锁时，客户端应该设置一个超时时间，这个超时时间应该小于锁的失效时间。</li><li>客户端通过当前时间减去步骤 1 记录的时间来计算获取锁使用的时间。当且仅当从大多数（N/2+1，这里是 3 个节点）的 Redis 节点都取到锁，并且获取锁使用的时间小于锁失效时间时，锁才算获取成功；</li><li>如果取到了锁，其真正有效时间等于初始有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。</li><li>如果由于某些原因未能获得锁（无法在至少 N/2 + 1 个 Redis 实例获取锁、或获取锁的时间超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li></ol><p>该方案为了解决数据不一致的问题，直接舍弃了异步复制只使用 master 节点，同时由于舍弃了 slave，为了保证可用性，引入了 N 个节点，官方建议是 5。<br>客户端只有在满足下面的这两个条件时，才能认为是加锁成功。<br>条件1：客户端从超过半数（大于等于N/2+1）的Redis实例上成功获取到了锁；<br>条件2：客户端获取锁的总耗时没有超过锁的有效时间。<br><strong>解决方案：</strong><br>为什么是奇数？  N = 2X + 1   (N是最终部署机器数，X是容错机器数)<br>1 先知道什么是容错<br>  失败了多少个机器实例后我还是可以容忍的，所谓的容忍就是数据一致性还是可以Ok的，CP数据一致性还是可以满足<br>  加入在集群环境中，redis失败1台，可接受。2X+1 = 2 <em> 1+1 =3，部署3台，死了1个剩下2个可以正常工作，那就部署3台。<br>  加入在集群环境中，redis失败2台，可接受。2X+1 = 2 </em> 2+1 =5，部署5台，死了2个剩下3个可以正常工作，那就部署5台。<br>2 为什么是奇数？<br>   最少的机器，最多的产出效果<br>  加入在集群环境中，redis失败1台，可接受。2N+2= 2 <em> 1+2 =4，部署4台<br>  加入在集群环境中，redis失败2台，可接受。2N+2 = 2 </em> 2+2 =6，部署6台<br><strong> 执行步骤</strong><br><strong>第一步是，客户端获取当前时间。</strong><br><strong>第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</strong><br>这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间。<br>如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。<br><strong>第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。</strong><br>客户端只有在满足下面的这两个条件时，才能认为是加锁成功。</p><ul><li>条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；</li><li>条件二：客户端获取锁的总耗时没有超过锁的有效时间。</li></ul><p>在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。当然，如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有 Redis 节点发起释放锁的操作。在 Redlock 算法中，释放锁的操作和在单实例上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。这样一来，只要 N 个 Redis 实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了。所以，在实际的业务应用中，如果你想要提升分布式锁的可靠性，就可以通过 Redlock 算法来实现。<br><strong>3. Redisson源码解析</strong><br>在获取锁成功后，给锁加一个 watchdog，watchdog 会起一个定时任务，在锁没有被释放且快要过期的时候会续期</p><ul><li>缓存续命<ul><li>通过redisson新建出来的锁key，默认是30秒</li></ul></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713306349-ef8723f7-e830-4bdc-a5cd-2e346dfe58b1.png#averageHue=%23faf7f5&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=310&amp;id=quW5b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=387&amp;originWidth=634&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29984&amp;status=done&amp;style=none&amp;taskId=u56f6a589-1f06-4b8e-82e8-9d4c719ab93&amp;title=&amp;width=507.2" alt="image.png"></p><ul><li>加锁的逻辑会进入到scheduleExpirationRenewal</li><li>这里面初始化了一个定时器，dely 的时间是 internalLockLeaseTime/3。</li></ul><p>在 Redisson 中，internalLockLeaseTime 是 30s，也就是每隔 10s 续期一次，每次 30s。</p><ul><li>客户端A加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间，默认每次续命又从30秒新开始</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713570512-88b8e39e-f86c-46ac-bbc0-d4acfd1ffa4e.png#averageHue=%23fcf6f5&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=294&amp;id=e7PJb&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=367&amp;originWidth=814&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=24478&amp;status=done&amp;style=none&amp;taskId=u3dc5952d-8c06-4e68-a6e2-91bbf647bed&amp;title=&amp;width=651.2" alt="image.png"></p><ul><li>加锁流程解释</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713775568-53ffa92c-70f0-425b-88cd-fff5b19893b0.png#averageHue=%23fdf9f7&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=340&amp;id=TOaPC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=425&amp;originWidth=1110&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=119076&amp;status=done&amp;style=none&amp;taskId=u73d926f3-ffc3-4dd0-bc56-2ffcc8a6406&amp;title=&amp;width=888" alt="image.png"></p><ul><li>通过exists判断，如果锁不存在，则设置值和过期时间，加锁成功</li><li>通过hexists判断，如果锁已存在，并且锁的是当前线程，则证明是重入锁，加锁成功</li><li>如果锁已存在，但锁的不是当前线程，则证明有其他线程持有锁。</li></ul><p>返回当前锁的过期时间(代表了lockzzyy这个锁key的剩余生存时间)，加锁失败<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648713831802-1634b987-6608-4eed-bbc8-59d40c840e40.png#averageHue=%23fbf5f4&amp;clientId=ud488f2a4-31f5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=170&amp;id=qoHHT&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=212&amp;originWidth=553&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18432&amp;status=done&amp;style=none&amp;taskId=u76e6d89e-215e-4345-bbca-9fc0590683b&amp;title=&amp;width=442.4" alt="image.png"></p><h2 id="Redis-如何实现延迟队列？"><a href="#Redis-如何实现延迟队列？" class="headerlink" title="Redis 如何实现延迟队列？"></a>Redis 如何实现延迟队列？</h2><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p><ul><li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；</li><li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；</li><li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；</li></ul><p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。<br>使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658646467285-57b96fe1-5be0-4d8c-ae07-f6b37148ed8a.png#averageHue=%23f0f0f0&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9997cc03&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=145&amp;originWidth=632&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=43357&amp;status=done&amp;style=none&amp;taskId=u4a845c6b-a274-43a8-9be0-67036e5548f&amp;title=" alt="image.png"></p><h2 id="Redis的大-key-如何处理？"><a href="#Redis的大-key-如何处理？" class="headerlink" title="Redis的大 key 如何处理？"></a>Redis的大 key 如何处理？</h2><p>什么是 Redis 大 key？<br>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。<br>一般而言，下面这两种情况被称为大 key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 元素的个数超过 5000个；</li></ul><p>如何找到大 key ？<br><em><strong>1、redis-cli —bigkeys 查找大key</strong></em><br>可以通过 redis-cli —bigkeys 命令查找大 key：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -p6379 -a <span class="string">&quot;password&quot;</span> -- bigkeys</span><br></pre></td></tr></table></figure><br>使用的时候注意事项：</p><ul><li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li><li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li></ul><p>该方式的不足之处：</p><ul><li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li><li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li></ul><p><em><strong>2、使用 SCAN 命令查找大key</strong></em><br>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。<br>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。<br>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p><ul><li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：LLEN 命令；Hash 类型：HLEN 命令；Set 类型：SCARD 命令；Sorted Set 类型：ZCARD 命令；</li><li>如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li></ul><p><em><strong>3、使用 RdbTools 工具查找大 key</strong></em><br>另外，可以使用 RdbTools 工具，比如下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdb dump.rdb -c memory --bytes <span class="number">10240</span> -f redis.csv</span><br></pre></td></tr></table></figure><br>如何删除大 key？<br>删除操作的本质是要释放键值对占用的内存空间。不要小瞧内存的释放过程。释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。<br>所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。<br>我们可以采用<strong>分批次删除</strong>的方式：</p><ul><li>对于 Hash，使用 hscan 扫描法；</li><li>对于 Set，采用 srandmember 每次随机取数据进程删除；</li><li>对于 ZSet，可以使用 zremrangebyrank 命令直接删除；</li><li>对于 List，直接 pop 即可了；</li></ul><p>另外，也可以采用<strong>异步删除</strong>法，用 unlink 命令代替 del 来删除，这样 Redis 会讲这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</p><h2 id="Redis-管道有什么用？"><a href="#Redis-管道有什么用？" class="headerlink" title="Redis 管道有什么用？"></a>Redis 管道有什么用？</h2><p>管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。<br>普通命令模式，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658646467351-03b26cf2-fbd1-4ddb-a067-83254d72f1a0.png#averageHue=%23f2eddb&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u54a222d3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=360&amp;originWidth=804&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=41873&amp;status=done&amp;style=none&amp;taskId=udc2bf0b9-3d74-4ff3-a0dc-a4846288fac&amp;title=" alt="image.png"><br>管道模式，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658646467364-fd9470ea-8e7b-4790-a9fe-a0009e1c053b.png#averageHue=%23f3eedb&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u481b8a4e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=360&amp;originWidth=804&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=39824&amp;status=done&amp;style=none&amp;taskId=u25c0a940-a535-4811-a7fb-121db0aa360&amp;title=" alt="image.png"><br>使用<strong>管道技术可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。<br>但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。<br>要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。</p><h2 id="Redis-事务支持回滚吗？"><a href="#Redis-事务支持回滚吗？" class="headerlink" title="Redis 事务支持回滚吗？"></a>Redis 事务支持回滚吗？</h2><p>MySQL 在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。<br><strong>Redis 中并没有提供回滚机制</strong>，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。<br>下面是 DISCARD 命令用法：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#读取 count 的值<span class="number">4</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; GET count</span><br><span class="line"><span class="string">&quot;1&quot;</span></span><br><span class="line">#开启事务</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; MULTI </span><br><span class="line">OK</span><br><span class="line">#发送事务的第一个操作，对count减<span class="number">1</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; DECR count</span><br><span class="line">QUEUED</span><br><span class="line">#执行DISCARD命令，主动放弃事务</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; DISCARD</span><br><span class="line">OK</span><br><span class="line">#再次读取a:stock的值，值没有被修改</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; GET count</span><br><span class="line"><span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure><br>事务执行过程中，如果命令入队时没报错，而事务提交后，实际执行时报错了，正确的命令依然可以正常执行，所以这可以看出 <strong>Redis 并不一定保证原子性</strong>（原子性：事务中的命令要不全部成功，要不全部失败）。<br>比如下面这个例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#获取name原本的值</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; GET name</span><br><span class="line"><span class="string">&quot;xiaolin&quot;</span></span><br><span class="line">#开启事务</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">#设置新值</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>(TX)&gt; GET name xialincoding</span><br><span class="line">QUEUED</span><br><span class="line">#注意，这条命令是错误的</span><br><span class="line"><span class="meta"># expire 过期时间正确来说是数字，并不是‘10s’字符串，但是还是入队成功了</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>(TX)&gt; EXPIRE name <span class="number">10</span>s</span><br><span class="line">QUEUED</span><br><span class="line">#提交事务，执行报错</span><br><span class="line">#可以看到 <span class="built_in">set</span> 执行成功，而 expire 执行错误。</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>(TX)&gt; EXEC</span><br><span class="line"><span class="number">1</span>) OK</span><br><span class="line"><span class="number">2</span>) (error) ERR value is not an integer or out of range</span><br><span class="line">#可以看到，name 还是被设置为新值了</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; GET name</span><br><span class="line"><span class="string">&quot;xialincoding&quot;</span></span><br></pre></td></tr></table></figure><br>为什么Redis 不支持事务回滚？<br>Redis <a href="https://redis.io/topics/transactions">官方文档(opens new window)</a>的解释如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658646468093-27aed757-279c-494b-88fa-b105581c1345.png#averageHue=%23fefbf8&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u27fe29e5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=792&amp;originWidth=1500&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=923400&amp;status=done&amp;style=none&amp;taskId=u15b8ff03-e562-443e-a8c0-3282f566691&amp;title=" alt="image.png"><br>大概的意思是，作者不支持事务回滚的原因有以下两个：</p><ul><li>他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；</li><li>不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。</li></ul><p>这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚。</p><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>持久化篇</title>
      <link href="/2022/08/09/redis/%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2022/08/09/redis/%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis-如何实现数据不丢失？"><a href="#Redis-如何实现数据不丢失？" class="headerlink" title="Redis 如何实现数据不丢失？"></a>Redis 如何实现数据不丢失？</h2><p>Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。<br>Redis 共有三种数据持久化的方式：</p><ul><li><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li><li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li><li><p><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RDB 的优点；</p><h2 id="ⅠRDB-快照（snapshotting）"><a href="#ⅠRDB-快照（snapshotting）" class="headerlink" title="ⅠRDB 快照（snapshotting）"></a>ⅠRDB 快照（snapshotting）</h2><h3 id="①概念："><a href="#①概念：" class="headerlink" title="①概念："></a>①概念：</h3></li><li><p>RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。</p></li><li><p>快照持久化是 Redis 默认采用的持久化方式。</p><h3 id="②触发方式"><a href="#②触发方式" class="headerlink" title="②触发方式"></a>②触发方式</h3><p>触发rdb持久化的方式有2种，分别是手动触发和自动触发。</p><h4 id="¶-手动触发："><a href="#¶-手动触发：" class="headerlink" title="¶ 手动触发："></a>¶ 手动触发：</h4><p>手动触发分别对应save和bgsave命令</p></li><li><p>save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用</p></li><li>bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短<blockquote><p><strong>bgsave具体流程如下：</strong></p><ol><li>redis客户端执行bgsave命令或者自动触发bgsave命令；</li><li>主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；</li><li>如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；</li><li>子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；</li></ol><p>同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence        下的rdb_*相关选项）。<br>bgsave流程图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649988149307-6bb18e26-9456-4354-8b7d-1f8e0f6f1470.png#averageHue=%23212121&amp;clientId=u3b371be1-c586-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=456&amp;id=u5b530bb8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=646&amp;originWidth=578&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32206&amp;status=done&amp;style=none&amp;taskId=u597de321-8468-4227-b963-48cc049743a&amp;title=&amp;width=408" alt="image.png"><a href="https://blog.csdn.net/weixin_43064185/article/details/122035596"></a></p></blockquote></li></ul><h4 id="¶-自动触发"><a href="#¶-自动触发" class="headerlink" title="¶ 自动触发"></a>¶ 自动触发</h4><p>在以下4种情况时会自动触发</p><ul><li>redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件；</li><li>主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点；</li><li>执行debug reload命令重新加载redis时也会触发bgsave操作；</li><li><p>默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作；</p><h3 id="③RDB-更深入理解"><a href="#③RDB-更深入理解" class="headerlink" title="③RDB 更深入理解"></a>③RDB 更深入理解</h3><p>执行快照时数据能被修改吗？<br>关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong><br><strong>概念</strong></p></li><li><p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。</p></li><li>只有在发生修改内存数据的情况时，物理内存才会被复制一份。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659423564170-1e1eef97-dee2-4b91-a164-4b7dc371e5f1.png#averageHue=%23f9f7f4&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=199&amp;id=PwWtn&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=707&amp;originWidth=774&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55470&amp;status=done&amp;style=none&amp;taskId=u3664a963-f7aa-4eb7-9557-bfb02777d8d&amp;title=&amp;width=218" alt="image.png">                        <img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659423564133-e4d1d710-c5ff-4af6-8bed-2c8c2cfdc61f.png#averageHue=%23faf9f6&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=202&amp;id=ud88e94a3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=707&amp;originWidth=969&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59927&amp;status=done&amp;style=none&amp;taskId=u308a7143-58cf-4176-a84c-ddce850a332&amp;title=&amp;width=277.0000305175781" alt="image.png"></p><ul><li>这样的目的是为了减少创建子进程时的性能损耗，从而加快创建子进程的速度，毕竟创建子进程的过程中，是会阻塞主线程的。</li></ul><p>所以，创建 bgsave 子进程后，由于共享父进程的所有内存数据，于是就可以直接读取主线程（父进程）里的内存数据，并将数据写入到 RDB 文件。</p><ul><li>当主线程（父进程）对这些共享的内存数据也都是只读操作，那么，主线程（父进程）和 bgsave 子进程相互不影响。</li><li>但是，如果主线程（父进程）要<strong>修改共享数据里的某一块数据</strong>（比如键值对 A）时，就会发生写时复制，于是这块数据的<strong>物理内存就会被复制一份（键值对 A’）</strong>，然后<strong>主线程在这个数据副本（键值对 A’）进行修改操作</strong>。与此同时，<strong>bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件</strong>。</li></ul><p>就是这样，Redis 使用 bgsave 对当前内存中的所有数据做快照，这个操作是由 bgsave 子进程在后台完成的，执行时不会阻塞主线程，这就使得主线程同时可以修改数据。</p><blockquote><p><strong>会产生的问题：</strong></p><ul><li>细心的同学，肯定发现了，bgsave 快照过程中，如果主线程修改了共享数据，<strong>发生了写时复制后，RDB 快照保存的是原本的内存数据</strong>，而主线程刚修改的数据，是没有办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。</li><li>所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据。</li><li>如果系统恰好在 RDB 快照文件创建完毕后崩溃了，那么 Redis 将会丢失主线程在快照期间修改的数据。</li></ul><p>另外，写时复制的时候会出现这么个极端的情况。<br>在 Redis 执行 RDB 持久化期间，刚 fork 时，主进程和子进程共享同一物理内存，但是途中主进程处理了写操作，修改了共享内存，于是当前被修改的数据的物理内存就会被复制一份。<br>那么极端情况下，<strong>如果所有的共享内存都被修改，则此时的内存占用是原先的 2 倍。</strong><br>所以，针对写操作多的场景，我们要留意下快照过程中内存的变化，防止内存被占满了。</p></blockquote><p>在进行快照操作的这段时间，如果发生服务崩溃怎么办？<br>很简单，在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。</p><p>可以每秒做一次快照吗？</p><blockquote><p>对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。</p><p>如下图所示，我们先在 T0 时刻做了一次快照，然后又在 T0+t 时刻做了一次快照，在这期间，数据块 5 和 9 被修改了。如果在 t 这段时间内，机器宕机了，那么，只能按照 T0 时刻的快照进行恢复。此时，数据块 5 和 9 的修改值因为没有快照记录，就无法恢复了。 　　<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649988751186-ec8901c1-8d2a-4687-88ee-7a1bc82fd427.png#averageHue=%23f5f9ea&amp;clientId=u3b371be1-c586-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uaabbad03&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1244&amp;originWidth=3292&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=428670&amp;status=done&amp;style=none&amp;taskId=u03ef6f2e-67b8-4ae6-affb-23efef9fd0e&amp;title=" alt="image.png"></p><p>所以，要想尽可能恢复数据，t 值就要尽可能小，t 越小，就越像“连拍”。那么，t 值可以小到什么程度呢，比如说是不是可以每秒做一次快照？毕竟，每次快照都是由 bgsave 子进程在后台执行，也不会阻塞主线程。</p></blockquote><p>这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销：</p><ul><li>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</li><li>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。</li></ul><p>那么，有什么其他好方法吗？此时，我们可以做增量快照，就是指做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。这个比较好理解。</p><p>但是它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？且看后文中4.0版本中引入的RDB和AOF的混合方式。<br>为什么要fork子进程而不是用子线程去做<br>如果子线程去做备份的时候没法保证数据的一致性，因为子线程会共享内存，如果需要单独的内存需要重新copy一份内存这样对于性能而言是非常不适合的</p><p>这样也能解释为什么要在fork完子进程的时候，要把redis的键值空间设置为禁止rehash<br>，因为redis是采用的渐进式hash的方式，如果处于rehash 无论set 或者get方式都会对旧的空间进行更改，这样就会不断的触发页帧写的异常，而需要分配更多的内存空间，这样对于性能还是受比较多的影响，但是rdb触发并没有判断是否处于rehash状态，所以rdb的方案是在必须执行的条件下，在rdb过程中尽量减少对页帧的修改而不是完全禁止。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424665766-0fb78334-caaf-4b70-b9c9-631f04479fb4.png#averageHue=%23f9f7f4&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=270&amp;id=X0qTu&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=707&amp;originWidth=774&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55420&amp;status=done&amp;style=none&amp;taskId=u1deabaee-2824-486e-a1cc-3afedd366ea&amp;title=&amp;width=296.0000305175781" alt="image.png"></p><h3 id="④RDB优缺点"><a href="#④RDB优缺点" class="headerlink" title="④RDB优缺点"></a>④RDB优缺点</h3><p>优点</p><ul><li>RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；</li><li>Redis加载RDB文件恢复数据要远远快于AOF方式；</li></ul><p>缺点</p><ul><li>RDB方式实时性不够，无法做到秒级的持久化；</li><li>每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；</li><li>RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全；</li><li>版本兼容RDB文件问题；</li></ul><p>针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决</p><h2 id="ⅡAOF（append-only-file）日志"><a href="#ⅡAOF（append-only-file）日志" class="headerlink" title="ⅡAOF（append-only file）日志"></a>ⅡAOF（append-only file）日志</h2><p>概念-&gt;为什么采用写后日志-&gt;如何实现aof-&gt;aof重写</p><h3 id="①概念"><a href="#①概念" class="headerlink" title="①概念"></a>①概念</h3><p>Redis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。<strong>注意只会记录写操作命令，读操作命令是不会被记录的</strong></p><blockquote><p>PS: 大多数的数据库采用的是写前日志（WAL），例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。<br>而AOF日志采用写后日志，即<strong>先写内存，后写日志</strong>。</p></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649988962678-07f7b0d1-1620-4302-bf51-936f978e493b.png#averageHue=%23f8f7e2&amp;clientId=u3b371be1-c586-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=290&amp;id=u57ae3b30&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1789&amp;originWidth=3218&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=429445&amp;status=done&amp;style=none&amp;taskId=u891c58ec-6c84-46c5-ba1b-66cc37bbb11&amp;title=&amp;width=522.0000610351562" alt="image.png"></p><h3 id="②为什么采用写后日志？"><a href="#②为什么采用写后日志？" class="headerlink" title="②为什么采用写后日志？"></a>②为什么采用写后日志？</h3><p>Redis要求高性能，采用写日志有两方面好处：</p><ul><li><strong>避免额外的检查开销</strong>：Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。</li><li><strong>不会阻塞当前的写操作</strong></li></ul><p>但这种方式存在潜在风险：</p><ul><li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。</li><li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。<h3 id="③AOF的三种写回策略"><a href="#③AOF的三种写回策略" class="headerlink" title="③AOF的三种写回策略"></a>③AOF的三种写回策略</h3>先来看看，Redis 写入 AOF 日志的过程，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658046514287-4d692f81-fe56-4195-83d5-b8975994f915.png#averageHue=%23fbf9f6&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=420&amp;id=ueae20460&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=977&amp;originWidth=860&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=74638&amp;status=done&amp;style=none&amp;taskId=u8990f4a3-8baa-41bd-aea5-beed32c25da&amp;title=&amp;width=370.0000305175781" alt="image.png"><br>具体说说：</li></ul><ol><li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；</li><li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li><li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li></ol><p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：</p><ul><li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><p>我也把这 3 个写回策略的优缺点总结成了一张表格：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658046514278-06da027c-cb6c-44a0-b063-43555ddf8d60.png#averageHue=%23f0eee4&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=253&amp;id=u39761324&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=362&amp;originWidth=857&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=71731&amp;status=done&amp;style=none&amp;taskId=u0dd55520-15d0-41e3-9309-741f6b588a6&amp;title=&amp;width=598.0000610351562" alt="image.png"><br>大家知道这三种策略是怎么实现的吗？<br>深入到源码后，你就会发现这三种策略只是在控制 <strong>fsync() </strong>函数的调用时机。<br>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424326811-66975244-80d6-47f0-b2f4-c31f012af7d2.png#averageHue=%23f9f5f2&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=370&amp;id=u74b75b90&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=647&amp;originWidth=527&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=43161&amp;status=done&amp;style=none&amp;taskId=u0221a56b-f366-447d-8756-5e5b3931288&amp;title=&amp;width=301.0000305175781" alt="image.png"><br>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><ul><li>Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li><li>Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li><li>No 策略就是永不执行 fsync() 函数;<h3 id="④redis-conf中配置AOF👌"><a href="#④redis-conf中配置AOF👌" class="headerlink" title="④redis.conf中配置AOF👌"></a>④redis.conf中配置AOF👌</h3>详细内容默认情况下，Redis是没有开启AOF的，可以通过配置redis.conf文件来开启AOF持久化，关于AOF的配置如下：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># appendonly参数开启AOF持久化</span><br><span class="line">appendonly no</span><br><span class="line"> </span><br><span class="line"># AOF持久化的文件名，默认是appendonly.aof</span><br><span class="line">appendfilename <span class="string">&quot;appendonly.aof&quot;</span></span><br><span class="line"> </span><br><span class="line"># AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的</span><br><span class="line">dir ./</span><br><span class="line"> </span><br><span class="line"># 同步策略</span><br><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"> </span><br><span class="line"># aof重写期间是否同步</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"> </span><br><span class="line"># 重写触发配置</span><br><span class="line">auto-aof-rewrite-percentage <span class="number">100</span></span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"> </span><br><span class="line"># 加载aof出错如何处理</span><br><span class="line">aof-load-truncated yes</span><br><span class="line"> </span><br><span class="line"># 文件重写策略</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br></pre></td></tr></table></figure>以下是Redis中关于AOF的主要配置信息：</li></ul><p>appendonly：默认情况下AOF功能是关闭的，将该选项改为yes以便打开Redis的AOF功能。</p><p>appendfilename：这个参数项很好理解了，就是AOF文件的名字。</p><p>appendfsync：这个参数项是AOF功能最重要的设置项之一，主要用于设置“真正执行”操作命令向AOF文件中同步的策略。</p><p>什么叫“真正执行”呢？还记得Linux操作系统对磁盘设备的操作方式吗？ 为了保证操作系统中I/O队列的操作效率，应用程序提交的I/O操作请求一般是被放置在linux Page Cache中的，然后再由Linux操作系统中的策略自行决定正在写到磁盘上的时机。而Redis中有一个fsync()函数，可以将Page Cache中待写的数据真正写入到物理设备上，而缺点是频繁调用这个fsync()函数干预操作系统的既定策略，可能导致I/O卡顿的现象频繁 。</p><p>与上节对应，appendfsync参数项可以设置三个值，分别是：always、everysec、no，默认的值为everysec。</p><p>no-appendfsync-on-rewrite：always和everysec的设置会使真正的I/O操作高频度的出现，甚至会出现长时间的卡顿情况，这个问题出现在操作系统层面上，所有靠工作在操作系统之上的Redis是没法解决的。为了尽量缓解这个情况，Redis提供了这个设置项，保证在完成fsync函数调用时，不会将这段时间内发生的命令操作放入操作系统的Page Cache（这段时间Redis还在接受客户端的各种写操作命令）。</p><p>auto-aof-rewrite-percentage：上文说到在生产环境下，技术人员不可能随时随地使用“BGREWRITEAOF”命令去重写AOF文件。所以更多时候我们需要依靠Redis中对AOF文件的自动重写策略。Redis中对触发自动重写AOF文件的操作提供了两个设置：auto-aof-rewrite-percentage表示如果当前AOF文件的大小超过了上次重写后AOF文件的百分之多少后，就再次开始重写AOF文件。例如该参数值的默认设置值为100，意思就是如果AOF文件的大小超过上次AOF文件重写后的1倍，就启动重写操作。</p><p>auto-aof-rewrite-min-size：参考auto-aof-rewrite-percentage选项的介绍，auto-aof-rewrite-min-size设置项表示启动AOF文件重写操作的AOF文件最小大小。如果AOF文件大小低于这个值，则不会触发重写操作。注意，auto-aof-rewrite-percentage和auto-aof-rewrite-min-size只是用来控制Redis中自动对AOF文件进行重写的情况，如果是技术人员手动调用“BGREWRITEAOF”命令，则不受这两个限制条件左右。</p><h3 id="⑤AOF-重写机制"><a href="#⑤AOF-重写机制" class="headerlink" title="⑤AOF 重写机制"></a>⑤AOF 重写机制</h3><ul><li>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。</li><li>如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。</li><li>所以，Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</li></ul><p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p><blockquote><p>举个例子，在没有使用重写机制前，假设前后执行了「<em>set name xiaolin</em>」和「<em>set name xiaolincoding</em>」这两个命令的话，就会将这两个命令记录到 AOF 文件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424665802-0f158b7f-eb3f-49c4-a0a9-e5fe317840dd.png#averageHue=%23f8f3ea&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uae25c102&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=423&amp;originWidth=1667&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=92170&amp;status=done&amp;style=none&amp;taskId=ua85d1661-e8ff-474f-84ce-6b312edcc1d&amp;title=" alt="image.png"><br>但是<strong>在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件</strong>，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。<br>重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。<br>然后，在通过 AOF 日志恢复数据时，只用执行这条命令，就可以直接完成这个键值对的写入了。</p></blockquote><p>所以，重写机制的妙处在于，尽管某个键值对被多条写命令反复修改，<strong>最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对</strong>，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。</p><p>这里说一下为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去。<br>因为<strong>如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染</strong>，可能无法用于恢复使用。所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。</p><h3 id="⑥AOF-后台重写"><a href="#⑥AOF-后台重写" class="headerlink" title="⑥AOF 后台重写"></a>⑥AOF 后台重写</h3><blockquote><p>写入 AOF 日志的操作虽然是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。<br>但是在触发 AOF 重写时，比如当 AOF 文件大于 64M 时，就会对 AOF 文件进行重写，这时是需要读取所有缓存的键值对数据，并为每个键值对生成一条命令，然后将其写入到新的 AOF 文件，重写完后，就把现在的 AOF 文件替换掉。<br>这个过程其实是很耗时的，所以重写的操作不能放在主进程里。</p></blockquote><p>所以，Redis 的<strong>重写 AOF**</strong> 过程是由后台子进程 <em>bgrewriteaof</em> 来完成的**，这么做可以达到两个好处：</p><ul><li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</li><li>子进程带有主进程的数据副本（<em>数据副本怎么产生的后面会说</em>），这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</li></ul><p>AOF重写会阻塞吗？<br>AOF重写过程是由后台进程<strong>bgrewriteaof</strong>来完成的。主线程fork出后台的bgrewriteaof子进程，所以aof在重写时，在fork进程时是会阻塞住主线程的。<br>子进程是怎么拥有主进程一样的数据副本的呢？</p><ul><li>主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「<strong>页表</strong>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424665766-0fb78334-caaf-4b70-b9c9-631f04479fb4.png#averageHue=%23f9f7f4&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=237&amp;id=u156d05d6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=707&amp;originWidth=774&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55420&amp;status=done&amp;style=none&amp;taskId=u1deabaee-2824-486e-a1cc-3afedd366ea&amp;title=&amp;width=260.0000305175781" alt="image.png"></p><ul><li>这样一来，子进程就共享了父进程的物理内存数据了，这样能够<strong>节约物理内存资源</strong>，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</li><li>不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发<strong>缺页中断</strong>，这个缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行<strong>物理内存的复制</strong>，并重新设置其内存映射关系，将父子进程的内存读写权限设置为<strong>可读写</strong>，最后才会对内存进行写操作，这个过程被称为「<strong>写时复制(<em>Copy On Write</em>)</strong>」。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424665766-42d77f86-beac-450b-9392-ade1cfa0421b.png#averageHue=%23faf9f6&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=255&amp;id=u58769d28&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=707&amp;originWidth=969&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59657&amp;status=done&amp;style=none&amp;taskId=u204d1544-3e86-4f96-81a9-0dfa68be94a&amp;title=&amp;width=349.0000305175781" alt="image.png"><br>写时复制顾名思义，<strong>在发生写操作的时候，操作系统才会去复制物理内存</strong>，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。<br>当然，操作系统复制父进程页表的时候，父进程也是阻塞中的，不过页表的大小相比实际的物理内存小很多，所以通常复制页表的过程是比较快的。<br>不过，如果父进程的内存数据非常大，那自然页表也会很大，这时父进程在通过 fork 创建子进程的时候，阻塞的时间也越久。</p><p>所以，有两个阶段会导致阻塞父进程：</p><ul><li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；<blockquote><p>触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。<br>但是子进程重写过程中，主进程依然可以正常处理命令。<br>如果此时<strong>主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的</strong>。</p></blockquote></li></ul><p>所以如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险。<br>在重写日志整个过程时，主线程有哪些地方会被阻塞？</p><ol><li>fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。</li><li>主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。</li><li>子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。</li></ol><p>还有个问题，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？（重写日志时，有新数据写入怎么办）<br>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。<br>在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659424665795-2102abc0-f421-4068-a3c8-ff83cdaf42a4.png#averageHue=%23f9f8f3&amp;clientId=u8c49ffa9-bcbc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=352&amp;id=uee417517&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=947&amp;originWidth=1412&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=121562&amp;status=done&amp;style=none&amp;taskId=u1eaaefd8-080d-4cec-a733-82ed7989b17&amp;title=&amp;width=525.0000610351562" alt="image.png"><br>也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</p><ul><li>执行客户端发来的命令；</li><li>将执行后的写命令追加到 「AOF 缓冲区」；</li><li>将执行后的写命令追加到 「AOF 重写缓冲区」；<blockquote><p>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。<br>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p><ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li><li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li></ul><p>信号函数执行完后，主进程就可以继续像往常一样处理命令了。<br>在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程</p></blockquote></li></ul><h2 id="Ⅲ为什么会有混合持久化？"><a href="#Ⅲ为什么会有混合持久化？" class="headerlink" title="Ⅲ为什么会有混合持久化？"></a>Ⅲ为什么会有混合持久化？</h2><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p><p>AOF 优点是丢失数据少，但是数据恢复不快。</p><p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。<br>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658046888525-4811d472-4ffd-417e-be71-03a97b56d10f.png#averageHue=%23fbf0cd&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1db06f95&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=356&amp;originWidth=325&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=39512&amp;status=done&amp;style=none&amp;taskId=u206c8f4f-b6a6-47ca-8377-947e4b22a5b&amp;title=" alt="image.png"><br>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。<br>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。<br><strong>混合持久化优点：</strong></p><ul><li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li></ul><p><strong>混合持久化缺点：</strong></p><ul><li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li><li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基础篇</title>
      <link href="/2022/08/09/%E8%AE%A1%E7%BD%91/%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2022/08/09/%E8%AE%A1%E7%BD%91/%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="①OSI七层模型及各层功能概述"><a href="#①OSI七层模型及各层功能概述" class="headerlink" title="①OSI七层模型及各层功能概述"></a>①OSI七层模型及各层功能概述</h2><blockquote><p>1.OSI的基本概念及原则<br>OSI是Open System Interconnect的缩写，意为开放式系统互联。其各个层次的划分遵循下列原则：<br>    （1）同一层中的各网络节点都有相同的层次结构，具有同样的功能。<br>    （2）同一节点内相邻层之间通过接口进行通信。<br>    （3）七层结构中的每一层使用下一层提供的服务，并且向其上层提供服务。<br>    （4）不同节点的同等层按照协议实现对等层之间的通信。<br>2.OSI七层模型各层功能概述<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1660702352856-126c1d6b-170b-4fb6-9da3-a227e1de6838.png#averageHue=%23fdfdf0&amp;clientId=u9cc8d833-cc45-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u4c102f5c&amp;name=image.png&amp;originHeight=584&amp;originWidth=847&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=45412&amp;status=done&amp;style=none&amp;taskId=u3e37a60f-f9d5-4260-86aa-4ec1be8daae&amp;title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1660702348158-a4680ace-7497-4a5a-99ef-eac0f33c3565.gif#averageHue=%238ba955&amp;clientId=u9cc8d833-cc45-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u8d58dd07&amp;originHeight=1587&amp;originWidth=1120&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uac849643-7048-4c0b-8b22-49b739d10ff&amp;title=" alt=""></p></blockquote><p><strong>第一层：物理层</strong><br>        在OSI参考模型中，物理层是参考模型的最低层，也是OSI模型的第一层。<strong>物理层的主要功能是</strong>：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异，使其上面的数据链路层不必考虑网络的具体传输介质是什么。<br><strong>第二层：数据链路层</strong><br>       数据链路层（Data Link Layer）是OSI模型的第二层，负责建立和管理节点间的链路。在计算机网络中由于各种干扰的存在，导致物理链路是不可靠的。<strong>因此这一层的主要功能是：</strong>在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路，即提供可靠的通过物理介质传输数据的方法。</p><p><strong>第三层：网络层✊</strong><br>       网络层（Network Layer）是OSI模型的第三层，它是OSI参考模型中最复杂的一层，也是通信子网的最高一层，它在下两层的基础上向资源子网提供服务。<strong>其主要功能是</strong>：在数据链路层提供的两个相邻端点之间的数据帧的传送功能上，进一步管理网络中的数据通信，控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接，将数据设法从源端经过若干个中间节点传送到目的端（点到点），从而向传输层提供最基本的端到端的数据传输服务。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。<br><strong>数据链路层和网络层的区别为：数据链路层的目的是解决同一网络内节点之间的通信，而网络层主要解决不同子网间的通信。</strong></p><p><strong>第四层：传输层</strong><br>       OSI下3层的任务是数据通信，上3层的任务是数据处理。而传输层（Transport Layer）是OSI模型的第4层。该层提供建立、维护和拆除传输连接的功能，起到承上启下的作用。<strong>该层的主要功能是：</strong>向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输，同时向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。<br><strong>第五层：会话层</strong><br>       会话层是OSI模型的第5层，是用户应用程序和网络之间的接口，<strong>该层的主要功能是：</strong>组织和协调两个会话进程之间的通信  ，并对数据交换进行管理。当建立会话时，用户必须提供他们想要连接的远程地址。而这些地址与MAC地址或网络层的逻辑地址不同，它们是为用户专门设计的，更便于用户记忆。域名就是一种网络上使用的远程地址。会话层的具体功能如下：</p><ul><li>会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。</li><li>会话流量控制：提供会话流量控制和交叉会话功能。</li><li>寻址：使用远程地址建立会话连接。</li><li>出错控制：从逻辑上讲会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠正错误。</li></ul><p><strong>第六层：表示层</strong><br>       表示层是OSI模型的第六层，它对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。<strong>该层的主要功能是：</strong>处理用户信息的表示问题，如编码、数据格式转换和加密解密等。表示层的具体功能如下：</p><ul><li>数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。</li><li>数据的编码：处理字符集和数字的转换。</li><li>压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。</li><li>数据的加密和解密：可以提高网络的安全性。</li></ul><p><strong>第七层：应用层</strong><br>      应用层是OSI参考模型的最高层，它是计算机用户，以及各种应用程序和网络之间的接口，<strong>该层的主要功能是：</strong>直接向用户提供服务，完成用户希望在网络上完成的各种工作。它在其他6层工作的基础上，负责完成网络中应用程序与网络操作系统之间的联系，建立与结束使用者之间的联系，并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外该层还负责协调各个应用程序间的工作。应用层的具体功能如下：</p><blockquote><p>用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。<br>实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。<br>3.OSI七层模型举例<br>       举例：以A公司向B公司发送一次商业报价单为例。<br>（用户只管发送商业报价单，具体怎么实现不关心）<br>       应用层：A公司相当于实际的电脑用户，要发送的商业报价单相当于应用层提供的一种网络服务，当然A公司也可以选择其他服务，比如发一份商业合同，发一份询价单等等。</p><pre><code>   表示层：由于A公司和B公司是不同国家的公司，他们之间商定统一用英语作为交流语言，所以此时A公司的文秘（表示层）将从上级手中（应用层）获取到的商业报价单的语言转翻译成英语，同时为了防止被别的公司盗取机密信息，A公司的文秘也会对这份报价单做一些加密的处理。这就是表示层的作用，将应用层的数据转换翻译。   会话层：A公司外联部同事（会话层）掌握着其他许多公司的联系方式，他们负责管理本公司与外界许多公司的联系会话。当外联部同事拿到文秘（表示层）转换成英文的商业报价单后，他首先要找到B公司的地址信息，并附上自己的地址和联系方式，然后将整份资料放进信封准备寄出。等确认B公司接收到此报价单后，外联部的同事就去办其他的事情了，继而终止此次会话。   传输层：传输层就相当于A公司中的负责收发快递邮件的人，A公司自己的投递员负责将上一层（会话层）要寄出的资料投递到快递公司或邮局。   网络层：网络层就相当于快递公司庞大的快递网络，全国不同的集散中心，比如说从深圳发往北京的顺丰快递，首先要到顺丰的深圳集散中心，从深圳集散中心再送到武汉集散中心，从武汉集散中心再寄到北京顺义集散中心。这个每个集散中心，就相当于网络中的一个IP节点。   数据链路层：相当于顺丰快递内部为了保证效率和质量的一种内部操作。   物理层：快递寄送过程中的交通工具，就相当于物理层，例如汽车，火车，飞机，船。</code></pre><p>4.OSI七层模型总结<br>       应用层：产生网络流量的程序<br>       表示层：传输之前是否进行加密或者压缩处理<br>       会话层：查看会话，查木马  netstat-n<br>       传输层：可靠传输、流量控制、不可靠传输<br>       网络层：负责选择最佳路径、规划ip地址<br>       数据链路层：帧的开始和结束、透明传输、差错校验<br>       物理层：接口标准、电器标准、如何更快传输数据</p></blockquote><h2 id="②TCP-IP-网络模型有哪几层？"><a href="#②TCP-IP-网络模型有哪几层？" class="headerlink" title="②TCP/IP 网络模型有哪几层？"></a>②TCP/IP 网络模型有哪几层？</h2><p><strong>应用层</strong></p><ul><li>最上层的，也是用户能直接接触到的就是<strong>应用层</strong>（<em>Application Layer</em>），我们电脑或手机使用的应用软件都是在应用层实现。</li><li>当两个不同设备的应用需要通信的时候（比如请求一个url地址），应用就把应用数据传给下一层，也就是传输层。所以，应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。</li><li>应用层是不用去关心数据是如何传输的。</li><li>而且应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。</li></ul><p><strong>传输层</strong></p><ul><li>该层提供建立、维护和拆除传输连接的功能，起到承上启下的作用。<strong>该层的主要功能是：</strong>向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输，同时向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。</li><li>应用层的数据包会传给传输层，<strong>传输层</strong>（<em>Transport Layer</em>）是为应用层提供网络支持的。<blockquote><ul><li>在传输层会有两个传输协议，分别是 TCP 和 UDP。<ul><li>TCP 的全称叫传输控制协议（<em>Transmission Control Protocol</em>），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。</li><li>UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以。</li></ul></li></ul></blockquote></li></ul><blockquote><p>可以讲也可以不讲下述！！</p><ul><li>应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 <strong>TCP 段</strong>（<em>TCP Segment</em>）。</li><li>当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是<strong>端口</strong>。<ul><li>比如 80 端口通常是 Web 服务器用的，22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。</li><li>由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。</li></ul></li></ul></blockquote><p><strong>网络层</strong></p><ul><li>网络环节是错综复杂的，中间有各种各样的线路和分叉路口，如果一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是<strong>网络层</strong>（<em>Internet Layer</em>）。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657443215483-ee56a4d4-a0ee-4e82-ac39-eb489e34cae4.png#averageHue=%23fbf1ea&amp;clientId=u7fc47fd7-29de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=372&amp;id=ua71ae4df&amp;name=image.png&amp;originHeight=467&amp;originWidth=602&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54341&amp;status=done&amp;style=none&amp;taskId=ua58541bd-f7fa-4942-b649-d49ca198975&amp;title=&amp;width=479" alt="image.png"></p><ul><li>网络层最常使用的是 IP 协议（<em>Internet Protocol</em>），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会<strong>再次进行分片</strong>，得到一个即将发送到网络的 IP 报文。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657443215651-9b56b99f-07ef-44bc-90d1-13d6e9343564.png#averageHue=%23f8f6f3&amp;clientId=u7fc47fd7-29de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u94e3ee19&amp;name=image.png&amp;originHeight=702&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=282029&amp;status=done&amp;style=none&amp;taskId=u95050033-a6f6-4f0d-9535-57f0ffd6be6&amp;title=" alt="image.png"></p><ul><li>网络层负责将数据从一个设备传输到另一个设备，世界上那么多设备，又该如何找到对方呢？因此，网络层需要有区分设备的编号。我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。只有一个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然不科学。<blockquote><p>因此，需要将 IP 地址分成两种意义：</p><ul><li>一个是<strong>网络号</strong>，负责标识该 IP 地址是属于哪个「子网」的；</li><li>一个是<strong>主机号</strong>，负责标识同一「子网」下的不同主机；</li></ul></blockquote></li></ul><p>所以，<strong>IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘</strong>。<br><strong>网络接口层</strong><br>生成了 IP 头部之后，接下来要交给<strong>网络接口层</strong>（<em>Link Layer</em>）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657443218134-777ec172-68ed-4804-b577-2f52567308c4.png#averageHue=%23fbf2ec&amp;clientId=u7fc47fd7-29de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=479&amp;id=u126c5ec8&amp;name=image.png&amp;originHeight=647&amp;originWidth=602&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=81570&amp;status=done&amp;style=none&amp;taskId=u278c2f53-6ed1-4ff7-80d1-a8407a80b4d&amp;title=&amp;width=446" alt="image.png"></p><blockquote><ul><li>IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。</li><li>什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。</li><li>以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。</li><li>MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。</li></ul></blockquote><p>所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。<br><strong>总结</strong><br>综上所述，TCP/IP 网络通常是由上到下分成 4 层，分别是<strong>应用层，传输层，网络层和网络接口层</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657443218242-c4da4987-9c9b-4ad2-b88c-dca8499c678f.png#averageHue=%23faf3ee&amp;clientId=u7fc47fd7-29de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=499&amp;id=u61f2c07c&amp;name=image.png&amp;originHeight=782&amp;originWidth=602&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=109007&amp;status=done&amp;style=none&amp;taskId=u4e31ed15-73f1-4c7a-8e3d-8db51a28fe6&amp;title=&amp;width=384" alt="image.png"><br>再给大家贴一下每一层的封装格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657443218251-7c4696b0-d28d-440c-8207-dfae489161b9.png#averageHue=%23cfdec7&amp;clientId=u7fc47fd7-29de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=262&amp;id=uefa593ed&amp;name=image.png&amp;originHeight=501&amp;originWidth=905&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=114165&amp;status=done&amp;style=none&amp;taskId=uf086af48-6229-4265-a6c5-d95ce941148&amp;title=&amp;width=473.00006103515625" alt="image.png"><br>网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。</p><h2 id="Ⅱ-键入网址到网页显示，期间发生了什么？"><a href="#Ⅱ-键入网址到网页显示，期间发生了什么？" class="headerlink" title="Ⅱ 键入网址到网页显示，期间发生了什么？"></a>Ⅱ 键入网址到网页显示，期间发生了什么？</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693681794-ab95d680-f343-4db3-9811-019cfc331134.png#averageHue=%23f5d38d&amp;clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf1791288&amp;name=image.png&amp;originHeight=759&amp;originWidth=1803&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=391299&amp;status=done&amp;style=none&amp;taskId=ud3319096-ec88-488f-8ff7-1143c8b5789&amp;title=" alt="image.png"><br><strong>孤单小弟 —— HTTP</strong><br>首先浏览器做的第一步工作就是要对 URL 进行解析（ex:<a href="http://xiaolingcoding.com/network），对">http://xiaolingcoding.com/network），对</a> URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。<br>补充让我们看看一条长长的 URL 里的各个元素的代表什么，见下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697146120-0eaffaf2-ce17-48fc-ba62-d9501e014a64.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7f273c5b&amp;name=image.png&amp;originHeight=1879&amp;originWidth=1503&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=698740&amp;status=done&amp;style=none&amp;taskId=u4001fc2c-d715-4e8a-a32e-b99fee9b91c&amp;title=" alt="image.png"><br>所以图中的长长的 URL 实际上是请求服务器里的文件资源。<br>要是上图中的蓝色部分 URL 元素都省略了，那应该是请求哪个文件呢？<br>当没有路径名时，就代表访问根目录下事先设置的<strong>默认文件</strong>，也就是 /index.html 或者 /default.html 这些文件，这样就不会发生混乱了。</p><hr><p><strong>真实地址查询 —— DNS</strong></p><ul><li>通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。</li><li>但在发送之前，需要<strong>查询服务器域名对应的 IP 地址</strong>，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。</li><li>所以，有一种服务器就专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。<blockquote><p>域名解析的工作流程</p><ol><li>客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。</li><li>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</li><li>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</li><li>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”</li><li>顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</li><li>本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ol><p>那是不是每次解析域名都要经过那么多的步骤呢？<br>当然不是了，还有缓存这个东西的嘛。<br>浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。</p></blockquote></li></ul><hr><p><strong>指南好帮手 —— 协议栈</strong><br>通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的<strong>协议栈</strong>。</p><blockquote><ul><li>协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。</li></ul></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693687669-c8d589a6-9b9c-4d63-b264-37e2614a08d1.png#averageHue=%23f4f3f1&amp;clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=483&amp;id=u5fe9b7ad&amp;name=image.png&amp;originHeight=917&amp;originWidth=903&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=292464&amp;status=done&amp;style=none&amp;taskId=u15805e64-e072-4c16-a449-368c4e228d0&amp;title=&amp;width=476" alt="image.png"></p><ul><li>应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。</li><li><p>协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。此外 IP 中还包括 ICMP 协议和 ARP 协议。</p><blockquote><ul><li>ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。</li><li>ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。</li></ul></blockquote></li><li><p>IP 下面的网卡驱动程序负责控制网卡硬件。</p></li><li>最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。</li></ul><p>因此数据包首先会去找TCP</p><hr><p><strong>可靠传输 —— TCP</strong><br>TCP 传输数据之前，要先三次握手建立连接<br>在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为<strong>三次握手</strong>。<br>三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p><blockquote><p>TCP 分割数据<br>如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693688071-59415224-0bce-4bbc-a10e-3845661f2894.png#averageHue=%23f6f6f6&amp;clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=262&amp;id=u6bb05fcd&amp;name=image.png&amp;originHeight=422&amp;originWidth=1067&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=152459&amp;status=done&amp;style=none&amp;taskId=uc1ea9916-de4d-4447-a30a-802f2422711&amp;title=&amp;width=663" alt="image.png"></p><ul><li>MTU：一个网络包的最大长度，以太网中一般为 1500 字节。</li><li>MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。</li></ul><p>数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。</p></blockquote><p>生成TCP 报文<br>TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。<br>在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。</p><blockquote><p>至此，网络包的报文如下图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1662517186369-5e734a82-607f-49be-b055-319822ef0f12.png#averageHue=%23e0c784&amp;clientId=ua55694af-8f3a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=473&amp;id=u2554d26e&amp;name=image.png&amp;originHeight=1038&amp;originWidth=1233&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=481140&amp;status=done&amp;style=none&amp;taskId=u78c64cda-3b4e-4d57-885a-02129591fb0&amp;title=&amp;width=562.0000610351562" alt="image.png"></p></blockquote><hr><p><strong>远程定位 —— IP</strong></p><ul><li>TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成<strong>网络包</strong>发送给通信对象。<blockquote><p>假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？<br>当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。<br>这个时候就需要根据<strong>路由表</strong>规则，来判断哪一个网卡作为源地址 IP。<br>在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697846448-95954a6c-1e50-4a1a-8b4b-719d55e2698e.png#averageHue=%23efece2&amp;clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0a3d5734&amp;name=image.png&amp;originHeight=242&amp;originWidth=917&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=127964&amp;status=done&amp;style=none&amp;taskId=uddb3b7a4-1074-4119-b102-61ff75ae284&amp;title=" alt="image.png"><br>举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697847054-50cf2092-6cbc-4264-838b-f3f0678d0db4.png#averageHue=%23f9f8f4&amp;clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u87662db5&amp;name=image.png&amp;originHeight=1313&amp;originWidth=1442&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=557965&amp;status=done&amp;style=none&amp;taskId=u028833be-2bcf-433f-9cba-eec866148ec&amp;title=" alt="image.png"></p><ol><li>首先先和第一条目的子网掩码（Genmask）进行 <strong>与运算</strong>，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。</li><li>再与第二条目的子网掩码进行 <strong>与运算</strong>，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。</li></ol><p>那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。<br>第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示<strong>默认网关</strong>，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。</p></blockquote></li></ul><p>补充IP 包头格式<br>我们先看看 IP 报文头部的格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697533750-0b343333-6117-47e4-83d6-9896798f1348.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=652&amp;id=u61d06504&amp;name=image.png&amp;originHeight=1203&amp;originWidth=603&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=174834&amp;status=done&amp;style=none&amp;taskId=udb9e54b5-9ffd-4a13-b7d6-f093e303ea0&amp;title=&amp;width=327" alt="image.png"><br>在 IP 协议里面需要有<strong>源地址 IP</strong> 和 <strong>目标地址 IP</strong>：</p><ul><li>源地址IP，即是客户端输出的 IP 地址；</li><li>目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。</li></ul><p>因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的<strong>协议号</strong>，要填写为 06（十六进制），表示协议为 TCP。</p><p>IP 报文生成<br>至此，网络包的报文如下图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697492339-60d52f64-3d23-4502-8ce5-76f732e42a64.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udae87ec0&amp;name=image.png&amp;originHeight=1818&amp;originWidth=1233&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=827461&amp;status=done&amp;style=none&amp;taskId=ua9a5e3a4-9015-4686-beb0-efbaae4ea56&amp;title=" alt="image.png"><br>然后就是生成ip</p><hr><p><strong>两点传输 —— MAC</strong><br>生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 <strong>MAC 头部</strong>。<br>MAC 发送方和接收方如何确认?<br><strong>发送方</strong>的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。<br><strong>接收方</strong>的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。<br>所以先得搞清楚应该把包发给谁，这个只要查一下<strong>路由表</strong>就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。<br>既然知道要发给谁，按如何获取对方的 MAC 地址呢？<br>不知道对方 MAC 地址？不知道就喊呗。<br>此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697717756-f195d142-da3f-4244-8dff-2095e6b74528.png#averageHue=%23f8f8f5&amp;clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=354&amp;id=u63b2832d&amp;name=image.png&amp;originHeight=498&amp;originWidth=594&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=170276&amp;status=done&amp;style=none&amp;taskId=u5a0e1d60-8536-46f2-aec4-ae660e7e88b&amp;title=&amp;width=422" alt="image.png"><br>ARP 协议会在以太网中以<strong>广播</strong>的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。<br>然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。<br>如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。<br>好像每次都要广播获取，这不是很麻烦吗？<br>放心，在后续操作系统会把本次查询结果放到一块叫做 <strong>ARP 缓存</strong>的内存空间留着以后用，不过缓存的时间就几分钟。<br>也就是说，在发包时：</p><ul><li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li><li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。</li></ul><p>查看 ARP 缓存内容<br>在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697717673-89dc0cd9-0dac-46b2-9501-cd533f333ef9.png#averageHue=%23f2ebd8&amp;clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uaf64f2df&amp;name=image.png&amp;originHeight=183&amp;originWidth=671&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58558&amp;status=done&amp;style=none&amp;taskId=u08231123-0aca-4e47-9376-9a557aacb38&amp;title=" alt="image.png"><br>补充MAC 包头格式<br>MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697591087-5caa2efe-1652-4220-8be7-92b4368f91e3.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1e9f4767&amp;name=image.png&amp;originHeight=558&amp;originWidth=558&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=90271&amp;status=done&amp;style=none&amp;taskId=ub93ff98d-c9a4-4d41-9bbf-cf1d85a9c81&amp;title=" alt="image.png"><br>在 MAC 包头里需要<strong>发送方 MAC 地址</strong>和<strong>接收方目标 MAC 地址</strong>，用于<strong>两点之间的传输</strong>。<br>一般在 TCP/IP 通信里，MAC 包头的<strong>协议类型</strong>只使用：</p><ul><li>0800 ： IP 协议</li><li>0806 ： ARP 协议</li></ul><p>MAC 报文生成<br>至此，网络包的报文如下图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657697592023-d8a00b58-faa4-4f16-9dd2-e6e5d7d33816.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ude025c1e&amp;name=image.png&amp;originHeight=2373&amp;originWidth=1235&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=968828&amp;status=done&amp;style=none&amp;taskId=u4f476f7b-8a0b-43bc-aff2-10e2c82d9cb&amp;title=" alt="image.png"></p><p>此时，加上了 MAC 头部的数据包万分感谢，说道 ：“感谢 MAC 大佬，我知道我下一步要去哪了！我现在有很多头部兄弟，相信我可以到达最终的目的地！”。 带着众多头部兄弟的数据包，终于准备要出门了。</p><hr><p><strong>出口 —— 网卡</strong></p><ul><li>网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将<strong>数字信息转换为电信号</strong>，才能在网线上传输，也就是说，这才是真正的数据发送过程。</li><li>负责执行这一操作的是<strong>网卡</strong>，要控制网卡还需要靠<strong>网卡驱动程序</strong>。<br>补充</li><li>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693702216-d0af5826-f43b-45b3-8e7f-06e2d1a83577.png#clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Rxyeq&amp;name=image.png&amp;originHeight=392&amp;originWidth=968&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=128661&amp;status=done&amp;style=none&amp;taskId=u63ac4744-c875-4113-b7ec-e89fd0b8bed&amp;title=" alt="image.png"></p><ul><li>起始帧分界符是一个用来表示包起始位置的标记</li><li>末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏</li></ul><p>最后网卡会将包转为电信号，通过网线发送出去。<br>唉，真是不容易，发一个包，真是历经千辛万苦。致此，一个带有许多头部的数据终于踏上寻找目的地的征途了！</p><hr><p><strong>送别者 —— 交换机</strong><br>下面来看一下包是如何通过交换机的。交换机的设计是将网络包<strong>原样</strong>转发到目的地。<strong>交换机工作在 MAC 层</strong>，也称为<strong>二层网络设备</strong>。</p><p>补充交换机的包接收操作<br>首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。<br>然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。<br>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。<br>将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。<br>交换机的 MAC 地址表主要包含两个信息：</p><ul><li>一个是设备的 MAC 地址，</li><li>另一个是该设备连接在交换机的哪个端口上。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657698055979-852c43f8-b5a1-4752-a85a-a3dd5b972b3f.png#clientId=u6faf5e84-3205-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5a07ec13&amp;name=image.png&amp;originHeight=629&amp;originWidth=947&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=274560&amp;status=done&amp;style=none&amp;taskId=uff77b4a5-08e3-4504-afd5-1faf4339c93&amp;title=" alt="image.png"><br>举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。<br>所以，<strong>交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口</strong>。<br>当 MAC 地址表找不到指定的 MAC 地址会怎么样？<br>地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。<br>这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。<br>这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后<strong>只有相应的接收者才接收包，而其他设备则会忽略这个包</strong>。<br>有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”<br>其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。<br>局域网中每秒可以传输上千个包，多出一两个包并无大碍。<br>此外，如果接收方 MAC 地址是一个<strong>广播地址</strong>，那么交换机会将包发送到除源端口之外的所有端口。<br>以下两个属于广播地址：</p><ul><li>MAC 地址中的 FF:FF:FF:FF:FF:FF</li><li>IP 地址中的 255.255.255.255</li></ul><p>数据包通过交换机转发抵达了路由器，准备要离开土生土长的子网了。此时，数据包和交换机离别时说道：“感谢交换机兄弟，帮我转发到出境的大门，我要出远门啦！”</p><hr><p><strong>出境大门 —— 路由器</strong><br>通过路由器找到目的地<br>补充路由器与交换机的区别<br>网络包经过交换机之后，现在到达了<strong>路由器</strong>，并在此被转发到下一个路由器或目标设备。<br>这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。<br>不过在具体的操作过程上，路由器和交换机是有区别的。</p><ul><li>因为<strong>路由器</strong>是基于 IP 设计的，俗称<strong>三层</strong>网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；</li><li>而<strong>交换机</strong>是基于以太网设计的，俗称<strong>二层</strong>网络设备，交换机的端口不具有 MAC 地址。</li></ul><p>路由器基本原理<br>路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。<br>当转发包时，首先路由器端口会接收发给自己的以太网包，然后<strong>路由表</strong>查询转发目标，再由相应的端口作为发送方将以太网包发送出去。<br>路由器的包接收操作<br>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。<br>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。<br>总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。<br>查询路由表确定输出端口<br>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。<br><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。<br>接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。<br>转发操作分为几个阶段，首先是查询<strong>路由表</strong>判断转发目标。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693706047-990a18a5-9bd6-4a09-9c87-fae12ef9cfc0.png#clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=353&amp;id=PXVTd&amp;name=image.png&amp;originHeight=798&amp;originWidth=1260&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=385830&amp;status=done&amp;style=none&amp;taskId=uc3914457-0f23-4f84-8618-929c8c40f6f&amp;title=&amp;width=558" alt="image.png"><br>具体的工作流程根据上图，举个例子。<br>假设地址为 10.10.1.101 的计算机要向地址为 192.168.1.100 的服务器发送一个包，这个包先到达图中的路由器。<br>判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。<br>路由匹配和前面讲的一样，每个条目的子网掩码和 192.168.1.100 IP 做 <strong>&amp; 与运算</strong>后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。<br>如第二条目的子网掩码 255.255.255.0 与 192.168.1.100 IP 做 <strong>&amp; 与运算</strong>后，得到结果是 192.168.1.0 ，这与第二条目的目标地址 192.168.1.0 匹配，该第二条目记录就会被作为转发目标。<br>实在找不到匹配路由时，就会选择<strong>默认路由</strong>，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。<br>路由器的发送操作<br>接下来就会进入包的<strong>发送操作</strong>。<br>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p><ul><li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li><li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li></ul><p>知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。<br>路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。<br>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。<br>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。<br>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。<br>接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。<br>不知你发现了没有，在网络包传输的过程中，<strong>源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址</strong>，因为需要 MAC 地址在以太网内进行<strong>两个设备</strong>之间的包传输。</p><p>数据包通过多个路由器道友的帮助，在网络世界途经了很多路程，最终抵达了目的地的城门！城门值守的路由器，发现了这个小兄弟数据包原来是找城内的人，于是它就将数据包送进了城内，再经由城内的交换机帮助下，最终转发到了目的地了。数据包感慨万千的说道：“多谢这一路上，各路大侠的相助！”</p><hr><p><strong>互相扒皮 —— 服务器 与 客户端</strong><br>服务器一层一层<br>补充数据包抵达了服务器，服务器肯定高兴呀，正所谓有朋自远方来，不亦乐乎？<br>服务器高兴的不得了，于是开始扒数据包的皮！就好像你收到快递，能不兴奋吗？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652693706158-46e9eb80-5d19-4357-b5fc-cfad2ea1608e.png#averageHue=%23e6d8b4&amp;clientId=ua5e7c927-1424-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=543&amp;id=C5beG&amp;name=image.png&amp;originHeight=953&amp;originWidth=936&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=473371&amp;status=done&amp;style=none&amp;taskId=u583246bd-5fd4-4029-a07c-f762eb6fddb&amp;title=&amp;width=533" alt="image.png"><br>数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。<br>接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。<br>于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。<br>于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。<br>服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。<br>HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。<br>穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。<br>最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。<br>客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！<br>于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！<br>最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。</p><h2 id="Ⅲcookie和session"><a href="#Ⅲcookie和session" class="headerlink" title="Ⅲcookie和session"></a>Ⅲcookie和session</h2><h3 id="①共同之处："><a href="#①共同之处：" class="headerlink" title="①共同之处："></a>①共同之处：</h3><p>cookie和session都是用来跟踪浏览器用户身份的会话方式。</p><h3 id="②工作原理："><a href="#②工作原理：" class="headerlink" title="②工作原理："></a>②工作原理：</h3><p>1.Cookie的工作原理<br>（1）浏览器端第一次发送请求到服务器端<br>（2）<strong>服务器端创建Cookie</strong>，该Cookie中包含用户的信息，然后将该Cookie发送到浏览器端<br>（3）浏览器端再次访问服务器端时会携带服务器端创建的Cookie<br>（4）服务器端通过Cookie中携带的数据区分不同的用户</p><p>2.Session的工作原理<br>（1）浏览器端第一次发送请求到服务器端，服务器端创建一个Session，同时会创建一个特殊的Cookie（name为JSESSIONID的固定值，value为session对象的ID），然后将该Cookie发送至浏览器端<br>（2）浏览器端发送第N（N&gt;1）次请求到服务器端,浏览器端访问服务器端时就会携带该name为JSESSIONID的Cookie对象<br>（3）服务器端根据name为JSESSIONID的Cookie的value(sessionId),去查询Session对象，从而区分不同用户。</p><ul><li>name为JSESSIONID的Cookie不存在（关闭或更换浏览器），返回1中重新去创建Session与特殊的Cookie</li><li>name为JSESSIONID的Cookie存在，根据value中的SessionId去寻找session对象</li><li>value为SessionId不存在<strong>（Session对象默认存活30分钟）</strong>，返回1中重新去创建Session与特殊的Cookie</li><li>value为SessionId存在，返回session对象</li></ul><p>Session的工作原理图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658456759691-e0e00ffa-c156-4594-a3f9-8e9d0815d8f1.png#averageHue=%23fcf8f8&amp;clientId=u6dc524c5-d932-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u563a1056&amp;name=image.png&amp;originHeight=379&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=23670&amp;status=done&amp;style=none&amp;taskId=u0be23b20-0090-4920-b273-6179234cec5&amp;title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658456769430-da3726e4-e2e9-403e-bc6e-8e395ce338e2.png#averageHue=%23f8f8f8&amp;clientId=u6dc524c5-d932-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf400a554&amp;name=image.png&amp;originHeight=410&amp;originWidth=630&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=38981&amp;status=done&amp;style=none&amp;taskId=ufa0e248a-f74b-4c6a-b5d5-9c20d7ae481&amp;title=" alt="image.png"></p><h3 id="③Cookie和Session的区别？"><a href="#③Cookie和Session的区别？" class="headerlink" title="③Cookie和Session的区别？"></a>③Cookie和Session的区别？</h3><ul><li><strong>作用范围不同</strong>，Cookie 保存在客户端，Session 保存在服务器端。</li><li><strong>有效期不同</strong>，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。</li><li><strong>隐私策略不同</strong>，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。</li><li><strong>存储大小不同</strong>， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。<br>补充cookie数据保存在客户端，session数据保存在服务端。</li></ul><p>session<br>简单的说，当你登陆一个网站的时候，如果web服务器端使用的是session，那么所有的数据都保存在服务器上，客户端每次请求服务器的时候会发送当前会话sessionid，服务器根据当前sessionid判断相应的用户数据标志，以确定用户是否登陆或具有某种权限。由于数据是存储在服务器上面，所以你不能伪造。</p><p>cookie<br>sessionid是服务器和客户端连接时候随机分配的，如果浏览器使用的是cookie，那么所有数据都保存在浏览器端，比如你登陆以后，服务器设置了cookie用户名，那么当你再次请求服务器的时候，浏览器会将用户名一块发送给服务器，这些变量有一定的特殊标记。服务器会解释为cookie变量，所以只要不关闭浏览器，那么cookie变量一直是有效的，所以能够保证长时间不掉线。</p><p>如果你能够截获某个用户的cookie变量，然后伪造一个数据包发送过去，那么服务器还是 认为你是合法的。所以，使用cookie被攻击的可能性比较大。</p><p>如果cookie设置了有效值，那么cookie会保存到客户端的硬盘上，下次在访问网站的时候，浏览器先检查有没有cookie，如果有的话，读取cookie，然后发送给服务器。</p><p>所以你在机器上面保存了某个论坛cookie，有效期是一年，如果有人入侵你的机器，将你的cookie拷走，放在他机器下面，那么他登陆该网站的时候就是用你的身份登陆的。当然，伪造的时候需要注意，直接copy cookie文件到 cookie目录，浏览器是不认的，他有一个index.dat文件，存储了 cookie文件的建立时间，以及是否有修改，所以你必须先要有该网站的 cookie文件，并且要从保证时间上骗过浏览器</p><p>两个都可以用来存私密的东西，session过期与否，取决于服务器的设定。cookie过期与否，可以在cookie生成的时候设置进去。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java容器</title>
      <link href="/2022/08/09/java/Java%E5%AE%B9%E5%99%A8/"/>
      <url>/2022/08/09/java/Java%E5%AE%B9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ集合概述"><a href="#Ⅰ集合概述" class="headerlink" title="Ⅰ集合概述"></a>Ⅰ集合概述</h2><h3 id="①Java-集合概览"><a href="#①Java-集合概览" class="headerlink" title="①Java 集合概览"></a>①Java 集合概览</h3><p>Java 集合， 也叫作容器，主要是由两大接口派生而来：</p><ul><li>一个是 Collection接口，主要用于存放单一元素；<ul><li>对于Collection 接口，下面又有三个主要的子接口：List、Set 和 Queue。</li></ul></li><li>另一个是 Map 接口，主要用于存放键值对。</li></ul><p>Java 集合框架如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647571525662-aaf32cc4-03ed-465c-86ee-91796006cb71.png#averageHue=%23fdfdfd&amp;clientId=u6441117b-7d6c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udcc75149&amp;margin=%5Bobject%20Object%5D&amp;originHeight=646&amp;originWidth=1024&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ufcd66ced-11f3-4ba5-946b-90411ea86d4&amp;title=" alt=""><br>注：图中只列举了主要的继承派生关系，并没有列举所有关系。比方省略了AbstractList, NavigableSet等抽象类以及其他的一些辅助类，如想深入了解，可自行查看源码。</p><h3 id="②说说-List-Set-Queue-Map-四者的区别？"><a href="#②说说-List-Set-Queue-Map-四者的区别？" class="headerlink" title="②说说 List, Set, Queue, Map 四者的区别？"></a>②说说 List, Set, Queue, Map 四者的区别？</h3><ul><li>List(对付顺序的好帮手): 存储的元素是有序的、可重复的。</li><li>Set(注重独一无二的性质): 存储的元素是无序的、不可重复的。</li><li>Queue(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。</li><li><p>Map(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，”x” 代表 key，”y” 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。</p><h3 id="③集合框架底层数据结构总结"><a href="#③集合框架底层数据结构总结" class="headerlink" title="③集合框架底层数据结构总结"></a>③集合框架底层数据结构总结</h3><p>先来看一下 Collection 接口下面的集合。</p><h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4></li><li><p>Arraylist： Object[] 数组</p></li><li>Vector：Object[] 数组</li><li><p>LinkedList： 双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)</p><h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4></li><li><p>HashSet(无序，唯一): 基于 HashMap 实现的，底层采用 HashMap 来保存元素</p></li><li>LinkedHashSet: LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的 LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的</li><li><p>TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树)</p><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4></li><li><p>PriorityQueue: Object[] 数组来实现二叉堆</p></li><li>ArrayDeque: 可变长的数组 + 双指针</li></ul><p>再来看看 Map 接口下面的集合。</p><h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4><ul><li>HashMap： JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间</li><li>LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。</li><li>Hashtable： 数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在的</li><li><p>TreeMap： 红黑树（自平衡的排序二叉树）</p><h3 id="④如何选用集合"><a href="#④如何选用集合" class="headerlink" title="④如何选用集合?"></a>④如何选用集合?</h3><p>主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用 Map 接口下的集合，需要排序时选择 TreeMap,不需要排序时就选择 HashMap,需要保证线程安全就选用 ConcurrentHashMap。<br>当我们只需要存放元素值时，就选择实现Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。</p><h3 id="⑤为什么要使用集合？"><a href="#⑤为什么要使用集合？" class="headerlink" title="⑤为什么要使用集合？"></a>⑤为什么要使用集合？</h3><p>当我们需要保存一组类型相同的数据的时候，我们应该是用一个容器来保存，这个容器就是数组，但是，使用数组存储对象具有一定的弊端， 因为我们在实际开发中，存储的数据的类型是多种多样的，于是，就出现了“集合”，集合同样也是用来存储多个数据的。<br>数组的缺点是一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 但是集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。</p><h2 id="ⅡCollection-子接口之-List"><a href="#ⅡCollection-子接口之-List" class="headerlink" title="ⅡCollection 子接口之 List"></a>ⅡCollection 子接口之 List</h2><h3 id="①Arraylist-和-Vector-的区别"><a href="#①Arraylist-和-Vector-的区别" class="headerlink" title="①Arraylist 和 Vector 的区别?"></a>①Arraylist 和 Vector 的区别?</h3></li><li><p>ArrayList 是 List 的主要实现类，底层使用 Object[ ]存储，适用于频繁的查找工作，线程不安全 ；</p></li><li>Vector 是 List 的古老实现类，底层使用Object[ ] 存储，线程安全的。<h3 id="✊②Arraylist-与-LinkedList-区别"><a href="#✊②Arraylist-与-LinkedList-区别" class="headerlink" title="✊②Arraylist 与 LinkedList 区别?"></a>✊②Arraylist 与 LinkedList 区别?</h3></li></ul><ol><li><strong>是否保证线程安全：</strong> ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；</li><li><strong>底层数据结构：</strong> Arraylist 底层使用的是 <strong>Object 数组</strong>；LinkedList 底层使用的是 <strong>双向链表</strong> 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）</li><li><strong>插入和删除是否受元素位置的影响：</strong><ul><li>ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。</li><li>LinkedList 采用链表存储，所以，如果是在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst() 、 removeLast()），近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。</li></ul></li><li><strong>是否支持快速随机访问：</strong> LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。</li><li><p><strong>内存空间占用：</strong> ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。</p><h3 id="✊③ArrayList-的扩容机制-以jdk1-7为例"><a href="#✊③ArrayList-的扩容机制-以jdk1-7为例" class="headerlink" title="✊③ArrayList 的扩容机制 以jdk1.7为例"></a>✊③ArrayList 的扩容机制 以jdk1.7为例</h3></li><li><p>以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 将指定的元素追加到此列表的末尾。</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">add</span><span class="params">(E e)</span> &#123;</span><br><span class="line"> <span class="comment">//添加元素之前，先调用ensureCapacityInternal方法</span></span><br><span class="line">      ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></span><br><span class="line">      <span class="comment">//这里看到ArrayList添加元素的实质就相当于为数组赋值</span></span><br><span class="line">      elementData[size++] = e;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>以JDK7为例，当添加第一个元素时调用 add 方法 add方法里面调用了ensureCapacityInternal(size + 1)，此时参数<strong>minCapacity </strong>为 1，在 通过Math.max()方法跟默认的容量比较后，minCapacity 为 10。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//得到最小扩容量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">ensureCapacityInternal</span><span class="params">(<span class="type">int</span> minCapacity)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;</span><br><span class="line">              <span class="comment">// 获取默认的容量和传入参数的较大值</span></span><br><span class="line">            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ensureExplicitCapacity(minCapacity);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>接着会进入<strong>ensureExplicitCapacity（）</strong>方法</p></li></ol><ul><li>由于此时添加第一个元素的时候，此时数组的长度也就是elementData.length 为 0 （因为还是一个空的 list）。此时，<strong>minCapacity - elementData.length &gt; 0</strong>成立，所以会进入 grow(minCapacity) 方法。<blockquote><ul><li>当 add 第 2 个元素时，minCapacity 为 2，此时 e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。</li><li>添加第 3、4···到第 10 个元素时，依然不会执行 grow 方法，数组容量都为 10。</li></ul><p>直到添加第 11 个元素，minCapacity(为 11)比 elementData.length（为 10）要大。进入 grow 方法进行扩容。<strong>int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！</strong> 奇偶不同，比如 ：10+10/2 = 15, 33+33/2=49。如果是奇数的话会丢掉小数.</p></blockquote></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//判断是否需要扩容</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">ensureExplicitCapacity</span><span class="params">(<span class="type">int</span> minCapacity)</span> &#123;</span><br><span class="line">       modCount++;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// overflow-conscious code</span></span><br><span class="line">       <span class="keyword">if</span> (minCapacity - elementData.length &gt; <span class="number">0</span>)</span><br><span class="line">           <span class="comment">//调用grow方法进行扩容，调用此方法代表已经开始扩容了</span></span><br><span class="line">           grow(minCapacity);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>进入grow方法，<strong>newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1)</strong>，由于此时oldCapacity 为 0，经比较后第一个 if 判断成立，newCapacity = 传进来的参数minCapacity(为 10)。调用Arrays.copyof方法扩容。至此添加第一个元素的过程结束</li><li>之后添加的元素直到添加第11个元素才会再次进入grow方法，此时<strong>int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！</strong></li><li><strong>扩容都是调用</strong>Arrays.copyOf(elementData, newCapacity);方法进行扩容的<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 要分配的最大数组大小</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">MAX_ARRAY_SIZE</span> <span class="operator">=</span> Integer.MAX_VALUE - <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * ArrayList扩容的核心方法。</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">grow</span><span class="params">(<span class="type">int</span> minCapacity)</span> &#123;</span><br><span class="line">      <span class="comment">// oldCapacity为旧容量，newCapacity为新容量</span></span><br><span class="line">      <span class="type">int</span> <span class="variable">oldCapacity</span> <span class="operator">=</span> elementData.length;</span><br><span class="line">      <span class="comment">//将oldCapacity 右移一位，其效果相当于oldCapacity /2，</span></span><br><span class="line">      <span class="comment">//我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，</span></span><br><span class="line">      <span class="type">int</span> <span class="variable">newCapacity</span> <span class="operator">=</span> oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</span><br><span class="line">      <span class="comment">//然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，</span></span><br><span class="line">      <span class="keyword">if</span> (newCapacity - minCapacity &lt; <span class="number">0</span>)</span><br><span class="line">          newCapacity = minCapacity;</span><br><span class="line">     <span class="comment">// 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，</span></span><br><span class="line">     <span class="comment">//如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。</span></span><br><span class="line">      <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">          newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">      <span class="comment">// minCapacity is usually close to size, so this is a win:</span></span><br><span class="line">      elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="④CopyOnWriteArrayList"><a href="#④CopyOnWriteArrayList" class="headerlink" title="④CopyOnWriteArrayList"></a>④CopyOnWriteArrayList</h4>引导语<br>在 ArrayList 的类注释上，JDK 就提醒了我们，如果要把 ArrayList 作为共享变量的话，是线程不安全的，推荐我们自己加锁或者使用 Collections.synchronizedList 方法，其实 JDK 还提供了另外一种线程安全的 List，叫做 CopyOnWriteArrayList，这个 List 具有以下特征：</li></ol><p>线程安全的，多线程环境下可以直接使用，无需加锁；<br>通过锁 + 数组拷贝 + volatile 关键字保证了线程安全；<br>每次数组操作，都会把数组拷贝一份出来，在新数组上进行操作，操作成功之后再赋值回去。</p><p>1 整体架构<br>从整体架构上来说，CopyOnWriteArrayList 数据结构和 ArrayList 是一致的，底层是个数组，只不过 CopyOnWriteArrayList 在对数组进行操作的时候，基本会分四步走：</p><p>加锁；<br>从原数组中拷贝出新数组；<br>在新数组上进行操作，并把新数组赋值给数组容器；<br>解锁<br>除了加锁之外，CopyOnWriteArrayList 的底层数组还被 volatile 关键字修饰，意思是一旦数组被修改，其它线程立马能够感知到，代码如下：</p><p>private transient volatile Object[] array;<br>1<br>整体上来说，CopyOnWriteArrayList 就是利用锁 + 数组拷贝 + volatile 关键字保证了 List 的线程安全。<br><a href="https://blog.csdn.net/zlfing/article/details/109738440"></a></p><h2 id="ⅢCollection-子接口之-Set"><a href="#ⅢCollection-子接口之-Set" class="headerlink" title="ⅢCollection 子接口之 Set"></a>ⅢCollection 子接口之 Set</h2><h3 id="①comparable-和-Comparator-的区别"><a href="#①comparable-和-Comparator-的区别" class="headerlink" title="①comparable 和 Comparator 的区别"></a>①comparable 和 Comparator 的区别</h3><ul><li>comparable 接口实际上是出自java.lang包 它有一个 compareTo(Object obj)方法用来排序</li><li>comparator接口实际上是出自 java.util 包它有一个compare(Object obj1, Object obj2)方法用来排序</li></ul><p>一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo()方法或compare()方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo()方法和使用自制的Comparator方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 Collections.sort().</p><h3 id="②无序性和不可重复性的含义是什么"><a href="#②无序性和不可重复性的含义是什么" class="headerlink" title="②无序性和不可重复性的含义是什么"></a>②无序性和不可重复性的含义是什么</h3><p>1、什么是无序性？无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。<br>2、什么是不可重复性？不可重复性是指添加的元素按照 equals()判断时 ，返回 false，需要同时重写 equals()方法和 HashCode()方法。</p><h3 id="③比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同"><a href="#③比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同" class="headerlink" title="③比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同"></a>③比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同</h3><ul><li>HashSet、LinkedHashSet 和 TreeSet 都是 Set 接口的实现类，都能保证元素唯一，并且都不是线程安全的。</li><li>HashSet、LinkedHashSet 和 TreeSet 的主要区别在于底层数据结构不同。HashSet 的底层数据结构是哈希表（基于 HashMap 实现）。LinkedHashSet 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。TreeSet 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。</li><li>底层数据结构不同又导致这三者的应用场景不同。HashSet 用于不需要保证元素插入和取出顺序的场景，LinkedHashSet 用于保证元素的插入和取出顺序满足 FIFO 的场景，TreeSet 用于支持对元素自定义排序规则的场景。<h2 id="ⅣCollection-子接口之-Queue"><a href="#ⅣCollection-子接口之-Queue" class="headerlink" title="ⅣCollection 子接口之 Queue"></a>ⅣCollection 子接口之 Queue</h2><h3 id="Queue-与-Deque-的区别"><a href="#Queue-与-Deque-的区别" class="headerlink" title="Queue 与 Deque 的区别"></a><a href="https://javaguide.cn/java/collection/java-collection-questions-01.html#queue-%E4%B8%8E-deque-%E7%9A%84%E5%8C%BA%E5%88%AB"></a>Queue 与 Deque 的区别</h3><strong>Queue 是单端队列</strong>，只能从一端插入元素，另一端删除元素，实现上一般遵循 <strong>先进先出（FIFO）</strong> 规则。<br>Queue 扩展了 Collection 的接口，根据 <strong>因为容量问题而导致操作失败后处理方式的不同</strong> 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。</li></ul><div class="table-container"><table><thead><tr><th>Queue 接口</th><th>抛出异常</th><th>返回特殊值</th></tr></thead><tbody><tr><td>插入队尾</td><td>add(E e)</td><td>offer(E e)</td></tr><tr><td>删除队首</td><td>remove()</td><td>poll()</td></tr><tr><td>查询队首元素</td><td>element()</td><td>peek()</td></tr></tbody></table></div><p><strong>Deque 是双端队列</strong>，在队列的两端均可以插入或删除元素。<br>Deque 扩展了 Queue 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：</p><div class="table-container"><table><thead><tr><th>Deque 接口</th><th>抛出异常</th><th>返回特殊值</th></tr></thead><tbody><tr><td>插入队首</td><td>addFirst(E e)</td><td>offerFirst(E e)</td></tr><tr><td>插入队尾</td><td>addLast(E e)</td><td>offerLast(E e)</td></tr><tr><td>删除队首</td><td>removeFirst()</td><td>pollFirst()</td></tr><tr><td>删除队尾</td><td>removeLast()</td><td>pollLast()</td></tr><tr><td>查询队首元素</td><td>getFirst()</td><td>peekFirst()</td></tr><tr><td>查询队尾元素</td><td>getLast()</td><td>peekLast()</td></tr></tbody></table></div><p>事实上，Deque 还提供有 push() 和 pop() 等其他方法，可用于模拟栈。</p><h3 id="✊讲一下ArrayDeque？"><a href="#✊讲一下ArrayDeque？" class="headerlink" title="✊讲一下ArrayDeque？"></a>✊讲一下ArrayDeque？</h3><p>ArrayDeque实现了双端队列，基于可变长的数组和双指针实现，数组默认大小为16。它的特点有：</p><ol><li>在两端添加、删除元素的效率较高</li><li>根据元素内容查找和删除的效率比较低。</li><li>没有索引位置的概念，不能根据索引位置进行操作。</li></ol><p>ArrayDeque和LinkedList都实现了Deque接口，如果只需要从两端进行操作，ArrayDeque效率更高一些。如果同时需要根据索引位置进行操作，或者经常需要在中间进行插入和删除（LinkedList有相应的 api，如add(int index, E e)），则应该选LinkedList。<br>ArrayDeque和LinkedList都是线程不安全的，可以使用Collections工具类中synchronizedXxx()转换成线程同步。</p><h3 id="ArrayDeque-与-LinkedList-的区别"><a href="#ArrayDeque-与-LinkedList-的区别" class="headerlink" title="ArrayDeque 与 LinkedList 的区别"></a><a href="https://javaguide.cn/java/collection/java-collection-questions-01.html#arraydeque-%E4%B8%8E-linkedlist-%E7%9A%84%E5%8C%BA%E5%88%AB"></a>ArrayDeque 与 LinkedList 的区别</h3><p>ArrayDeque 和 LinkedList 都实现了 Deque 接口，两者都具有队列的功能，但两者有什么区别呢？</p><ul><li>ArrayDeque 是基于可变长的数组和双指针来实现，而 LinkedList 则通过链表来实现。</li><li>ArrayDeque 不支持存储 NULL 数据，但 LinkedList 支持。</li><li>ArrayDeque 是在 JDK1.6 才被引入的，而LinkedList 早在 JDK1.2 时就已经存在。</li><li>ArrayDeque 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 LinkedList 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。</li></ul><p>从性能的角度上，选用 ArrayDeque 来实现队列要比 LinkedList 更好。此外，ArrayDeque 也可以用于实现栈。</p><h3 id="说一说-PriorityQueue"><a href="#说一说-PriorityQueue" class="headerlink" title="说一说 PriorityQueue"></a>说一说 PriorityQueue</h3><p>PriorityQueue 是在 JDK1.5 中被引入的, 其与 Queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。<br>这里列举其相关的一些要点：</p><ul><li>PriorityQueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据</li><li>PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。</li><li>PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。</li><li><p>PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。</p><h3 id="什么是fail-fast？"><a href="#什么是fail-fast？" class="headerlink" title="什么是fail fast？"></a>什么是fail fast？</h3><p>fast-fail是Java集合的一种错误机制。当多个线程对同一个集合进行操作时，就有可能会产生fast-fail事件。例如：当线程a正通过iterator遍历集合时，另一个线程b修改了集合的内容，此时modCount（记录集合操作过程的修改次数）会加1，不等于expectedModCount，那么线程a访问集合的时候，就会抛出ConcurrentModificationException，产生fast-fail事件。边遍历边修改集合也会产生fast-fail事件。<br>解决方法：</p></li><li><p>使用Colletions.synchronizedList方法或在修改集合内容的地方加上synchronized。这样的话，增删集合内容的同步锁会阻塞遍历操作，影响性能。 </p></li><li>使用CopyOnWriteArrayList来替换ArrayList。在对CopyOnWriteArrayList进行修改操作的时候，会拷贝一个新的数组，对新的数组进行操作，操作完成后再把引用移到新的数组。 <h3 id="什么是fail-safe？"><a href="#什么是fail-safe？" class="headerlink" title="什么是fail safe？"></a>什么是fail safe？</h3>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。<br><strong>原理</strong>：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。<br><strong>缺点</strong>：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 <h2 id="线程安全的集合"><a href="#线程安全的集合" class="headerlink" title="线程安全的集合"></a>线程安全的集合</h2></li></ul><h2 id="ⅤMap-接口"><a href="#ⅤMap-接口" class="headerlink" title="ⅤMap 接口"></a>ⅤMap 接口</h2><h3 id="①HashMap基础面试题"><a href="#①HashMap基础面试题" class="headerlink" title="①HashMap基础面试题"></a>①HashMap基础面试题</h3><h4 id="HashMap-和-Hashtable-的区别"><a href="#HashMap-和-Hashtable-的区别" class="headerlink" title="HashMap 和 Hashtable 的区别"></a>HashMap 和 Hashtable 的区别</h4><ol><li><strong>线程是否安全：</strong> HashMap 是非线程安全的，Hashtable 是线程安全的,因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）；</li><li><strong>效率：</strong> 因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它；</li><li><strong>对 Null key 和 Null value 的支持：</strong> HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。</li><li><strong>初始容量大小和每次扩充容量大小的不同 ：</strong> ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，<strong>之后每次扩充，容量变为原来的 2n+1</strong>。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。</li><li><strong>底层数据结构：</strong> JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。</li></ol><h4 id="HashMap-和-HashSet-区别"><a href="#HashMap-和-HashSet-区别" class="headerlink" title="HashMap 和 HashSet 区别"></a>HashMap 和 HashSet 区别</h4><p>如果你看过 HashSet 源码的话就应该知道：HashSet 底层就是基于 HashMap 实现的。（HashSet 的源码非常非常少，因为除了 clone()、writeObject()、readObject()是 HashSet 自己不得不实现之外，其他方法都是直接调用 HashMap 中的方法。</p><div class="table-container"><table><thead><tr><th>HashMap</th><th>HashSet</th></tr></thead><tbody><tr><td>实现了 Map 接口</td><td>实现 Set 接口</td></tr><tr><td>存储键值对</td><td>仅存储对象</td></tr><tr><td>调用 put()向 map 中添加元素</td><td>调用 add()方法向 Set 中添加元素</td></tr><tr><td>HashMap 使用键（Key）计算 hashcode</td><td>HashSet 使用成员对象来计算 hashcode 值，对于两个对象来说 hashcode 可能相同，所以equals()方法用来判断对象的相等性</td></tr></tbody></table></div><h4 id="HashMap-和-TreeMap-区别"><a href="#HashMap-和-TreeMap-区别" class="headerlink" title="HashMap 和 TreeMap 区别"></a>HashMap 和 TreeMap 区别</h4><p>TreeMap 和HashMap 都继承自AbstractMap ，但是需要注意的是TreeMap它还实现了NavigableMap接口和SortedMap 接口。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647572677747-c5ca47e4-a0a8-489c-bb1c-c469c984f85e.png#averageHue=%232f2f2d&amp;clientId=u6441117b-7d6c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uba7eaa33&amp;margin=%5Bobject%20Object%5D&amp;originHeight=423&amp;originWidth=1024&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u20091c62-9219-4c79-bfff-1e534c47c9a&amp;title=" alt=""></p><ul><li>实现 NavigableMap 接口让 TreeMap 有了对集合内元素的搜索的能力。</li><li>实现SortedMap接口让 TreeMap 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。</li></ul><p><strong>综上，相比于HashMap来说 TreeMap 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。</strong></p><h4 id="HashSet-如何检查重复"><a href="#HashSet-如何检查重复" class="headerlink" title="HashSet 如何检查重复"></a>HashSet 如何检查重复</h4><p>当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。</p><p>在openjdk8中，HashSet的add()方法只是简单的调用了HashMap的put()方法，并且判断了一下返回值以确保是否有重复元素。</p><p>也就是说，在openjdk8中，实际上无论HashSet中是否已经存在了某元素，HashSet都会直接插入，只是会在add()方法的返回值处告诉我们插入前是否存在相同元素。<br><strong>hashCode()与 equals() 的相关规定：</strong></p><ol><li>如果两个对象相等，则 hashcode 一定也是相同的</li><li>两个对象相等,对两个 equals() 方法返回 true</li><li>两个对象有相同的 hashcode 值，它们也不一定是相等的</li><li>综上，equals() 方法被覆盖过，则 hashCode() 方法也必须被覆盖</li><li>hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。</li></ol><p><strong>==与 equals 的区别</strong><br>对于基本类型来说，== 比较的是值是否相等；<br>对于引用类型来说，== 比较的是两个引用是否指向同一个对象地址（两者在内存中存放的地址（堆内存地址）是否指向同一个地方）；<br>对于引用类型（包括包装类型）来说，equals 如果没有被重写，对比它们的地址是否相等；如果 equals()方法被重写（例如 String），则比较的是地址里的内容。</p><h4 id="解决hash冲突的办法有哪些？HashMap用的哪种？"><a href="#解决hash冲突的办法有哪些？HashMap用的哪种？" class="headerlink" title="解决hash冲突的办法有哪些？HashMap用的哪种？"></a>解决hash冲突的办法有哪些？HashMap用的哪种？</h4><p>解决Hash冲突方法有:开放定址法、再哈希法、链地址法（拉链法）、建立公共溢出区。HashMap中采用的是 链地址法 。</p><ul><li>开放定址法也称为再散列法，基本思想就是，如果p=H(key)出现冲突时，则以p为基础，再次hash，p1=H(p),如果p1再次出现冲突，则以p1为基础，以此类推，直到找到一个不冲突的哈希地址pi。 因此开放定址法所需要的hash表的长度要大于等于所需要存放的元素，而且因为存在再次hash，所以只能在删除的节点上做标记，而不能真正删除节点。</li><li>再哈希法(双重散列，多重散列)，提供多个不同的hash函数，当R1=H1(key1)发生冲突时，再计算R2=H2(key1)，直到没有冲突为止。 这样做虽然不易产生堆集，但增加了计算的时间。</li><li>链地址法(拉链法)，将哈希值相同的元素构成一个同义词的单链表,并将单链表的头指针存放在哈希表的第i个单元中，查找、插入和删除主要在同义词链表中进行。链表法适用于经常进行插入和删除的情况。</li><li><p>建立公共溢出区，将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。</p><h4 id="一般用什么作为HashMap的key"><a href="#一般用什么作为HashMap的key" class="headerlink" title="一般用什么作为HashMap的key?"></a>一般用什么作为HashMap的key?</h4><p>一般用Integer、String 这种不可变类当 HashMap 当 key，而且 String 最为常用。</p></li><li><p>因为字符串是不可变的，所以在它创建的时候 hashcode 就被缓存了，不需要重新计算。这就是 HashMap 中的键往往都使用字符串的原因。</p></li><li><p>因为获取对象的时候要用到 equals() 和 hashCode() 方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的重写了 hashCode() 以及 equals() 方法。</p><h3 id="②HashMap深入"><a href="#②HashMap深入" class="headerlink" title="②HashMap深入"></a>②HashMap深入</h3><h4 id="1-存储结构"><a href="#1-存储结构" class="headerlink" title="1.存储结构"></a>1.存储结构</h4><p><strong>HashMap的底层数据结构是什么？</strong><br>在JDK1.7 和JDK1.8 中有所差别：<br>在JDK1.7 中，由“数组+链表”组成，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的。<br>在JDK1.8 中，由“数组+链表+红黑树”组成。当链表过长，则会严重影响 HashMap 的性能，红黑树搜索时间复杂度是 O(logn)，而链表是糟糕的 O(n)。因此，JDK1.8 对数据结构做了进一步的优化，引入了红黑树，链表和红黑树在达到一定条件会进行转换：</p></li><li><p>当链表超过 8 且数组的长度超过 64 才会转红黑树。</p></li><li>将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树，以减少搜索时间。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991880301-6c3bc27a-946c-4c90-b690-42274ddde830.png#averageHue=%23f5f1f1&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u46594eb5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=349&amp;originWidth=815&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=34550&amp;status=done&amp;style=none&amp;taskId=u0ae44cff-ffe2-47d0-bde8-8a2ba2250bf&amp;title=" alt="image.png"><br>更深入的面试问题，<br><strong>为什么在解决 hash 冲突的时候，不直接用红黑树？而选择先用链表，再转红黑树?</strong><br>因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。<br>因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的。<br><strong><em>不用红黑树，用二叉查找树可以么?</em></strong><br>可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。<br><strong>为什么链表改为红黑树的阈值是 8?</strong><br>是因为泊松分布，我们来看作者在源码中的注释：<br>翻译过来大概的意思是：理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循<a href="http://en.wikipedia.org/wiki/Poisson_distribution">泊松分布</a>，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为 8 时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了 8，是根据概率统计而选择的。</p><h5 id="字段结构"><a href="#字段结构" class="headerlink" title="字段结构"></a>字段结构</h5><p><strong>默认加载因子是多少？为什么是 0.75，不是 0.6 或者 0.8 ？</strong><br>回答这个问题前，我们来先看下HashMap的默认构造函数：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> threshold;             <span class="comment">// 容纳键值对的最大值</span></span><br><span class="line">final <span class="type">float</span> loadFactor;    <span class="comment">// 负载因子</span></span><br><span class="line"><span class="type">int</span> modCount;  </span><br><span class="line"><span class="type">int</span> size;  </span><br></pre></td></tr></table></figure><br>Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳键值对的最大值。threshold = length <em> Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。<br>默认的loadFactor是0.75<em>*，0.75是对空间和时间效率的一个平衡选择</em></em>，一般不要修改，除非在时间和空间比较特殊的情况下 ：</p><ul><li>如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。</li><li>相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。</li></ul><p>我们来追溯下作者在源码中的注释（JDK1.7）：<br>翻译过来大概的意思是：作为一般规则，默认负载因子（0.75）在时间和空间成本上提供了很好的折衷。较高的值会降低空间开销，但提高查找成本（体现在大多数的HashMap类的操作，包括get和put）。设置初始大小时，应该考虑预计的entry数在map及其负载系数，并且尽量减少rehash操作的次数。如果初始容量大于最大条目数除以负载因子，rehash操作将不会发生。</p><h4 id="2-索引计算"><a href="#2-索引计算" class="headerlink" title="2.索引计算"></a>2.索引计算</h4><p><strong>HashMap 中 key 的存储索引是怎么计算的？</strong><br>jdk1.8是首先根据key的值计算出hashcode的值，然后根据hashcode计算出hash值，最后通过（length-1）&amp;hash计算得到存储的位置。看看源码的实现：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// jdk1.7</span></span><br><span class="line">方法一：</span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">hash</span><span class="params">(<span class="type">int</span> h)</span> &#123;</span><br><span class="line">    <span class="type">int</span> h = hashSeed;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> != h &amp;&amp; k instanceof String) &#123;</span><br><span class="line">            <span class="keyword">return</span> sun.misc.Hashing.stringHash32((String) k);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    h ^= k.hashCode(); <span class="comment">// 为第一步：取hashCode值</span></span><br><span class="line">    h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>); </span><br><span class="line">    <span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>);</span><br><span class="line">&#125;</span><br><span class="line">方法二：</span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">indexFor</span><span class="params">(<span class="type">int</span> h, <span class="type">int</span> length)</span> &#123;  <span class="comment">//jdk1.7的源码，jdk1.8没有这个方法，但实现原理一样</span></span><br><span class="line">     <span class="keyword">return</span> h &amp; (length<span class="number">-1</span>);  <span class="comment">//第三步：取模运算</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// jdk1.8</span></span><br><span class="line"><span class="type">static</span> final <span class="type">int</span> <span class="title function_">hash</span><span class="params">(Object key)</span> &#123;   </span><br><span class="line">     <span class="type">int</span> h;</span><br><span class="line">     <span class="keyword">return</span> (key == null) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">     h = key.hashCode() 为第一步：取hashCode值</span></span><br><span class="line"><span class="comment">     h ^ (h &gt;&gt;&gt; 16)  为第二步：高位参与运算</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这里的 Hash 算法本质上就是三步：<strong>取key的 hashCode 值、根据 hashcode 计算出hash值、通过取模计算下标</strong>。其中，JDK1.7和1.8的不同之处，就在于第二步。我们来看下详细过程，以JDK1.8为例，n为table的长度。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991880455-8d5f65bb-24a9-4949-8f23-31434e929308.png#averageHue=%23f7f6f6&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7ecb6f08&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=684&amp;originWidth=1198&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=123665&amp;status=done&amp;style=none&amp;taskId=u57c789b7-947d-4b77-b69f-4d0ae351200&amp;title=" alt="image.png"><br>扩展出以下几个问题，<br><strong>JDK1.8 为什么要 hashcode 异或其右移十六位的值？</strong></p><ul><li>因为在JDK 1.7 中扰动了 4 次，计算 hash 值的性能会稍差一点点。 从速度、功效、质量来考虑，JDK1.8 优化了高位运算的算法，通过hashCode()的高16位异或低16位实现：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)。</li><li>这么做可以在数组 table 的 length 比较小的时候，也能保证考虑到高低位Bit都参与到Hash的计算中，同时不会有太大的开销。</li></ul><p><strong>为什么 hash 值要与length-1相与？</strong></p><ul><li>把 hash 值对数组长度取模运算，模运算的消耗很大，没有位运算快。</li><li>当 length 总是 2 的n次方时，h&amp; (length-1) 运算等价于对length取模，也就是 h%length，但是 &amp; 比 % 具有更高的效率。</li></ul><p><strong>HashMap数组的长度为什么是 2 的幂次方？</strong></p><blockquote><p>HashMap 为了存取高效，减少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现的关键就在把数据存到哪个链表中的算法。<br>数组下标的计算方法是(n - 1) &amp; hash，取余<strong>(%)</strong>操作中如果除数是<strong>2</strong>的幂次则等价<br>于与其除数减一的与<strong>(&amp;)</strong>操作（也就是说 <strong>hash%length==hash&amp;(length-1)</strong>的前提是<br><strong>length </strong>是<strong>2</strong>的 <strong>n </strong>次方；）。<strong>” </strong>并且 采用二进制位操作 <strong>&amp;</strong>，相对于<strong>%</strong>能够提高运算效率，<br>这就解释了 <strong>HashMap </strong>的长度为什么是<strong>2</strong>的幂次方。</p></blockquote><p>这样做效果上等同于取模，在速度、效率上比直接取模要快得多。但是位运算比模运算速度快<br><strong>hash%length==hash&amp;(length-1)</strong>的前提是 <strong>length </strong>是<strong>2</strong>的 <strong>n </strong>次方<br>除此之外，2 的 N 次幂有助于减少碰撞的几率。如果 length 为2的幂次方，则 length-1 转化为二进制必定是11111……的形式，在与h的二进制与操作效率会非常的快，而且空间不浪费。我们来举个例子，看下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991880444-a3782b92-9d1a-4f39-a83f-f1e5dee09061.png#averageHue=%23f6f7f5&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ubc0f9c00&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=425&amp;originWidth=383&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=76624&amp;status=done&amp;style=none&amp;taskId=u52c805b8-2e79-462a-ad92-706b1167771&amp;title=" alt="image.png"><br>当 length =15时，6 和 7 的结果一样，这样表示他们在 table 存储的位置是相同的，也就是产生了碰撞，6、7就会在一个位置形成链表，4和5的结果也是一样，这样就会导致查询速度降低。<br>如果我们进一步分析，还会发现空间浪费非常大，以 length=15 为例，在 1、3、5、7、9、11、13、15 这八处没有存放数据。因为hash值在与14（即 1110）进行&amp;运算时，得到的结果最后一位永远都是0，即 0001、0011、0101、0111、1001、1011、1101、1111位置处是不可能存储数据的。<br><strong>补充数组容量计算的小奥秘</strong><br>HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。会取大于或等于这个数的 且最近的2次幂作为 table 数组的初始容量，使用tableSizeFor(int)方法，如 tableSizeFor(10) = 16（2 的 4 次幂），tableSizeFor(20) = 32（2 的 5 次幂），也就是说 table 数组的长度总是 2 的次幂。JDK1.8 源码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> final <span class="type">int</span> <span class="title function_">tableSizeFor</span><span class="params">(<span class="type">int</span> cap)</span> &#123;</span><br><span class="line">        <span class="type">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">        <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">解释：位或( | )</span></span><br><span class="line"><span class="comment">int n = cap - 1;　让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p><h4 id="3-put方法"><a href="#3-put方法" class="headerlink" title="3.put方法"></a>3.put方法</h4><p><strong>HashMap 的put方法流程？</strong><br>简要流程如下：</p><ul><li>首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标；</li><li>如果数组是空的，则调用 resize 进行初始化；</li><li>如果数组不为空<ul><li>并且没有哈希冲突直接放在对应的数组下标里；</li><li>如果有哈希冲突<ul><li>且 key 已经存在，就覆盖掉 value；</li><li>key不存在，发现该节点是红黑树，就将这个节点挂在树上；</li><li>如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value。<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991880492-11c2f742-63a0-43b0-8d46-42e319b06629.png#averageHue=%23f2e3cb&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u71c53776&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=695&amp;originWidth=665&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=219454&amp;status=done&amp;style=none&amp;taskId=uc604567b-d547-4d9f-9c44-bb95431b7ed&amp;title=" alt="image.png"></li></ul></li></ul></li></ul><p>详细分析，见JDK1.8HashMap 的 put 方法源码:```c<br> public V put(K key, V value) {<br>     // 对key的hashCode()做hash<br>        return putVal(hash(key), key, value, false, true);<br>    }</p><p>final V putVal(int hash, K key, V value, boolean onlyIfAbsent,<br>                   boolean evict) {<br>        Node<K,V>[] tab; Node<K,V> p; int n, i;<br>        // 步骤1：tab为空则创建<br>        if ((tab = table) == null || (n = tab.length) == 0)<br>            n = (tab = resize()).length;<br>        // 步骤2：计算index，并对null做处理<br>        if ((p = tab[i = (n - 1) &amp; hash]) == null)<br>            tab[i] = newNode(hash, key, value, null);<br>        else {<br>            Node<K,V> e; K k;<br>            // 步骤3：节点key存在，直接覆盖value<br>            if (p.hash == hash &amp;&amp;<br>                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))<br>                e = p;<br>            // 步骤4：判断该链为红黑树<br>            else if (p instanceof TreeNode)<br>                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);<br>            // 步骤5：该链为链表<br>            else {<br>                for (int binCount = 0; ; ++binCount) {<br>                    if ((e = p.next) == null) {<br>                        p.next = newNode(hash, key, value, null);<br>                        //链表长度大于8转换为红黑树进行处理<br>                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st<br>                            treeifyBin(tab, hash);<br>                        break;<br>                    }<br>                    // key已经存在直接覆盖value<br>                    if (e.hash == hash &amp;&amp;<br>                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))<br>                        break;<br>                    p = e;<br>                }<br>            }<br>            if (e != null) { // existing mapping for key<br>                V oldValue = e.value;<br>                if (!onlyIfAbsent || oldValue == null)<br>                    e.value = value;<br>                afterNodeAccess(e);<br>                return oldValue;<br>            }<br>        }<br>        ++modCount;<br>           // 步骤6：超过最大容量 就扩容<br>        if (++size &gt; threshold)<br>            resize();<br>        afterNodeInsertion(evict);<br>        return null;<br>    }</p><p>// 第31行treeifyBin方法部分代码<br>final void treeifyBin(Node<K,V>[] tab, int hash) {<br>        int n, index; Node<K,V> e;<br>        // static final int MIN_TREEIFY_CAPACITY = 64;<br>        // 如果大于8但是数组容量小于64，就进行扩容<br>        if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY)<br>            resize();</p><pre><code>&#125;</code></pre><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">       </span><br><span class="line">扩展的问题</span><br><span class="line">**JDK1.7 和1.8 的put方法区别是什么？**</span><br><span class="line">区别在两处：</span><br><span class="line">解决哈希冲突时，JDK1.7 只使用链表，JDK1.8 使用链表+红黑树，当满足一定条件，链表会转换为红黑树。</span><br><span class="line">链表插入元素时，JDK1.7 使用头插法插入元素，在多线程的环境下有可能导致环形链表的出现，扩容的时候会导致死循环。因此，JDK1.8使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了，但JDK1.8 的 HashMap 仍然是线程不安全的，具体原因会在另一篇文章分析。</span><br><span class="line">#### 4.扩容机制</span><br><span class="line">**HashMap 的扩容方式？**</span><br><span class="line">Hashmap 在容量超过负载因子所定义的容量之后，就会扩容。Java 里的数组是无法自动扩容的，方法是将 Hashmap 的大小扩大为原来数组的两倍，并将原来的对象放入新的数组中。</span><br><span class="line">那扩容的具体步骤是什么？让我们看看源码。</span><br><span class="line">JDK1.7 的代码：</span><br><span class="line">```c</span><br><span class="line">void resize(int newCapacity) &#123;   //传入新的容量</span><br><span class="line">        Entry[] oldTable = table;    //引用扩容前的Entry数组</span><br><span class="line">        int oldCapacity = oldTable.length;</span><br><span class="line">        if (oldCapacity == MAXIMUM_CAPACITY) &#123;  //扩容前的数组大小如果已经达到最大(2^30)了</span><br><span class="line">            threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组</span><br><span class="line">        transfer(newTable);                         //！！将数据转移到新的Entry数组里</span><br><span class="line">        table = newTable;                           //HashMap的table属性引用新的Entry数组</span><br><span class="line">        threshold = (int)(newCapacity * loadFactor);//修改阈值</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">transfer</span><span class="params">(Entry[] newTable)</span> &#123;</span><br><span class="line">        Entry[] src = table;                   <span class="comment">//src引用了旧的Entry数组</span></span><br><span class="line">        <span class="type">int</span> newCapacity = newTable.length;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) &#123; <span class="comment">//遍历旧的Entry数组</span></span><br><span class="line">            Entry&lt;K,V&gt; e = src[j];             <span class="comment">//取得旧Entry数组的每个元素</span></span><br><span class="line">            <span class="keyword">if</span> (e != null) &#123;</span><br><span class="line">                src[j] = null;<span class="comment">//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）</span></span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">                    <span class="type">int</span> i = indexFor(e.hash, newCapacity); <span class="comment">//！！重新计算每个元素在数组中的位置</span></span><br><span class="line">                    e.next = newTable[i]; <span class="comment">//标记[1]</span></span><br><span class="line">                    newTable[i] = e;      <span class="comment">//将元素放在数组上</span></span><br><span class="line">                    e = next;             <span class="comment">//访问下一个Entry链上的元素</span></span><br><span class="line">                &#125; <span class="keyword">while</span> (e != null);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>newTable[i] 的引用赋给了 e.next ，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到 Entry 链的尾部(如果发生了 hash 冲突的话）。</p><h5 id="JDK1-8的优化"><a href="#JDK1-8的优化" class="headerlink" title="JDK1.8的优化"></a>JDK1.8的优化</h5><p><strong>扩容在JDK1.8中有什么不一样？</strong><br>JDK1.8做了两处优化：</p><ol><li>resize 之后，元素的位置在原来的位置，或者原来的位置 +oldCap (原来哈希表的长度）。不需要像 JDK1.7 的实现那样重新计算hash ，只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引 + oldCap ”。这个设计非常的巧妙，省去了重新计算 hash 值的时间。如下图所示，n 为 table 的长度，图（a）表示扩容前的 key1 和 key2 两种 key 确定索引位置的示例，图（b）表示扩容后 key1 和key2 两种 key 确定索引位置的示例，其中 hash1 是 key1 对应的哈希与高位运算结果。</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991880405-d4b8effc-20f6-4369-b0c2-cba815d775e7.png#averageHue=%23fdfcfc&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u787fb2f1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=446&amp;originWidth=1632&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=70033&amp;status=done&amp;style=none&amp;taskId=u62fca651-fe9e-4c1c-ac87-812fafa2bc3&amp;title=" alt="image.png">元素在重新计算 hash 之后，因为 n 变为 2倍，那么 n-1 的 mask 范围在高位多 1 bit(红色)，因此新的index就会发生这样的变化：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991882325-b4a0ffc6-2b85-48e8-b249-245b0dfcfa62.png#averageHue=%23f5f5f5&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucdbdf499&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=202&amp;originWidth=1064&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48503&amp;status=done&amp;style=none&amp;taskId=ud5757694-73c3-4cbb-8f8a-e3d4e547276&amp;title=" alt="image.png"></p><blockquote><ol><li>JDK1.7 中 rehash 的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置（头插法）。JDK1.8 不会倒置，使用尾插法。</li></ol><p>下图为 16扩充为 32 的 resize 示意图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991882417-40e3231f-bb6e-49e2-8f6e-271afe2bbc11.png#averageHue=%23f1f1f1&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u970c11e2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=730&amp;originWidth=1268&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=234529&amp;status=done&amp;style=none&amp;taskId=ue1aafcbd-90f9-4681-bbf1-5d3d813215f&amp;title=" alt="image.png"><br>感兴趣的小伙伴可以看下 JDK1.8 的 resize 源码：</p></blockquote><h4 id="5-HashMap为什么线程不安全？"><a href="#5-HashMap为什么线程不安全？" class="headerlink" title="5.HashMap为什么线程不安全？"></a>5.HashMap为什么线程不安全？</h4><p>第一点:多线程下扩容死循环<br>JDK1.7中的 HashMap 使用头插法插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，不会出现环形链表的问题。<br>详细内容下面看看多线程情况下， JDK1.7 扩容死循环问题的分析。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990393386-f594ecac-05f4-4c2e-9bc5-33e3afb9590c.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=bBht9&amp;margin=%5Bobject%20Object%5D&amp;originHeight=413&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u2de8bc81-deb8-4480-b737-2d781d1ec91&amp;title=" alt=""><br>新建一个更大尺寸的hash表，然后把数据从老的hash表中迁移到新的hash表中。重点看下transfer方法：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">transfer</span><span class="params">(Entry[] newTable)</span> &#123;</span><br><span class="line">        Entry[] src = table;                   <span class="comment">//src引用了旧的Entry数组</span></span><br><span class="line">        <span class="type">int</span> newCapacity = newTable.length;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) &#123; <span class="comment">//遍历旧的Entry数组</span></span><br><span class="line">            Entry&lt;K,V&gt; e = src[j];             <span class="comment">//取得旧Entry数组的每个元素</span></span><br><span class="line">            <span class="keyword">if</span> (e != null) &#123;</span><br><span class="line">                src[j] = null;<span class="comment">//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）</span></span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">                    <span class="type">int</span> i = indexFor(e.hash, newCapacity); <span class="comment">//！！重新计算每个元素在数组中的位置</span></span><br><span class="line">                    e.next = newTable[i]; <span class="comment">//标记[1]</span></span><br><span class="line">                    newTable[i] = e;      <span class="comment">//将元素放在数组上</span></span><br><span class="line">                    e = next;             <span class="comment">//访问下一个Entry链上的元素</span></span><br><span class="line">                &#125; <span class="keyword">while</span> (e != null);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br><strong>正常的ReHash的过程</strong><br>画了个图做了个演示。</p><ul><li>我假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。</li><li>最上面的是old hash 表，其中的Hash表的size=2, 所以key = 3, 7, 5，在mod 2以后都冲突在table[1]这里了。</li><li>接下来的三个步骤是Hash表 resize成4，然后所有的<key,value> 重新rehash的过程</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991037256-a9eb58f8-c885-4b41-bb0f-128dbfc5176b.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=TSRiC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=462&amp;originWidth=623&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=208218&amp;status=done&amp;style=none&amp;taskId=u7cad244c-cb5a-4888-be11-06479b6425f&amp;title=" alt="image.png"><br>所以能看出来jdk1.7采用的是头插法</p><h4 id="并发下的Rehash"><a href="#并发下的Rehash" class="headerlink" title="并发下的Rehash"></a>并发下的Rehash</h4><p><strong>1）假设我们有两个线程。</strong>我用红色和浅蓝色标注了一下。<br>我们再回头看一下我们的 transfer代码中的这个细节：<br><strong>do</strong>{<br> Entry<K,V> next = e.next; // &lt;—假设线程一执行到这里就被调度挂起了<br><strong>int</strong> i = indexFor(e.hash, newCapacity);<br> e.next = newTable[i];<br> newTable[i] = e;<br> e = next;<br>}<strong>while</strong>(e != <strong>null</strong>);<br>而我们的线程二执行完成了。于是我们有下面的这个样子。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991036936-3d791f94-7eaa-4f56-8d85-590c567f4544.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=gBtLY&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=434&amp;originWidth=616&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=131348&amp;status=done&amp;style=none&amp;taskId=u6cebbd74-33a2-4969-846f-9e9aeeb5c5f&amp;title=" alt="image.png"><br>注意，<strong>因为Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表</strong>。我们可以看到链表的顺序被反转后。<br><strong>2）线程一被调度回来执行。</strong></p><ul><li><strong>先是执行 newTalbe[i] = e;</strong></li><li><strong>然后是e = next，导致了e指向了key(7)，</strong></li><li><strong>而下一次循环的next = e.next导致了next指向了key(3)</strong></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991037120-81a6293d-bec4-4e6d-86b8-3221939a1f5b.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=KO62X&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=376&amp;originWidth=591&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=114776&amp;status=done&amp;style=none&amp;taskId=u138dca9b-2304-4c55-a6c9-5fa9b65a366&amp;title=" alt="image.png"><br><strong>3）一切安好。</strong><br>线程一接着工作。<strong>把key(7)摘下来，放到newTable[i]的第一个，然后把e和next往下移</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991037141-3ad7c91a-3c26-4a67-ac65-8d6df984f905.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=311&amp;id=Ocqpf&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=411&amp;originWidth=627&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=148648&amp;status=done&amp;style=none&amp;taskId=u1656a541-0b25-4ee9-997e-87272a9321f&amp;title=&amp;width=474" alt="image.png"><br><strong>4）环形链接出现。</strong><br><strong>e.next = newTable[i] 导致  key(3).next 指向了 key(7)</strong><br><strong>注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991036888-189a77bb-09d7-40ae-b893-7ad9f1b42866.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=264&amp;id=CJRFe&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=395&amp;originWidth=623&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=135714&amp;status=done&amp;style=none&amp;taskId=ud8fc6ba0-fe6f-4438-a029-dc7d24e9126&amp;title=&amp;width=417" alt="image.png"><br><strong>于是，当我们的线程一调用到，HashTable.get(11)时，悲剧就出现了——Infinite Loop。</strong><br>第二点：多线程的put可能导致元素的丢失<br>多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。此问题在JDK 1.7和 JDK 1.8 中都存在。<br>详细内容我们来看下JDK 1.8 中 put 方法的部分源码，重点看黄色部分：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990394899-3d34dfd5-1ab5-48db-af47-d84059f63093.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=lVkTQ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=950&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc953623e-a745-4cae-bfc6-b75c196b5b5&amp;title=" alt=""><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658991620117-f9e7fbae-aacb-4302-af22-979e3eaa0e4a.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=57&amp;id=Z1o4e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=100&amp;originWidth=869&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=15823&amp;status=done&amp;style=none&amp;taskId=uc7d30379-1890-477c-b606-ebd72cd8bfd&amp;title=&amp;width=496.57142857142856" alt="image.png"><br>我们来演示个例子。<br>假设线程1和线程2同时执行put，线程1执行put(“1”, “A”)，线程2执行put(“5”, “B”)，hash算法就是用key mod 表的长度，表长度为4，在mod 4 以后都冲突在table[1]这里了。注：下面的例子，只演示了 #1 和#2代码的情况，其他代码也会出现类似情况。<br>正常情况下，put完成后，table的状态应该是下图中的任意一个。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990394533-249c6c08-89f4-4e3e-8888-f699d80a43a1.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=qRuMQ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=334&amp;originWidth=341&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue35165a4-0547-4e9b-9215-71e96a2f285&amp;title=" alt=""><br>下面来看看异常情况，两个线程都执行了#1处的if ((p = tab[i = (n - 1) &amp; hash]) == null)这句代码。<br>此时假设线程1 先执行#2处的tab[i] = newNode(hash, key, value, null);<br>那么table会变成如下状态：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990394539-61155662-a828-4ca6-b9d2-f4d491004ddd.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=dbvv2&amp;margin=%5Bobject%20Object%5D&amp;originHeight=165&amp;originWidth=321&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u42b0e851-d3d2-40b3-9be0-e1222fb8e88&amp;title=" alt=""><br>紧接着线程2 执行tab[i] = newNode(hash, key, value, null);<br>此时table会变成如下状态:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990394730-22ade3e7-3b05-4990-a122-2de9865c5f3d.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=YcdUz&amp;margin=%5Bobject%20Object%5D&amp;originHeight=252&amp;originWidth=321&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub251f84b-89ec-44c1-b53c-f8c4c2c5c7c&amp;title=" alt=""><br>这样一来，元素A就丢失了。<br>第三点：put和get并发时，可能导致get为null<br>线程1执行put时，因为元素个数超出threshold而导致rehash，线程2此时执行get，有可能导致这个问题。此问题在JDK 1.7和 JDK 1.8 中都存在。<br>详细内容我们来看下JDK 1.8 中 resize 方法的部分源码，重点看黄色部分：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658990395083-3adfcd08-5e57-4a9f-91b8-96306c542b3d.png#clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=B5s8c&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1193&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ud510350e-2ea8-4bd9-80a3-6ffde8bff97&amp;title=" alt=""><br>在代码#1位置，用新计算的容量new了一个新的hash表，#2将新创建的空hash表赋值给实例变量table。<br>注意此时实例变量table是空的，如果此时另一个线程执行get，就会get出null。</p><h3 id="③ConcurrentHashMap"><a href="#③ConcurrentHashMap" class="headerlink" title="③ConcurrentHashMap"></a>③ConcurrentHashMap</h3><h4 id="1-实现原理"><a href="#1-实现原理" class="headerlink" title="1.实现原理"></a>1.实现原理</h4><p>ConcurrentHashMap 在 JDK1.7 和 JDK1.8 的实现方式是不同的。<br><strong>先来看下JDK1.7</strong></p><ul><li>JDK1.7中的ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成，即ConcurrentHashMap 把哈希桶切分成小数组（Segment ），每个小数组有 n 个 HashEntry 组成。</li><li>其中，Segment 继承了 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色；HashEntry 用于存储键值对数据。</li><li>它将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问，能够实现真正的并发访问。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993056948-5d30c61b-8e1d-4ec1-af3c-d61b98d091f1.png#averageHue=%23fbf2df&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=337&amp;id=udf31ff9f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=670&amp;originWidth=1087&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=63655&amp;status=done&amp;style=none&amp;taskId=u86680cdd-57ef-4a86-a273-9730d4be3e0&amp;title=&amp;width=547.0000610351562" alt="image.png"><br>Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993312953-72d6daaf-16e8-4972-8194-36210f4609c0.png#averageHue=%2316191a&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=275&amp;id=uef548d32&amp;margin=%5Bobject%20Object%5D&amp;originHeight=543&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u962949a3-699c-4d77-b3a8-9ff67468f75&amp;title=&amp;width=547.0000610351562" alt=""><br>Segment 继承了 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色。Segment 默认为 16，也就是并发度为 16。<br>存放元素的 HashEntry，也是一个静态内部类，主要的组成如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993313013-9fd8a0ad-36e9-45cd-a3a6-aa3b6c15817b.png#averageHue=%23161a1b&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=253&amp;id=ue27f6fe0&amp;margin=%5Bobject%20Object%5D&amp;originHeight=370&amp;originWidth=758&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0e18664d-4359-4f44-8a1c-c8cf898493a&amp;title=&amp;width=519.0000610351562" alt=""><br>其中，用 volatile 修饰了 HashEntry 的数据 value 和 下一个节点 next，保证了多线程环境下数据获取时的<strong>可见性</strong>！</p><p><strong>再来看下JDK1.8</strong></p><ul><li>在数据结构上， JDK1.8 中的ConcurrentHashMap 选择了与 HashMap 相同的<strong>数组+链表+红黑树</strong>结构；在锁的实现上，抛弃了原有的 Segment 分段锁，采用CAS + synchronized实现更加低粒度的锁。synchronized只锁定当前链表或红黑二叉树的首节点。</li><li>将锁的级别控制在了更细粒度的哈希桶元素级别，也就是说只需要锁住这个链表头结点（红黑树的根节点），就不会影响其他的哈希桶元素的读写，大大提高了并发度。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993056913-e561c03d-3dab-43e4-a74f-f19c011b3352.png#averageHue=%23fcf6eb&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u609f3aa1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=728&amp;originWidth=1001&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61773&amp;status=done&amp;style=none&amp;taskId=u9df3c8c2-98df-46bc-9521-67d1e4213e2&amp;title=" alt="image.png"><br>JDK1.8  中为什么使用内置锁 synchronized替换 可重入锁 ReentrantLock？★★★★★</p><ul><li>在 JDK1.6 中，对 synchronized 锁的实现引入了大量的优化，并且 synchronized 有多种锁状态，会从无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁一步步转换。</li><li>减少内存开销 。假设使用可重入锁来获得同步支持，那么每个节点都需要通过继承 AQS 来获得同步支持。但并不是每个节点都需要获得同步支持的，只有链表的头节点（红黑树的根节点）需要同步，这无疑带来了巨大内存浪费。<h4 id="2-存取"><a href="#2-存取" class="headerlink" title="2.存取"></a>2.存取</h4><strong>ConcurrentHashMap  的 put 方法执行逻辑是什么？★★★★</strong><br><strong>先来看JDK1.7</strong><br>首先，会尝试获取锁，如果获取失败，利用自旋获取锁；如果自旋重试的次数超过 64 次，则改为阻塞获取锁。<br>获取到锁后：</li></ul><ol><li>将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。</li><li>遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。</li><li>不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。</li><li>释放 Segment 的锁。</li></ol><p><strong>再来看JDK1.8</strong><br>大致可以分为以下步骤：</p><ol><li>根据 key 计算出 hash 值；</li><li>判断是否需要进行初始化；</li><li>定位到 Node，拿到首节点 f，判断首节点 f：<ul><li>如果为  null  ，则通过 CAS 的方式尝试添加；</li><li>如果为 f.hash = MOVED = -1 ，说明其他线程在扩容，参与一起扩容；</li><li>如果都不满足 ，synchronized 锁住 f 节点，判断是链表还是红黑树，遍历插入；</li></ul></li><li>当在链表长度达到 8 的时候，数组扩容或者将链表转换为红黑树。</li></ol><p><strong>ConcurrentHashMap  的 get 方法执行逻辑是什么？★★★★</strong><br>同样，<strong>先来看JDK1.7</strong></p><ul><li>首先，根据 key 计算出 hash 值定位到具体的 Segment ，再根据 hash 值获取定位 HashEntry 对象，并对 HashEntry 对象进行链表遍历，找到对应元素。</li><li>由于 HashEntry 涉及到的共享变量都使用 volatile 修饰，volatile 可以保证内存可见性，所以每次获取时都是最新值。</li></ul><p><strong>再来看JDK1.8</strong><br>大致可以分为以下步骤：</p><ol><li>根据 key 计算出 hash 值，判断数组是否为空；</li><li>如果是首节点，就直接返回；</li><li>如果是红黑树结构，就从红黑树里面查询；</li><li>如果是链表结构，循环遍历判断。</li></ol><p>ConcurrentHashMap 的 get 方法是否要加锁，为什么？★★★<br>get 方法不需要加锁。因为 Node 的元素 value 和指针 next 是用 volatile 修饰的，在多线程环境下线程A修改节点的 value 或者新增节点的时候是对线程B可见的。<br>这也是它比其他并发集合比如 Hashtable、用 Collections.synchronizedMap()包装的 HashMap 效率高的原因之一。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993410742-67955f27-1143-47ff-8e14-f528dde9421b.png#averageHue=%2316191b&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u48f27f38&amp;margin=%5Bobject%20Object%5D&amp;originHeight=406&amp;originWidth=978&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8ea04b91-88d7-4b09-9278-5efeb66f8ad&amp;title=" alt=""><br>get 方法不需要加锁与 volatile 修饰的哈希桶数组有关吗？★★★<br>没有关系。哈希桶数组table用 volatile 修饰主要是保证在数组扩容的时候保证可见性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993410703-7c611e85-dc8a-4d40-abc8-7c3aaee24792.png#averageHue=%2316191a&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud7ef757a&amp;margin=%5Bobject%20Object%5D&amp;originHeight=218&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u2e9a86e4-eb90-42b0-adfa-a44a187d81d&amp;title=" alt=""></p><h4 id="3-其他"><a href="#3-其他" class="headerlink" title="3. 其他"></a>3. 其他</h4><h5 id="ConcurrentHashMap-不支持-key-或者-value-为-null-的原因？★★★"><a href="#ConcurrentHashMap-不支持-key-或者-value-为-null-的原因？★★★" class="headerlink" title="ConcurrentHashMap  不支持 key 或者 value 为  null  的原因？★★★"></a>ConcurrentHashMap  不支持 key 或者 value 为  null  的原因？★★★</h5><p>我们先来说value 为什么不能为 null。</p><ul><li>因为 ConcurrentHashMap 是用于多线程的 ，如果ConcurrentHashMap.get(key)得到了 null ，这就无法判断，是映射的value是 null ，还是没有找到对应的key而为 null ，就有了二义性。</li></ul><p>而用于单线程状态的 HashMap 却可以用containsKey(key) 去判断到底是否包含了这个 null 。</p><blockquote><p>我们用<strong>反证法</strong>来推理：<br>假设 ConcurrentHashMap 允许存放值为 null 的 value，这时有A、B两个线程，线程A调用ConcurrentHashMap.get(key)方法，返回为 null ，我们不知道这个 null 是没有映射的 null ，还是存的值就是 null 。<br>假设此时，返回为 null 的真实情况是没有找到对应的 key。那么，我们可以用 ConcurrentHashMap.containsKey(key)来验证我们的假设是否成立，我们期望的结果是返回 false 。<br>但是在我们调用 ConcurrentHashMap.get(key)方法之后，containsKey方法之前，线程B执行了ConcurrentHashMap.put(key, null)的操作。那么我们调用containsKey方法返回的就是 true 了，这就与我们的假设的真实情况不符合了，这就有了二义性。<br>至于 ConcurrentHashMap 中的 key 为什么也不能为 null 的问题，源码就是这样写的，哈哈。如果面试官不满意，就回答因为作者Doug不喜欢 null ，所以在设计之初就不允许了 null 的 key 存在。想要深入了解的小伙伴，可以看这篇文章<a href="https://mp.weixin.qq.com/s?__biz=MzIxNTQ4MzE1NA==&amp;mid=2247484354&amp;idx=1&amp;sn=80c92881b47a586eba9c633eb78d36f6&amp;chksm=9796d5bfa0e15ca9713ff9dc6e100593e0ef06ed7ea2f60cb984e492c4ed438d2405fbb2c4ff&amp;scene=21#wechat_redirect">这道面试题我真不知道面试官想要的回答是什么</a></p></blockquote><h5 id="ConcurrentHashMap-的并发度是什么？★★"><a href="#ConcurrentHashMap-的并发度是什么？★★" class="headerlink" title="ConcurrentHashMap 的并发度是什么？★★"></a>ConcurrentHashMap 的并发度是什么？★★</h5><p>并发度可以理解为程序运行时能够同时更新 ConccurentHashMap且不产生锁竞争的最大线程数。</p><ul><li>在JDK1.7中，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度，默认是16，这个值可以在构造函数中设置。</li><li>如果自己设置了并发度，ConcurrentHashMap 会使用大于等于该值的最小的2的幂指数作为实际并发度，也就是比如你设置的值是17，那么实际并发度是32。</li><li>如果并发度设置的过小，会带来严重的锁竞争问题；</li><li>如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。</li></ul><p>在JDK1.8中，已经摒弃了Segment的概念，选择了Node数组+链表+红黑树结构，并发度大小依赖于数组的大小。</p><h5 id="ConcurrentHashMap-迭代器是强一致性还是弱一致性？★★"><a href="#ConcurrentHashMap-迭代器是强一致性还是弱一致性？★★" class="headerlink" title="ConcurrentHashMap 迭代器是强一致性还是弱一致性？★★"></a>ConcurrentHashMap 迭代器是强一致性还是弱一致性？★★</h5><p>与 HashMap 迭代器是强一致性不同，ConcurrentHashMap 迭代器是弱一致性。<br>ConcurrentHashMap 的迭代器创建后，就会按照哈希表结构遍历每个元素，但在遍历过程中，内部元素可能会发生变化，如果变化发生在已遍历过的部分，迭代器就不会反映出来，而如果变化发生在未遍历过的部分，迭代器就会发现并反映出来，这就是弱一致性。<br>这样迭代器线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。想要深入了解的小伙伴，可以看这篇文章：<a href="http://ifeve.com/ConcurrentHashMap-weakly-consistent/">http://ifeve.com/ConcurrentHashMap-weakly-consistent/</a></p><h5 id="JDK1-7-与-JDK1-8-中ConcurrentHashMap-的区别？★★★★★"><a href="#JDK1-7-与-JDK1-8-中ConcurrentHashMap-的区别？★★★★★" class="headerlink" title="JDK1.7 与 JDK1.8 中ConcurrentHashMap 的区别？★★★★★"></a>JDK1.7 与 JDK1.8 中ConcurrentHashMap 的区别？★★★★★</h5><ul><li>数据结构：取消了 Segment 分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。</li><li>保证线程安全机制：JDK1.7 采用 Segment 的分段锁机制实现线程安全，其中 Segment 继承自 ReentrantLock 。JDK1.8 采用CAS+synchronized保证线程安全。</li><li>锁的粒度：JDK1.7 是对需要进行数据操作的 Segment 加锁，JDK1.8 调整为对每个数组元素加锁（Node）。</li><li>链表转化为红黑树：因此在链表节点数量大于 8（且数据总量大于等于 64）时，会将链表转化为红黑树进行存储。</li><li><p>查询时间复杂度：从 JDK1.7的遍历链表O(n)， JDK1.8 变成遍历红黑树O(logN)。</p><h5 id="ConcurrentHashMap-和-Hashtable-的效率哪个更高？为什么？★★★★★"><a href="#ConcurrentHashMap-和-Hashtable-的效率哪个更高？为什么？★★★★★" class="headerlink" title="ConcurrentHashMap 和 Hashtable 的效率哪个更高？为什么？★★★★★"></a>ConcurrentHashMap 和 Hashtable 的效率哪个更高？为什么？★★★★★</h5><p>ConcurrentHashMap 的效率要高于 Hashtable，因为 Hashtable 给整个哈希表加了一把大锁从而实现线程安全。而ConcurrentHashMap 的锁粒度更低，在 JDK1.7 中采用分段锁实现线程安全，在 JDK1.8 中采用CAS+synchronized实现线程安全。</p><h5 id="ConcurrentHashMap-和-Hashtable-的区别"><a href="#ConcurrentHashMap-和-Hashtable-的区别" class="headerlink" title="ConcurrentHashMap 和 Hashtable 的区别"></a>ConcurrentHashMap 和 Hashtable 的区别</h5><p>ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。</p></li><li><p><strong>底层数据结构：</strong> JDK1.7 的 ConcurrentHashMap 底层采用 <strong>分段的数组+链表</strong> 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 <strong>数组+链表</strong> 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；</p></li><li><strong>实现线程安全的方式（重要）：</strong> ① <strong>在 JDK1.7 的时候，ConcurrentHashMap（分段锁）</strong> 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 <strong>到了 JDK1.8 的时候已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 对 synchronized 锁做了很多优化）</strong> 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② <strong>Hashtable(同一把锁)</strong> :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。<h5 id="具体说一下Hashtable的锁机制-★★★★★"><a href="#具体说一下Hashtable的锁机制-★★★★★" class="headerlink" title="具体说一下Hashtable的锁机制 ★★★★★"></a>具体说一下Hashtable的锁机制 ★★★★★</h5>Hashtable 是使用 synchronized来实现线程安全的，给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞等待需要的锁被释放，在竞争激烈的多线程场景中性能就会非常差！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993757033-5d17fd53-88b3-494a-949d-4bb5227dafbd.png#averageHue=%23fcf8ec&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=402&amp;id=u1b11a02a&amp;margin=%5Bobject%20Object%5D&amp;originHeight=592&amp;originWidth=821&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uae8a26a0-ccb0-475b-a518-3e3c5ab299e&amp;title=&amp;width=558.0000610351562" alt=""><br><strong>多线程下安全的操作 map还有其他方法吗？★★★</strong><br>还可以使用Collections.synchronizedMap方法，对方法进行加同步锁。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658993756936-6df9d3ba-b619-4015-aa1c-7b2cb61095d1.png#averageHue=%23161a1b&amp;clientId=ua09ed129-6bab-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue8e900cd&amp;margin=%5Bobject%20Object%5D&amp;originHeight=635&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub13d3e54-8445-47fc-a02e-753c9293ad7&amp;title=" alt=""><br>如果传入的是 HashMap 对象，其实也是对 HashMap 做的方法做了一层包装，里面使用对象锁来保证多线程场景下，线程安全，本质也是对 HashMap 进行全表锁。<strong>在竞争激烈的多线程环境下性能依然也非常差，不推荐使用！</strong><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h2 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h2></li></ul>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>锁篇</title>
      <link href="/2022/08/09/MySQL/%E9%94%81%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E9%94%81%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ锁的划分"><a href="#Ⅰ锁的划分" class="headerlink" title="Ⅰ锁的划分"></a>Ⅰ锁的划分</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649829094741-2ec90a4a-4a9d-4a12-8f39-d87523a27741.png#averageHue=%23fbfbfb&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=723&amp;id=fToOy&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=904&amp;originWidth=714&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=2586998&amp;status=done&amp;style=none&amp;taskId=ub9ed9fbf-fbce-4da1-bc48-5daa2548b0e&amp;title=&amp;width=571.2" alt="image.png"></p><h3 id="一、从数据操作的类型划分：读锁、写锁"><a href="#一、从数据操作的类型划分：读锁、写锁" class="headerlink" title="一、从数据操作的类型划分：读锁、写锁"></a>一、从数据操作的类型划分：读锁、写锁</h3><p>读锁：也称为共享锁、英文用S(shared lock) 表示。针对同一份数据，多个事务的读操作可以同时进行而不会相互阻塞的。<br>写锁：也称为排他锁、英文用X (exclusive lock)表示。当前写操作没有完成前，它会阻断其他写锁和读锁。这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。<br>需要注意的是对于InnoDB 引擎来说，读锁和写锁可以加在表上，也可以加在行上。</p><h4 id="锁定读"><a href="#锁定读" class="headerlink" title="锁定读"></a>锁定读</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649829348269-cf855e1a-79f0-4ffb-9267-cea027d44e59.png#averageHue=%23eae3d7&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=436&amp;id=JiDps&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=545&amp;originWidth=783&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=356584&amp;status=done&amp;style=none&amp;taskId=u0c3c1117-7021-4212-8e8f-1bbe71a4e40&amp;title=&amp;width=626.4" alt="image.png"></p><h4 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649829470106-52d9d9bc-7ea2-482d-91e9-27923bb1e111.png#averageHue=%23ebe6de&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=355&amp;id=FhWJU&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=444&amp;originWidth=790&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=310271&amp;status=done&amp;style=none&amp;taskId=u4c18a62c-d36f-494d-bfc1-f5c82e55352&amp;title=&amp;width=632" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649829476734-1ff5c49f-9751-49a0-8df1-741301c92a39.png#averageHue=%23f6f6f5&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=75&amp;id=gXVsL&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=94&amp;originWidth=778&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=43132&amp;status=done&amp;style=none&amp;taskId=ud2c86a54-86ff-4ef9-ade6-54b371575cf&amp;title=&amp;width=622.4" alt="image.png"></p><h3 id="二、根据加锁的粒度或者范围"><a href="#二、根据加锁的粒度或者范围" class="headerlink" title="二、根据加锁的粒度或者范围"></a>二、根据加锁的粒度或者范围</h3><p>在 MySQL 里，根据加锁的范围，可以分为<strong>全局锁、表级锁和行锁</strong>三类。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659853430118-21d8ad34-fb03-4ae1-90af-894fee6ee0e7.png#averageHue=%23f8f5f3&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=427&amp;id=Hs04L&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=589&amp;originWidth=720&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=141370&amp;status=done&amp;style=none&amp;taskId=u95634d98-4373-484c-80e1-7d9625c3dc5&amp;title=&amp;width=522.0000610351562" alt="image.png"></p><h4 id="①全局锁"><a href="#①全局锁" class="headerlink" title="①全局锁"></a>①全局锁</h4><p>全局锁是怎么用的？<br>要使用全局锁，则要执行这条命：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flush tables with read lock </span><br></pre></td></tr></table></figure><br>执行后，<strong>整个数据库就处于只读状态了</strong>，这时其他线程执行以下操作，都会被阻塞：</p><ul><li>对数据的增删改操作，比如 insert、delete、update等语句；</li><li>对表结构的更改操作，比如 alter table、drop table 等语句。</li></ul><p>如果要释放全局锁，则要执行这条命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unlock tables </span><br></pre></td></tr></table></figure><br>当然，当会话断开了，全局锁会被自动释放。<br>全局锁应用场景是什么？<br>全局锁主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。</p><p>举个例子大家就知道了。</p><p>在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。<br>如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更新，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。<br>那么，有可能出现这样的顺序：</p><ol><li>先备份了用户表的数据；</li><li>然后有用户发起了购买商品的操作；</li><li>接着再备份商品表的数据。</li></ol><p>也就是在备份用户表和商品表之间，有用户购买了商品。</p><p>这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。</p><p>所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。<br>加全局锁又会带来什么缺点呢？<br>加上全局锁，意味着整个数据库都是只读状态。</p><p>那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。<br>既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？<br>有的，如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。</p><p>因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。</p><p>备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。</p><p>InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。</p><p>但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。</p><h4 id="②表级锁"><a href="#②表级锁" class="headerlink" title="②表级锁"></a>②表级锁</h4><p>MySQL 表级锁有哪些？具体怎么用的。<br>MySQL 里面表级别的锁有这几种：</p><ul><li>表锁；</li><li>元数据锁（MDL）;</li><li>意向锁；</li><li>AUTO-INC 锁；<h5 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h5>先来说说<strong>表锁</strong>。<br>该锁会锁定整张表，它是MySQL中最基本的锁策略，并不依赖于存储引擎，并且表锁是开销最小的策略（因为锁的粒度比较大）。由于表级锁一次会将整个表锁定，所以可以很好的避免死锁问题。当然，锁的粒度大所带来的最大的问题就是出现锁资源争用的概念也会最高，导致并发率大大下降<br>LOCK TABLES t READ ：InnoDB存储引擎会对表t 加表级别的S锁。<br>LOCK TABLES t WRITE ：InnoDB存储引擎会对表t 加表级别的X锁。</li></ul><hr><p>详细内容如果我们想对学生表（t_student）加表锁，可以使用下面的命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//表级别的共享锁，也就是读锁；</span></span><br><span class="line">lock tables t_student read;</span><br><span class="line"></span><br><span class="line"><span class="comment">//表级别的独占锁，也就是写锁；</span></span><br><span class="line">lock tables t_stuent write;</span><br></pre></td></tr></table></figure><br>需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。</p><p>也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。</p><p>要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：<br>unlock tables<br>另外，当会话退出后，也会释放所有表锁。<br>不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，<strong>InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁</strong>。</p><h5 id="元数据锁"><a href="#元数据锁" class="headerlink" title="元数据锁"></a>元数据锁</h5><p>再来说说<strong>元数据锁</strong>（MDL）。</p><p>我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p><ul><li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li><li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li></ul><p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p><blockquote><p>当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。</p><p>反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。<br>MDL 不需要显示调用，那它是在什么时候释放的?<br>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p><p>那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：</p><ol><li>首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；</li><li>然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；</li><li>接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，</li></ol><p>那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。<br>为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？<br>这是因为申请 MDL 锁的操作会形成一个队列，队列中<strong>写锁获取优先级高于读锁</strong>，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。</p><p>所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。</p></blockquote><h5 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h5><p>InnoDB 支持多粒度锁（multiple granularity locking），它允许行级锁与表级锁共存，而<strong>意向锁</strong>就是其中的一种表锁。</p><ul><li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li><li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li></ul><p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。</p><p>意向锁分为两种：<br><strong>意向共享锁</strong>（intention shared lock,<strong> IS</strong>）：事务有意向对表中的某些行加<strong>共享锁</strong>（S锁）<br> — 事务要获取某些行的S 锁，必须先获得表的IS 锁。<br>SELECT column FROM table … LOCK IN SHARE MODE;<br><strong>意向排他锁</strong>（intention exclusive lock, <strong>IX</strong>）：事务有意向对表中的某些行加<strong>排他锁</strong>（X锁）<br> — 事务要获取某些行的X 锁，必须先获得表的IX 锁。<br>SELECT column FROM table … FOR UPDATE;<br>即：意向锁是由存储引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/ 排他锁之前，<br>InooDB 会先获取该数据行所在数据表的对应意向锁。</p><hr><p>而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。</p><p>不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//先在表上加上意向共享锁，然后对读取的记录加共享锁</span></span><br><span class="line">select ... lock in share mode;</span><br><span class="line"></span><br><span class="line"><span class="comment">//先表上加上意向独占锁，然后对读取的记录加独占锁</span></span><br><span class="line">select ... <span class="keyword">for</span> update;</span><br></pre></td></tr></table></figure><br><strong>意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（<em>lock tables … read</em>）和独占表锁（<em>lock tables … write</em>）发生冲突。</strong></p><p>表锁和行锁是满足读读共享、读写互斥、写写互斥的。</p><p>如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。</p><p>那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。</p><p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p><h5 id="AUTO-INC（自增）-锁"><a href="#AUTO-INC（自增）-锁" class="headerlink" title="AUTO-INC（自增） 锁"></a>AUTO-INC（自增） 锁</h5><p>最后，说说 <strong>AUTO-INC 锁</strong>。</p><p>在为某个字段声明 AUTO_INCREMENT 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。<br>AUTO-INC 锁是特殊的表锁机制，锁<strong>不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放</strong>。</p><p><strong>在插入数据时，会加一个表级别的 AUTO-INC 锁</strong>，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。</p><p>那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是连续递增的。</p><p>但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p><p>因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>来实现自增。<br>一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，<strong>然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁</strong>。<br>InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。</p><ul><li>当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁；</li><li>当 innodb_autoinc_lock_mode = 2，就采用轻量级锁；</li><li>当 innodb_autoinc_lock_mode = 1，这个是默认值，两种锁混着用，如果能够确定插入记录的数量就采用轻量级锁，不确定时就采用 AUTO-INC 锁。</li></ul><p>不过，当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，<strong>这在有主从复制的场景中是不安全的</strong>。</p><h4 id="③行级锁"><a href="#③行级锁" class="headerlink" title="③行级锁"></a>③行级锁</h4><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。<br>行级锁的类型主要有三类：</p><ul><li>Record Lock，记录锁，也就是仅仅把一条记录锁上；</li><li>Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li><li>Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li></ul><p>前面也提到，普通的 select 语句是不会对记录加锁的，如果要在查询时对记录加行锁，可以使用下面这两个方式：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对读取的记录加共享锁</span></span><br><span class="line">select ... lock in share mode;</span><br><span class="line"></span><br><span class="line"><span class="comment">//对读取的记录加独占锁</span></span><br><span class="line">select ... <span class="keyword">for</span> update;</span><br></pre></td></tr></table></figure><br>上面这两条语句必须在一个事务中，<strong>因为当事务提交了，锁就会被释放</strong>，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。</p><hr><p>行锁（Row Lock）也称为记录锁，顾名思义，就是锁住某一行（某条记录row）。需要注意的是，MySQL服务器层并没有实现行锁机制，行级锁只在存储引擎实现。<br>优点：锁粒度小，发生锁冲突概率低，可以实现的并发度高。<br>缺点：对于锁的开销比较大，加锁会比较慢，容易出现死锁情况。<br>Innodb于myisam最大不同有两点：一是支持事务，二是采用了行级锁。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830350469-6d45120a-e94c-4c3e-bcda-ce5101a80813.png#averageHue=%23f5f3ec&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=166&amp;id=Qjmio&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=207&amp;originWidth=301&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=43900&amp;status=done&amp;style=none&amp;taskId=ua439e2c2-4b49-4d68-92f6-c872725b156&amp;title=&amp;width=240.8" alt="image.png"><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830357940-8b88baa3-3883-4604-a047-f0160b352bab.png#averageHue=%23f5f4f1&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=359&amp;id=To3FE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=487&amp;originWidth=434&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=113075&amp;status=done&amp;style=none&amp;taskId=u1e324dfc-11c2-4020-9734-8e55f7b0466&amp;title=&amp;width=320.1999969482422" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830375901-a18f8fb1-2df7-4160-a76d-dd19a2a7ade3.png#averageHue=%23fafafa&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=151&amp;id=oitpy&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=189&amp;originWidth=794&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50390&amp;status=done&amp;style=none&amp;taskId=u721a0cb7-3a2a-448e-9ba9-fbfb1aba569&amp;title=&amp;width=635.2" alt="image.png"></p><h5 id="1-记录锁（Record-Locks）"><a href="#1-记录锁（Record-Locks）" class="headerlink" title="1. 记录锁（Record Locks）"></a>1. 记录锁（Record Locks）</h5><p>记录锁也就是仅仅把一条记录锁上，官方的类型名称为：LOCK_REC_NOT_GAP 。比如我们把id值为8的那条记录加一个记录锁的示意图如图所示。仅仅是锁住了id值为8的记录，对周围的数据没有影响。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830412355-5d3a37b1-d9df-4240-a640-6d27c1cdf91d.png#averageHue=%23d1d8ba&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=179&amp;id=uxVPT&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=224&amp;originWidth=690&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=619559&amp;status=done&amp;style=none&amp;taskId=u03210215-0698-4a5b-8b2d-ce3394d6f9f&amp;title=&amp;width=552" alt="image.png"><br>举例如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830423704-94ae6b79-0fea-400f-9ef8-943cda7fc82d.png#averageHue=%23f4f4f4&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=294&amp;id=YPdJE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=368&amp;originWidth=732&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1079704&amp;status=done&amp;style=none&amp;taskId=u2e32c06d-4f82-4d55-9dbc-a13211d4018&amp;title=&amp;width=585.6" alt="image.png"><br>记录锁是有S锁和X锁之分的，称之为S型记录锁和X型记录锁。<br>不同的记录之间是不冲突的。</p><ul><li>当一个事务获取了一条记录的S型记录锁后，其他事务也可以继续获取该记录的S型记录锁，但不可  以继续获取X型记录锁；</li><li>当一个事务获取了一条记录的X型记录锁后，其他事务既不可以继续获取该记录的S型记录锁，也不  可以继续获取X型记录锁。<h5 id="2-间隙锁（Gap-Locks）"><a href="#2-间隙锁（Gap-Locks）" class="headerlink" title="2. 间隙锁（Gap Locks）"></a>2. 间隙锁（Gap Locks）</h5>MySQL 在REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用MVCC 方案解决，也可以采用加锁方案解决。但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些幻影记录加上记录锁。InnoDB提出了一种称之为Gap Locks 的锁，官方的类型名称为：LOCK_GAP ，我们可以简称为gap锁。比如，把id值为8的那条记录加一个gap锁的示意图如下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830540923-edb07c7f-cc1e-420a-af4e-537e9c5245e9.png#averageHue=%23e5ceab&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=287&amp;id=yLs6S&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=359&amp;originWidth=856&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=156623&amp;status=done&amp;style=none&amp;taskId=uff42f499-2e48-447c-b451-99a7f94328c&amp;title=&amp;width=684.8" alt="image.png"><br>图中id值为8的记录加了gap锁，意味着不允许别的事务在id值为8的记录前边的间隙插入新记录，其实就是id列的值(3,   8)这个区间的新记录是不允许立即插入的。比如，有另外一个事务再想插入一条id值为4的新记录，它定位到该条新记录的下一条记录的id值为8，而这条记录上又有一个gap锁，所以就会阻塞插入   操作，直到拥有这个gap锁的事务提交了之后，id列的值在区间(3, 8)中的新记录才可以被插入。<br>gap锁的提出仅仅是为了防止插入幻影记录而提出的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830640521-599370a6-d6eb-4870-8743-7c1d60af73e3.png#averageHue=%23f8f8f8&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=190&amp;id=kZH3k&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=237&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=721971&amp;status=done&amp;style=none&amp;taskId=uf4ccd3cc-dddc-4668-9766-29ae10cfeac&amp;title=&amp;width=608" alt="image.png"><br>如果再开一个会话，在3-8之间添加数据会阻塞。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830677615-716a81eb-4eb7-4a21-a5d5-ab2936787600.png#averageHue=%230c0c0c&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=127&amp;id=gyBU1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=159&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=484402&amp;status=done&amp;style=none&amp;taskId=u8ca1626d-70c5-4c6d-aea1-c842f009d00&amp;title=&amp;width=608" alt="image.png"><h5 id="3-临键锁（Next-Key-Locks）"><a href="#3-临键锁（Next-Key-Locks）" class="headerlink" title="3. 临键锁（Next-Key Locks）"></a>3. 临键锁（Next-Key Locks）</h5>有时候我们既想锁住某条记录，又想阻止其他事务在该记录前边的间隙插入新记录，所以InnoDB就提出了一种称之为Next-Key Locks 的锁，官方的类型名称为：LOCK_ORDINARY ，我们也可以简称为next-key锁。Next-Key Locks是在存储引擎innodb 、事务级别在可重复读的情况下使用的数据库锁，innodb默认的锁就是Next-Key locks。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649830727494-d406c472-6063-4c8e-8e9b-57af1d10bbf5.png#averageHue=%23f2f1eb&amp;clientId=u20113b0d-de5a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=266&amp;id=fQ956&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=333&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1014384&amp;status=done&amp;style=none&amp;taskId=u86e59688-923b-48da-8952-3a7122732a4&amp;title=&amp;width=608" alt="image.png"><br>begin;<br>select * from student where id &lt;=8 and id &gt; 3 for update;<h5 id="4-插入意向锁（Insert-Intention-Locks）"><a href="#4-插入意向锁（Insert-Intention-Locks）" class="headerlink" title="4. 插入意向锁（Insert Intention Locks）"></a>4. 插入意向锁（Insert Intention Locks）</h5>我们说一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了gap锁（next-key锁<br>也包含gap锁），如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交。但是<strong>InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构</strong>，表明有事务想在某个间隙中插入新记录，但是现在在等待。InnoDB就把这种类型的锁命名为Insert Intention Locks ，官方的类型名称为：LOCK_INSERT_INTENTION，我们称为插入意向锁。插入意向锁是一种Gap锁，不是意向锁，在insert<br>操作时产生。<h4 id="④页锁"><a href="#④页锁" class="headerlink" title="④页锁"></a>④页锁</h4>页锁就是在页的粒度上进行锁定，锁定的数据资源比行锁要多，因为一个页中可以有多个行记录。当我们使用页锁的时候，会出现数据浪费的现象，但这样的浪费最多也就是一个页上的数据行。<strong>页锁的开销  介于表锁和行锁之间，会出现死锁。锁定粒度介于表锁和行锁之间，并发度一般。</strong><br>每个层级的锁数量是有限制的，因为锁会占用内存空间，锁空间的大小是有限的。当某个层级的锁数量超过了这个层级的阈值时，就会进行锁升级。锁升级就是用更大粒度的锁替代多个更小粒度的锁，比如InnoDB 中行锁升级为表锁，这样做的好处是占用的锁空间降低了，但同时数据的并发度也下降了。<h3 id="三、从对待锁的态度划分-乐观锁、悲观锁"><a href="#三、从对待锁的态度划分-乐观锁、悲观锁" class="headerlink" title="三、从对待锁的态度划分:乐观锁、悲观锁"></a>三、从对待锁的态度划分:乐观锁、悲观锁</h3>乐观锁与悲观锁<br>为什么需要锁<br>在并发环境下，如果多个客户端访问同一条数据，此时就会产生数据不一致的问题，如何解决，通过加锁的机制，常见的有两种锁，<a href="https://so.csdn.net/so/search?q=%E4%B9%90%E8%A7%82%E9%94%81&amp;spm=1001.2101.3001.7020">乐观锁</a>和悲观锁，可以在一定程度上解决并发访问。<h4 id="1-悲观锁（Pessimistic-Locking）"><a href="#1-悲观锁（Pessimistic-Locking）" class="headerlink" title="1. 悲观锁（Pessimistic Locking）"></a>1. 悲观锁（Pessimistic Locking）</h4>悲观锁是一种思想，顾名思义，就是很悲观，对数据被其他事务的修改持保守态度，会通过数据库自身  的锁机制来实现，从而保证数据操作的排它性。<br>悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上   锁，这样别人想拿这个数据就会阻塞直到它拿到锁（<strong>共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程</strong>）。比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，当   其他线程想要访问数据时，都需要阻塞挂起。Java中synchronized 和ReentrantLock 等独占锁就是悲观锁思想的实现。<h4 id="2-乐观锁（Optimistic-Locking）"><a href="#2-乐观锁（Optimistic-Locking）" class="headerlink" title="2. 乐观锁（Optimistic Locking）"></a>2. 乐观锁（Optimistic Locking）</h4>先进行业务操作，不到最后一步不进行加锁，乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新   的时候会判断一下在此期间别人有没有去更新这个数据，也就是<strong>不采用数据库自身的锁机制，而是通过程序来实现</strong>。在程序上，我们可以采用版本号机制或者CAS机制实现。<strong>乐观锁适用于多读的应用类型，这样可以提高吞吐量</strong>。在Java中java.util.concurrent.atomic 包下的原子变量类就是使用了乐观锁的一种实现方式：CAS实现的。<h5 id="①乐观锁的版本号机制"><a href="#①乐观锁的版本号机制" class="headerlink" title="①乐观锁的版本号机制"></a>①乐观锁的版本号机制</h5>在表中设计一个版本字段version ，第一次读的时候，会获取version 字段的取值。然后对数据进行更新或删除操作时，会执行UPDATE … SET version=version+1 WHERE version=version 。此时如果已经有事务对这条数据进行了更改，修改就不会成功。</li></ul><h5 id="②乐观锁的时间戳机制"><a href="#②乐观锁的时间戳机制" class="headerlink" title="②乐观锁的时间戳机制"></a>②乐观锁的时间戳机制</h5><p>时间戳和版本号机制一样，也是在更新提交的时候，将当前数据的时间戳和更新之前取得的时间戳进行  比较，如果两者一致则更新成功，否则就是版本冲突。<br>你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是通过给数据行增加一个戳（版本号或  者时间戳），从而证明当前拿到的数据是否最新。</p><h4 id="3-两种锁的适用场景"><a href="#3-两种锁的适用场景" class="headerlink" title="3. 两种锁的适用场景"></a>3. 两种锁的适用场景</h4><p>从这两种锁的设计思想中，我们总结一下乐观锁和悲观锁的适用场景：</p><ol><li>乐观锁适合读操作多的场景，相对来说写的操作比较少。它的优点在于程序实现，问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。</li><li>悲观锁适合写操作多的场景，因为写的操作具有排它性。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止读- 写和写- 写的冲突。</li></ol><h2 id="ⅡMySQL-是怎么加锁的？"><a href="#ⅡMySQL-是怎么加锁的？" class="headerlink" title="ⅡMySQL 是怎么加锁的？"></a>ⅡMySQL 是怎么加锁的？</h2><p>大家好，我是小林。<br>在前一篇文章我讲了下 MySQL 的全局锁、表级锁和行级别锁，其中行级锁只提了概念，并没有具体说。<br>因为行级锁加锁规则比较复杂，不同的场景，加锁的形式还不同，所以这次就来好好介绍下行级锁。<br>对记录加锁时，<strong>加锁的基本单位是 next-key lock</strong>，它是由记录锁和间隙锁组合而成的，<strong>next-key lock 是前开后闭区间，而间隙锁是前开后开区间</strong>。<br>但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。<br>那到底是什么场景呢？今天，我们就以下面这个表来进行实验说明。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855594616-1f16a47b-1a8d-45f0-97da-cc10a0ca0884.png#averageHue=%23fbfbfb&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1d1032b9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=143&amp;originWidth=336&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=3971&amp;status=done&amp;style=none&amp;taskId=u238ec4fb-470b-496d-8c98-e52fa6deca9&amp;title=" alt="image.png"><br>其中，id 是主键索引（唯一索引），b 是普通索引（非唯一索引），a 是普通的列。<br>注意，<strong>我的 MySQL 的版本是 8.0.26，不同版本的加锁规则可能是不同的</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855594667-c7429579-fd1b-4303-9753-d70756ea1b22.png#averageHue=%23f7f6f5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=510&amp;id=uf17e1194&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=888&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=94391&amp;status=done&amp;style=none&amp;taskId=u505d5471-b7e6-4b4f-98d7-ab97058551a&amp;title=&amp;width=620.0000610351562" alt="image.png"></p><h3 id="唯一索引等值查询"><a href="#唯一索引等值查询" class="headerlink" title="唯一索引等值查询"></a>唯一索引等值查询</h3><p>当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><ul><li><strong>当查询的记录是存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「记录锁」</strong>。</li><li><strong>当查询的记录是不存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「间隙锁」</strong>。</li></ul><p>接下里用两个案例来说明。<br>先看看记录是存在的。<br>来看下面这个例子：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855594684-704ef3de-426d-4661-88e7-a8f16880b9ad.png#averageHue=%23f1e6c0&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u19d3ca07&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=482&amp;originWidth=947&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=52323&amp;status=done&amp;style=none&amp;taskId=u87bb7e4b-814b-4ef9-b781-513ddc26bc9&amp;title=" alt="image.png"><br>会话1加锁变化过程如下：</p><ol><li>加锁的基本单位是 next-key lock，因此会话1的加锁范围是(8, 16];</li><li>但是由于是用唯一索引进行等值查询，且查询的记录存在，所以 <strong>next-key lock 退化成记录锁，因此最终加锁的范围是 id = 16 这一行</strong>。</li></ol><p>所以，会话 2 在修改 id=16 的记录时会被锁住，而会话 3 插入 id=9 的记录可以被正常执行。<br>接下来，看看记录不存在的情况<br>来看看，下面这个例子：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855594554-fb7605ef-3333-4064-9d16-ebcc65c8b43d.png#averageHue=%23ece1bc&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2f43eeca&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=482&amp;originWidth=947&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58828&amp;status=done&amp;style=none&amp;taskId=u25d5518e-3520-4560-9a92-2cef69251bc&amp;title=" alt="image.png"><br>会话1加锁变化过程如下：</p><ol><li>加锁的基本单位是 next-key lock，因此主键索引 id 的加锁范围是(8, 16];</li><li>但是由于查询记录不存在，next-key lock 退化成间隙锁，因此最终加锁的范围是 (8,16)。</li></ol><p>所以，会话 2 要往这个间隙里面插入 id=9 的记录会被锁住，但是会话 3 修改 id =16 是可以正常执行的，因为 id = 16 这条记录并没有加锁。</p><h3 id="唯一索引范围查询"><a href="#唯一索引范围查询" class="headerlink" title="唯一索引范围查询"></a>唯一索引范围查询</h3><p>范围查询和等值查询的加锁规则是不同的。<br>举个例子，下面这两条查询语句，查询的结果虽然是一样的，但是加锁的范围是不一样的。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from t_test where id=<span class="number">8</span> <span class="keyword">for</span> update;</span><br><span class="line">select * from t_test where id&gt;=<span class="number">8</span> and id&lt;<span class="number">9</span> <span class="keyword">for</span> update;</span><br></pre></td></tr></table></figure><br>做个实验就知道了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855594649-26a6ba72-dfd1-46eb-9e8a-ddc3d27581aa.png#averageHue=%23e9ddba&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udf55eed2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=515&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=79381&amp;status=done&amp;style=none&amp;taskId=u93dc5b6d-868a-45cf-a349-c1842ff6eb5&amp;title=" alt="image.png"><br>会话 1 加锁变化过程如下：</p><ol><li>最开始要找的第一行是 id = 8，因此 next-key lock(4,8]，但是由于 id 是唯一索引，且该记录是存在的，因此会退化成记录锁，也就是只会对 id = 8 这一行加锁；</li><li>由于是范围查找，就会继续往后找存在的记录，也就是会找到 id = 16 这一行停下来，然后加 next-key lock (8, 16]，但由于 id = 16 不满足 id &lt; 9，所以会退化成间隙锁，加锁范围变为 (8, 16)。</li></ol><p>所以，会话 1 这时候主键索引的锁是记录锁 id=8 和间隙锁(8, 16)。<br>会话 2 由于往间隙锁里插入了 id = 9 的记录，所以会被锁住了，而 id = 8 是被加锁的，因此会话 3 的语句也会被阻塞。<br>由于 id = 16 并没有加锁，所以会话 4 是可以正常被执行。</p><h3 id="非唯一索引等值查询"><a href="#非唯一索引等值查询" class="headerlink" title="非唯一索引等值查询"></a>非唯一索引等值查询</h3><p>当我们用非唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><ul><li><strong>当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁</strong>。</li><li><strong>当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。</strong></li></ul><p>接下里用两个案例来说明。<br>我们先来看看查询的值存在的情况。<br>比如下面这个例子：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855596108-3aac9a05-5789-4c37-87c1-ab17430b6f1f.png#averageHue=%23f8f2f0&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=436&amp;id=u039c4e54&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=804&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=106822&amp;status=done&amp;style=none&amp;taskId=ub499ad59-de6c-46c9-9ff3-1220e84718d&amp;title=&amp;width=586.0000610351562" alt="image.png"><br>会话 1 加锁变化过程如下：</p><ol><li>先会对普通索引 b 加上 next-key lock，范围是(4,8];</li><li>然后因为是非唯一索引，且查询的记录是存在的，所以还会加上间隙锁，规则是向下遍历到第一个不符合条件的值才能停止，因此间隙锁的范围是(8,16)。</li></ol><p>所以，会话1的普通索引 b 上共有两个锁，分别是 next-key lock (4,8] 和间隙锁 (8,16) 。<br>那么，当会话 2 往间隙锁里插入 id = 9 的记录就会被锁住，而会话 3 和会话 4 是因为更改了 next-key lock 范围里的记录而被锁住的。<br>然后因为 b = 16 这条记录没有加锁，所以会话 5 是可以正常执行的。</p><blockquote><p><strong>TIP</strong><br>之前有读者反馈说，他自己做实验，发现插入 b = 4 这条记录会被阻塞，和我说的 next-key lock (4,8] 有点矛盾。<br>其实测试锁的范围是开区间还是闭区间不能用 insert 语句测试，而是要用 update 语句去测试。<br>因为 insert 加的锁是比较特殊的，<strong>每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁</strong>。<br>插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，然后插入意向锁和间隙锁是冲突的，所以插入 b = 4 这条记录就发生阻塞了。具体 insert 语句是怎么加锁的，可以看这篇：<a href="https://xiaolincoding.com/mysql/lock/deadlock.html#insert-%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E8%A1%8C%E7%BA%A7%E9%94%81%E7%9A%84">MySQL 死锁了，怎么办？(opens new window)</a><br>而用 update 语句来更新 b = 4 的这条记录，加的是记录锁，你测试的时候，会发现更新 b = 4 的这条记录是能更新成功的，所以 b = 4 这条并没有加锁，因此 next-key lock 的范围是 (4,8] ，是没问题。</p></blockquote><p>接下来，我们看看查询的值不存在的情况<br>直接看案例：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855596014-20285e30-baff-479f-939b-48f81e205029.png#averageHue=%23e9e4c9&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udeb75707&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=557&amp;originWidth=917&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=129308&amp;status=done&amp;style=none&amp;taskId=u3ec1c347-8acb-4b0b-8f96-382fea33306&amp;title=" alt="image.png"><br>会话 1 加锁变化过程如下：</p><ol><li>先会对普通索引 b 加上 next-key lock，范围是(8,16];</li><li>但是由于查询的记录是不存在的，所以不会再额外加个间隙锁，但是 next-key lock 会退化为间隙锁，最终加锁范围是 (8,16)。</li></ol><p>会话 2 因为往间隙锁里插入了 b = 9 的记录，所以会被锁住，而 b = 16 是没有被加锁的，因此会话 3 的语句可以正常执行。</p><h3 id="非唯一索引范围查询"><a href="#非唯一索引范围查询" class="headerlink" title="非唯一索引范围查询"></a>非唯一索引范围查询</h3><p>非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于<strong>普通索引范围查询，next-key lock 不会退化为间隙锁和记录锁</strong>。<br>来看下面这个案例：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659855596029-fe82cf15-14bf-4e91-9b81-f844ab0ce931.png#averageHue=%23f6eeeb&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucd337023&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=678&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=98139&amp;status=done&amp;style=none&amp;taskId=uf1154a92-808b-4fad-a01f-330e6b1f9cc&amp;title=" alt="image.png"><br>会话 1 加锁变化过程如下：</p><ol><li>最开始要找的第一行是 b = 8，因此 next-key lock(4,8]，但是由于 b 不是唯一索引，并不会退化成记录锁。</li><li>但是由于是范围查找，就会继续往后找存在的记录，也就是会找到 b = 16 这一行停下来，然后加 next-key lock (8, 16]，因为是普通索引查询，所以并不会退化成间隙锁。</li></ol><p>所以，会话 1 的普通索引 b 有两个 next-key lock，分别是 (4,8] 和(8, 16]。这样，你就明白为什么会话 2 、会话 3 、会话 4 的语句都会被锁住了。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这次我以 <strong><em>MySQL 8.0.26</em></strong> 版本做了几个实验，让大家了解了唯一索引和非唯一索引的行级锁的加锁规则。<br>这里需要注意的是，不同的版本加锁规则可能会有所不同。我这里总结下， 我这个 MySQL 版本的行级锁的加锁规则。<br>唯一索引等值查询：</p><ul><li>当查询的记录是存在的，next-key lock 会退化成「记录锁」。</li><li>当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。</li></ul><p>非唯一索引等值查询：</p><ul><li>当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。</li><li>当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。</li></ul><p>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：</p><ul><li>唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。</li><li>非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。</li></ul><p>这些加锁规则其实很好总结的，大家自己可以用我文中的案例测试一遍，看一下你的 MySQL 版本和我的 MySQL 版本的加锁规则有什么不同。<br>加锁规则## 加锁规则<br>首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，<strong>这个规则有以下两条前提说明：</strong></p><ol><li>MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13。</li><li>如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。</li></ol><p>因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。<br><strong>我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。</strong></p><ol><li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。</li><li>原则 2：查找过程中访问到的对象才会加锁。</li><li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ol><p>我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。<br>复制代码<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651894063125-10dea1b5-ff56-47c4-be61-e0be67d0f186.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=212&amp;id=YyZFH&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=265&amp;originWidth=449&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=13742&amp;status=done&amp;style=none&amp;taskId=u171b7ba0-fd4e-4c59-a417-e8d0b254a81&amp;title=&amp;width=359.2" alt="image.png"><br>接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。</p><h3 id="案例一：等值查询间隙锁"><a href="#案例一：等值查询间隙锁" class="headerlink" title="案例一：等值查询间隙锁"></a>案例一：等值查询间隙锁</h3><p>第一个例子是关于等值条件操作间隙：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893901297-3871443c-bf63-4ca9-9db3-a37c1f5912f2.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=gwEtW&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=313&amp;originWidth=936&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=31058&amp;status=done&amp;style=none&amp;taskId=ueffd6602-f3fa-485b-b812-4124115716d&amp;title=" alt="image.png"><br>图 1 等值查询的间隙锁<br>由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：</p><ol><li>根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；</li><li>同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。</li></ol><p>所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。</p><h3 id="案例二：非唯一索引等值锁"><a href="#案例二：非唯一索引等值锁" class="headerlink" title="案例二：非唯一索引等值锁"></a>案例二：非唯一索引等值锁</h3><p>第二个例子是关于覆盖索引上的锁：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893901395-7ccd2af9-886a-4687-bf7a-f48a626bc720.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=TqVHV&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=462&amp;originWidth=1244&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50829&amp;status=done&amp;style=none&amp;taskId=u796bb1f5-a9fa-47fd-bd35-ccf80fa7c3c&amp;title=" alt="image.png"><br>图 2 只加在非唯一索引上的锁<br>看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。<br>这里 session A 要给索引 c 上 c=5 的这一行加上读锁。</p><ol><li>根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 next-key lock。</li><li>要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 next-key lock。</li><li>但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。</li><li>根据原则 2 ，<strong>只有访问到的对象才会加锁</strong>，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。</li></ol><p>但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。<br>需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。<br>这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。你可以自己验证一下效果。</p><h3 id="案例三：主键索引范围锁"><a href="#案例三：主键索引范围锁" class="headerlink" title="案例三：主键索引范围锁"></a>案例三：主键索引范围锁</h3><p>第三个例子是关于范围查询的。<br>举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？<br>复制代码<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651894300946-51e8aa02-f41d-4d99-9146-ba164747cab6.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=56&amp;id=KUudc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=70&amp;originWidth=554&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=5444&amp;status=done&amp;style=none&amp;taskId=u6eb3b1f2-6c57-4e36-8107-30b7698b741&amp;title=&amp;width=443.2" alt="image.png"><br>你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。<br>在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893901716-e5797456-47a0-4033-94b7-27e734ee5c81.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=JmHSm&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=718&amp;originWidth=1244&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72388&amp;status=done&amp;style=none&amp;taskId=u8c1d3139-82cb-4538-8277-3422f30d6e2&amp;title=" alt="image.png"><br>图 3 主键索引上范围查询的锁<br>现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？</p><ol><li>开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。</li><li>范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。</li></ol><p>所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。<br>这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。</p><h3 id="案例四：非唯一索引范围锁"><a href="#案例四：非唯一索引范围锁" class="headerlink" title="案例四：非唯一索引范围锁"></a>案例四：非唯一索引范围锁</h3><p>接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。<br>需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893901712-aba85012-48b7-444f-9e64-85bdb1d0c837.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=wdNiL&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=550&amp;originWidth=1246&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54082&amp;status=done&amp;style=none&amp;taskId=u20e40614-e5f7-4285-ab17-f9dbfd6d09d&amp;title=" alt="image.png"><br>图 4 非唯一索引范围锁<br>这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。<br>所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。<br>这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。</p><h3 id="案例五：唯一索引范围锁-bug"><a href="#案例五：唯一索引范围锁-bug" class="headerlink" title="案例五：唯一索引范围锁 bug"></a>案例五：唯一索引范围锁 bug</h3><p>前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893901721-ed6188ac-7b01-455a-a6c4-bd38a08454c0.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=r79Cw&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=590&amp;originWidth=1250&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57554&amp;status=done&amp;style=none&amp;taskId=ub918bf04-c00a-4c76-be09-16f824fb132&amp;title=" alt="image.png"><br>图 5 唯一索引范围锁的 bug<br>session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。<br>但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。<br>所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。<br>照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。<br>我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。</p><h3 id="案例六：非唯一索引上存在”等值”的例子"><a href="#案例六：非唯一索引上存在”等值”的例子" class="headerlink" title="案例六：非唯一索引上存在”等值”的例子"></a>案例六：非唯一索引上存在”等值”的例子</h3><p>接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651894530747-6b6db23d-6fea-4ddf-8bc5-fcd0e0350191.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=30&amp;id=z5fcj&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=38&amp;originWidth=393&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=2204&amp;status=done&amp;style=none&amp;taskId=u573e2e40-8804-4cfd-bd8c-26bf968a695&amp;title=&amp;width=314.4" alt="image.png"><br>新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893902493-66bed29d-9e69-42fa-a6f0-22d3e1e2a3f0.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=gWKBt&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72863&amp;status=done&amp;style=none&amp;taskId=ufc3f9b11-495c-4f42-850a-74d493434bd&amp;title=" alt="image.png"><br>图 6 非唯一索引等值的例子<br>可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。<br>图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。<br>现在，我们来看一下案例六。<br>这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select … for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893902726-fee2b240-3946-4ca9-936a-e35b707b1bd6.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=kBluN&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=556&amp;originWidth=1248&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50662&amp;status=done&amp;style=none&amp;taskId=u9130bc78-78dd-4e2e-91a5-bcebf6c42b6&amp;title=" alt="image.png"><br>图 7 delete 示例<br>这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。<br>然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。<br>也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893902804-709f38ae-09df-4aba-813e-9786c1ffd279.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Dhcd0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=87764&amp;status=done&amp;style=none&amp;taskId=uf41ae9dd-233a-46b1-8b6d-25edd9d36fb&amp;title=" alt="image.png"><br>图 8 delete 加锁效果示例<br>这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。</p><h3 id="案例七：limit-语句加锁"><a href="#案例七：limit-语句加锁" class="headerlink" title="案例七：limit 语句加锁"></a>案例七：limit 语句加锁</h3><p>例子 6 也有一个对照案例，场景如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893902924-5ee227b0-0526-4236-a4cc-e7c0c8747133.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Zhln5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=318&amp;originWidth=954&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29607&amp;status=done&amp;style=none&amp;taskId=u8fb1fd59-1664-48b5-b9a4-dbd94e3dfa6&amp;title=" alt="image.png"><br>图 9 limit 语句加锁<br>这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。<br>这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。<br>因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893903022-59de2144-6b04-4836-ba17-f595331a64bb.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=BfFzI&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=88164&amp;status=done&amp;style=none&amp;taskId=ubc3d2e01-c66b-4541-9e24-b6ce2ac8ac8&amp;title=" alt="image.png"><br>图 10 带 limit 2 的加锁效果<br>可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。<br>这个例子对我们实践的指导意义就是，<strong>在删除数据的时候尽量加 limit</strong>。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。</p><h3 id="案例八：一个死锁的例子"><a href="#案例八：一个死锁的例子" class="headerlink" title="案例八：一个死锁的例子"></a>案例八：一个死锁的例子</h3><p>前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。<br>你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893903847-adf31ea3-42a0-4eb5-8184-c28b7a1d6400.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=KgXG4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=650&amp;originWidth=1106&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=68523&amp;status=done&amp;style=none&amp;taskId=ud62906b2-72c4-4111-9fe7-542fc812659&amp;title=" alt="image.png"><br>图 11 案例八的操作序列<br>现在，我们按时间顺序来分析一下为什么是这样的结果。</p><ol><li>session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；</li><li>session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；</li><li>然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。</li></ol><p>你可能会问，session B 的 next-key lock 不是还没申请成功吗？<br>其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。<br>也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。<br>在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。<br>其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。<br>另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。<br>也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。<br>不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。<br>在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。<br>经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。<br>我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6 条记录，图 12 的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651893903821-619a9d8e-054f-4c3c-a849-3fa393854310.png#clientId=ub7e7a10a-73cd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=dC1U2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=270&amp;originWidth=942&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=27789&amp;status=done&amp;style=none&amp;taskId=u126f06a8-8d8e-489a-bfd5-221c06ecdda&amp;title=" alt="image.png"><br>图 12 锁分析思考题<br>另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。<br>对于那些你自己无法解释的结果，可以发到评论区里，后面我争取挑一些有趣的案例在文章中分析。<br>你可以把你关于思考题的分析写在留言区，也可以分享你自己设计的锁验证方案，我会在下一篇文章的末尾选取有趣的评论跟大家分享。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p><h3 id="上期问题时间"><a href="#上期问题时间" class="headerlink" title="上期问题时间"></a>上期问题时间</h3><p>上期的问题，我在本期继续作为了课后思考题，所以会在下篇文章再一起公布“答案”。<br>这里，我展开回答一下评论区几位同学的问题。</p><ul><li>@令狐少侠 说，以前一直认为间隙锁只在二级索引上有。现在你知道了，有间隙的地方就可能有间隙锁。</li><li>@浪里白条 同学问，如果是 varchar 类型，加锁规则是什么样的。<br>回答：实际上在判断间隙的时候，varchar 和 int 是一样的，排好序以后，相邻两个值之间就有间隙。</li><li>有几位同学提到说，上一篇文章自己验证的结果跟案例一不同，就是在 session A 执行完这两个语句：</li></ul><p>复制代码<br>begin;<br>begin;<br>select <em> from t where d=5 for update; /</em>Q1<em>/<br>select </em> from t where d=5 for update; /<em>Q1</em>/<br>以后，session B 的 update 和 session C 的 insert 都会被堵住。这是不是跟文章的结论矛盾？<br>其实不是的，这个例子用的是反证假设，就是假设不堵住，会出现问题；然后，推导出 session A 需要锁整个表所有的行和所有间隙。</p><h2 id="Ⅲupdate-没加索引会锁全表？"><a href="#Ⅲupdate-没加索引会锁全表？" class="headerlink" title="Ⅲupdate 没加索引会锁全表？"></a>Ⅲupdate 没加索引会锁全表？</h2><p>大家好，我是小林。<br>昨晚在群划水的时候，看到有位读者说了这么一件事。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856023906-b51862c1-a491-4ced-8006-8a8bcdd807e0.png#averageHue=%23e8e7e3&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=471&amp;id=ueacf32da&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=634&amp;originWidth=750&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=220471&amp;status=done&amp;style=none&amp;taskId=ub5e28576-fc80-4e74-9739-1a03efb90c1&amp;title=&amp;width=557.2857666015625" alt="image.png"><br>大概就是，在线上执行一条 update 语句修改数据库数据的时候，where 条件没有带上索引，导致业务直接崩了，被老板教训了一波<br>这次我们就来看看：</p><ul><li>为什么会发生这种的事故？</li><li>又该如何避免这种事故的发生？</li></ul><p>说个前提，接下来说的案例都是基于 InnoDB 存储引擎，且事务的隔离级别是可重复读。</p><h3 id="为什么会发生这种的事故？"><a href="#为什么会发生这种的事故？" class="headerlink" title="为什么会发生这种的事故？"></a>为什么会发生这种的事故？</h3><p>InnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，所谓的幻读是指在同一事务下，连续执行两次同样的查询语句，第二次的查询语句可能会返回之前不存在的行。</p><p>因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。</p><p>当我们执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。</p><p>在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上。<br>比如，在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。</p><p>这里举个例子，这里有一张数据库表，其中 id 为主键索引。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856023698-9c72e26c-1b4c-46b6-acc6-b6cf55f8c8b7.png#averageHue=%23f6f4eb&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u6bce2b9e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=302&amp;originWidth=542&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=22033&amp;status=done&amp;style=none&amp;taskId=u50720f5e-8d52-4003-ab4a-0788becae95&amp;title=" alt="image.png"><br>假设有两个事务的执行顺序如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856023819-d1cd7af3-7113-4876-8463-39a019a72b81.png#averageHue=%23f4f2ea&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u26b84911&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=542&amp;originWidth=722&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48193&amp;status=done&amp;style=none&amp;taskId=u8d8457a7-ae49-401f-a13e-9b0e1c1535d&amp;title=" alt="image.png"><br>可以看到，事务 A 的 update 语句中 where 是等值查询，并且 id 是唯一索引，所以只会对 id = 1 这条记录加锁，因此，事务 B 的更新操作并不会阻塞。</p><p>但是，<strong>在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了</strong>。</p><p>假设有两个事务的执行顺序如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856023777-e12b5408-8d33-481e-9949-87be98205e54.png#averageHue=%23f4eee7&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0f8f3525&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=542&amp;originWidth=722&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=45617&amp;status=done&amp;style=none&amp;taskId=u3799bf9d-3f3c-4450-9def-8b5ef705a31&amp;title=" alt="image.png"><br>可以看到，这次事务 B 的 update 语句被阻塞了。</p><p>这是因为事务 A的 update 语句中 where 条件没有索引列，所有记录都会被加锁，也就是这条 update 语句产生了 4 个记录锁和 5 个间隙锁，相当于锁住了全表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856023772-5279880f-a5b3-417e-ab0f-cc7ded16ef88.png#averageHue=%23f7eed5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u64364802&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=107&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=14106&amp;status=done&amp;style=none&amp;taskId=u6be6829b-36db-4cbd-a864-e13a00d8520&amp;title=" alt="image.png"><br>因此，当在数据量非常大的数据库表执行 update 语句时，如果没有使用索引，就会给全表的加上 next-key 锁， 那么锁就会持续很长一段时间，直到事务结束，而这期间除了 select … from语句，其他语句都会被锁住不能执行，业务会因此停滞，接下来等着你的，就是老板的挨骂。</p><p>那 update 语句的 where 带上索引就能避免全表记录加锁了吗？<br>并不是。<br><strong>关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了</strong>。<br>PS：网上很多资料说，update 没加锁索引会加表锁，这是不对的，所以我在标题里加了个问号。Innodb 源码里面在扫码记录的时候，都是针对索引项这个单位去加锁的， update 不带索引就是全表扫扫描，也就是表里的索引项都加锁，所以大家误以为加了表锁。所以，大家要清楚 innodb 不会对select、insert、delete、update语句加表锁的。</p><h3 id="又该如何避免这种事故的发生？"><a href="#又该如何避免这种事故的发生？" class="headerlink" title="又该如何避免这种事故的发生？"></a>又该如何避免这种事故的发生？</h3><p>我们可以将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。<br>官方的解释： If set to 1, MySQL aborts UPDATE or DELETE statements that do not use a key in the WHERE clause or a LIMIT clause. (Specifically, UPDATE statements must have a WHERE clause that uses a key or a LIMIT clause, or both. DELETE statements must have both.) This makes it possible to catch UPDATE or DELETE statements where keys are not used properly and that would probably change or delete a large number of rows. The default value is 0.<br>大致的意思是，当 sql_safe_updates 设置为 1 时。<br>update 语句必须满足如下条件之一才能执行成功：</p><ul><li>使用 where，并且 where 条件中必须有索引列；</li><li>使用 limit；</li><li>同时使用 where 和 limit，此时 where 条件中可以没有索引列；</li></ul><p>delete 语句必须满足以下条件能执行成功：</p><ul><li>同时使用 where 和 limit，此时 where 条件中可以没有索引列；</li></ul><p>如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 force index([index_name]) 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>不要小看一条 update 语句，在生产机上使用不当可能会导致业务停滞，甚至崩溃。<br>当我们要执行 update 语句的时候，确保 where 条件中带上了索引列，并且在测试机确认该语句是否走的是索引扫描，防止因为扫描全表，而对表中的所有记录加上锁。<br>我们可以打开 MySQL sql_safe_updates 参数，这样可以预防 update 操作时 where 条件没有带上索引列。<br>如果发现即使在 where 条件中带上了列索引列，优化器走的还是全标扫描，这时我们就要使用 force index([index_name]) 可以告诉优化器使用哪个索引。<br>这次就说到这啦，下次要小心点，别再被老板挨骂啦。</p><h2 id="Ⅳ-MySQL-死锁了，怎么办？"><a href="#Ⅳ-MySQL-死锁了，怎么办？" class="headerlink" title="Ⅳ MySQL 死锁了，怎么办？"></a>Ⅳ MySQL 死锁了，怎么办？</h2><p>大家好，我是小林。<br>说个很早之前自己遇到过数据库死锁问题。<br>有个业务主要逻辑就是新增订单、修改订单、查询订单等操作。然后因为订单是不能重复的，所以当时在新增订单的时候做了幂等性校验，做法就是在新增订单记录之前，先通过 select … for update 语句查询订单是否存在，如果不存在才插入订单记录。<br>而正是因为这样的操作，当业务量很大的时候，就可能会出现死锁。<br>接下来跟大家聊下<strong>为什么会发生死锁，以及怎么避免死锁</strong>。</p><h3 id="死锁的发生"><a href="#死锁的发生" class="headerlink" title="死锁的发生"></a>死锁的发生</h3><p>本次案例使用存储引擎 Innodb，隔离级别为可重复读（RR）。<br>接下来，我用实战的方式来带大家看看死锁是怎么发生的。<br>我建了一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_order` (</span><br><span class="line">  `id` <span class="type">int</span> NOT <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `order_no` <span class="type">int</span> DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  `create_date` datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `index_order` (`order_no`) USING BTREE</span><br><span class="line">) ENGINE=InnoDB ;</span><br></pre></td></tr></table></figure><br>然后，先 t_order 表里现在已经有了 6 条记录：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856128415-abceb8c9-32f8-417e-b052-1c2965bd4210.png#averageHue=%23f3f3f3&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc1c35bd1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=302&amp;originWidth=650&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=33755&amp;status=done&amp;style=none&amp;taskId=u0811f100-8b79-48e2-a554-02d0aa27fdf&amp;title=" alt="image.png"><br>假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856128532-13841047-acbd-4cf1-b9d0-c4e0ef120acc.png#averageHue=%23f6e5d5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2bbdf80e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=497&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=205694&amp;status=done&amp;style=none&amp;taskId=uaf14cbce-39a9-47cd-8316-863c145dc2c&amp;title=" alt="image.png"><br>可以看到，两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。</p><p>这里在查询记录是否存在的时候，使用了 select … for update 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。</p><p>如果没有使用 select … for update 语句，而使用了单纯的 select 语句，如果是两个订单号一样的请求同时进来，就会出现两个重复的订单，有可能出现幻读，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856128568-b773b83f-6d5c-4ca5-9150-13ade0c3741e.png#averageHue=%23f2c244&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3d0e13ba&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=592&amp;originWidth=1000&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=198952&amp;status=done&amp;style=none&amp;taskId=u9e1d3b40-8f80-485f-8503-40735ec47cc&amp;title=" alt="image.png"></p><h3 id="为什么会产生死锁？"><a href="#为什么会产生死锁？" class="headerlink" title="为什么会产生死锁？"></a>为什么会产生死锁？</h3><p>可重复读隔离级别下，是存在幻读的问题。<br><strong>Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁</strong>，它是记录锁和间隙锁的组合。</p><ul><li>Record Loc，记录锁，锁的是记录本身；</li><li>Gap Lock，间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。</li></ul><p>普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读，如果要在查询时对记录加行锁，可以使用下面这两个方式：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line"><span class="comment">//对读取的记录加共享锁</span></span><br><span class="line">select ... lock in share mode;</span><br><span class="line">commit; <span class="comment">//锁释放</span></span><br><span class="line"></span><br><span class="line">begin;</span><br><span class="line"><span class="comment">//对读取的记录加排他锁</span></span><br><span class="line">select ... <span class="keyword">for</span> update;</span><br><span class="line">commit; <span class="comment">//锁释放</span></span><br></pre></td></tr></table></figure><br>行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁。</p><p>比如，下面事务 A 查询语句会锁住(2, +∞]范围的记录，然后期间如果有其他事务在这个锁住的范围插入数据就会被阻塞。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856128397-6f7a7ba3-8b2e-4dee-bb44-928b57d6e008.png#averageHue=%23cee2cd&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua64b472c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=348&amp;originWidth=842&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=37631&amp;status=done&amp;style=none&amp;taskId=u77ed581b-6bce-4e2c-8dd2-b4c3651d0c3&amp;title=" alt="image.png"><br>next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁，我之前也写一篇加锁规则，详细可以看这篇：<a href="https://xiaolincoding.com/mysql/lock/how_to_lock.html">MySQL 是怎么加锁的？(opens new window)</a></p><p>需要注意的是，如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行记录加上了行锁，还给行记录两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。</p><p>所以在线上千万不要执行没有带索引条件的 update 语句，不然会造成业务停滞，我有个读者就因为干了这个事情，然后被老板教育了一波，详细可以看这篇：<a href="https://xiaolincoding.com/mysql/lock/update_index.html">update 没加索引会锁全表？(opens new window)</a><br>回到前面死锁的例子。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856128530-ccd99234-3fb5-464c-a8ca-2e9fcd0b1395.png#averageHue=%23f6e5d5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u763fab38&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=497&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=205694&amp;status=done&amp;style=none&amp;taskId=ua6729991-7a0f-4ebe-bccb-4fa03a8ef84&amp;title=" alt="image.png"><br>事务 A 在执行下面这条语句的时候：<br>select id from t_order where order_no = 1007 for update;<br>因为 order_no 不是唯一索引，所以行锁的类型是间隙锁，于是间隙锁的范围是（1006, +∞）。那么，当事务 B 往间隙锁里插入 id = 1008 的记录就会被锁住。</p><p>因为当我们执行以下插入语句时，会在插入间隙上获取插入意向锁。<br>Insert into t<em>order (order_no, create_date) values (1008, now());<br><strong>插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 select … for update 语句并不会相互影响</strong>。<br>案例中的事务 A 和事务 B 在执行完后 select … for update 语句后都持有范围为(1006,+∞）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。<br>为什么间隙锁与间隙锁之间是兼容的？<br>在MySQL官网上还有一段非常关键的描述：<br>_Gap locks in InnoDB are “purely inhibitive”, which means that their only purpose is to prevent other transactions from Inserting to the gap. Gap locks can co-exist. A gap lock taken by one transaction does not prevent another transaction from taking a gap lock on the same gap. There is no difference between shared and exclusive gap locks. They do not conflict with each other, and they perform the same function.</em><br>这段话表明间隙锁在本质上是不区分共享间隙锁或互斥间隙锁的，而且间隙锁是不互斥的，即两个事务可以同时持有包含共同间隙的间隙锁。<br>这里的共同间隙包括两种场景：</p><ul><li>其一是两个间隙锁的间隙区间完全一样；</li><li>其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。</li></ul><p><strong>间隙锁本质上是用于阻止其他事务在该间隙内插入新记录，而自身事务是允许在该间隙内插入数据的</strong>。也就是说间隙锁的应用场景包括<strong>并发读取、并发更新、并发删除和并发插入</strong>。<br>插入意向锁是什么？<br>注意！插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁。<br>在MySQL的官方文档中有以下重要描述：<br><em>An Insert intention lock is a type of gap lock set by Insert operations prior to row Insertion. This lock signals the intent to Insert in such a way that multiple transactions Inserting into the same index gap need not wait for each other if they are not Inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to Insert values of 5 and 6, respectively, each lock the gap between 4 and 7 with Insert intention locks prior to obtaining the exclusive lock on the Inserted row, but do not block each other because the rows are nonconflicting.</em><br>这段话表明尽管<strong>插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作</strong>。<br>如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。<br>插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。<br>另外，我补充一点，插入意向锁的生成时机：</p><ul><li>每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁 。<h3 id="Insert-语句是怎么加行级锁的？"><a href="#Insert-语句是怎么加行级锁的？" class="headerlink" title="Insert 语句是怎么加行级锁的？"></a>Insert 语句是怎么加行级锁的？</h3>Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为<strong>隐式锁</strong>来保护记录的。<br>什么是隐式锁？<br>当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。隐式锁是 InnoDB 实现的一种延迟加锁机制，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。</li></ul><p>隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁，这里我们列举两个场景。</p><ul><li>如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的；</li><li><p>如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录；</p><h4 id="1、记录之间加有间隙锁"><a href="#1、记录之间加有间隙锁" class="headerlink" title="1、记录之间加有间隙锁"></a>1、记录之间加有间隙锁</h4><p>每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁。<br>举个例子，现在 t_order 表中，只有这些数据，<strong>order_no 是二级索引</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856129413-cf9f96a5-d6a5-407a-bc8f-6bca0ab2b9a4.png#averageHue=%23f3f3f3&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u110a59b7&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=254&amp;originWidth=642&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32509&amp;status=done&amp;style=none&amp;taskId=u8980b5a8-c0fb-4f8b-930e-4eacb85a347&amp;title=" alt="image.png"><br>现在，事务 A 执行了下面这条语句。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 事务 A</span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, <span class="number">0</span> rows <span class="title function_">affected</span> <span class="params">(<span class="number">0.01</span> sec)</span></span><br><span class="line"></span><br><span class="line">mysql&gt; select * from t_order where order_no = <span class="number">1006</span> <span class="keyword">for</span> update;</span><br><span class="line">Empty <span class="title function_">set</span> <span class="params">(<span class="number">0.01</span> sec)</span></span><br></pre></td></tr></table></figure><p>接着，我们执行 select * from performance_schema.data_locks\G; 语句 ，确定事务 A 加了什么类型的锁，这里只关注在记录上加锁的类型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856130619-c65b8468-ad26-4f9c-846a-a69bb5217c5b.png#averageHue=%230e1119&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ubd579bc4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1310&amp;originWidth=1248&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=813779&amp;status=done&amp;style=none&amp;taskId=u1a51876f-1d36-4c43-ab6e-1d1420be5e4&amp;title=" alt="image.png"><br>可以看到，加的是 X 型的锁（排他锁），但是具体是记录锁、间隙锁、next-key 锁呢？注意，这里 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思。<br>首先通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：</p></li><li><p>如果 LOCK_MODE 为 X，说明是 next-key 锁；</p></li><li>如果 LOCK_MODE 为 X, REC_NOT_GAP，说明是记录锁；</li><li>如果 LOCK_MODE 为 X, GAP，说明是间隙锁；</li></ul><p>因此，本次的例子加的是 next-key 锁（记录锁+间隙锁），锁范围是（1005, +∞]。<br>然后，有个事务 B 在这个间隙锁中，插入了一个记录，那么此时该事务 B 就会被阻塞：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 事务 B 插入一条记录</span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, <span class="number">0</span> rows <span class="title function_">affected</span> <span class="params">(<span class="number">0.01</span> sec)</span></span><br><span class="line"></span><br><span class="line">mysql&gt; insert into <span class="title function_">t_order</span><span class="params">(order_no, create_date)</span> <span class="title function_">values</span><span class="params">(<span class="number">1010</span>,now())</span>;</span><br><span class="line">### 阻塞状态。。。。</span><br></pre></td></tr></table></figure><br>接着，我们执行 select * from performance_schema.data_locks\G; 语句 ，确定事务 B 加了什么类型的锁，这里只关注在记录上加锁的类型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856130308-71ea2cd6-16ed-41a3-b89c-62711d59753e.png#averageHue=%230e1119&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uea8a9fa6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=660&amp;originWidth=1270&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=426714&amp;status=done&amp;style=none&amp;taskId=uf818ad42-d8f3-4e94-9ada-eb41e3dcec1&amp;title=" alt="image.png"><br>可以看到，事务 B 的状态为等待状态（LOCK_STATUS: WAITING），因为向事务 A 生成的 next-key 锁（记录锁+间隙锁）范围（1005, +∞] 中插入了一条记录，所以事务 B 的插入操作生成了一个插入意向锁（LOCK_MODE: X,INSERT_INTENTION）。</p><h4 id="2、遇到唯一键冲突"><a href="#2、遇到唯一键冲突" class="headerlink" title="2、遇到唯一键冲突"></a>2、遇到唯一键冲突</h4><p>如果在插入新记录时，插入了一个与「已有的记录的主键或者唯一二级索引列值相同」的记录」（不过可以有多条记录的唯一二级索引列的值同时为NULL，这里不考虑这种情况），此时插入就会失败，然后对于这条记录加上了 <strong>S 型的锁</strong>。</p><p>至于是行级锁的类型是记录锁，还是 next-key 锁，跟是「主键冲突」还是「唯一二级索引冲突」有关系。</p><p>如果主键值重复：</p><ul><li>当隔离级别为<strong>读已提交</strong>时，插入新记录的事务会给已存在的主键值重复的聚簇索引记录<strong>添加 S 型记录锁</strong>。</li><li>当隔离级别是<strong>可重复读</strong>（默认隔离级别），插入新记录的事务会给已存在的主键值重复的聚簇索引记录<strong>添加 S 型记录锁</strong>。</li></ul><p>如果唯一二级索引列重复：</p><ul><li><strong>不论是哪个隔离级别</strong>，插入新记录的事务都会给已存在的二级索引列值重复的二级索引记录<strong>添加 S 型 next-key 锁</strong>。对的，没错，即使是读已提交隔离级别也是加 next-key 锁，这是读已提交隔离级别中为数不多的给记录添加间隙锁的场景。因为如果不添加间隙锁的话，会让唯一二级索引中出现多条唯一二级索引列值相同的记录，这就违背了 UNIQUE 的约束。</li></ul><p>下面举个「唯一二级索引冲突」的例子，MySQL 8.0 版本，事务隔离级别为可重复读（默认隔离级别）。<br>t_order 表中的 order_no 字段为唯一二级索引，并且已经存在 order_no 值为 1001 的记录，此时事务 A，插入了 order_no 为 1001 的记录，就出现了报错。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856132508-2b98bbe6-a882-4268-8170-75873abeca3f.png#averageHue=%23b3b5b5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue2dafaf6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=336&amp;originWidth=2156&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=301419&amp;status=done&amp;style=none&amp;taskId=ub82b9b85-885a-428a-ac2e-3256ad148a2&amp;title=" alt="image.png"><br>但是除了报错之外，还做一个很重要的事情，就是对 order_no 值为 1001 这条记录加上了 <strong>S 型的 next-key 锁</strong>。<br>我们可以执行 select * from performance_schema.data_locks\G; 语句 ，确定事务加了什么类型的锁，这里只关注在记录上加锁的类型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856132527-d106670c-061e-4509-bd97-ab4e2e35d124.png#averageHue=%230e1118&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udb17fcf4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=628&amp;originWidth=1196&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=372887&amp;status=done&amp;style=none&amp;taskId=u955ded22-30a0-4126-bf8e-33ecd97baf9&amp;title=" alt="image.png"><br>可以看到，index_order 二级索引中的 1001（LOCK_DATA） 记录的锁类型为 S 型的 next-key 锁。注意，这里 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思。如果是记录锁的话，LOCK_MODE 会显示 S, REC_NOT_GAP。</p><p>此时，事务 B 执行了 select <em> from t_order where order_no = 1001 for update; 就会阻塞，因为这条语句想加 X 型的锁，是与 S 型的锁是冲突的，所以就会被阻塞。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856132400-7dd9e748-1274-4944-a39b-9b4e5f730ae3.png#averageHue=%23f8e7cd&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud41ddb76&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=611&amp;originWidth=991&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=156092&amp;status=done&amp;style=none&amp;taskId=u0124e6ea-ee6b-4dba-bfbe-8bc306d6903&amp;title=" alt="image.png"><br>我们也可以从 performance_schema.data_locks 这个表中看到，事务 B 的状态（LOCK_STATUS）是等待状态，加锁的类型 X 型的记录锁（LOCK_MODE: X,REC_NOT_GAP ）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856132917-f868e85c-109e-49f2-9fc6-f51e84bc3c43.png#averageHue=%230e1119&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u188e49aa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=654&amp;originWidth=1204&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=416887&amp;status=done&amp;style=none&amp;taskId=ue4579302-9aad-4390-ad15-2ff4fe1775e&amp;title=" alt="image.png"><br>上面的案例是针对唯一二级索引重复而插入失败的场景。<br>接下来，分析两个事务执行过程中，执行了相同的 insert 语句的场景。<br>现在 t_order 表中，只有这些数据，<strong>order_no 为唯一二级索引</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856133428-6747b014-b909-45c1-b48a-ccdba1b39572.png#averageHue=%23f3f3f3&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9f1cc4d2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=254&amp;originWidth=642&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32509&amp;status=done&amp;style=none&amp;taskId=u8797adbe-70e3-45a9-a740-7696eda4eab&amp;title=" alt="image.png"><br>在隔离级别可重复读的情况下，开启两个事务，前后执行相同的 Insert 语句，此时<em>*事务 B 的 Insert 语句会发生阻塞</em></em>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856133796-49170dd2-9d67-474a-a85e-b5236cd8e7d5.png#averageHue=%23f5e7d0&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u01b0172c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=376&amp;originWidth=681&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=87501&amp;status=done&amp;style=none&amp;taskId=u3d3b35d5-e8e5-490d-b1c2-263e6284742&amp;title=" alt="image.png"><br>两个事务的加锁过程：</p><ul><li>事务 A 先插入 order_no 为 1006 的记录，可以插入成功，此时对应的唯一二级索引记录被「隐式锁」保护，此时还没有实际的锁结构（执行完这里的时候，你可以看查 performance_schema.data_locks 信息，可以看到这条记录是没有加任何锁的）；</li><li>接着，事务 B 也插入 order_no 为 1006 的记录，由于事务 A 已经插入 order_no 值为 1006 的记录，所以事务 B 在插入二级索引记录时会遇到重复的唯一二级索引列值，此时事务 B 想获取一个 S 型 next-key 锁，但是事务 A 并未提交，<strong>事务 A 插入的 order_no 值为 1006 的记录上的「隐式锁」会变「显示锁」且锁类型为 X 型的记录锁，所以事务 B 向获取 S 型 next-key 锁时会遇到锁冲突，事务 B 进入阻塞状态</strong>。</li></ul><p>我们可以执行 select <em> from performance<em>schema.data_locks\G; 语句 ，确定事务加了什么类型的锁，这里只关注在记录上加锁的类型。<br>先看事务 A 对 order_no 为 1006 的记录加了什么锁？<br>从下图可以看到，<strong>事务 A 对 order_no 为 1006 记录加上了类型为 X 型的记录锁</strong>（</em>注意，这个是在执行事务 B 之后才产生的锁，没执行事务 B 之前，该记录还是隐式锁_）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856136754-1106d164-67a8-4c68-9908-39dd7a3b55b5.png#averageHue=%230e1119&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf562ff8a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=608&amp;originWidth=1288&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=388451&amp;status=done&amp;style=none&amp;taskId=uc6ee4e5a-50cd-4cf0-bca1-3276ea5de15&amp;title=" alt="image.png"><br>然后看事务 B 想对 order_no 为 1006 的记录加什么锁？<br>从下图可以看到，<strong>事务 B 想对 order_no 为 1006 的记录加 S 型的 next-key 锁，但是由于事务 A 在该记录上持有了 X 型的记录锁，这两个锁是冲突的，所以导致事务 B 处于等待状态</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856136743-9fbfc5b8-6de4-4231-b6e4-7680c6966116.png#averageHue=%230e1119&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u32486a38&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=608&amp;originWidth=1204&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=369747&amp;status=done&amp;style=none&amp;taskId=uc9b84345-e61f-4ae7-8247-f9d8d2357a9&amp;title=" alt="image.png"><br>从这个实验可以得知，并发多个事务的时候，第一个事务插入的记录，并不会加锁，而是会用隐式锁保护唯一二级索引的记录。<br>但是当第一个事务还未提交的时候，有其他事务插入了与第一个事务相同的记录，第二个事务就会<strong>被阻塞</strong>，<em>*因为此时第一事务插入的记录中的隐式锁会变为显示锁且类型是 X 型的记录锁，而第二个事务是想对该记录加上 S 型的 next-key 锁，X 型与 S 型的锁是冲突的</em></em>，所以导致第二个事务会等待，直到第一个事务提交后，释放了锁。<br>如果 order_no 不是唯一二级索引，那么两个事务，前后执行相同的 Insert 语句，是不会发生阻塞的，就如前面的这个例子。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856136294-65d8f676-584c-4eff-aa22-003291e4a316.png#averageHue=%23f2c244&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u231fcf10&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=592&amp;originWidth=1000&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=198952&amp;status=done&amp;style=none&amp;taskId=u9339e79c-b524-4f1f-9537-132759a6ac6&amp;title=" alt="image.png"></p><h3 id="如何避免死锁？"><a href="#如何避免死锁？" class="headerlink" title="如何避免死锁？"></a>如何避免死锁？</h3><p>死锁的四个必要条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。<br>在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：</p><ul><li><strong>设置事务等待锁的超时时间</strong>。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。当发生超时后，就出现下面这个提示：</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856136188-ae49580d-c7c8-41cb-9027-673f18cd479f.png#averageHue=%2312141c&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u790122a7&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=31&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=25384&amp;status=done&amp;style=none&amp;taskId=u102d0582-b46d-4b25-a0fc-77e287f16c3&amp;title=" alt="image.png"></p><ul><li><strong>开启主动死锁检测</strong>。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。当检测到死锁后，就会出现下面这个提示：</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659856136412-fa3280f3-d441-4824-b2e6-9ae552e14dbd.png#averageHue=%2312141d&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u330e9806&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=28&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=22950&amp;status=done&amp;style=none&amp;taskId=u66183336-d123-4c14-9039-2389aac88fe&amp;title=" alt="image.png"><br>上面这个两种策略是「当有死锁发生时」的避免方式。<br>我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一下来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。</p><hr><p>最后说个段子：<br>面试官: 解释下什么是死锁?<br>应聘者: 你录用我,我就告诉你<br>面试官: 你告诉我,我就录用你<br>应聘者: 你录用我,我就告诉你<br>面试官: 卧槽滚！<br><strong>………..</strong></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>高可用篇</title>
      <link href="/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2022/08/09/redis/%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="redis的三种集群模型"><a href="#redis的三种集群模型" class="headerlink" title="redis的三种集群模型"></a>redis的三种集群模型</h2><h3 id="Ⅰ主从复制是怎么实现的？"><a href="#Ⅰ主从复制是怎么实现的？" class="headerlink" title="Ⅰ主从复制是怎么实现的？"></a>Ⅰ主从复制是怎么实现的？</h3><p>AOF 和 RDB，这两个持久化技术保证了即使在服务器重启的情况下也不会丢失数据（或少量损失）。<br>不过，由于数据都是存储在一台服务器上，如果出事就完犊子了，比如：</p><ul><li>如果服务器发生了宕机，由于数据恢复是需要点时间，那么这个期间是无法服务新的请求的；</li><li>如果这台服务器的硬盘出现了故障，可能数据就都丢失了。</li></ul><p>要避免这种单点故障，最好的办法是将数据备份到其他服务器上，让这些服务器也可以对外提供服务，这样即使有一台服务器出现了故障，其他服务器依然可以继续提供服务。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080221-b4c14623-7658-4b9c-8d41-250a88a8045e.png#averageHue=%23faf9f8&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=343&amp;id=u85e7973a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=661&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=91068&amp;status=done&amp;style=none&amp;taskId=u85a8384f-ed55-4d5e-a913-dfb1cfc82bf&amp;title=&amp;width=560.0000610351562" alt="image.png"><br>多台服务器要保存同一份数据，这里问题就来了。<br>这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？</p><p>Redis 提供了<strong>主从复制模式</strong>，来避免上述的问题。<br>这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是<strong>「读写分离」</strong>的方式。<br>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080191-76100d8b-81bb-4a41-ad95-e03c112f8062.png#averageHue=%23f9f6f5&amp;clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2b694aaa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=422&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49243&amp;status=done&amp;style=none&amp;taskId=ud960accc-5eeb-454b-bc5a-6eb3a1e0aee&amp;title=" alt="image.png"><br>也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。<br>同步这两个字说的简单，但是这个同步过程并没有想象中那么简单，要考虑的事情不是一两个。<br><strong>主从服务器</strong>间的第一次同步是如何工作的？#### ①第一次同步<br>多台服务器之间要通过什么方式来确定谁是主服务器，或者谁是从服务器呢？<br>我们可以使用 <strong>replicaof</strong>（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。<br>比如，现在有服务器 A 和 服务器 B，我们在服务器 B 上执行下面这条命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 服务器 B 执行这条命令</span><br><span class="line">replicaof &lt;服务器 A 的 IP 地址&gt; &lt;服务器 A 的 Redis 端口号&gt;</span><br></pre></td></tr></table></figure><br>接着，服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。<br><strong>主从服务器间的第一次同步的过程可分为三个阶段：</strong></p><ul><li><strong>第一阶段是建立链接、协商同步；</strong></li><li><strong>第二阶段是主服务器同步数据给从服务器；</strong></li><li><strong>第三阶段是主服务器发送新写操作命令给从服务器。</strong></li></ul><p>为了让你更清楚了解这三个阶段，我画了一张图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080280-933601dd-4609-41b7-a8fc-7827866550d9.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=315&amp;id=TSgEY&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=555&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=143619&amp;status=done&amp;style=none&amp;taskId=u4f1547a5-d0e6-4657-b954-71815208666&amp;title=&amp;width=613.0000610351562" alt="image.png"><br>接下来，我在具体介绍每一个阶段都做了什么。<br><em>第一阶段：建立链接、协商同步</em><br>执行了 replicaof 命令后，从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。<br>psync 命令包含两个参数，分别是<strong>主服务器的 runID</strong> 和<strong>复制进度 offset</strong>。</p><ul><li>runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 “?”。</li><li>offset，表示复制的进度，第一次同步时，其值为 -1。</li></ul><p>主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。<br>并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。<br>FULLRESYNC 响应命令的意图是采用<strong>全量复制</strong>的方式，也就是主服务器会把所有的数据都同步给从服务器。<br>所以，第一阶段的工作时为了全量复制做准备。<br>那具体怎么全量同步呀呢？我们可以往下看第二阶段。<br><em>第二阶段：主服务器同步数据给从服务器</em><br>接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。<br>从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。</p><p>这里有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。</p><p>但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。那么为了保证主从服务器的数据一致性，<strong>主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里。</strong></p><ul><li>主服务器生成 RDB 文件期间；</li><li>主服务器发送 RDB 文件给从服务器期间；</li><li>「从服务器」加载 RDB 文件期间；</li></ul><p><em>第三阶段：主服务器发送新写操作命令给从服务器</em><br>在主服务器生成的 RDB 文件发送完，从服务器加载完 RDB 文件后，然后将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，然后「从服务器」重新执行这些操作，至此主从服务器的数据就一致了。<br>至此，主从服务器的第一次同步的工作就完成了。</p><h4 id="②命令传播"><a href="#②命令传播" class="headerlink" title="②命令传播"></a>②命令传播</h4><p>主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080087-dad54cf0-ce53-4636-8f39-32fe8f9c8754.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=345&amp;id=bGuU5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=602&amp;originWidth=842&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=53580&amp;status=done&amp;style=none&amp;taskId=u89402ee2-1d1e-47bf-8110-9cd31080215&amp;title=&amp;width=482" alt="image.png"><br>后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。<br>而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。<br>上面的这个过程被称为<strong>基于长连接的命令传播</strong>，通过这种方式来保证第一次同步后的主从服务器的数据一致性。</p><h4 id="③分摊主服务器的压力"><a href="#③分摊主服务器的压力" class="headerlink" title="③分摊主服务器的压力"></a>③分摊主服务器的压力</h4><p>在前面的分析中，我们可以知道主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。<br>主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：</p><ul><li>由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；</li><li>传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。<blockquote><p>这种情况就好像，刚创业的公司，由于人不多，所以员工都归老板一个人管，但是随着公司的发展，人员的扩充，老板慢慢就无法承担全部员工的管理工作了。<br>要解决这个问题，老板就需要设立经理职位，由经理管理多名普通员工，然后老板只需要管理经理就好。<br>Redis 也是一样的，从服务器可以有自己的从服务器，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器，组织形式如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645080224-708cc951-807d-4784-90ec-6a110ad0f19e.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=335&amp;id=RFwwh&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=632&amp;originWidth=1052&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=88698&amp;status=done&amp;style=none&amp;taskId=u9d65afcc-8ff9-4513-8ef1-5fdd1bdbfed&amp;title=&amp;width=557.0000610351562" alt="image.png"></p></blockquote></li></ul><p>通过这种方式，<strong>主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器</strong>。<br>那具体怎么做到的呢？<br>其实很简单，我们在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof &lt;目标服务器的IP&gt; <span class="number">6379</span></span><br></pre></td></tr></table></figure><br>此时如果目标服务器本身也是「从服务器」，那么该目标服务器就会成为「经理」的角色，不仅可以接受主服务器同步的数据，也会把数据同步给自己旗下的从服务器，从而减轻主服务器的负担。</p><h4 id="④增量复制"><a href="#④增量复制" class="headerlink" title="④增量复制"></a>④增量复制</h4><p>主从服务器在完成第一次同步后，就会基于长连接进行命令传播。<br>可是，网络总是不按套路出牌的嘛，说延迟就延迟，说断开就断开。<br>如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081879-6a81191c-bb03-4c06-b96a-0085938bc72a.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=556&amp;id=CnjPy&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=812&amp;originWidth=834&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72549&amp;status=done&amp;style=none&amp;taskId=u8f9ec897-bf7c-49dd-8d7f-1bd71942c33&amp;title=&amp;width=571.0000610351562" alt="image.png"><br>那么问题来了，如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？</p><p>在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。<br>所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用<strong>增量复制</strong>的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。<br>网络恢复后的增量复制过程如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081795-099fb740-5694-41c8-ac30-7492ead59862.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=508&amp;id=tWwsX&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=617&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54774&amp;status=done&amp;style=none&amp;taskId=u4cbc26bf-835d-4c94-99c3-3b000c5115f&amp;title=&amp;width=582.0000610351562" alt="image.png"><br>主要有三个步骤：</p><ul><li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li><li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li><li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li></ul><p>那么关键的问题来了，<strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong><br>答案藏在这两个东西里：</p><ul><li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li><li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master<em>repl_offset 来记录自己「</em>写<em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「</em>读_」到的位置。</li></ul><p>那repl_backlog_buffer 缓冲区是什么时候写入的呢？<br>在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。<br>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：</p><ul><li>如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>增量同步</strong>的方式；</li><li>相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>全量同步</strong>的方式。</li></ul><p>当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081917-c00abe06-1988-459c-acf3-ba56fd6db733.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=eKHr9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84591&amp;status=done&amp;style=none&amp;taskId=u399d5ce3-13bc-4399-9fd5-20d4685e5cb&amp;title=" alt="image.png"><br>repl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。<br>因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。<br>那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。<br>因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。</p><blockquote><p>那 repl_backlog_buffer 缓冲区具体要调整到多大呢？<br>repl_backlog_buffer 最小的大小可以根据这面这个公式估算。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645081859-ec1c2425-f51e-4f78-a920-36dedb13d7ab.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PyRXc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=121&amp;originWidth=361&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6215&amp;status=done&amp;style=none&amp;taskId=u819284f4-c9cd-4bbb-a75e-42b53aab762&amp;title=" alt="image.png"><br>我来解释下这个公式的意思：</p><ul><li>second 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。</li><li>write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。</li></ul><p>举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。<br>那么 repl_backlog_buffer 大小就不能低于 5 MB，否则新写地命令就会覆盖旧数据了。<br>当然，为了应对一些突发的情况，可以将 repl_backlog_buffer 的大小设置为此基础上的 2 倍，也就是 10 MB。<br>关于 repl_backlog_buffer 大小修改的方法，只需要修改配置文件里下面这个参数项的值就可以。</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">repl-backlog-size <span class="number">1</span>mb</span><br></pre></td></tr></table></figure><h4 id="总结★（记熟悉）"><a href="#总结★（记熟悉）" class="headerlink" title="总结★（记熟悉）"></a>总结★（记熟悉）</h4><p>主从复制共有三种模式：<strong>全量复制、基于长连接的命令传播、增量复制</strong>。</p><ul><li>主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。</li><li>第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。</li><li>如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。</li></ul><p>如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。</p><h4 id="集群产生脑裂数据丢失"><a href="#集群产生脑裂数据丢失" class="headerlink" title="集群产生脑裂数据丢失"></a>集群产生脑裂数据丢失</h4><p>先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？<br>那么在 redis 中，集群脑裂产生数据丢失的现象是怎样的呢？<br>在 redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。<br>如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。<br>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。<br>这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。<br>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。<br><strong>解决方案：</strong><br>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p><p>在 redis 的配置文件中有两个参数我们可以设置：</p><ul><li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li><li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li></ul><p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p><p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。<br>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。<br><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。我再来给你举个例子。</strong><br>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h4 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h4><h5 id="redis主从节点时长连接还是短链接？"><a href="#redis主从节点时长连接还是短链接？" class="headerlink" title="redis主从节点时长连接还是短链接？"></a>redis主从节点时长连接还是短链接？</h5><p>长连接</p><h5 id="怎么判断-redis-某个节点是否正常工作？"><a href="#怎么判断-redis-某个节点是否正常工作？" class="headerlink" title="怎么判断 redis 某个节点是否正常工作？"></a>怎么判断 redis 某个节点是否正常工作？</h5><p>redis 判断接点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。<br>redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：</p><ul><li>redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。</li><li><p>redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：</p><ul><li>实时监测主从节点网络状态；</li><li>上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。<h5 id="主从复制架构中，过期key如何处理？"><a href="#主从复制架构中，过期key如何处理？" class="headerlink" title="主从复制架构中，过期key如何处理？"></a>主从复制架构中，过期key如何处理？</h5>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。<h5 id="redis-是同步复制还是异步复制？"><a href="#redis-是同步复制还是异步复制？" class="headerlink" title="redis 是同步复制还是异步复制？"></a>redis 是同步复制还是异步复制？</h5>redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。<h5 id="主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><a href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？" class="headerlink" title="主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？"></a>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</h5>replication buffer 、repl backlog buffer 区别如下：</li></ul></li><li><p>replication buffer 是在全量复制阶段会出现，<strong>主库会给每个新连接的从库，分配一个</strong> replication buffer；repl backlog buffer 是在增量复制阶段出现，<strong>一个主库只分配一个</strong>repl backlog buffer；</p></li><li><p>这两个 Buffer 都有大小限制的，当缓冲区满了之后。repl backlog buffer，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>，replication buffer则会导致连接断开，删除缓存，从库重新连接，<strong>重新开始全量复制</strong>。</p><h5 id="redis-主从切换如何减少数据丢失？"><a href="#redis-主从切换如何减少数据丢失？" class="headerlink" title="redis 主从切换如何减少数据丢失？"></a>redis 主从切换如何减少数据丢失？</h5><h6 id="异步复制同步丢失"><a href="#异步复制同步丢失" class="headerlink" title="异步复制同步丢失"></a>异步复制同步丢失</h6><p>对于 redis 主节点与从节点之间的数据复制，时异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。<br><strong>可以有 2 种解决方案：</strong></p></li><li><p>第一种：客户端将数据暂时写入本地缓存和磁盘中，在一段时间后将本地缓存或者磁盘的数据发送给主节点，来保证数据不丢失；</p></li><li>第二种：客户端将数据写入到消息队列中，发送一个延时消费消息，比如10分钟后再消费消息队列中的数据，然后再写到主节点。</li></ul><h5 id="redis-主从如何做到故障自动切换？"><a href="#redis-主从如何做到故障自动切换？" class="headerlink" title="redis 主从如何做到故障自动切换？"></a>redis 主从如何做到故障自动切换？</h5><p>主节点挂了 ，从节点是无法自动升级为主节点的，这个过程需要人工处理，在此期间 redis 无法对外提供写操作。<br>此时，redis 哨兵机制就登场了，哨兵在发现主节点出现故障时，由哨兵自动完成故障发现和故障转移，并通知给应用方，从而实现高可用性。</p><h3 id="Ⅱ为什么要有哨兵？"><a href="#Ⅱ为什么要有哨兵？" class="headerlink" title="Ⅱ为什么要有哨兵？"></a>Ⅱ为什么要有哨兵？</h3><p>这次聊聊，Redis 的哨兵机制。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992525-e378da71-0cf2-424d-b9f4-f8ca54fc8df5.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=471&amp;id=u7e4c967c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1404&amp;originWidth=1814&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=666006&amp;status=done&amp;style=none&amp;taskId=u0387f134-ceb4-4da1-9d88-286629f0d6e&amp;title=&amp;width=609.0000610351562" alt="image.png"></p><h4 id="①为什么要有哨兵机制？"><a href="#①为什么要有哨兵机制？" class="headerlink" title="①为什么要有哨兵机制？"></a>①为什么要有哨兵机制？</h4><ul><li>在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992237-60e4b944-b02d-4823-ba9b-0c5014b85d16.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=226&amp;id=ub7210b00&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1008&amp;originWidth=2082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=278739&amp;status=done&amp;style=none&amp;taskId=u9f0157a6-7bee-4e7c-86b6-de0b3a7f670&amp;title=&amp;width=466.00006103515625" alt="image.png"></p><ul><li>这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。</li><li>这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了 ，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！</li></ul><p>Redis 在 2.8 版本以后提供的<strong>哨兵（<em>Sentinel</em>）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p><h4 id="②哨兵机制是如何工作的？"><a href="#②哨兵机制是如何工作的？" class="headerlink" title="②哨兵机制是如何工作的？"></a>②哨兵机制是如何工作的？</h4><p>哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。<br>当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。<br>哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991701-eaa465bd-18aa-41fe-95bf-bfd0794de6ac.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e7aea3f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=326&amp;originWidth=912&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29102&amp;status=done&amp;style=none&amp;taskId=uaa5caac2-ea08-4000-853e-58cf208180f&amp;title=" alt="image.png"><br>所以，我们重点要学习这三件事情：</p><ul><li>哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？</li><li>根据什么规则选择一个从节点切换为主节点？</li><li><p>怎么把新主节点的相关信息通知给从节点和客户端呢？</p><h4 id="③如何判断主节点真的故障了？"><a href="#③如何判断主节点真的故障了？" class="headerlink" title="③如何判断主节点真的故障了？"></a>③如何判断主节点真的故障了？</h4><p>哨兵会每隔 1 秒给<strong>所有主从节点</strong>发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991918-2f292a86-232a-4324-8734-694e1e6dbfb8.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=341&amp;id=u6488a21b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=560&amp;originWidth=982&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61368&amp;status=done&amp;style=none&amp;taskId=uc67498ae-7a3b-446a-8c5c-e470b2e4b12&amp;title=&amp;width=598.0000610351562" alt="image.png"><br>如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「<strong>主观下线</strong>」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。<br>主观下线？难道还有客观下线？<br>是的没错，<strong>客观下线只适用于主节点。</strong></p></li><li><p>之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。</p></li><li>所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成<strong>哨兵集群</strong>（<em>最少需要三台机器来部署哨兵集群</em>），<strong>通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况</strong>。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</li></ul><p><strong>具体是怎么判定主节点为「客观下线」的呢？</strong><br>当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645991919-3b23464f-6552-4e7f-b54d-088539b160d2.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub2273e1c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=686&amp;originWidth=1066&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=86410&amp;status=done&amp;style=none&amp;taskId=ud7a35611-a0b0-4bce-9343-186bae91985&amp;title=" alt="image.png"><br>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。<br>例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。<br>PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。<br>哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。</p><h4 id="④由哪个哨兵进行主从故障转移？"><a href="#④由哪个哨兵进行主从故障转移？" class="headerlink" title="④由哪个哨兵进行主从故障转移？"></a>④由哪个哨兵进行主从故障转移？</h4><p>前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以<strong>哨兵是以哨兵集群的方式存在的</strong>。<br><strong>问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？</strong><br>所以这时候，还需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。<br>选举 leader 的过程其实是一个投票的过程，在投票开始前，肯定得有个「候选者」。<br>那谁来作为候选者呢？<br>哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。<br>举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645992714-d498bfdb-a0f8-40a5-8b54-423c285d1621.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=498&amp;id=u32b91fc8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=988&amp;originWidth=1124&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=125820&amp;status=done&amp;style=none&amp;taskId=ub0393f24-a234-41af-a7f8-61bd2deb28d&amp;title=&amp;width=566.0000610351562" alt="image.png"><br>当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。<br>候选者如何选举成为 Leader？<br>候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。<br>每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。<br>那么在投票过程中，任何一个「候选者」，要满足两个条件：</p><ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul><p>举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。<br>这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？<br>每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。<br>为什么哨兵节点至少要有 3 个？<br>如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。<br>所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。<br>因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。<br>当然，你要问，如果 3 个哨兵节点，挂了 2 个怎么办？这个时候得人为介入了，或者增加多一点哨兵节点。<br>再说一个问题，Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？</p><ul><li><strong>哨兵集群可以判定主节点“客观下线”</strong>。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。</li><li><strong>哨兵集群可以完成主从切换</strong>。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。</li></ul><p>如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。<br>如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。<br>可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。<br>所以，<strong>quorum 的值建议设置为哨兵个数的二分之一加1</strong>，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且<strong>哨兵节点的数量应该是奇数</strong>。</p><h4 id="⑤主从故障转移的过程是怎样的？"><a href="#⑤主从故障转移的过程是怎样的？" class="headerlink" title="⑤主从故障转移的过程是怎样的？"></a>⑤主从故障转移的过程是怎样的？</h4><p>在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645993557-963b926e-a3fb-4cbe-ab5f-acaffb8e4aa2.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3e967b7f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=701&amp;originWidth=2510&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=430642&amp;status=done&amp;style=none&amp;taskId=uad4c2133-9e3c-4c10-b131-187a6e14c2c&amp;title=" alt="image.png"><br>主从故障转移操作包含以下四个步骤：</p><ul><li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。</li><li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li><li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li><li><p>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；<br>详细步骤#### 步骤一：选出新主节点<br>故障转移操作第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」。<br><strong>那么多「从节点」，到底选择哪个从节点作为新主节点的？</strong></p></li><li><p>随机的方式好吗？随机的方式，实现起来很简单，但是如果选到一个网络状态不好的从节点作为新主节点，那么可能在将来不久又要做一次主从故障迁移。</p></li><li>所以，我们首先要把网络状态不好的从节点给过滤掉。首先把已经下线的从节点过滤掉，然后把以往网络连接状态不好的从节点也给过滤掉。</li></ul><p>怎么判断从节点之前的网络连接状态不好呢？<br>Redis 有个叫 down-after-milliseconds <em> 10 配置项，其down-after-milliseconds 是主从节点断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。<br>至此，我们就把网络状态不好的从节点过滤掉了，接下来要对所有从节点进行三轮考察：<em>*优先级、复制进度、ID 号</em></em>。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点。</p><ul><li>第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，</li><li>第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。</li><li><p>第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。</p><h5 id="第一轮考察：优先级最高的从节点胜出"><a href="#第一轮考察：优先级最高的从节点胜出" class="headerlink" title="第一轮考察：优先级最高的从节点胜出"></a>第一轮考察：优先级最高的从节点胜出</h5><p>Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。<br>每一台从节点的服务器配置不一定是相同的，我们可以根据服务器性能配置来设置从节点的优先级。<br>比如，如果 「 A 从节点」的物理内存是所有从节点中最大的， 那么我们可以把「 A 从节点」的优先级设置成最高。这样当哨兵进行第一轮考虑的时候，优先级最高的 A 从节点就会优先胜出，于是就会成为新主节点。</p><h5 id="第二轮考察：复制进度最靠前的从节点胜出"><a href="#第二轮考察：复制进度最靠前的从节点胜出" class="headerlink" title="第二轮考察：复制进度最靠前的从节点胜出"></a>第二轮考察：复制进度最靠前的从节点胜出</h5><p>如果在第一轮考察中，发现优先级最高的从节点有两个，那么就会进行第二轮考察，比较两个从节点哪个复制进度。<br>什么是复制进度？主从架构中，主节点会将写操作同步给从节点，在这个过程中，主节点会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置（如下图中的「主服务器已经写入的数据」的位置），而从节点会用 slave_repl_offset 这个值记录当前的复制进度（如下图中的「从服务器要读的位置」的位置）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645993347-fe1b7396-557e-44c4-a75d-be051bae531d.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tED3r&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84591&amp;status=done&amp;style=none&amp;taskId=u5c058a76-fd9d-47ef-9ea6-86791605b92&amp;title=" alt="image.png"><br>如果某个从节点的 slave_repl_offset 最接近 master_repl_offset，说明它的复制进度是最靠前的，于是就可以将它选为新主节点。</p><h5 id="第三轮考察：ID-号小的从节点胜出"><a href="#第三轮考察：ID-号小的从节点胜出" class="headerlink" title="第三轮考察：ID 号小的从节点胜出"></a>第三轮考察：ID 号小的从节点胜出</h5><p>如果在第二轮考察中，发现有两个从节点优先级和复制进度都是一样的，那么就会进行第三轮考察，比较两个从节点的 ID 号，ID 号小的从节点胜出。<br>什么是 ID 号？每个从节点都有一个编号，这个编号就是 ID 号，是用来唯一标识从节点的。<br>到这里，选主的事情终于结束了。简单给大家总结下：<br><img src="https://cdn.nlark.com/yuque/0/2022/webp/21371548/1658645993451-7cf5e318-e918-410a-9b8b-8188c84a21e9.webp#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Vm5go&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1027&amp;originWidth=879&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u96c37ec3-8121-4af1-98be-87f513cca7a&amp;title=" alt=""><br>在选举出从节点后，哨兵 leader 向被选中的从节点发送 SLAVEOF no one 命令，让这个从节点解除从节点的身份，将其变为新主节点。<br>如下图，哨兵 leader 向被选中的从节点 server2 发送 SLAVEOF no one 命令，将该从节点升级为新主节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995437-b08f67fd-2503-4643-8840-927a656d4ce0.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=skIkx&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1140&amp;originWidth=1830&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=601992&amp;status=done&amp;style=none&amp;taskId=u25596e48-fb8b-43df-b457-d23ab800786&amp;title=" alt="image.png"><br>在发送 SLAVEOF no one 命令之后，哨兵 leader 会以每秒一次的频率向被升级的从节点发送 INFO 命令（没进行故障转移之前，INFO 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。<br>如下图，选中的从节点 server2 升级成了新主节点：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995352-534e7c2e-3b41-48eb-b549-f4183aba9155.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=x8OY8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1070&amp;originWidth=1492&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=503409&amp;status=done&amp;style=none&amp;taskId=u9f0602ff-a450-4cb0-8469-8d3f78887fc&amp;title=" alt="image.png"></p><h4 id="步骤二：将从节点指向新主节点"><a href="#步骤二：将从节点指向新主节点" class="headerlink" title="步骤二：将从节点指向新主节点"></a>步骤二：将从节点指向新主节点</h4><p>当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 SLAVEOF 命令来实现。<br>如下图，哨兵 leader 向所有从节点（server3和server4）发送 SLAVEOF ，让它们成为新主节点的从节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995516-a02f6388-668e-47d2-971f-cb19cc08689e.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=AzQsa&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=928&amp;originWidth=1720&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=542845&amp;status=done&amp;style=none&amp;taskId=u81cc2c62-f837-4abb-a088-5a146b4bab1&amp;title=" alt="image.png"><br>所有从节点指向新主节点后的拓扑图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645995548-d735ebab-f4b1-4b9d-a298-2a129f75376b.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Fypeq&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1246&amp;originWidth=1630&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=559528&amp;status=done&amp;style=none&amp;taskId=uc247425f-b83b-4da6-a616-e49febb0df1&amp;title=" alt="image.png"></p><h4 id="步骤三：通知客户的主节点已更换"><a href="#步骤三：通知客户的主节点已更换" class="headerlink" title="步骤三：通知客户的主节点已更换"></a>步骤三：通知客户的主节点已更换</h4><p>经过前面一系列的操作后，哨兵集群终于完成主从切换的工作，那么新主节点的信息要如何通知给客户端呢？<br>这主要<strong>通过 Redis 的发布者/订阅者机制来实现</strong>的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。<br>哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件，几个常见的事件如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/webp/21371548/1658645995083-3883a2f6-347d-4393-a2cb-37cdb64a0988.webp#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=liKxB&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1738&amp;originWidth=2856&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8128f5e1-3cb7-419a-98d8-a20ba22fc7c&amp;title=" alt=""><br>客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。<strong>主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了</strong>。<br>通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p><h4 id="步骤四：将旧主节点变为从节点"><a href="#步骤四：将旧主节点变为从节点" class="headerlink" title="步骤四：将旧主节点变为从节点"></a>步骤四：将旧主节点变为从节点</h4><p>故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新主节点的从节点，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645996970-36b708d2-92e1-442a-badb-17d336d4afa4.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=xqrVM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1120&amp;originWidth=1392&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=531342&amp;status=done&amp;style=none&amp;taskId=u13359704-0f85-46ec-b273-fb8d90809af&amp;title=" alt="image.png"><br>至此，整个主从节点的故障转移的工作结束。</p><h4 id="哨兵集群是如何组成的？"><a href="#哨兵集群是如何组成的？" class="headerlink" title="哨兵集群是如何组成的？"></a>哨兵集群是如何组成的？</h4><p>前面提到了 Redis 的发布者/订阅者机制，那就不得不提一下哨兵集群的组成方式，因为它也用到了这个技术。<br>在我第一次搭建哨兵集群的时候，当时觉得很诧异。因为在配置哨兵的信息时，竟然只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。<br>sentinel monitor <master-name> <ip> <redis-port> <quorum><br>不需要填其他哨兵节点的信息，我就好奇它们是如何感知对方的，又是如何组成哨兵集群的？<br>后面才了解到，<strong>哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的</strong>。<br>在主从集群中，主节点上有一个名为<strong>sentinel</strong>:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。<br>在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到<strong>sentinel</strong>:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645997027-58d69efe-ed36-44f1-988e-797fa1b220d0.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e2d289d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1152&amp;originWidth=1290&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=158491&amp;status=done&amp;style=none&amp;taskId=uc687137e-9105-4e08-8586-65ba1043c99&amp;title=" alt="image.png"><br>通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。<br>哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？<br>主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。<br>如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658645997128-8aa9cbd7-9342-42be-9436-9e1656158851.png#clientId=u1ab4fe20-72cf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u420cccac&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1396&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=100621&amp;status=done&amp;style=none&amp;taskId=ufd1d7e66-9d30-482e-952a-739cf396e18&amp;title=" alt="image.png"><br>正式通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Redis 在 2.8 版本以后提供的<strong>哨兵（<em>Sentinel</em>）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。<br>哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：<strong>监控、选主、通知</strong>。<br>哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。<br><em>1、第一轮投票：判断主节点下线</em><br>当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。<br>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。<br><em>2、第二轮投票：选出哨兵leader</em><br>某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：</p></li><li><p>第一，拿到半数以上的赞成票；</p></li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul><p><em>3、由哨兵 leader 进行主从故障转移</em><br>选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：</p><ul><li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：<ul><li>过滤掉已经离线的从节点；</li><li>过滤掉历史网络连接状态不好的从节点；</li><li>将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。</li></ul></li><li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li><li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li><li>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li></ul><p>完！</p><h3 id="Ⅲ集群"><a href="#Ⅲ集群" class="headerlink" title="Ⅲ集群"></a>Ⅲ集群</h3><h4 id="①Redis集群介绍："><a href="#①Redis集群介绍：" class="headerlink" title="①Redis集群介绍："></a>①Redis集群介绍：</h4><p>1、为什么需要Redis集群？<br>        在讲Redis集群架构之前，我们先简单讲下Redis单实例的架构，从最开始的一主N从，到读写分离，再到Sentinel哨兵机制，单实例的Redis缓存足以应对大多数的使用场景，也能实现主从故障迁移。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667463929934-e9841e49-66a5-49fb-9970-244d86c251d5.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=208&amp;id=u9129082b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=422&amp;originWidth=494&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=104687&amp;status=done&amp;style=none&amp;taskId=u86f87354-d209-4370-abf5-341d2c67be6&amp;title=&amp;width=243.28573608398438" alt="image.png"></p><p>但是，在某些场景下，单实例存Redis缓存会存在的几个问题：</p><p>（1）写并发：<br>        Redis单实例读写分离可以解决读操作的负载均衡，但对于写操作，仍然是全部落在了master节点上面，在海量数据高并发场景，一个节点写数据容易出现瓶颈，造成master节点的压力上升。</p><p>（2）海量数据的存储压力：<br>        单实例Redis本质上只有一台Master作为存储，如果面对海量数据的存储，一台Redis的服务器就应付不过来了，而且数据量太大意味着持久化成本高，严重时可能会阻塞服务器，造成服务请求成功率下降，降低服务的稳定性。</p><p>针对以上的问题，Redis集群提供了较为完善的方案，解决了存储能力受到单机限制，写操作无法负载均衡的问题。</p><p>2、什么是Redis集群？</p><pre><code>    Redis3.0加入了Redis的集群模式，实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的master节点上面，从而解决了海量数据的存储问题。    Redis集群采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看成一个整体，可以连接任意一个节点进行操作，就像操作单一Redis实例一样，不需要任何代理中间件，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。    Redis也内置了高可用机制，支持N个master节点，每个master节点都可以挂载多个slave节点，当master节点挂掉时，集群会提升它的某个slave节点作为新的master节点。</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667463969408-e0330455-e5ce-4fbd-ab69-f15e96aaf04d.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=257&amp;id=uddd4dd13&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=404&amp;originWidth=720&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57980&amp;status=done&amp;style=none&amp;taskId=u4863c4ba-0e7f-4322-8312-21a3efea908&amp;title=&amp;width=458.2857666015625" alt="image.png"></p><pre><code>    如上图所示，Redis集群可以看成多个主从架构组合起来的，每一个主从架构可以看成一个节点（其中，只有master节点具有处理请求的能力，slave节点主要是用于节点的高可用）</code></pre><h4 id="②Redis集群的数据分布算法：哈希槽算法"><a href="#②Redis集群的数据分布算法：哈希槽算法" class="headerlink" title="②Redis集群的数据分布算法：哈希槽算法"></a>②Redis集群的数据分布算法：哈希槽算法</h4><p>1、什么是哈希槽算法？</p><pre><code>    前面讲到，Redis集群通过分布式存储的方式解决了单节点的海量数据存储的问题，对于分布式存储，需要考虑的重点就是如何将数据进行拆分到不同的Redis服务器上。常见的分区算法有hash算法、一致性hash算法，关于这些算法这里就不多介绍。</code></pre><ul><li>普通hash算法：将key使用hash算法计算之后，按照节点数量来取余，即hash(key)%N。优点就是比较简单，但是扩容或者摘除节点时需要重新根据映射关系计算，会导致数据重新迁移。</li><li><p>一致性hash算法：为每一个节点分配一个token，构成一个哈希环；查找时先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。优点是在加入和删除节点时只影响相邻的两个节点，缺点是加减节点会造成部分数据无法命中，所以一般用于缓存，而且用于节点量大的情况下，扩容一般增加一倍节点保障数据负载均衡。</p><pre><code>  Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作。  使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；哈希槽数据分区算法具有以下几种特点：</code></pre></li><li><p>解耦数据和节点之间的关系，简化了扩容和收缩难度；</p></li><li>节点自身维护槽的映射关系，不需要客户端代理服务维护槽分区元数据</li><li>支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景<blockquote><p>槽的迁移与指派命令：CLUSTER ADDSLOTS 0 1 2 3 4 … 5000 </p></blockquote></li></ul><pre><code>    默认情况下，redis集群的读和写都是到master上去执行的，不支持slave节点读和写，跟Redis主从复制下读写分离不一样，因为redis集群的核心的理念，主要是使用slave做数据的热备，以及master故障时的主备切换，实现高可用的。Redis的读写分离，是为了横向任意扩展slave节点去支撑更大的读吞吐量。而redis集群架构下，本身master就是可以任意扩展的，如果想要支撑更大的读或写的吞吐量，都可以直接对master进行横向扩展。</code></pre><p>2、Redis中哈希槽相关的数据结构：</p><p>（1）clusterNode数据结构：保存节点的当前状态，比如节点的创建时间，节点的名字，节点当前的配置纪元，节点的IP和地址，等等。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464136892-fdd95171-98fa-4024-8742-6ee58df1812f.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=661&amp;id=u2679d634&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=823&amp;originWidth=730&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=159857&amp;status=done&amp;style=none&amp;taskId=u9691a89f-2076-4fcf-aa16-6b3c79193cd&amp;title=&amp;width=586.2857666015625" alt="image.png"><br>（2）clusterState数据结构：记录当前节点所认为的集群目前所处的状态。</p><p>（3）节点的槽指派信息：</p><pre><code>    clusterNode数据结构的slots属性和numslot属性记录了节点负责处理那些槽：slots属性是一个二进制位数组(bit array)，这个数组的长度为16384/8=2048个字节，共包含16384个二进制位。Master节点用bit来标识对于某个槽自己是否拥有，时间复杂度为O(1)</code></pre><p>（4）集群所有槽的指派信息：</p><pre><code>    当收到集群中其他节点发送的信息时，通过将节点槽的指派信息保存在本地的clusterState.slots数组里面，程序要检查槽i是否已经被指派，又或者取得负责处理槽i的节点，只需要访问clusterState.slots[i]的值即可，时间复杂度仅为O(1)    如上图所示，ClusterState 中保存的 Slots 数组中每个下标对应一个槽，每个槽信息中对应一个 clusterNode 也就是缓存的节点。这些节点会对应一个实际存在的 Redis 缓存服务，包括 IP 和 Port 的信息。Redis Cluster 的通讯机制实际上保证了每个节点都有其他节点和槽数据的对应关系。无论Redis 的客户端访问集群中的哪个节点都可以路由到对应的节点上，因为每个节点都有一份 ClusterState，它记录了所有槽和节点的对应关系。</code></pre><h4 id="③集群的请求重定向："><a href="#③集群的请求重定向：" class="headerlink" title="③集群的请求重定向："></a>③集群的请求重定向：</h4><pre><code>    前面讲到，Redis集群在客户端层面没有采用代理，并且无论Redis 的客户端访问集群中的哪个节点都可以路由到对应的节点上，下面来看看 Redis 客户端是如何通过路由来调用缓存节点的：</code></pre><p>（1）MOVED请求：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464279693-c6577c2a-3a9d-45f3-870c-5e23ebf156f0.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=365&amp;id=u3d157440&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=548&amp;originWidth=808&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=125945&amp;status=done&amp;style=none&amp;taskId=u8806bf71-7d2a-4e65-842d-61a0578d0b0&amp;title=&amp;width=538.2857666015625" alt="image.png"></p><pre><code>    如上图所示，Redis 客户端通过 CRC16(key)%16383 计算出 Slot 的值，发现需要找“缓存节点1”进行数据操作，但是由于缓存数据迁移或者其他原因导致这个对应的 Slot 的数据被迁移到了“缓存节点2”上面。那么这个时候 Redis 客户端就无法从“缓存节点1”中获取数据了。但是由于“缓存节点1”中保存了所有集群中缓存节点的信息，因此它知道这个 Slot 的数据在“缓存节点2”中保存，因此向 Redis 客户端发送了一个 MOVED 的重定向请求。这个请求告诉其应该访问的“缓存节点2”的地址。Redis 客户端拿到这个地址，继续访问“缓存节点2”并且拿到数据。</code></pre><p>（2）ASK请求：<br>        上面的例子说明了，数据 Slot 从“缓存节点1”已经迁移到“缓存节点2”了，那么客户端可以直接找“缓存节点2”要数据。那么如果两个缓存节点正在做节点的数据迁移，此时客户端请求会如何处理呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667464287335-8c6ea7e5-e44a-4572-8e3b-68c635a6c031.png#clientId=u38993d08-2f5f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=332&amp;id=u69b85d6d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=478&amp;originWidth=817&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=123812&amp;status=done&amp;style=none&amp;taskId=uc5e5b594-542f-4c64-bd24-7cf6ebd670d&amp;title=&amp;width=568.2857666015625" alt="image.png"></p><pre><code>    Redis 客户端向“缓存节点1”发出请求，此时“缓存节点1”正向“缓存节点 2”迁移数据，如果没有命中对应的 Slot，它会返回客户端一个 ASK 重定向请求并且告诉“缓存节点2”的地址。客户端向“缓存节点2”发送 Asking 命令，询问需要的数据是否在“缓存节点2”上，“缓存节点2”接到消息以后返回数据是否存在的结果。</code></pre><p>（3）频繁重定向造成的网络开销的处理：smart客户端</p><p>① 什么是 smart客户端：<br>        在大部分情况下，可能都会出现一次请求重定向才能找到正确的节点，这个重定向过程显然会增加集群的网络负担和单次请求耗时。所以大部分的客户端都是smart的。所谓 smart客户端，就是指客户端本地维护一份hashslot =&gt; node的映射表缓存，大部分情况下，直接走本地缓存就可以找到hashslot =&gt; node，不需要通过节点进行moved重定向，</p><p>② JedisCluster的工作原理：</p><ul><li>在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot =&gt; node映射表，同时为每个节点创建一个JedisPool连接池。</li><li>每次基于JedisCluster执行操作时，首先会在本地计算key的hashslot，然后在本地映射表找到对应的节点node。</li><li>如果那个node正好还是持有那个hashslot，那么就ok；如果进行了reshard操作，可能hashslot已经不在那个node上了，就会返回moved。</li><li>如果JedisCluter API发现对应的节点返回moved，那么利用该节点返回的元数据，更新本地的hashslot =&gt; node映射表缓存</li><li>重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException</li></ul><p>③ hashslot迁移和ask重定向：</p><pre><code>    如果hashslot正在迁移，那么会返回ask重定向给客户端。客户端接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hashslot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存。    虽然ASK与MOVED都是对客户端的重定向控制，但是有本质区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道迁移什么时候完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，客户端需要更新slots缓存。</code></pre><h4 id="④Redis集群中节点的通信机制：goosip协议"><a href="#④Redis集群中节点的通信机制：goosip协议" class="headerlink" title="④Redis集群中节点的通信机制：goosip协议"></a>④Redis集群中节点的通信机制：goosip协议</h4><pre><code>    redis集群的哈希槽算法解决的是数据的存取问题，不同的哈希槽位于不同的节点上，而不同的节点维护着一份它所认为的当前集群的状态，同时，Redis集群是去中心化的架构。那么，当集群的状态发生变化时，比如新节点加入、slot迁移、节点宕机、slave提升为新Master等等，我们希望这些变化尽快被其他节点发现，Redis是如何进行处理的呢？也就是说，Redis不同节点之间是如何进行通信进行维护集群的同步状态呢？    在Redis集群中，不同的节点之间采用gossip协议进行通信，节点之间通讯的目的是为了维护节点之间的元数据信息。这些元数据就是每个节点包含哪些数据，是否出现故障，通过gossip协议，达到最终数据的一致性。</code></pre><blockquote><p>gossip协议，是基于流行病传播方式的节点或者进程之间信息交换的协议。原理就是在不同的节点间不断地通信交换信息，一段时间后，所有的节点就都有了整个集群的完整信息，并且所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，但只要这些节可以通过网络连通，最终他们的状态就会是一致的。Gossip协议最大的好处在于，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。</p></blockquote><p>Redis集群中节点的通信过程如下：</p><blockquote><ul><li>集群中每个节点都会单独开一个TCP通道，用于节点间彼此通信。</li><li>每个节点在固定周期内通过待定的规则选择几个节点发送ping消息</li><li>接收到ping消息的节点用pong消息作为响应</li></ul></blockquote><pre><code>    使用gossip协议的优点在于将元数据的更新分散在不同的节点上面，降低了压力；但是缺点就是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。另外，由于 gossip 协议对服务器时间的要求较高，时间戳不准确会影响节点判断消息的有效性。而且节点数量增多后的网络开销也会对服务器产生压力，同时结点数太多，意味着达到最终一致性的时间也相对变长，因此官方推荐最大节点数为1000左右。</code></pre><blockquote><p>redis cluster架构下的每个redis都要开放两个端口号，比如一个是6379，另一个就是加1w的端口号16379。</p><ul><li>6379端口号就是redis服务器入口。</li><li>16379端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用的是一种叫gossip 协议的二进制协议</li></ul></blockquote><p>1、gossip协议的常见类型：</p><p>gossip协议常见的消息类型包含： ping、pong、meet、fail等等。</p><p>（1）meet：主要用于通知新节点加入到集群中，通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。</p><p>（2）ping：用于交换节点的元数据。每个节点每秒会向集群中其他节点发送 ping 消息，消息中封装了自身节点状态还有其他部分节点的状态数据，也包括自身所管理的槽信息等等。</p><p>因为发送ping命令时要携带一些元数据，如果很频繁，可能会加重网络负担。因此，一般每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。<br>如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长导致信息严重滞后。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。<br>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 （总节点数 - 2）个其它节点的信息。<br>（3）pong：ping和meet消息的响应，同样包含了自身节点的状态和集群元数据信息。</p><p>（4）fail：某个节点判断另一个节点 fail 之后，向集群所有节点广播该节点挂掉的消息，其他节点收到消息后标记已下线。</p><p>由于Redis集群的去中心化以及gossip通信机制，Redis集群中的节点只能保证最终一致性。例如当加入新节点时(meet)，只有邀请节点和被邀请节点知道这件事，其余节点要等待 ping 消息一层一层扩散。除了 Fail 是立即全网通知的，其他诸如新节点、节点重上线、从节点选举成为主节点、槽变化等，都需要等待被通知到，也就是Gossip协议是最终一致性的协议。</p><p>2、meet命令的实现：</p><p>（1）节点A会为节点B创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。</p><p>（2）节点A根据CLUSTER MEET命令给定的IP地址和端口号，向节点B发送一条MEET消息。</p><p>（3）节点B接收到节点A发送的MEET消息，节点B会为节点A创建一个clusterNode结构，并将该结构添加到自己的clusterState.nodes字典里面。</p><p>（4）节点B向节点A返回一条PONG消息。</p><p>（5）节点A将受到节点B返回的PONG消息，通过这条PONG消息，节点A可以知道节点B已经成功的接收了自己发送的MEET消息。</p><p>（6）之后，节点A将向节点B返回一条PING消息。</p><p>（7）节点B将接收到的节点A返回的PING消息，通过这条PING消息节点B可以知道节点A已经成功的接收到了自己返回的PONG消息，握手完成。</p><p>（8）之后，节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间后，节点B会被集群中的所有节点认识。</p><p>四、集群的扩容与收缩：<br>        作为分布式部署的缓存节点总会遇到缓存扩容和缓存故障的问题。这就会导致缓存节点的上线和下线的问题。由于每个节点中保存着槽数据，因此当缓存节点数出现变动时，这些槽数据会根据对应的虚拟槽算法被迁移到其他的缓存节点上。所以对于redis集群，集群伸缩主要在于槽和数据在节点之间移动。</p><p>1、扩容：</p><p>（1）启动新节点<br>（2）使用cluster meet命令将新节点加入到集群<br>（3）迁移槽和数据：添加新节点后，需要将一些槽和数据从旧节点迁移到新节点</p><pre><code>    如上图所示，集群中本来存在“缓存节点1”和“缓存节点2”，此时“缓存节点3”上线了并且加入到集群中。此时根据虚拟槽的算法，“缓存节点1”和“缓存节点2”中对应槽的数据会应该新节点的加入被迁移到“缓存节点3”上面。    新节点加入到集群的时候，作为孤儿节点是没有和其他节点进行通讯的。因此需要在集群中任意节点执行 cluster meet 命令让新节点加入进来。假设新节点是 192.168.1.1 5002，老节点是 192.168.1.1 5003，那么运行以下命令将新节点加入到集群中。</code></pre><p>192.168.1.1 5003&gt; cluster meet 192.168.1.1 5002</p><pre><code>    这个是由老节点发起的，有点老成员欢迎新成员加入的意思。新节点刚刚建立没有建立槽对应的数据，也就是说没有缓存任何数据。如果这个节点是主节点，需要对其进行槽数据的扩容；如果这个节点是从节点，就需要同步主节点上的数据。总之就是要同步数据。</code></pre><p>如上图所示，由客户端发起节点之间的槽数据迁移，数据从源节点往目标节点迁移。</p><p>（1）客户端对目标节点发起准备导入槽数据的命令，让目标节点准备好导入槽数据。使用命令：cluster setslot {slot} importing {sourceNodeId}<br>（2）之后对源节点发起送命令，让源节点准备迁出对应的槽数据。使用命令：cluster setslot {slot} migrating {targetNodeId}<br>（3）此时源节点准备迁移数据了，在迁移之前把要迁移的数据获取出来。通过命令 cluster getkeysinslot {slot} {count}。Count 表示迁移的 Slot 的个数。<br>（4）然后在源节点上执行，migrate {targetIP} {targetPort} “” 0 {timeout} keys {keys} 命令，把获取的键通过流水线批量迁移到目标节点。<br>（5）重复 3 和 4 两步不断将数据迁移到目标节点。<br>（6）完成数据迁移到目标节点以后，通过 cluster setslot {slot} node {targetNodeId} 命令通知对应的槽被分配到目标节点，并且广播这个信息给全网的其他主节点，更新自身的槽节点对应表。<br>2、收缩：</p><p>迁移槽。<br>忘记节点。通过命令 cluster forget {downNodeId} 通知其他的节点</p><pre><code>    为了安全删除节点，Redis集群只能下线没有负责槽的节点。因此如果要下线有负责槽的master节点，则需要先将它负责的槽迁移到其他节点。迁移的过程也与上线操作类似，不同的是下线的时候需要通知全网的其他节点忘记自己，此时通过命令 cluster forget &#123;downNodeId&#125; 通知其他的节点。</code></pre><p>五、集群的故障检测与故障转恢复机制：<br>1、集群的故障检测：</p><pre><code>    Redis集群的故障检测是基于gossip协议的，集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。</code></pre><p>（1）主观下线（pfail）：当节点A检测到与节点B的通讯时间超过了cluster-node-timeout 的时候，就会更新本地节点状态，把节点B更新为主观下线。</p><p>主观下线并不能代表某个节点真的下线了，有可能是节点A与节点B之间的网络断开了，但是其他的节点依旧可以和节点B进行通讯。</p><p>（2）客观下线：</p><pre><code>    由于集群内的节点会不断地与其他节点进行通讯，下线信息也会通过 Gossip 消息传遍所有节点，因此集群内的节点会不断收到下线报告。    当半数以上的主节点标记了节点B是主观下线时，便会触发客观下线的流程（该流程只针对主节点，如果是从节点就会忽略）。将主观下线的报告保存到本地的 ClusterNode 的结构fail_reports链表中，并且对主观下线报告的时效性进行检查，如果超过 cluster-node-timeout*2 的时间，就忽略这个报告，否则就记录报告内容，将其标记为客观下线。    接着向集群广播一条主节点B的Fail 消息，所有收到消息的节点都会标记节点B为客观下线。</code></pre><p>2、集群地故障恢复：</p><pre><code>    当故障节点下线后，如果是持有槽的主节点则需要在其从节点中找出一个替换它，从而保证高可用。此时下线主节点的所有从节点都担负着恢复义务，这些从节点会定时监测主节点是否进入客观下线状态，如果是，则触发故障恢复流程。故障恢复也就是选举一个节点充当新的master，选举的过程是基于Raft协议选举方式来实现的。</code></pre><p>2.1、从节点过滤：</p><pre><code>    检查每个slave节点与master节点断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master</code></pre><p>2.2、投票选举：</p><p>（1）节点排序：</p><pre><code>    对通过过滤条件的所有从节点进行排序，按照priority、offset、run id排序，排序越靠前的节点，越优先进行选举。</code></pre><p>priority的值越低，优先级越高<br>offset越大，表示从master节点复制的数据越多，选举时间越靠前，优先进行选举<br>如果offset相同，run id越小，优先级越高<br>（2）更新配置纪元：</p><pre><code>    每个主节点会去更新配置纪元（clusterNode.configEpoch），这个值是不断增加的整数。这个值记录了每个节点的版本和整个集群的版本。每当发生重要事情的时候（例如：出现新节点，从节点精选）都会增加全局的配置纪元并且赋给相关的主节点，用来记录这个事件。更新这个值目的是，保证所有主节点对这件“大事”保持一致，大家都统一成一个配置纪元，表示大家都知道这个“大事”了。</code></pre><p>（3）发起选举：</p><pre><code>    更新完配置纪元以后，从节点会向集群发起广播选举的消息（CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST），要求所有收到这条消息，并且具有投票权的主节点进行投票。每个从节点在一个纪元中只能发起一次选举。</code></pre><p>（4）选举投票：</p><pre><code>    如果一个主节点具有投票权，并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点。每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。    如果超过(N/2 + 1)数量的master节点都投票给了某个从节点，那么选举通过，这个从节点可以切换成master，如果在 cluster-node-timeout*2 的时间内从节点没有获得足够数量的票数，本次选举作废，更新配置纪元，并进行第二轮选举，直到选出新的主节点为止。</code></pre><p>在第(1)步排序领先的从节点通常会获得更多的票，因为它触发选举的时间更早一些，获得票的机会更大</p><p>2.3、替换主节点：</p><pre><code>    当满足投票条件的从节点被选出来以后，会触发替换主节点的操作。删除原主节点负责的槽数据，把这些槽数据添加到自己节点上，并且广播让其他的节点都知道这件事情，新的主节点诞生了。</code></pre><p>（1）被选中的从节点执行SLAVEOF NO ONE命令，使其成为新的主节点</p><p>（2）新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己</p><p>（3）新的主节点对集群进行广播PONG消息，告知其他节点已经成为新的主节点</p><p>（4）新的主节点开始接收和处理槽相关的请求</p><p>备注：如果集群中某个节点的master和slave节点都宕机了，那么集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。</p><p>六、Redis集群的搭建：<br>该部分可以参考这篇文章：<a href="https://juejin.cn/post/6922690589347545102#heading-1">https://juejin.cn/post/6922690589347545102#heading-1</a></p><p>Redis集群的搭建可以分为以下几个部分：</p><p>1、启动节点：将节点以集群模式启动，读取或者生成集群配置文件，此时节点是独立的。</p><p>2、节点握手：节点通过gossip协议通信，将独立的节点连成网络，主要使用meet命令。</p><p>3、槽指派：将16384个槽位分配给主节点，以达到分片保存数据库键值对的效果。</p><p>七、Redis集群的运维：<br>1、数据迁移问题：</p><p>Redis集群可以进行节点的动态扩容缩容，这一过程目前还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。而 Redis为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦Key的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。</p><p>2、带宽消耗问题：</p><p>Redis集群是无中心节点的集群架构，依靠Gossip协议协同自动化修复集群的状态，但goosip有消息延时和消息冗余的问题，在集群节点数量过多的时候，goosip协议通信会消耗大量的带宽，主要体现在以下几个方面：</p><p>消息发送频率：跟cluster-node-timeout密切相关，当节点发现与其他节点的最后通信时间超过 cluster-node-timeout/2时会直接发送ping消息<br>消息数据量：每个消息主要的数据占用包含：slots槽数组（2kb）和整个集群1/10的状态数据<br>节点部署的机器规模：机器的带宽上限是固定的，因此相同规模的集群分布的机器越多，每台机器划分的节点越均匀，则整个集群内整体的可用带宽越高<br>集群带宽消耗主要分为：读写命令消耗+Gossip消息消耗，因此搭建Redis集群需要根据业务数据规模和消息通信成本做出合理规划：</p><p>在满足业务需求的情况下尽量避免大集群，同一个系统可以针对不同业务场景拆分使用若干个集群。<br>适度提供cluster-node-timeout降低消息发送频率，但是cluster-node-timeout还影响故障转移的速度，因此需要根据自身业务场景兼顾二者平衡<br>如果条件允许尽量均匀部署在更多机器上，避免集中部署。如果有60个节点的集群部署在3台机器上每台20个节点，这是机器的带宽消耗将非常严重<br>3、Pub/Sub广播问题：</p><p>集群模式下内部对所有publish命令都会向所有节点进行广播，加重带宽负担，所以集群应该避免频繁使用Pub/sub功能</p><p>4、集群倾斜：</p><p>集群倾斜是指不同节点之间数据量和请求量出现明显差异，这种情况将加大负载均衡和开发运维的难度。因此需要理解集群倾斜的原因</p><p>（1）数据倾斜：</p><p>节点和槽分配不均<br>不同槽对应键数量差异过大<br>集合对象包含大量元素<br>内存相关配置不一致<br>（2）请求倾斜：</p><p>合理设计键，热点大集合对象做拆分或者使用hmget代替hgetall避免整体读取</p><p>5、集群读写分离：</p><p>集群模式下读写分离成本比较高，直接扩展主节点数量来提高集群性能是更好的选择。<br>————————————————<br>版权声明：本文为CSDN博主「张维鹏」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/a745233700/article/details/112691126">https://blog.csdn.net/a745233700/article/details/112691126</a></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>索引篇</title>
      <link href="/2022/08/09/MySQL/%E7%B4%A2%E5%BC%95%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E7%B4%A2%E5%BC%95%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="Ⅰ索引基础面试题"><a href="#Ⅰ索引基础面试题" class="headerlink" title="Ⅰ索引基础面试题"></a>Ⅰ索引基础面试题</h2><h3 id="①什么是索引？"><a href="#①什么是索引？" class="headerlink" title="①什么是索引？"></a>①什么是索引？</h3><p>补充扯。。。。。<br>索引出现的原因：</p><ol><li>数据库的每行记录都是存储在磁盘中的块上的，块就是磁道和扇区交错的部分。通常块大小都是512字节，以达到稳定的目的。</li><li>假设有100条记录，每行记录占128个字节，那么一个块就可以存储四条记录，100条记录就需要25个块进行存储，如果你要访问特定的记录的话，就至多需要访问25个块。</li><li>为了加快数据的访问速度，就需要建立索引，为每行记录添加索引也就是稠密索引，同时索引也会存储在磁盘上。但是索引每行记录占用的字节比较少，一个块中就可以存储多行记录以减少磁盘的io。假设数据库中记录非常多的情况下，就需要建立多级索引，这就是b树和b加树的思想</li></ol><p>索引是存储引擎用于提高数据库表的访问速度的一种<strong>数据结构</strong>。<br>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。</p><h3 id="②索引的三种常见底层数据结构"><a href="#②索引的三种常见底层数据结构" class="headerlink" title="②索引的三种常见底层数据结构"></a>②索引的三种常见底层数据结构</h3><p>了解<br>详细内容三种常见的索引底层数据结构：分别是哈希表、有序数组和搜索树。</p><h4 id="a-哈希表"><a href="#a-哈希表" class="headerlink" title="a:哈希表"></a>a:哈希表</h4><ul><li><strong>哈希表</strong>是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key， 就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。 </li><li>不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的 一种方法是，拉出一个链表。 </li></ul><p>例子</p><blockquote><p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时<br>对应的哈希索引的示意图如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649383353717-c20de990-849e-4261-a9f2-0f44ac30faa6.png#averageHue=%23dce4d1&amp;clientId=uea3fc7bc-4e1d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=295&amp;id=hkcbc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=564&amp;originWidth=806&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=134107&amp;status=done&amp;style=none&amp;taskId=u26cf4416-43a5-4876-b81f-f243daed973&amp;title=&amp;width=421.79998779296875" alt="image.png"><br>需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时<br>速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速<br>度是很慢的。<br>你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用<br>户，就必须全部扫描一遍了。 </p></blockquote><p>所以，<strong>哈希表这种结构适用于只有等值查询的场景</strong>，比如 Memcached 及其他一些<br>NoSQL 引擎。</p><h4 id="b-有序数组"><a href="#b-有序数组" class="headerlink" title="b:有序数组"></a>b:有序数组</h4><ul><li>如果仅仅看查询效率，有序数组就是最好的数据结构了。</li><li>但是，在需要更新数据的时候就麻 烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 </li><li><p>所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是 2017 年某个城市的所有人 口信息，这类不会再修改的数据。</p><h4 id="c-树"><a href="#c-树" class="headerlink" title="c:树"></a>c:树</h4><p>N 叉树由于读写上的性能优点以及适配磁盘访问模式以及广泛应用在数据库引擎中。</p><h3 id="③索引的优缺点？"><a href="#③索引的优缺点？" class="headerlink" title="③索引的优缺点？"></a>③索引的优缺点？</h3><p>优点：</p></li><li><p><strong>加快数据查找的速度</strong></p></li><li>为用来<a href="/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>或者是分组的字段添加索引，可以加快分组和<a href="/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>的速度 </li><li>加快表与表之间的连接 </li></ul><p>缺点：</p><ul><li>需要占用物理空间，数量越大，占用空间越大；</li><li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；</li><li>会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。<h3 id="④索引的作用？"><a href="#④索引的作用？" class="headerlink" title="④索引的作用？"></a>④索引的作用？</h3>数据是存储在磁盘上的，查询数据时，如果没有索引，会加载<strong>所有</strong>的数据到内存，依次进行检索，读取磁盘次数较多。有了索引，就不需要加载所有数据，因为B+树的高度一般在2-4层，最多只需要读取2-4次磁盘，查询速度大大提升。</li></ul><p><strong>思考题：B＋树的存储能力如何？为何说一般查找行记录，最多只需要1~3次磁盘IO</strong><br>InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值 也就是说一个深度为3的B+Tree索引可以维护10^3<em>10^3</em>10^3=10亿条记录。<br>实际情况中每个节点不可能填充满，因此在数据库中，B+Tree的高度一般都在2~4层。MySQL的InnoDB存储引擎在设计的时候是将根节点常驻在内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作</p><h3 id="⑤什么情况下需要-不需要建索引？"><a href="#⑤什么情况下需要-不需要建索引？" class="headerlink" title="⑤什么情况下需要/不需要建索引？"></a>⑤什么情况下需要/不需要建索引？</h3><p><strong>什么时候适用索引？</strong></p><ul><li>字段有唯一性限制的，比如商品编码；</li><li>经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。</li><li>经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。</li></ul><p><strong>什么时候不需要创建索引？</strong></p><ul><li>WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。</li><li>字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。</li><li>表数据太少的时候，不需要创建索引；</li><li><p>经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。</p><h3 id="⑥索引的设计原则"><a href="#⑥索引的设计原则" class="headerlink" title="⑥索引的设计原则"></a>⑥索引的设计原则</h3></li><li><p>索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差。 </p></li><li>尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘I/O较少，查询速度更快。 </li><li>索引不是越多越好，每个索引都需要额外的物理空间，维护也需要花费时间。 </li><li><p>利用最左前缀原则。 </p><h3 id="⑦索引什么时候会失效"><a href="#⑦索引什么时候会失效" class="headerlink" title="⑦索引什么时候会失效"></a>⑦索引什么时候会失效</h3><p>导致索引失效的情况：</p></li><li><p>对于组合索引，不是使用组合索引最左边的字段，则不会使用索引 </p></li><li>以%开头的like查询如%abc，无法使用索引；非%开头的like查询如abc%，相当于范围查询，会使用索引<br>like查询以%开头的索引不一定会失效验证准备<br>创建一张users表，表结构如下，表中有999999条数据：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668245920842-8f6b0228-5483-48d1-8f4a-6c4838ed71cb.png#averageHue=%23f8f7f6&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u846eb8f3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=329&amp;originWidth=1324&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=27644&amp;status=done&amp;style=none&amp;taskId=u475c8486-ca5d-4668-9ed5-9b628673333&amp;title=" alt="image.png"><br>在name字段上创建索引<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668245937196-724699f4-de71-4540-929d-4887fce722d2.png#averageHue=%23f3f2f0&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u11e92120&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=147&amp;originWidth=1331&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=13272&amp;status=done&amp;style=none&amp;taskId=u295fb878-6ca7-4566-93d8-29a2f63875e&amp;title=" alt="image.png"><br>验证阶段<br>要验证一段SQL语句有没有使用到索引，最好的方法莫过于使用SQL执行计划EXPLAIN了。</li></ul><p><strong>首先先看一下LIKE查询不以%开头的情况：</strong><br>EXPLAIN SELECT  * FROM users WHERE <code>name</code> LIKE ‘001%’;<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668245980063-2cd95ad3-4f8f-49c7-80f4-d6012514b510.png#averageHue=%23f9f7f6&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u926e28a0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=158&amp;originWidth=1858&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=19678&amp;status=done&amp;style=none&amp;taskId=u4a4b1853-8ff9-4c40-bc9a-1a5dd01ca4c&amp;title=" alt="image.png"><br>type=range,key=idx_name，说明这段是使用了索引的。</p><p><strong>接着再看一下LIKE查询以%开头的情况</strong><br><strong>先看第一段SQL语句：</strong><br>EXPLAIN SELECT * FROM users WHERE <code>name</code> LIKE ‘%001%’<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668246012519-3ac7e58c-c3f6-432e-b0be-2805403ed404.png#averageHue=%23f9f7f6&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uba557ef3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=151&amp;originWidth=1859&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=19407&amp;status=done&amp;style=none&amp;taskId=u060af351-a032-4887-9bf0-7b6d9494765&amp;title=" alt="image.png"><br>type=ALL，所以这段SQL是没有使用索引的。</p><p><strong>再来看第二段SQL语句：</strong><br>EXPLAIN SELECT  <code>name</code> FROM users WHERE <code>name</code> LIKE ‘%001%’;<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668246036539-e9a818ff-2a4d-495e-bf7d-c4425e41f47c.png#averageHue=%23f9f3f2&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u194d9bcc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=159&amp;originWidth=1860&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=22103&amp;status=done&amp;style=none&amp;taskId=ub296178a-85c9-45d3-8e62-ac25066305e&amp;title=" alt="image.png"><br>type=index，key=idx_name，这个结果说明这段SQL是使用了索引的。</p><p><strong>接着看第三段SQL语句：</strong><br>EXPLAIN SELECT  id , <code>name</code> FROM users WHERE <code>name</code> LIKE ‘%001%’;<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668246072770-95752e9c-50e6-42fe-a52b-92f2ed88cd11.png#averageHue=%23f8f7f5&amp;clientId=u9e761034-dbd6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uaaa41423&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=146&amp;originWidth=1849&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=19292&amp;status=done&amp;style=none&amp;taskId=udaf5e6bf-b81d-4521-8300-882b6a3520a&amp;title=" alt="image.png"><br>第三段SQL语句是在第二段SQL语句的基础上多查询一列id。这个执行结果和第二段是一样的，说明这段也是使用了索引的。</p><p><strong>最后看一下第四段SQL语句：</strong><br>EXPLAIN SELECT  id , <code>name</code> , gender FROM users WHERE <code>name</code> LIKE ‘%001%’;</p><p>第四段SQL语句是在第三段SQL语句的基础上多查询两列id和gender。执行结果和第一段一样，是没有使用索引的。</p><p>验证结果<br>通过以上验证可以发现，LIKE查询 以%开头不一定会让索引失效。</p><p>为什么会走索引呢？<br>首先解释一下，执行计划中type=ALL和index。还有key的含义。</p><p>type=ALL：全表扫描，遍历整张表去查询匹配的结果，不走索引。<br>type=index：使用索引覆盖，仅仅扫描索引树，比ALL要快。<br>type=range：使用索引进行范围查询时就会用到range访问方法。<br>key：实际使用到的索引，如果为NULL就是没使用索引。<br><strong>LIKE查询以%开头使用了索引的原因就是使用了索引覆盖。</strong><br>针对二级索引MySQL提供了一个优化技术。即从辅助索引中就可以得到查询的记录，就不需要回表再根据聚集索引查询一次完整记录。使用索引覆盖的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作，但是前提是要查询的所有列必须都加了索引。</p><p>LIKE查询以%开头会导致全索引扫描或者全表扫描，如果没有索引覆盖的话，查询到的数据会回表，多了一次IO操作，当MySQL预估全表扫描或全索引扫描的时间比走索引花费的时间更少时，就不会走索引。有了索引覆盖就不需要回表了，减少了IO操作，花费的时间更少，所以就使用了索引。</p><p><strong>总结</strong><br>LIKE查询 以%开头不一定会让索引失效。如果查询的结果中只包含主键和索引字段则会使用索引，反之则不会。</p><ul><li>在索引列上使用“IS NULL”或“IS NOT NULL”操作</li><li>对索引列进行运算 比如”not”  “&lt;&gt;”  “!=”</li><li>查询条件使用or连接，前后没有同时使用索引<h2 id="Ⅱ索引拓展"><a href="#Ⅱ索引拓展" class="headerlink" title="Ⅱ索引拓展"></a>Ⅱ索引拓展</h2><h3 id="①覆盖索引"><a href="#①覆盖索引" class="headerlink" title="①覆盖索引"></a>①覆盖索引</h3>查询的数据列只用从索引中就能够取得，不需要<strong>回表</strong>进行二次查询，也就是说查询列要被所使用的索引覆盖。<br>对于innodb表的二级索引，如果索引能覆盖到查询的列，那么就可以避免对主键索引的二次查询。<br>不是所有类型的索引都可以成为覆盖索引。覆盖索引要存储索引列的值，而哈希索引、全文索引不存储索引列的值，所以MySQL使用b+树索引做覆盖索引。</li></ul><p>查询的字段在B+树只能确定我们要查找记录的主键值，所以如果我们想查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍，这个过程称为回表。</p><h3 id="②索引下推"><a href="#②索引下推" class="headerlink" title="②索引下推"></a>②索引下推</h3><blockquote><p>上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你<br>可能要问，那些不符合最左前缀的部分，会怎么样呢？<br>我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名<br>字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：<br> mysql&gt; select * from tuser where name like ‘张 %’ and age=10 and ismale=1;<br>你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第<br>一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。<br>然后呢？<br>当然是判断其他条件是否满足。在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段 值。 </p></blockquote><p>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过<br>程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 </p><blockquote><p>图 3 和图 4，是这两个过程的执行流程图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649384269026-0888a90a-b932-4fff-98cd-2b31bf11e6ec.png#averageHue=%23f1f0ea&amp;clientId=uea3fc7bc-4e1d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=228&amp;id=UfnSW&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=429&amp;originWidth=1005&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=200255&amp;status=done&amp;style=none&amp;taskId=u8e59fcdc-f014-4257-81bb-98b33948841&amp;title=&amp;width=533.0000610351562" alt="image.png"><br>图 3 无索引下推执行流程<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649384287056-644a0800-d89e-4eb4-975e-18cda31224de.png#averageHue=%23f0f0ea&amp;clientId=uea3fc7bc-4e1d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=225&amp;id=n7VpC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=422&amp;originWidth=962&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=205321&amp;status=done&amp;style=none&amp;taskId=u537f0718-6b8c-4a42-b2cc-c0aeae5efec&amp;title=&amp;width=512.0000610351562" alt="image.png"><br>图 4 索引下推执行流程<br>在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。<br>图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看<br>age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，<br>需要回表 4 次。<br>图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于<br>不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记<br>录回表取数据判断，就只需要回表 2 次。</p></blockquote><h3 id="③什么是最左匹配原则？"><a href="#③什么是最左匹配原则？" class="headerlink" title="③什么是最左匹配原则？"></a>③什么是最左匹配原则？</h3><ul><li>如果 SQL 语句中用到了组合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个组合索引去进行匹配。当遇到范围查询(&gt;、&lt;、between、like)就会停止匹配，后面的字段不会用到索引。</li><li>对(a,b,c)建立索引，查询条件使用 a/ab/abc 会走索引，使用 bc 不会走索引。</li><li>对(a,b,c,d)建立索引，查询条件为a = 1 and b = 2 and c &gt; 3 and d = 4，那么a、b和c三个字段能用到索引，而d无法使用索引。因为遇到了范围查询。</li></ul><p><strong>最左匹配原则的成因</strong><br>mysql创建复合索引的规则是首先对复合索引的最左边，也就是第一个索引数据进行排序，在第一个字段排序的基础上，再对第二个索引字段进行排序。其实就是实现了类似于order by 字段一 再 order by 字段二，这样一种排序规则。那么所以第一个字段是绝对有序的，而第二个字段就是无需的了。因此通常情况下使用第二个字段进行条件判断，就用不到索引了。这也就是mysql为什么会强调 联合索引最左匹配原则的原因。</p><p>如下图，对(a, b) 建立索引，a 在索引树中是全局有序的，而 b 是全局无序，局部有序（当a相等时，会根据b进行<a href="/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F">排序</a>）。直接执行b = 2这种查询条件无法使用索引。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647571051362-fefed543-f5d9-4ee8-a7e3-85d288c27f2a.png#averageHue=%23f1f1f1&amp;clientId=u1a81d606-b3de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=pXqe9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=221&amp;originWidth=501&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72420&amp;status=done&amp;style=none&amp;taskId=ubc36a95d-ac53-4c4b-ac13-4fa3a18d900&amp;title=" alt="image.png"><br>当a的值确定的时候，b是有序的。例如a = 1时，b值为1，2是有序的状态。当a = 2时候，b的值为1，4也是有序状态。 当执行a = 1 and b = 2时a和b字段能用到索引。而执行a &gt; 1 and b = 2时，a字段能用到索引，b字段用不到索引。因为a的值此时是一个范围，不是固定的，在这个范围内b值不是有序的，因此b字段无法使用索引。</p><h3 id="④有什么优化索引的方法"><a href="#④有什么优化索引的方法" class="headerlink" title="④有什么优化索引的方法"></a>④有什么优化索引的方法</h3><p>这里说一下几种常见优化索引的方法：</p><ul><li>前缀索引优化；</li><li>覆盖索引优化；</li><li>主键索引最好是自增的；</li><li>防止索引失效；<h4 id="前缀索引优化"><a href="#前缀索引优化" class="headerlink" title="前缀索引优化"></a>前缀索引优化</h4>前缀索引顾名思义就是使用某个字段中字符串的前几个字符建立索引，那我们为什么需要使用前缀来建立索引呢？</li></ul><p>使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。<br>不过，前缀索引有一定的局限性，例如：</p><ul><li>order by 就无法使用前缀索引；</li><li>无法把前缀索引用作覆盖索引；<h4 id="覆盖索引优化"><a href="#覆盖索引优化" class="headerlink" title="覆盖索引优化"></a>覆盖索引优化</h4>覆盖索引是指 SQL 中 查询的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。</li></ul><p>假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？<br>我们可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。<br>所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。</p><h4 id="主键索引最好是自增的"><a href="#主键索引最好是自增的" class="headerlink" title="主键索引最好是自增的"></a>主键索引最好是自增的</h4><p>我们在建表的时候，都会默认将主键索引设置为自增的，具体为什么要这样做呢？又什么好处？<br>InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。</p><p><strong>如果我们使用自增主键</strong>，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次<strong>插入一条新记录，都是追加操作，不需要重新移动数据</strong>，因此这种插入数据的方法效率非常高。<br><strong>如果我们使用非自增主键</strong>，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为<strong>页分裂</strong>。<strong>页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率</strong>。</p><blockquote><p>举个例子，假设某个数据页中的数据是1、3、5、9，且数据页满了，现在准备插入一个数据7，则需要把数据页分割为两个数据页：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659841299496-0208b7b4-d738-472c-a6fb-6e585a57df86.png#averageHue=%23f7e6d5&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=259&amp;id=fLjDR&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=782&amp;originWidth=1584&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=130138&amp;status=done&amp;style=none&amp;taskId=u6a6aa2b9-5b63-464f-a1d6-ba3c00ed1b0&amp;title=&amp;width=525.0000610351562" alt="image.png"><br>出现页分裂时，需要将一个页的记录移动到另外一个页，性能会受到影响，同时页空间的利用率下降，造成存储空间的浪费。<br>而如果记录是顺序插入的，例如插入数据11，则只需开辟新的数据页，也就不会发生页分裂：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659841299498-e1a95546-7819-4a20-b70b-2af8e0af98fd.png#averageHue=%23f8e8d9&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=277&amp;id=L1lKW&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=832&amp;originWidth=1662&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=149102&amp;status=done&amp;style=none&amp;taskId=u3462edf8-7f55-4ea6-9dcf-3219bd484a4&amp;title=&amp;width=554.0000610351562" alt="image.png"></p></blockquote><p>因此，在使用 InnoDB 存储引擎时，如果没有特别的业务需求，建议使用自增字段作为主键。<br>另外，主键字段的长度不要太大，因为<strong>主键字段长度越小，意味着二级索引的叶子节点越小（二级索引的叶子节点存放的数据是主键值），这样二级索引占用的空间也就越小</strong>。</p><h4 id="索引最好设置为-NOT-NULL"><a href="#索引最好设置为-NOT-NULL" class="headerlink" title="索引最好设置为 NOT NULL"></a>索引最好设置为 NOT NULL</h4><p>为了更好的利用索引，索引列要设置为 NOT NULL 约束。有两个原因：</p><ul><li>第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。</li><li><p>第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，会导致更多的存储空间占用，因为 InnoDB 默认行存储格式COMPACT，会用 1 字节空间存储 NULL 值列表，如下图的黄色部分：<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659841299383-3d3e6a29-3be4-4c6c-9a70-e8d976071fdd.png#averageHue=%23809678&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=p4v7S&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=102&amp;originWidth=1122&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48322&amp;status=done&amp;style=none&amp;taskId=uaee2d6ac-1ced-4f3b-9af7-66018846af8&amp;title=" alt="image.png"></p><h4 id="防止索引失效"><a href="#防止索引失效" class="headerlink" title="防止索引失效"></a>防止索引失效</h4><p>用上了索引并不意味着查询的时候会使用到索引，所以我们心里要清楚有哪些情况会导致索引失效，从而避免写出索引失效的查询语句，否则这样的查询效率是很低的。<br>我之前写过索引失效的文章，想详细了解的可以去看这篇文章：<a href="https://mp.weixin.qq.com/s/lEx6iRRP3MbwJ82Xwp675w">谁还没碰过索引失效呢?(opens new window)</a><br>这里简单说一下，发生索引失效的情况：</p></li><li><p>当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；</p></li><li>当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；</li><li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。</li><li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。<blockquote><p>我上面说的是常见的索引失效场景，实际过程中，可能会出现其他的索引失效场景，这时我们就需要查看执行计划，通过执行计划显示的数据判断查询语句是否使用了索引。<br>如下图，就是一个没有使用索引，并且是一个全表扫描的查询语句。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659841299452-2bffca9c-d061-48d5-94d1-8bbd664bff40.png#averageHue=%23f7f6f6&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=muR04&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=185&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60073&amp;status=done&amp;style=none&amp;taskId=u64cef69c-cc3f-4955-92f5-a59528e50e5&amp;title=" alt="image.png"><br>对于执行计划，参数有：</p><ul><li>possible_keys 字段表示可能用到的索引；</li><li>key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；</li><li>key_len 表示索引的长度；</li><li>rows 表示扫描的数据行数。</li><li>type 表示数据扫描类型，我们需要重点看这个。</li></ul><p>type 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的<strong>执行效率从低到高的顺序为</strong>：</p><ul><li>All（全表扫描）；</li><li>index（全索引扫描）；</li><li>range（索引范围扫描）；</li><li>ref（非唯一索引扫描）；</li><li>eq_ref（唯一索引扫描）；</li><li>const（结果只有一条的主键或唯一索引扫描）。</li></ul><p>在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。<br>range 表示采用了索引范围扫描，一般在 where 子句中使用 &lt; 、&gt;、in、between 等关键词，只检索给定范围的行，属于范围查找。<strong>从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式</strong>。<br>ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。<br>eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。<br>const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。<br>需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，<strong>const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中</strong>。<br>除了关注 type，我们也要关注 extra 显示的结果。<br>这里说几个重要的参考指标：</p><ul><li>Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。</li><li>Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。</li><li>Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。</li></ul></blockquote></li></ul><h2 id="⑤普通索引和唯一索引怎么选"><a href="#⑤普通索引和唯一索引怎么选" class="headerlink" title="⑤普通索引和唯一索引怎么选"></a>⑤普通索引和唯一索引怎么选</h2><blockquote><p><strong>changebuffer：</strong><br>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内<br>存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change<br>buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的<br>时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方<br>式就能保证这个数据逻辑的正确性。<br>需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，<br>change buffer 在内存中有拷贝，也会被写入到磁盘上。<br>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 <strong>merge</strong>。除了访问<br>这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭<br>（shutdown）的过程中，也会执行 merge 操作。 </p></blockquote><ul><li>查询比较 <ul><li>查询会以页为单位将数据页加载进内存，不需要一条记录一条记录读取磁盘。然后唯一索引根据 条件查询到记录时就返回结果，普通索引查到第一条记录往后遍历直到不满足条件，由于都在内 存中，不需要磁盘读取那么大开销，带来的额外查询开销忽略不计，所以查询性能几乎一致 </li></ul></li><li>更新比较 <ul><li>唯一索引由于更新时要检查唯一性，所以需要将数据页先加载进内存才能判断，此时直接操作内 存，不需要操作change buffer </li><li>补充：普通索引若数据再内存中直接内存中更新，否则会将更新操作先记录到change buffer 中，等下一次查询将数据读到内存中再进行change buffer里相关更新操作后将数据返回，这样 一来，再<strong>写多读少的情况下就减少了磁盘IO</strong>，若写完就马上查询，就大可不必用change buffer，不但没提高多少效率还造成维护change buffer额外消耗 将change buffer的操作对应到原始数据页的操作称为merge（可以查询来时读到内存再修改数 据，后台线程也会merge，数据库正常关闭也会merge） </li></ul></li><li>适合场景 <ul><li>写多读少，选用普通索引更好，可以利用change buffer进行性能优化减少磁盘IO，将更新操作 记录到change bufer，等查询来了将数据读到内存再进行修改.  </li></ul></li></ul><p><strong>如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据。</strong><br>这个问题的答案是不会丢失。虽然是只更新内存，但是在事<br>务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时<br>候，change buffer 也能找回来。</p><p>merge 的执行流程是这样的：</p><ol><li>从磁盘读入数据页到内存（老版本的数据页）；</li><li>从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应<br>用，得到新版数据页；</li><li>写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。<br>到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都<br>还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</li></ol><p><strong>change buffer 和 redo log</strong><br>插入数据：insert into t(id,k) values(id1,k1),(id2,k2);<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651628130110-75b9eb67-24eb-4b8f-b0a6-f1b0f66d66d9.png#averageHue=%23fdfcf6&amp;clientId=uee8de687-a63b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=293&amp;id=l583d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=798&amp;originWidth=1446&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=80406&amp;status=done&amp;style=none&amp;taskId=u0309de32-eb7b-45c8-8376-bba177e5e9b&amp;title=&amp;width=531.2857666015625" alt="image.png"></p><p>假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中<br>Page 1 在内存中，直接更新内存<br>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下 我要往 Page 2 插入一行 这个信息<br>将上述两个动作记入 redo log 中<br>查询数据：select * from t where k in (k1, k2)<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651628136984-341d6149-223b-41ed-98f6-6c9001edef83.png#averageHue=%23fffff9&amp;clientId=uee8de687-a63b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=zfVp4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=886&amp;originWidth=1384&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62246&amp;status=done&amp;style=none&amp;taskId=ua35f3fbd-7fb2-43e6-8790-8f43cbbb08d&amp;title=" alt="image.png"></p><p>读 Page 1 的时候，直接从内存返回<br>读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果<br>redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗</p><h2 id="✊ⅢMySQL中的索引分类"><a href="#✊ⅢMySQL中的索引分类" class="headerlink" title="✊ⅢMySQL中的索引分类"></a>✊ⅢMySQL中的索引分类</h2><h3 id="1-按数据结构分类"><a href="#1-按数据结构分类" class="headerlink" title="1. 按数据结构分类"></a>1. 按数据结构分类</h3><blockquote><p>从数据结构的角度来看，MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。<br>每一种存储引擎支持的索引类型不一定相同，我在表中总结了 MySQL 常见的存储引擎 InnoDB、MyISAM 和 Memory 分别支持的索引类型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659837829679-1bf67d5d-98b8-435b-afb8-4e433bfb5031.png#averageHue=%23f7cb56&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=300&amp;id=u778f7ee3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=421&amp;originWidth=811&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=110111&amp;status=done&amp;style=none&amp;taskId=uce722832-5649-4591-b65d-1ae7ffb4856&amp;title=&amp;width=577.0000610351562" alt="image.png"><br>InnoDB 是在 MySQL 5.5 之后成为默认的 MySQL 存储引擎，B+Tree 索引类型也是 MySQL 存储引擎采用最多的索引类型。</p></blockquote><p>在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：</p><ul><li>如果有主键，默认会使用主键作为聚簇索引的索引键（key）；</li><li>如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；</li><li>在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；</li></ul><p>其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。<strong>创建的主键索引和二级索引默认使用的是 B+Tree 索引</strong>。</p><h4 id="①哈希索引"><a href="#①哈希索引" class="headerlink" title="①哈希索引"></a>①哈希索引</h4><p>哈希索引是基于<a href="/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8">哈希表</a>实现的，对于每一行数据，存储引擎会对索引列进行哈希计算得到哈希码，将哈希码的值作为<a href="/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8">哈希表</a>的key值，将指向数据行的指针作为<a href="/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8">哈希表</a>的value值。这样查找一个数据的时间复杂度就是O(1)，一般多用于精确查找。</p><h4 id="✊②B-树索引"><a href="#✊②B-树索引" class="headerlink" title="✊②B+树索引"></a>✊②B+树索引</h4><ul><li><strong>概念：</strong><ul><li>B+ 树是基于B 树和叶子节点顺序访问指针进行实现，它具有B树的平衡性，并且通过顺序访问指针来提高区间查询的性能。</li></ul></li><li>特点：<ul><li><ol><li>所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。</li></ol></li></ul></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647571051030-c78872ac-1de2-4d38-a618-0d0742e8cf74.png#averageHue=%23f4f0e9&amp;clientId=u1a81d606-b3de-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=R01cB&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=201&amp;originWidth=376&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48084&amp;status=done&amp;style=none&amp;taskId=u541d84c6-1dc0-49f8-8864-d59ed1e3383&amp;title=" alt="image.png"></p><ul><li>如何找到指定元素：<ul><li>进行查找操作时，首先在根节点进行<a href="/jump/super-jump/word?word=%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE">二分查找</a>，找到key所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行<a href="/jump/super-jump/word?word=%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE">二分查找</a>，找出key所对应的数据项。</li></ul></li></ul><p>MySQL 数据库使用最多的索引类型是BTREE索引，底层基于B+树数据结构来实现。</p><h5 id="b-树相关面试题"><a href="#b-树相关面试题" class="headerlink" title="b+树相关面试题"></a>b+树相关面试题</h5><p><strong>1.在MySQL中为什么会选用B+tree做索引结构呢？</strong><br>B站咖喱味的视频## 拓展：为什么使用B+树作为mysql索引</p><p>数据库的每行记录都是存储在磁盘中的块上的，块就是磁道和扇区交错的部分。通常块大小都是512字节，以达到稳定的目的。<br>假设有100条记录，每行记录占128个字节，那么一个块就可以存储四条记录，100条记录就需要25个块进行存储，如果你要访问特定的记录的话，就至多需要访问25个块。</p><p>为了加快数据的访问速度，就需要建立索引，为每行记录添加索引也就是稠密索引，同时索引也会存储在磁盘上。但是索引每行记录占用的字节比较少，一个块中就可以存储多行记录以减少磁盘的io。假设数据库中记录非常多的情况下，就需要建立多级索引，这就是b树和b加树的思想</p><h3 id="磁盘结构"><a href="#磁盘结构" class="headerlink" title="磁盘结构"></a>磁盘结构</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283255430-d3186cb8-0eca-44e3-a77f-132b94af9c86.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=293&amp;id=WGco1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=366&amp;originWidth=451&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=89491&amp;status=done&amp;style=none&amp;taskId=u0c171e19-174e-4219-8b1a-4cb6f8e3fd6&amp;title=&amp;width=360.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283263903-97137ad4-8c61-445d-a451-362e1a9729eb.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=28&amp;id=O9UWg&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=35&amp;originWidth=595&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=23266&amp;status=done&amp;style=none&amp;taskId=udf954a74-b594-4519-bea0-ad9c6dc8c93&amp;title=&amp;width=476" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283305394-76d45fce-4976-4b3f-9fc6-cb0139aac674.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=54&amp;id=eJzN4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=68&amp;originWidth=294&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18945&amp;status=done&amp;style=none&amp;taskId=ua2084c41-c2f2-4f87-ae29-25bb0197456&amp;title=&amp;width=235.2" alt="image.png">轨道号和扇区号定位<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283349880-79ed0cf3-6627-45eb-bb99-eff0d66a1619.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=29&amp;id=yiCUd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=36&amp;originWidth=522&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=19607&amp;status=done&amp;style=none&amp;taskId=u25dd0790-77eb-47db-982c-220c774578a&amp;title=&amp;width=417.6" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283180424-022c227c-b321-47c0-8891-fbf068091cb2.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tPr31&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=515&amp;originWidth=589&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=82123&amp;status=done&amp;style=none&amp;taskId=u8e1ae0e3-a589-47d7-92fc-fa51360030e&amp;title=" alt="image.png"></p><h3 id="数据如何存储在磁盘上"><a href="#数据如何存储在磁盘上" class="headerlink" title="数据如何存储在磁盘上"></a>数据如何存储在磁盘上</h3><p>以块形式将数据存储在磁盘上<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650283670057-fcd1ca92-1205-4661-adf3-4dad05bfcce6.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=313&amp;id=kdcFe&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=391&amp;originWidth=666&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=128285&amp;status=done&amp;style=none&amp;taskId=uaa095f0d-d729-4962-884b-728ae96eefc&amp;title=&amp;width=532.8" alt="image.png"><br>假设数据库每行占128字节，块大小512字节<br>所以一个块中可以存储四行</p><p>假设一张表中有100条记录，那么就需要25个块。<br>如果要查找特点的记录，就最多需要访问25个块。</p><p>这时为数据库准备索引来减少访问的时间<br>为每行记录添加索引就是稠密索引<br>同时索引也会存储在磁盘上<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650284155235-441461dc-8b24-44bd-9868-dbba8fc18fe5.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=318&amp;id=YAsPz&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=397&amp;originWidth=226&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72177&amp;status=done&amp;style=none&amp;taskId=u6a0aeb1e-e8da-4398-9cc1-1218cc9469e&amp;title=&amp;width=180.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650284163321-de3e13cd-8ae8-4182-b238-1b6df47099df.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=30&amp;id=f8reV&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=37&amp;originWidth=561&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=20649&amp;status=done&amp;style=none&amp;taskId=u0607b63d-ec3a-4ee1-8f8f-bd7d58c0eb7&amp;title=&amp;width=448.8" alt="image.png"><br>那么100条记录 100/32 约等于4 所以最多只需要访问4+1个块<br>4个索引加上要去访问数据的那个块</p><h3 id="多级索引"><a href="#多级索引" class="headerlink" title="多级索引"></a>多级索引</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650284422918-e966ab3b-4fd3-48c4-8d89-6c2c18c9759f.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=326&amp;id=NmZdk&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=407&amp;originWidth=575&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=180215&amp;status=done&amp;style=none&amp;taskId=uc038fa10-7c28-4987-b104-3a081cb65a1&amp;title=&amp;width=460" alt="image.png"><br>指向条目集的指针<br>以上就是B树和B+树索引的思想<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650284681823-c7b8ac0e-c945-4bb7-8f84-a9bb275db1da.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=283&amp;id=lruOz&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=354&amp;originWidth=340&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=75966&amp;status=done&amp;style=none&amp;taskId=u3b17da69-58b3-491e-93ee-00ad443aafe&amp;title=&amp;width=272" alt="image.png"></p><h3 id="M-way-search-tree"><a href="#M-way-search-tree" class="headerlink" title="M-way search tree"></a>M-way search tree</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650285052771-970946f6-bd5e-472b-af4d-1a4d1556d954.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=342&amp;id=jd3ME&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=427&amp;originWidth=554&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=119865&amp;status=done&amp;style=none&amp;taskId=ub08f78e6-639a-4763-8ec5-6e202f5a71d&amp;title=&amp;width=443.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650285336282-00c17720-f535-4bff-8098-3fc87239d043.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=373&amp;id=EmT5L&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=466&amp;originWidth=614&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=138621&amp;status=done&amp;style=none&amp;taskId=uce293c8e-02d8-4793-9d98-573353e5a0c&amp;title=&amp;width=491.2" alt="image.png"></p><p>规则：ex 10-way<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650285735773-3464a6ab-549a-4370-95cd-e7afe92c1c52.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=45&amp;id=aSIhI&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=56&amp;originWidth=586&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=14437&amp;status=done&amp;style=none&amp;taskId=ud8aa930b-8e01-48fd-b9d0-759fd3dfbf7&amp;title=&amp;width=468.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650285803473-177fb3f7-391b-474a-a78b-b3459ac23e22.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=123&amp;id=UAcuO&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=154&amp;originWidth=550&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=52331&amp;status=done&amp;style=none&amp;taskId=ub71c014b-8e70-4bed-94c6-5dd428926c4&amp;title=&amp;width=440" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650285831331-56d8fc48-ab70-49b0-902d-502bc947780d.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=53&amp;id=YN1QC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=66&amp;originWidth=233&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=11084&amp;status=done&amp;style=none&amp;taskId=uef5ac9f7-e1cb-40c8-9a34-3ccfd56fea9&amp;title=&amp;width=186.4" alt="image.png">创建过程自下而上<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650286383950-157a6994-c47c-45f1-882a-ecb2b2ef31a4.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=363&amp;id=tktxu&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=454&amp;originWidth=854&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=244042&amp;status=done&amp;style=none&amp;taskId=ubbd98087-859e-43c6-802f-23d9c0e3094&amp;title=&amp;width=683.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650286474759-15dc1759-ce6c-4b59-b7b7-2424176e93d5.png#clientId=ue6991ab5-e7f4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=344&amp;id=ozecu&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=430&amp;originWidth=788&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=181095&amp;status=done&amp;style=none&amp;taskId=u86541e63-0350-433e-b256-791766bc3c0&amp;title=&amp;width=630.4" alt="image.png"><br>详细内容—演变过程是如何使用B+树的怎样的索引的数据结构是好的？<br>MySQL 的数据是持久化的，意味着数据（索引+记录）是保存到磁盘上的，因为这样即使设备断电了，数据也不会丢失。</p><p>磁盘是一个慢的离谱的存储设备，有多离谱呢？</p><p>内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的，也就是说读取同样大小的数据，磁盘中读取的速度比从内存中读取的速度要慢上万倍，甚至几十万倍。<br>磁盘读写的最小单位是<strong>扇区</strong>，扇区的大小只有 512B 大小，操作系统一次会读写多个扇区，所以<strong>操作系统的最小读写单位是块（Block）。Linux 中的块大小为 4KB</strong>，也就是一次磁盘  I/O 操作会直接读写 8 个扇区。</p><p>由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I/O，而磁盘 I/O 次数越多，所消耗的时间也就越大。</p><p>所以，我们希望索引的数据结构能在尽可能少的磁盘的 I/O 操作中完成查询工作，因为磁盘  I/O 操作越少，所消耗的时间也就越小。</p><p>另外，MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。<br>所以，要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：</p><ul><li>能在尽可能少的磁盘的 I/O 操作中完成查询工作；</li><li>要能高效地查询某一个记录，也要能高效地执行范围查找；</li></ul><p>分析完要求后，我们针对每一个数据结构分析一下。</p><p>什么是二分查找？<br>索引数据最好能按顺序排列，这样可以使用「二分查找法」高效定位数据。</p><p>假设我们现在用数组来存储索引，比如下面有一个排序的数组，如果要从中找出数字 3，最简单办法就是从头依次遍历查询，这种方法的时间复杂度是 O(n)，查询效率并不高。因为该数组是有序的，所以我们可以采用二分查找法，比如下面这张采用二分法的查询过程图：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1659838524793-609e5181-249d-4cc0-84f3-04d625ec75b4.jpeg#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=JZkbS&amp;margin=%5Bobject%20Object%5D&amp;originHeight=432&amp;originWidth=981&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0a59a2f4-af8c-4f0c-92fc-b0cb5684acf&amp;title=" alt=""><br>可以看到，二分查找法每次都把查询的范围减半，这样时间复杂度就降到了 O(logn)，但是每次查找都需要不断计算中间位置。</p><p>什么是二分查找树？<br>用数组来实现线性排序的数据虽然简单好用，但是插入新元素的时候性能太低。</p><p>因为插入一个元素，需要将这个元素之后的所有元素后移一位，如果这个操作发生在磁盘中呢？这必然是灾难性的。因为磁盘的速度比内存慢几十万倍，所以我们不能用一种线性结构将磁盘排序。</p><p>其次，有序的数组在使用二分查找的时候，每次查找都要不断计算中间的位置。</p><p>就可以设计一个非线形且天然适合二分查找的数据结构呢？</p><p>有的，请看下图这个神奇的操作，找到所有二分查找中用到的所有中间节点，把他们用指针连起来，并将最中间的节点作为根节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838582658-58112110-7407-4438-b6ee-90e6c3cc7b61.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=c5OVZ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=257&amp;originWidth=612&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ufa96c9a0-7089-491c-ab6b-2480499cc97&amp;title=" alt=""><br>怎么样？是不是变成了二叉树，不过它不是普通的二叉树，它是一个<strong>二叉查找树</strong>。<br><strong>二叉查找树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点</strong>，这样我们在查询数据时，不需要计算中间节点的位置了，只需将查找的数据与节点的数据进行比较。<br>假设，我们查找索引值为 key 的节点：</p><ol><li>如果 key 大于根节点，则在右子树中进行查找；</li><li>如果 key 小于根节点，则在左子树中进行查找；</li><li>如果 key 等于根节点，也就是找到了这个节点，返回根节点即可。</li></ol><p>二叉查找树查找某个节点的动图演示如下，比如要查找节点 3 ：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838582537-1cbeb669-80e9-419f-b587-4a810ca77672.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=cu3c4&amp;margin=%5Bobject%20Object%5D&amp;originHeight=165&amp;originWidth=253&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue4f34ebe-cbbe-429d-809c-cfdd05756cc&amp;title=" alt=""><br>另外，二叉查找树解决了插入新节点的问题，因为二叉查找树是一个跳跃结构，不必连续排列。这样在插入的时候，新节点可以放在任何位置，不会像线性结构那样插入一个元素，所有元素都需要向后排列。<br>下面是二叉查找树插入某个节点的动图演示：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838582754-a217ea81-ca95-4bc0-8e8d-7357c2719145.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=zMh0N&amp;margin=%5Bobject%20Object%5D&amp;originHeight=197&amp;originWidth=689&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u74de552c-d30b-40fc-b776-fd18f5ee231&amp;title=" alt=""></p><p>因此，二叉查找树解决了连续结构插入新元素开销很大的问题，同时又保持着天然的二分结构。<br>那是不是二叉查找树就可以作为索引的数据结构了呢？<br>不行不行，二叉查找树存在一个极端情况，会导致它变成一个瘸子！<br><strong>当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)</strong>，如下动图演示：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838582702-c2e0e9bc-7a15-4f00-9f83-bb1256fefb31.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ZFzld&amp;margin=%5Bobject%20Object%5D&amp;originHeight=253&amp;originWidth=714&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua503a4b8-7a3e-4083-8caf-a211e720744&amp;title=" alt=""><br>由于树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作（<em>假设一个节点的大小「小于」操作系统的最小读写单位块的大小</em>），也就是说<strong>树的高度就等于每次查询数据时磁盘 IO 操作的次数</strong>，所以树的高度越高，就会影响查询性能。<br>二叉查找树由于存在退化成链表的可能性，会使得查询操作的时间复杂度从 O(logn)降低为 O(n)。<br>而且会随着插入的元素越多，树的高度也变高，意味着需要磁盘 IO 操作的次数就越多，这样导致查询性能严重下降，再加上不能范围查询，所以不适合作为数据库的索引结构。<br>什么是自平衡二叉树？<br>为了解决二叉查找树会在极端情况下退化成链表的问题，后面就有人提出<strong>平衡二叉查找树（AVL 树）</strong>。</p><p>主要是在二叉查找树的基础上增加了一些条件约束：<strong>每个节点的左子树和右子树的高度差不能超过 1</strong>。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 O(logn) 。<br>下图是每次插入的元素都是平衡二叉查找树中最大的元素，可以看到，它会维持自平衡：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838764490-74bbd6db-20e6-42b6-9133-54fe5def1fb0.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ApUiQ&amp;margin=%5Bobject%20Object%5D&amp;originHeight=189&amp;originWidth=387&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue6e1de8f-6b8d-4fdd-b32a-e867a09174e&amp;title=" alt=""><br>除了平衡二叉查找树，还有很多自平衡的二叉树，比如红黑树，它也是通过一些约束条件来达到自平衡，不过红黑树的约束条件比较复杂，不是本篇的重点重点，大家可以看《数据结构》相关的书籍来了解红黑树的约束条件。<br>下面是红黑树插入节点的过程，这左旋右旋的操作，就是为了自平衡。<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838764739-0a67372a-3fee-4a9d-b83b-99e7e2e30bf9.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=z3lVN&amp;margin=%5Bobject%20Object%5D&amp;originHeight=248&amp;originWidth=747&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=udc7b532a-551f-43d4-b616-9979b8ede98&amp;title=" alt=""><br><strong>不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率</strong>。<br>比如，下面这个平衡二叉查找树的高度为 5，那么在访问最底部的节点时，就需要磁盘 5 次 I/O 操作。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659838764561-913682ab-1e58-4a6c-b1ef-c27f8b859a0e.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=hM0Ba&amp;margin=%5Bobject%20Object%5D&amp;originHeight=491&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u2571034a-c180-484a-b235-4a383cda21e&amp;title=" alt=""><br>根本原因是因为它们都是二叉树，也就是每个节点只能保存 2 个子节点 ，如果我们把二叉树改成 M 叉树（M&gt;2）呢？<br>比如，当 M=3 时，在同样的节点个数情况下，三叉树比二叉树的树高要矮。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659838764498-14c5ce08-4a7e-487f-ae27-6e6bc6c45a75.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=J9dUT&amp;margin=%5Bobject%20Object%5D&amp;originHeight=465&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub33fbea2-a4d6-44e5-bae5-e4184a601b5&amp;title=" alt=""><br>因此，<strong>当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度</strong>。<br>什么是 B 树<br>自平衡二叉树虽然能保持查询操作的时间复杂度在O(logn)，但是因为它本质上是一个二叉树，每个节点只能有 2 个子节点，那么当节点个数越多的时候，树的高度也会相应变高，这样就会增加磁盘的 I/O 次数，从而影响数据查询的效率。</p><p>为了解决降低树的高度的问题，后面就出来了 B 树，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M&gt;2)，从而降低树的高度。</p><p>B 树的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶，所以 B 树就是一个多叉树。<br>假设 M = 3，那么就是一棵 3 阶的 B 树，特点就是每个节点最多有 2 个（M-1个）数据和最多有 3 个（M个）子节点，超过这些要求的话，就会分裂节点，比如下面的的动图：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838764477-b3fb7c60-76d7-45da-a59a-345b4c850416.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PwzJY&amp;margin=%5Bobject%20Object%5D&amp;originHeight=310&amp;originWidth=847&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3b886a5c-38fd-4fbb-8ba0-bbdbbb950de&amp;title=" alt=""><br>我们来看看一棵 3 阶的 B 树的查询过程是怎样的？<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838765220-22a6967f-e7d2-4343-a5f6-67ff5c589c17.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=meC7T&amp;margin=%5Bobject%20Object%5D&amp;originHeight=192&amp;originWidth=385&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u65c805ad-cfcf-482d-96c5-d1efa62a499&amp;title=" alt=""><br>假设我们在上图一棵 3 阶的 B 树中要查找的索引值是 9 的记录那么步骤可以分为以下几步：</p><ol><li>与根节点的索引(4，8）进行比较，9 大于 8，那么往右边的子节点走；</li><li>然后该子节点的索引为（10，12），因为 9 小于 10，所以会往该节点的左边子节点走；</li><li>走到索引为9的节点，然后我们找到了索引值 9 的节点。</li></ol><p>可以看到，一棵 3 阶的 B 树在查询叶子节点中的数据时，由于树的高度是 3 ，所以在查询过程中会发生 3 次磁盘 I/O 操作。</p><p>而如果同样的节点数量在平衡二叉树的场景下，树的高度就会很高，意味着磁盘 I/O 操作会更多。所以，B 树在数据查询中比平衡二叉树效率要高。</p><p>但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。</p><p>而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I/O 操作次数，也占用内存资源。</p><p>另外，如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I/O  问题，从而导致整体速度下降。<br>什么是 B+ 树？<br>B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659838765199-e9836925-83d3-43d6-bf08-c1b4da08a046.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=YnT9M&amp;margin=%5Bobject%20Object%5D&amp;originHeight=671&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u83d51890-e55f-4dc3-8b36-188182722de&amp;title=" alt=""><br>B+ 树与 B 树差异的点，主要是以下这几点：</p><ul><li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；</li><li>所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；</li><li>非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。</li><li>非叶子节点中有多少个子节点，就有多少个索引；</li></ul><p>下面通过三个方面，比较下 B+ 和 B 树的性能区别。<br><strong>1、单点查询</strong><br>B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。</p><p>但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。</p><p><strong>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少</strong>。<br><strong>2、插入和删除效率</strong><br>B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，</p><p>比如下面这个动图是删除 B+ 树某个叶子节点节点的过程：</p><p><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838765212-b0352e19-6d21-45df-a50f-05545ab481c1.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=cFazU&amp;margin=%5Bobject%20Object%5D&amp;originHeight=168&amp;originWidth=408&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u5b5d1127-d80a-48c7-9c29-4b9628f7c93&amp;title=" alt=""><br>注意，：B+ 树对于非叶子节点的子节点和索引的个数，定义方式可能会有不同，有的是说非叶子节点的子节点的个数为 M 阶，而索引的个数为 M-1（这个是维基百科里的定义），因此我本文关于 B+ 树的动图都是基于这个。但是我在前面介绍 B+ 树与 B+ 树的差异时，说的是「非叶子节点中有多少个子节点，就有多少个索引」，主要是 MySQL 用到的 B+ 树就是这个特性。<br>甚至，B+ 树在删除根节点的时候，由于存在冗余的节点，所以不会发生复杂的树的变形，比如下面这个动图是删除 B+ 树根节点的过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838765521-f985cdd9-df80-4aa7-9850-6100636341ed.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=cQPHj&amp;margin=%5Bobject%20Object%5D&amp;originHeight=258&amp;originWidth=439&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u54d944bf-89fc-499b-829c-d9ce7c56a98&amp;title=" alt=""><br>B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形，比如下面这个动图是删除 B 树根节点的过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659838766025-33c530fd-eaa5-4dba-b540-72589a2a3182.gif#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=wveDV&amp;margin=%5Bobject%20Object%5D&amp;originHeight=208&amp;originWidth=324&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u43893288-7c9e-479b-84b9-59aec969009&amp;title=" alt=""><br>B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等。</p><p>因此，<strong>B+ 树的插入和删除效率更高</strong>。<br><strong>3、范围查询</strong><br>B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。</p><p>因为 <strong>B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助</strong>，比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。</p><p>而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。</p><p>因此，存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于大量的单个索引查询的场景，可以考虑 B 树，比如 nosql 的MongoDB。<br><strong>MySQL 中的 B+ 树</strong><br>MySQL 的存储方式根据存储引擎的不同而不同，我们最常用的就是 Innodb 存储引擎，它就是采用了 B+ 树作为了索引的数据结构。<br>下图就是 Innodb 里的 B+ 树：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659838766186-be15afbd-690e-4119-9821-b3f2ceb585a1.png#clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=M5X8D&amp;margin=%5Bobject%20Object%5D&amp;originHeight=509&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u4fdf0df0-b112-4b9c-8c04-86e0df51b51&amp;title=" alt=""><br>但是 Innodb 使用的  B+ 树有一些特别的点，比如：</p><ul><li>B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。</li><li>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。</li></ul><p>Innodb 根据索引类型不同，分为聚集和二级索引。他们区别在于，聚集索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据。<br>因为表的数据都是存放在聚集索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚集索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个，而二级索引可以创建多个。<br>更多关于 Innodb 的 B+ 树，可以看我之前写的这篇：<a href="https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;mid=2247502059&amp;idx=1&amp;sn=ccbee22bda8c3d6a98237be769a7c89c&amp;scene=21#wechat_redirect">从数据页的角度看 B+ 树</a>。<br>总结</p><ul><li><p>MySQL 是会将数据持久化在硬盘，而存储功能是由 MySQL 存储引擎实现的，所以讨论 MySQL 使用哪种数据结构作为索引，实际上是在讨论存储引使用哪种数据结构作为索引，InnoDB 是 MySQL 默认的存储引擎，它就是采用了 B+ 树作为索引的数据结构。</p></li><li><p>要设计一个 MySQL 的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I/0 的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I/0 的操作次数内完成。</p></li><li><p>二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。</p></li><li><p>为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。</p></li></ul><p><strong>而树的高度决定于磁盘  I/O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。</strong></p><p>B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。<br>但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：<br>这也是为什么<strong>B+树比B树更适合实现数据库索引</strong></p><ul><li><strong>更少的IO次数：</strong>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。</li><li>B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；</li><li><strong>更适合与范围查询</strong>：B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。</li></ul><p><strong>2.B+树与 B 树的区别主要在于： </strong></p><ul><li>B 树中每个节点（包括叶节点和非叶节点）都存储真实的数据，B+树中只有叶子节点存储真实的数据，非 叶节点只存储索引的key值。</li><li>B 树中一条记录只会出现一次，不会重复出现，而 B+树的键则可能重复重现——一定会在叶节点出现，也 可能在非叶节点重复出现。 </li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652168120194-2cba9745-70bf-4bea-866c-f29b6f4ed4ef.png#averageHue=%23f4e8de&amp;clientId=uc6d7e8c9-8aaf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=162&amp;id=NWnV9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=141&amp;originWidth=234&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=22009&amp;status=done&amp;style=none&amp;taskId=u1ef1568b-1d9b-4753-888a-b52a02792e9&amp;title=&amp;width=269.1999969482422" alt="image.png"><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652168072433-e7780b01-be96-494d-aa52-2691dedc0aa0.png#averageHue=%23e8dbd1&amp;clientId=uc6d7e8c9-8aaf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=177&amp;id=jIG6b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=415&amp;originWidth=767&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=252664&amp;status=done&amp;style=none&amp;taskId=u8fa5b90b-336f-4e0c-ba41-998983323e5&amp;title=&amp;width=326.6000061035156" alt="image.png"></p><ul><li>B+树的叶节点之间通过链表连接。并且所有的关键字都在叶子节点出现<blockquote><ul><li>B 树中的非叶节点，记录数比子节点个数少 1；而 B+树中记录数与子节点个数相同。  </li></ul></blockquote></li></ul><p><strong>3.Hash索引和B+树索引的区别？</strong></p><ul><li>哈希索引<strong>不支持</strong>排序，因为哈希表是无序的。 </li><li>哈希索引<strong>不支持范围查找</strong>。 </li><li>哈希索引<strong>不支持模糊查询</strong>及多列索引的最左前缀匹配。 </li><li>因为哈希表中会<strong>存在哈希冲突</strong>，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点。 <h4 id="③Full-text-索引"><a href="#③Full-text-索引" class="headerlink" title="③Full-text 索引"></a>③Full-text 索引</h4><strong>概念</strong><br>通过数值比较、范围过滤等就可以完成绝大多数我们需要的查询，但是，如果希望通过关键字的匹配来进行查询过滤，那么就需要基于相似度的查询，而不是原来的精确数值比较。全文索引就是为这种场景设计的。</li></ul><p>你可能会说，用 like + % 就可以实现模糊匹配了，为什么还要全文索引？like + % 在文本比较少时是合适的，但是对于大量的文本数据检索，是不可想象的。全文索引在大量的数据面前，能比 like + % 快 N 倍，速度不是一个数量级，但是全文索引可能存在精度问题。</p><p>你可能没有注意过全文索引，不过至少应该对一种全文索引技术比较熟悉：各种的搜索引擎。虽然搜索引擎的索引对象是超大量的数据，并且通常其背后都不是关系型数据库，不过全文索引的基本原理是一样的。</p><h3 id="2-按物理存储分类"><a href="#2-按物理存储分类" class="headerlink" title="2. 按物理存储分类"></a>2. 按物理存储分类</h3><h4 id="①聚簇索引"><a href="#①聚簇索引" class="headerlink" title="①聚簇索引"></a>①聚簇索引</h4><ol><li>InnoDB使用表的主键构造主键索引树，同时叶子节点中存放的即为整张表的记录数据。聚集索引叶子节点的存储是逻辑上连续的，使用链表连接，按照主键的顺序排序，因此对于主键的排序查找和范围查找速度比较快。</li><li>对于InnoDB来说，聚集索引一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引。如果没有主键也没有合适的唯一索引，那么InnoDB内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键长度为6个字节，它的值会随着数据的插入自增。<h4 id="②二级索引（非聚集索引）"><a href="#②二级索引（非聚集索引）" class="headerlink" title="②二级索引（非聚集索引）"></a>②二级索引（非聚集索引）</h4></li></ol><ul><li>二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。</li></ul><p>所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。</p><h3 id="3-按字段特性-逻辑上"><a href="#3-按字段特性-逻辑上" class="headerlink" title="3. 按字段特性 逻辑上"></a>3. 按字段特性 逻辑上</h3><h4 id="①主键索引："><a href="#①主键索引：" class="headerlink" title="①主键索引："></a>①主键索引：</h4><p>主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。</p><h4 id="②唯一索引："><a href="#②唯一索引：" class="headerlink" title="②唯一索引："></a>②唯一索引：</h4><p>唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。</p><p>索引列中的值必须是唯一的，但是允许为空值。唯一索引和主键索引的区别是：唯一约束的列可以为null且可以存在多个null值。唯一索引的用途：唯一标识数据库表中的每条记录，主要是用来防止数据重复插入。</p><h4 id="③普通索引："><a href="#③普通索引：" class="headerlink" title="③普通索引："></a>③普通索引：</h4><p>普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。</p><h4 id="④前缀索引"><a href="#④前缀索引" class="headerlink" title="④前缀索引"></a>④前缀索引</h4><p>前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。</p><p>使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。<br><strong>注意点</strong><br>创建前缀索引的关键在于选择足够长的前缀来保证一个高的区分度，否则会导致增加扫描磁盘的次数。<br><strong>所以使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询 ，</strong>使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用 前缀索引时需要考虑的一个因素。</p><ul><li>建立前缀索引的方式：<ul><li>建立索引时关注的是区分度，区分度越高越好。依次选取不同长度的前缀来看这个值<blockquote><p><strong>遇到前缀的区分 度不够好的情况时，我们要怎么办呢？</strong><br>倒序存储和hash：都不支持范围查询<br>mysql&gt; select field_list from t where id_card = reverse(‘input_id_card_string’);<br>mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc);<br>mysql&gt; select field_list from t where id_card_crc=crc32(‘input_id_card_string’) and id_c</p><ol><li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而<br>hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是<br>不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</li><li>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而<br>hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来<br>看的话，reverse 函数额外消耗的 CPU 资源会更小些。</li><li>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来<br>的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。<br>而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li></ol></blockquote></li></ul></li></ul><h3 id="4-按字段个数分类"><a href="#4-按字段个数分类" class="headerlink" title="4. 按字段个数分类"></a>4. 按字段个数分类</h3><h4 id="①单列索引：建立在单列上的"><a href="#①单列索引：建立在单列上的" class="headerlink" title="①单列索引：建立在单列上的"></a>①单列索引：建立在单列上的</h4><h4 id="②联合索引：建立在多列上的。通过将多个字段组合成一个索引，该索引就被称为联合索引。"><a href="#②联合索引：建立在多列上的。通过将多个字段组合成一个索引，该索引就被称为联合索引。" class="headerlink" title="②联合索引：建立在多列上的。通过将多个字段组合成一个索引，该索引就被称为联合索引。"></a>②联合索引：建立在多列上的。通过将多个字段组合成一个索引，该索引就被称为联合索引。</h4><p>详细内容通过将多个字段组合成一个索引，该索引就被称为联合索引。比如将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name)，创建联合索引的方式如下：<br>CREATE INDEX index_product_no_name ON product(product_no, name);<br>联合索引(product_no, name) 的 B+Tree 示意图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842702988-b963356c-c5e5-47fc-a096-211a79ad91d1.png#averageHue=%23f9efd7&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=EgeFl&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=571&amp;originWidth=1141&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=178606&amp;status=done&amp;style=none&amp;taskId=ud8ee1b52-f732-488e-ae5f-11eaff615ee&amp;title=" alt="image.png"><br>可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。<br>也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。因此，使用联合索引时，存在<strong>最左匹配原则</strong>，也就是按照最左优先的方式进行索引的匹配。<br>比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：</p><ul><li>where a=1；</li><li>where a=1 and b=2 and c=3；</li><li>where a=1 and b=2；</li></ul><p>需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。<br>但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:</p><ul><li>where b=2；</li><li>where c=3；</li><li>where b=2 and c=3；</li></ul><p>上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，<strong>b 和 c 是全局无序，局部相对有序的</strong>，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。<br>我这里举联合索引（a，b）的例子，该联合索引的 B+ Tree 如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842703024-46c88550-b84a-463e-92a5-d67fa119ee77.png#averageHue=%23fbf2db&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=gqjsz&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=902&amp;originWidth=1848&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=282385&amp;status=done&amp;style=none&amp;taskId=uf611e3a1-2117-4d08-9be3-3cd4a22c046&amp;title=" alt="image.png"><br>可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8），而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。因此，直接执行where b = 2这种查询条件没有办法利用联合索引的，<strong>利用索引的前提是索引里的 key 是有序的</strong>。<br>只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候，b 的值为（7，8），这时就是有序的，这个有序状态是局部的，因此，执行where a = 2 and b = 7是 a 和 b 字段能用到联合索引的，也就是联合索引生效了。<br>但是，如果执行where a &gt; 1 and b = 2时，a 字段能用到联合索引，而 b 字段用不到联合索引。<strong>因为 a 的值此时是一个范围，不是固定的，在这个范围内 b 值不是有序的，因此 b 字段用不上联合索引</strong>。<br>综上所示，<strong>联合索引的最左匹配原则，在遇到范围查询（&gt;、&lt;、between、like 包括like ‘林%’这种）的时候，就会停止匹配，也就是范围列可以用到联合索引，但是范围列后面的列无法用到联合索引</strong>。<br>现在我们知道，对于联合索引（a, b），在执行 select * from table where a &gt; 1 and b = 2 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？</p><ul><li>在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。</li><li>而 MySQL 5.6 引入的<strong>索引下推优化</strong>（index condition pushdown)， <strong>可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</strong>。</li></ul><p>当你的查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。<br>另外，建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中<strong>建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到</strong>。<br>区分度就是某个字段 column 不同值的个数「除以」表的总行数，计算公式如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842702931-653e25d7-fc72-475e-a58f-7e13f6500458.png#averageHue=%23f2f2f2&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=VIc7l&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=282&amp;originWidth=922&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58940&amp;status=done&amp;style=none&amp;taskId=u2ea74050-8e8c-4dd2-8f02-9e528e6dea2&amp;title=" alt="image.png"><br>比如，性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 UUID 这类字段就比较适合做索引或排在联合索引列的靠前的位置。<br>因为如果索引的区分度很小，假设字段的值分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比（惯用的百分比界线是”30%”）很高的时候，它一般会忽略索引，进行全表扫描。<br>这里出一个题目，针对针对下面这条 SQL，你怎么通过索引来提高查询效率呢？<br>select * from order where status = 1 order by create_time asc<br>有的同学会认为，单独给 status 建立一个索引就可以了。<br>但是更好的方式给 status 和 create_time 列建立一个联合索引，因为这样可以避免 MySQL 数据库发生文件排序。<br>因为在查询时，如果只用到 status 的索引，但是这条语句还要对 create_time 排序，这时就要用文件排序 filesort，也就是在 SQL 执行计划中，Extra 列会出现 Using filesort。<br>所以，要利用索引的有序性，在 status 和 create_time 列建立联合索引，这样根据 status 筛选后的数据就是按照 create_time 排好序的，避免在文件排序，提高了查询效率。<br>注意事项：在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。<br>具体原因为:<br>MySQL使用索引时需要索引有序，如建立了”name，age，school”的联合索引，索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。<br>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。<br>优点：前缀索引能使索引更小，更快的有效办法。<br>缺点：mysql无法使用其前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。</p><h2 id="count-和-count-1-有什么区别？哪个性能最好？"><a href="#count-和-count-1-有什么区别？哪个性能最好？" class="headerlink" title="count(*) 和 count(1) 有什么区别？哪个性能最好？"></a>count(*) 和 count(1) 有什么区别？哪个性能最好？</h2><p>大家好，我是小林。<br>当我们对一张数据表中的记录进行统计的时候，习惯都会使用 count 函数来统计，但是 count 函数传入的参数有很多种，比如 count(1)、count(<em>)、count(字段) 等。<br>到底哪种效率是最好的呢？是不是 count(</em>) 效率最差？<br>我曾经以为 count(<em>) 是效率最差的，因为认知上 selete </em> from t 会读取所有表中的字段，所以凡事带有 * 字符的就觉得会读取表中所有的字段，当时网上有很多博客也这么说。<br>但是，当我深入 count 函数的原理后，被啪啪啪的打脸了！<br>不多说， 发车！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842414078-ad94ee61-a618-4303-aba8-eca79eb223bc.png#averageHue=%23f8f8f7&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=276&amp;id=u6e582a58&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=623&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=103583&amp;status=done&amp;style=none&amp;taskId=u5969652a-078d-479d-a5a9-6a8bef5127b&amp;title=&amp;width=478.00006103515625" alt="image.png"></p><h3 id="哪种-count-性能最好？"><a href="#哪种-count-性能最好？" class="headerlink" title="哪种 count 性能最好？"></a>哪种 count 性能最好？</h3><p>哪种 count 性能最好？<br>我先直接说结论：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842414091-725b61d9-1886-4ca2-b54e-8d6b4ea84f8d.png#averageHue=%23f2da91&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=150&amp;id=u516c9b81&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=307&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=108457&amp;status=done&amp;style=none&amp;taskId=udd1bc8cc-e941-4ae3-b49d-8935edabe75&amp;title=&amp;width=529.0000610351562" alt="image.png"><br>要弄明白这个，我们得要深入 count 的原理，以下内容基于常用的 innodb 存储引擎来说明。<br>count() 是什么？<br>count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是<strong>统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个</strong>。<br>假设 count() 函数的参数是字段名，如下：<br>select count(name) from t<em>order;<br>这条语句是统计「 t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。<br>再来假设 count() 函数的参数是数字 1 这个表达式，如下：<br>select count(1) from t_order;<br>这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。<br>1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录。<br>count(主键字段) 执行过程是怎样的？<br>在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。<br>server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。<br>InnoDB 是通过 B+ 树来保持记录的，根据索引的类型又分为聚簇索引和二级索引，它们区别在于，聚簇索引的叶子节点存放的是实际数据，而二级索引的叶子节点存放的是主键值，而不是实际数据。<br>用下面这条语句作为例子：<br>//id 为主键值 select count(id) from t_order;<br>如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842414110-6ce265d9-3be2-43c7-a080-9681b618ff71.png#averageHue=%23f2f1f1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=194&amp;id=u9143c6f2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=338&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=128541&amp;status=done&amp;style=none&amp;taskId=ub7cb14ac-f6c0-4af2-8676-83a02799457&amp;title=&amp;width=619.0000610351562" alt="image.png"><br>但是，如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842414082-8b0dc675-e43f-40d0-9e2c-5819ed3f0af2.png#averageHue=%23f2efef&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=145&amp;id=u242706c2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=286&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=101920&amp;status=done&amp;style=none&amp;taskId=u9b6468b0-e9c5-4d09-ab16-0006ab6a280&amp;title=&amp;width=548.0000610351562" alt="image.png"><br>这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引。<br>count(1) 执行过程是怎样的？<br>用下面这条语句作为例子：<br>select count(1) from t_order;<br>如果表里只有主键索引，没有二级索引时。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842414098-f818e8ee-5490-45b0-b1e3-5ba2c9a7bdd6.png#averageHue=%23f2f1f1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u194634e7&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=301&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=113469&amp;status=done&amp;style=none&amp;taskId=u8e8842e0-8170-463d-83bf-90272280008&amp;title=" alt="image.png"><br>那么，InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，<strong>但是不会读取记录中的任何字段的值</strong>，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。<br>可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。<br>但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842416922-6b2d63c5-7a1b-4de5-b292-4d7c734352bf.png#averageHue=%23f3f1f1&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u640dacd9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=311&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=111287&amp;status=done&amp;style=none&amp;taskId=u009c07a4-0d16-405b-a3a7-5b7026bacae&amp;title=" alt="image.png"><br>count(<em>) 执行过程是怎样的？<br>看到 </em> 这个字符的时候，是不是大家觉得是读取记录中的所有字段值？<br>对于 selete <em> 这条语句来说是这个意思，但是在 count(</em>) 中并不是这个意思。<br><strong>count(*) 其实等于 count(0)</strong>，也就是说，当你使用 count(<em>) 时，MySQL 会将 </em> 参数转化为参数 0 来处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842416927-ad250896-5cd0-4d54-b75d-334fe23ed390.png#averageHue=%23f6efee&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e3046c0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=320&amp;originWidth=1066&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=109823&amp;status=done&amp;style=none&amp;taskId=u78f5fe92-d7ea-40ec-b433-41495cc0a0e&amp;title=" alt="image.png"><br>所以，<strong>count(*) 执行过程跟 count(1) 执行过程基本一样的</strong>，性能没有什么差异。<br>在 MySQL 5.7 的官方手册中有这么一句话：<br>_InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.</em><br><em>翻译：InnoDB以相同的方式处理SELECT COUNT（*）和SELECT COUNT（1）操作，没有性能差异。</em><br>而且 MySQL 会对 count(<em>) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。<br>只有当没有二级索引的时候，才会采用主键索引来进行统计。<br>count(字段) 执行过程是怎样的？<br>count(字段) 的执行效率相比前面的 count(1)、 count(</em>)、 count(主键字段) 执行效率是最差的。<br>用下面这条语句作为例子：<br>// name不是索引，普通字段 select count(name) from t_order;<br>对于这个查询来说，会采用全表扫描的方式来计数，所以它的执行效率是比较差的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842416941-c4ca29ec-d549-4c8b-bbcf-efe6203aad07.png#averageHue=%23f6f5f4&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u14aba4e4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=312&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=105014&amp;status=done&amp;style=none&amp;taskId=ufd63fcdf-af06-4553-97e0-d4afebe1dea&amp;title=" alt="image.png"><br>小结<br>count(1)、 count(<em>)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。<br>所以，如果要执行 count(1)、 count(</em>)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。<br>再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。</p><h3 id="为什么要通过遍历的方式来计数？"><a href="#为什么要通过遍历的方式来计数？" class="headerlink" title="为什么要通过遍历的方式来计数？"></a>为什么要通过遍历的方式来计数？</h3><p>你可以会好奇，为什么 count 函数需要通过遍历的方式来统计记录个数？<br>我前面将的案例都是基于 Innodb 存储引擎来说明的，但是在 MyISAM 存储引擎里，执行 count 函数的方式是不一样的，通常在没有任何查询条件下的 count(*)，MyISAM 的查询速度要明显快于 InnoDB。<br>使用 MyISAM 引擎时，执行 count 函数只需要 O(1 )复杂度，这是因为每张 MyISAM 的数据表都有一个 meta 信息有存储了row_count值，由表级锁保证一致性，所以直接读取 row_count 值就是 count 函数的执行结果。<br>而 InnoDB 存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。<br>举个例子，假设表 t_order 有 100 条记录，现在有两个会话并行以下语句：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842417016-24146a37-1897-40e8-8930-43fa60409610.png#averageHue=%23eee6d4&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=333&amp;id=u2858823e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=654&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=133834&amp;status=done&amp;style=none&amp;taskId=uee009949-4ea1-4022-881f-26cbd7c9256&amp;title=&amp;width=550.0000610351562" alt="image.png"><br>在会话 A 和会话 B的最后一个时刻，同时查表 t_order 的记录总个数，可以发现，显示的结果是不一样的。所以，在使用 InnoDB 存储引擎时，就需要扫描表来统计具体的记录。<br>而当带上 where 条件语句之后，MyISAM 跟 InnoDB 就没有区别了，它们都需要扫描表来进行记录个数的统计。</p><h3 id="如何优化-count-？"><a href="#如何优化-count-？" class="headerlink" title="如何优化 count(*)？"></a>如何优化 count(*)？</h3><p>如果对一张大表经常用 count(<em>) 来做统计，其实是很不好的。<br>比如下面我这个案例，表 t_order 共有 1200+ 万条记录，我也创建了二级索引，但是执行一次 select count(</em>) from t_order 要花费差不多 5 秒！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842416965-64b71028-0ddb-4eba-8368-bd3fc2722301.png#averageHue=%23f8f6f6&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u8bb0f151&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=428&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=102223&amp;status=done&amp;style=none&amp;taskId=uf51eeb52-12e6-44dd-8c8d-d522f9b9e63&amp;title=" alt="image.png"><br>面对大表的记录统计，我们有没有什么其他更好的办法呢？<br>第一种，近似值<br>如果你的业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842419143-13e55387-90ad-4347-8a66-01804f67a325.png#averageHue=%23fefbfb&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9cc05a8b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=397&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=148969&amp;status=done&amp;style=none&amp;taskId=ub9c99a61-509f-456c-97f7-818ec341a27&amp;title=" alt="image.png"><br>这时，我们就可以使用 show table status 或者 explain 命令来表进行估算。<br>执行 explain 命令效率是很高的，因为它并不会真正的去查询，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659842419175-21f937db-a7be-40e7-a3bc-a7693b3c44de.png#averageHue=%23f7f5f4&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ueb59b3d3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=604&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=150700&amp;status=done&amp;style=none&amp;taskId=ueed8ee70-c3d9-46cf-986a-23b6c5e7004&amp;title=" alt="image.png"><br>第二种，额外表保存计数值<br>如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。<br>当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。</p><h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><h1 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h1>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>日志篇</title>
      <link href="/2022/08/09/MySQL/%E6%97%A5%E5%BF%97%E7%AF%87/"/>
      <url>/2022/08/09/MySQL/%E6%97%A5%E5%BF%97%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651563738807-6d5e65e4-066b-49f9-bf88-5279538637ef.png#averageHue=%23faf8f7&amp;clientId=u032535be-8a03-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=270&amp;id=u12fb5d46&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=337&amp;originWidth=905&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=42714&amp;status=done&amp;style=none&amp;taskId=u81b8eec0-1a1c-47c3-b3a2-fe5b9e3a462&amp;title=&amp;width=724" alt="image.png"><br>知识点总结：<br><a href="https://blog.csdn.net/qq_48825548/article/details/120482321?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_default&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">https://blog.csdn.net/qq_48825548/article/details/120482321?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_default&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3</a></p><h2 id="前置：Buffer-Pool"><a href="#前置：Buffer-Pool" class="headerlink" title="前置：Buffer Pool"></a>前置：Buffer Pool</h2><p>MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢？<br>当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。<br>为此，Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659857613445-aa851468-e696-42bd-9ddd-58fba3cd1927.png#averageHue=%23f2ecd8&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=397&amp;id=u5f78f913&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=969&amp;originWidth=725&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=171411&amp;status=done&amp;style=none&amp;taskId=uee5c74a0-e237-405b-9efd-8de23de0658&amp;title=&amp;width=297.2857360839844" alt="image.png"><br>有了 Buffer Pool后：</p><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。<h3 id="Buffer-Pool-缓存什么？"><a href="#Buffer-Pool-缓存什么？" class="headerlink" title="Buffer Pool 缓存什么？"></a>Buffer Pool 缓存什么？</h3>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。</li></ul><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。</p><p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659857613372-45f0d712-4d9d-4a3a-9e05-372422b1b166.png#averageHue=%23f9ebd8&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=265&amp;id=ud9290bfc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=377&amp;originWidth=812&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=90462&amp;status=done&amp;style=none&amp;taskId=uaaea2cac-dd2d-45fd-9c34-9c7207698a3&amp;title=&amp;width=570.2857666015625" alt="image.png"><br>Undo 页是记录什么？<br>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。<br>查询一条记录，就只需要缓冲一条记录吗？<br>不是的。<br>当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。<br>关于页结构长什么样和索引怎么查询数据的问题可以在这篇找到答案：<a href="https://mp.weixin.qq.com/s/A5gNVXMNE-iIlY3oofXtLw">换一个角度看 B+ 树</a></p><h2 id="ⅠUndo日志"><a href="#ⅠUndo日志" class="headerlink" title="ⅠUndo日志"></a>ⅠUndo日志</h2><h3 id="①概述"><a href="#①概述" class="headerlink" title="①概述"></a>①概述</h3><p>回滚日志，<strong>它保证了事务的 </strong><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7">ACID 特性(opens new window)</a><strong>中的原子性（Atomicity）</strong>。</p><p>undo log 是一种用于回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。<br>例子&gt; 如下图：</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659857069711-b82ddb28-3530-4632-9a22-026f97e5f531.png#averageHue=%23f8f5ee&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=399&amp;id=EkAtA&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=571&amp;originWidth=352&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=75036&amp;status=done&amp;style=none&amp;taskId=u8bed7387-6bf6-4263-b41d-7ca5a6ead09&amp;title=&amp;width=246.00003051757812" alt="image.png"><br>每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p><ul><li>在<strong>插入</strong>一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录<strong>删掉</strong>就好了；</li><li>在<strong>删除</strong>一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录<strong>插入</strong>到表中就好了；</li><li>在<strong>更新</strong>一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列<strong>更新为旧值</strong>就好了。</li></ul><p>在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。</p><p>不同的操作，需要记录的内容也是不同的，所以不同类型的操作（修改、删除、新增）产生的 undo log 的格式也是不同的，具体的每一个操作的 undo log 的格式我就不详细介绍了，感兴趣的可以自己去查查。</p></blockquote><p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer（回滚） 指针和一个 trx_id 事务id：</p><ul><li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li><li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；</li></ul><p>版本链如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659857069785-624456fc-32a7-4164-a7fa-31153d4a4adb.png#averageHue=%23f0ece0&amp;clientId=uadf23417-eae1-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=240&amp;id=uf998e830&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=457&amp;originWidth=1063&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=166982&amp;status=done&amp;style=none&amp;taskId=ua1330b17-5dea-43e4-a6bd-b72fca2c1e9&amp;title=&amp;width=559.2857666015625" alt="image.png"><br>另外，<strong>undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）</strong>。<br>对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同：</p><ul><li>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</li><li>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</li></ul><p>这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。</p><h3 id="②undo-log作用"><a href="#②undo-log作用" class="headerlink" title="②undo log作用"></a>②undo log作用</h3><ul><li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li><li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。<br>undo的存储结构（了解）<strong>1. 回滚段与undo页</strong><br>InnoDB对undo log的管理采用段的方式，也就是回滚段（rollback segment）。每个回滚段记录了1024 个undo log segment ，而在每个undo log segment段中进行undo页的申请。<br>在InnoDB1.1版本之前（不包括1.1版本），只有一个rollback  segment，因此支持同时在线的事务限制为1024 。虽然对绝大多数的应用来说都已经够用。<br>从1.1版本开始InnoDB支持最大128个rollback segment ，故其支持同时在线的事务限制提高到128<em>1024<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858140470-94a3db7f-9f2b-4fa0-b2e0-a0e417311f0d.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=118&amp;id=YsJC8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=147&amp;originWidth=832&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=7317&amp;status=done&amp;style=none&amp;taskId=u6d8f0204-bc53-4592-9484-bda16a91c74&amp;title=&amp;width=665.6" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858155916-44c3bed0-e942-4d62-917b-01d353748617.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=226&amp;id=whIt5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=283&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=862093&amp;status=done&amp;style=none&amp;taskId=u65e9b525-a593-493c-89af-c097c4bf463&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858167062-986c2111-43f2-431f-8294-182bd090fa5f.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=224&amp;id=j7Ion&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=280&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=852946&amp;status=done&amp;style=none&amp;taskId=u3e89c6ab-86dc-4df9-bb25-f2b50c4330a&amp;title=&amp;width=608" alt="image.png"><br>生命周期<strong>1. 详细生成过程</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858737869-d00e09cf-b330-4b8a-8c19-1b6d5a64b5f5.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=147&amp;id=cAb77&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=184&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=560545&amp;status=done&amp;style=none&amp;taskId=u4ad52361-fdd5-4f1e-ba8b-7221b629cc7&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858741962-5e6baa9c-cfb4-4e42-ad66-109d3dc34b5b.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=51&amp;id=pYDsp&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=64&amp;originWidth=599&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=153749&amp;status=done&amp;style=none&amp;taskId=ue1ac73f3-59fc-453a-8f8b-157fbc4c7e5&amp;title=&amp;width=479.2" alt="image.png"><br><strong>当我们执行INSERT时：</strong><br><strong> </strong><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858763960-c5eaae59-9147-45d2-8730-fcbe0eb6e40c.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=50&amp;id=fLNKU&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=62&amp;originWidth=728&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=3714&amp;status=done&amp;style=none&amp;taskId=u9359d936-2fb2-4e27-b6d8-bc13d29a9de&amp;title=&amp;width=582.4" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858770181-1d6f6994-7bfc-420d-a8d0-774197c99893.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=53&amp;id=iDxNS&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=66&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=201129&amp;status=done&amp;style=none&amp;taskId=u2afe3b09-ed7b-444e-bb09-d9850981092&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858779416-e419b189-466d-42d1-a540-6a25371730c3.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=190&amp;id=b0MX6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=238&amp;originWidth=514&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=490449&amp;status=done&amp;style=none&amp;taskId=ub7f9f694-4682-452d-8777-3bac1cd4d3a&amp;title=&amp;width=411.2" alt="image.png"><br><em>*当我们执行UPDATE时：</em></em></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858791093-3d214ad4-e5aa-4414-a05b-e4dea26173b7.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=77&amp;id=iiPBw&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=96&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=292501&amp;status=done&amp;style=none&amp;taskId=uaa166b50-2ab5-4c7e-af01-5d7d9ceca5b&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858798776-20fb5d6d-76d1-4ed4-9663-c3add5724e66.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=194&amp;id=iyOmj&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=242&amp;originWidth=545&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=528755&amp;status=done&amp;style=none&amp;taskId=u11b3c917-3666-4d01-8c21-1aef98c3649&amp;title=&amp;width=436" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858811273-c726172f-f6bb-4e56-b8ca-a1a9fd1c27cb.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=64&amp;id=W6rtq&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=80&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=243768&amp;status=done&amp;style=none&amp;taskId=u05dd0589-e0c6-481e-935c-5d742510cea&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858818285-5e2e847b-9820-432c-88a3-befa959bffcc.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=45&amp;id=zz1cM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=56&amp;originWidth=803&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=2657&amp;status=done&amp;style=none&amp;taskId=ud11599be-8a4e-4188-a623-460841e5354&amp;title=&amp;width=642.4" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858822514-620e5377-dbd6-4885-98a4-61ca76627c28.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=157&amp;id=vUXpm&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=162&amp;originWidth=659&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=427983&amp;status=done&amp;style=none&amp;taskId=u61a426be-e9ae-4327-96bb-13ea7e52c99&amp;title=&amp;width=640.2000122070312" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858827726-fa73b091-7933-41e6-aa4c-2ddae49347f4.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=114&amp;id=Dj2ts&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=142&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=432611&amp;status=done&amp;style=none&amp;taskId=ub0e122be-e483-4763-9055-b00015efa7d&amp;title=&amp;width=608" alt="image.png"><br><strong>1. undo log是如何回滚的</strong><br>以上面的例子来说，假设执行rollback，那么对应的流程应该是这样：</p><ol><li>通过undo no=3的日志把id=2的数据删除</li><li>通过undo no=2的日志把id=1的数据的deletemark还原成0</li><li>通过undo no=1的日志把id=1的数据的name还原成Tom</li><li>通过undo no=0的日志把id=1的数据删除</li></ol><p><strong>2. undo log的删除</strong><br>针对于insert undo log<br>因为insert操作的记录，只对事务本身可见，对其他事务不可见。故该undo   log可以在事务提交后直接删除，不需要进行purge操作。<br>针对于update undo log<br>该undo  log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo  log链表，等待purge线程进行最后的删除。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858865583-4e8b576f-d2b9-4d4f-9ecd-f4b5e65e590f.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=102&amp;id=qakMQ&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=128&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=389972&amp;status=done&amp;style=none&amp;taskId=u35add451-3d54-47ae-8dc9-779dc30e160&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649858897511-8accdf3a-93aa-45fd-be10-20d1811dd85e.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=275&amp;id=VPzxE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=344&amp;originWidth=746&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1028600&amp;status=done&amp;style=none&amp;taskId=u6a9d9827-3827-42a4-94ff-b5c05d18a64&amp;title=&amp;width=596.8" alt="image.png"></p><h2 id="Ⅱredolog"><a href="#Ⅱredolog" class="headerlink" title="Ⅱredolog"></a>Ⅱredolog</h2><h3 id="①为什么需要redolog"><a href="#①为什么需要redolog" class="headerlink" title="①为什么需要redolog"></a>①为什么需要redolog</h3><blockquote><p>Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。</p></blockquote><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>，<strong>指的是 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上</strong>。<br>InnoDB引擎的事务采用了WAL技术（Write-Ahead Logging），这种技术的思想就是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo-log。当发生宕机且数据未刷到磁盘的时候，可以通过redo log来恢复，保证事务的持久性，这就是redo-log的作用。<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649856830295-43484947-5df3-4365-9395-d85394f4a2e8.png#averageHue=%23f0eae9&amp;clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=237&amp;id=xywNs&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=296&amp;originWidth=628&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=745143&amp;status=done&amp;style=none&amp;taskId=ud69aa798-2e1d-4871-9c12-98d29ab636d&amp;title=&amp;width=502.4" alt="image.png"><br>好处是不用每一次操作都实时把数据写盘，就算 crash 后也可以通过redo log 恢复，所以能够实现快速响应 SQL 语句。<br>过程如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858394287-14b62058-d704-400f-9a06-69c02908fb9c.png#averageHue=%23f9f4ed&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=265&amp;id=ue54233d0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=651&amp;originWidth=861&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=144244&amp;status=done&amp;style=none&amp;taskId=uc356d1a5-5b5f-439e-bb9a-dde20f814d3&amp;title=&amp;width=350.0000305175781" alt="image.png"><br>什么是WAL(write-ahead log)机制, 好处是什么.&gt; WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写小黑板，等不忙的时候再写账本。</p><blockquote><p>  具体来说，当有一条update语句要执行的时候，InnoDB 引擎就会先把记录写到 redo log（小黑板）里面，并更新内存，这个时候更新就算完成了。<br>  同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。<br>  与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 100MB，那么这块“小黑板”总共就可以记录 400MB 的操作记录。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651564020508-15cd69d0-28e5-4e3f-8cbe-d6d90cc509d8.png#averageHue=%23c6e2a5&amp;clientId=u032535be-8a03-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=367&amp;id=AOd8D&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=439&amp;originWidth=500&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=144787&amp;status=done&amp;style=none&amp;taskId=u5ac55230-c8cb-4e0c-9b87-c2e585fe62a&amp;title=&amp;width=418" alt="image.png"></p><p>write position 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。<br>checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。<br>  write position 和 checkpoint 之间的是“小黑板”上还空着的部分，可以用来记录新的操作。</p><p>  如果 write pos 追上 checkpoint，表示“小黑板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</p><p>  有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。</p><p>crash-safe：<br>  可以对照前面赊账记录的例子。只要赊账记录记在了小黑板上或写在了账本上，即使秀才突然被老邢抓走几天，回来后依然可以通过账本和小黑板上的数据明确赊账账目。就是维护数据的持久性。<br>  本质上说，crash-safe 就是落盘处理，将数据存储到了磁盘上，断电重启也不会丢失。</p></blockquote><h3 id="②什么是redolog"><a href="#②什么是redolog" class="headerlink" title="②什么是redolog"></a>②什么是redolog</h3><p>redo log 是物理日志，记录了某个数据页做了什么修改，对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。</p><p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p><h3 id="③redolog常见问题"><a href="#③redolog常见问题" class="headerlink" title="③redolog常见问题"></a>③redolog常见问题</h3><h4 id="1-被修改-Undo-页面，需要记录对应-redo-log-吗？"><a href="#1-被修改-Undo-页面，需要记录对应-redo-log-吗？" class="headerlink" title="1. 被修改 Undo 页面，需要记录对应 redo log 吗？"></a>1. 被修改 Undo 页面，需要记录对应 redo log 吗？</h4><p>需要的。<br>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。</p><p>不过，在修改该 Undo 页面前需要先记录对应的 redo log，所以<strong>先记录修改 Undo 页面的 redo log ，然后再真正的修改 Undo 页面</strong>。</p><h4 id="2-redo-log-和-undo-log-区别在哪？"><a href="#2-redo-log-和-undo-log-区别在哪？" class="headerlink" title="2. redo log 和 undo log 区别在哪？"></a>2. redo log 和 undo log 区别在哪？</h4><p>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p><ul><li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li><li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li></ul><p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659857870482-21326374-ed3e-4a8a-8648-59bb35a79007.png#averageHue=%23faf8f3&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=292&amp;id=u66f7c5e8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=601&amp;originWidth=551&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=102603&amp;status=done&amp;style=none&amp;taskId=ud34363af-7362-4c09-9605-c1ee41f2a01&amp;title=&amp;width=268.0000305175781" alt="image.png"><br>所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 <strong>crash-safe</strong>（崩溃恢复）。可以看出来， <strong>redo log 保证了事务四大特性中的持久性</strong>。</p><h4 id="3-redo-log-要写到磁盘，数据也要写磁盘，为什么要多此一举？"><a href="#3-redo-log-要写到磁盘，数据也要写磁盘，为什么要多此一举？" class="headerlink" title="3. redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？"></a>3. redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</h4><p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。</p><p>磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。</p><p>针对「顺序写」为什么比「随机写」更快这个问题，可以比喻为你有一个本子，按照顺序一页一页写肯定比写一个字都要找到对应页写快得多。</p><p>可以说这是 WAL 技术的另外一个优点：<strong>MySQL 的写操作从磁盘的「随机写」变成了「顺序写」</strong>，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。</p><p>至此， 针对为什么需要 redo log 这个问题我们有两个答案：</p><ul><li><strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</li><li><strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能。<h4 id="4-产生的-redo-log-是直接写入磁盘的吗？"><a href="#4-产生的-redo-log-是直接写入磁盘的吗？" class="headerlink" title="4.产生的 redo log 是直接写入磁盘的吗？"></a>4.产生的 redo log 是直接写入磁盘的吗？</h4>不是的。</li></ul><p>实际上， 执行一个事务，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。</p><p>所以，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/webp/21371548/1659857870320-72addf50-d122-4e58-aabb-5538cd586495.webp#averageHue=%23f1efec&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=438&amp;id=ud8903d32&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1344&amp;originWidth=1398&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8e8a7244-b3d7-4e8a-bb29-2059ae47c6a&amp;title=&amp;width=456" alt=""><br>redo log buffer 默认大小 16 MB，可以通过 innodb_log_Buffer_size 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。</p><h3 id="④redo-log-什么时候刷盘？"><a href="#④redo-log-什么时候刷盘？" class="headerlink" title="④redo log 什么时候刷盘？"></a>④redo log 什么时候刷盘？</h3><p>缓存在 redo log buffer里的 redo log 还是在内存中，它什么时候刷新到磁盘？<br>主要有下面几个时机：</p><ul><li>MySQL 正常关闭时；</li><li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li><li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li><li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</li></ul><p>innodb_flush_log_at_trx_commit 参数控制的是什么？<br>单独执行一个更新语句的时候，InnoDB 引擎会自己启动一个事务，在执行更新语句的过程中，生成的 redo log 先写入到 redo log buffer 中，然后等事务提交的时候，再将缓存在 redo log buffer 中的 redo log 按组的方式「顺序写」到磁盘。</p><p>上面这种 redo log 刷盘时机是在事务提交的时候，这个默认的行为。</p><p>除此之外，InnoDB 还提供了另外两种策略，由参数 innodb_flush_log_at_trx_commit 参数控制，可取的值有：0、1、2，默认值为 1，这三个值分别代表的策略如下：</p><ul><li>当设置该<strong>参数为 0 时</strong>，表示每次事务提交时 ，还是<strong>将 redo log 留在 redo log buffer 中</strong> ，该模式下在事务提交时不会主动触发写入磁盘的操作。</li><li>当设置该<strong>参数为 1 时</strong>，表示每次事务提交时，都<strong>将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘</strong>，这样可以保证 MySQL 异常重启之后数据不会丢失。</li><li>当设置该<strong>参数为 2 时</strong>，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log <strong>写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘</strong>，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看<a href="https://xiaolincoding.com/os/6_file_system/pagecache.html">这篇(opens new window)</a>），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</li></ul><p>我画了一个图，方便大家理解：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858237108-c78bfb1c-c50b-4df3-9121-597e32d0962b.png#averageHue=%23f1ead2&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=378&amp;id=u30f29724&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=863&amp;originWidth=951&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=306758&amp;status=done&amp;style=none&amp;taskId=u8b107198-42d9-4fb9-8ef1-1dc30d93683&amp;title=&amp;width=417" alt="image.png"><br>innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？<br>InnoDB 的后台线程每隔 1 秒：</p><ul><li>针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。<strong>所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失</strong>;</li><li>针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。<strong>所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失</strong>。</li></ul><p>加入了后台现线程后，innodb_flush_log_at_trx_commit 的刷盘时机如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858237358-74ced6da-cb44-4bd6-b665-a8d418e7b8fb.png#averageHue=%23f1edd6&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u23420b52&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=863&amp;originWidth=1061&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=416656&amp;status=done&amp;style=none&amp;taskId=ua9db0672-e498-4b5a-94b2-965926e6db6&amp;title=" alt="image.png"><br>这三个参数的应用场景是什么？<br>这三个参数的数据安全性和写入性能的比较如下：</p><ul><li>数据安全性：参数 1 &gt; 参数 2 &gt; 参数 0</li><li>写入性能：参数 0 &gt; 参数 2&gt; 参数 1</li></ul><p>所以，数据安全性和写入性能是熊掌不可得兼的，<strong>要不追求数据安全性，牺牲性能；要不追求性能，牺牲数据安全性</strong>。</p><ul><li>在一些对数据安全性要求比较高的场景中，显然 innodb_flush_log_at_trx_commit 参数需要设置为 1。</li><li>在一些可以容忍数据库崩溃时丢失 1s 数据的场景中，我们可以将该值设置为 0，这样可以明显地减少日志同步到磁盘的 I/O 操作。</li><li>安全性和性能折中的方案就是参数 2，虽然参数 2 没有参数 0 的性能高，但是数据安全性方面比参数 0 强，因为参数 2 只要操作系统不宕机，即使数据库崩溃了，也不会丢失数据，同时性能方便比参数 1 高。<h3 id="⑤redo-log-文件写满了怎么办？"><a href="#⑤redo-log-文件写满了怎么办？" class="headerlink" title="⑤redo log 文件写满了怎么办？"></a>⑤redo log 文件写满了怎么办？</h3>默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：ib_logfile0 和 ib_logfile1 。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858236926-b31fb933-c7eb-4c5d-8f07-0e5a31eb52b3.png#averageHue=%23efefef&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u59b3cf1f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=101&amp;originWidth=350&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=11710&amp;status=done&amp;style=none&amp;taskId=u8b0bd2e0-613e-478d-87e6-4648e7379c9&amp;title=" alt="image.png"><br>在重做日志组中，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。</li></ul><p>重做日志文件组是以<strong>循环写</strong>的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。<br>所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858236953-71ed1e48-3f59-4339-8d34-d920412a8c75.png#averageHue=%23f6f3e9&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=223&amp;id=u76dc8a97&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=261&amp;originWidth=441&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=36916&amp;status=done&amp;style=none&amp;taskId=u82273e2c-38c5-48f2-bf00-72f5b77cd77&amp;title=&amp;width=376.0000305175781" alt="image.png"><br>我们知道 redo log 是为了防止Buffer Pool 中的脏页丢失而设计的，那么如果随着系统运行，Buffer Pool 的脏页刷新到了磁盘中，那么 redo log 对应的记录也就没用了，这时候我们擦除这些旧记录，以腾出空间记录新的更新操作。</p><p>redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659858237349-b9540ba9-61bf-417d-a7bd-2e57191122ac.png#averageHue=%23efe8e8&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=272&amp;id=ueae49ccc&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=906&amp;originWidth=1362&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=382902&amp;status=done&amp;style=none&amp;taskId=u03ef2bcc-e51e-4b10-a2aa-bbe488243a4&amp;title=&amp;width=409.00006103515625" alt="image.png"><br>图中的：</p><ul><li>write pos 和 checkpoint 的移动都是顺时针方向；</li><li>write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；</li><li>check point ～ write pos 之间的部分（图中蓝色部分）：待落盘的脏数据页记录；</li></ul><p>如果 write pos 追上了 checkpoint，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（<em>因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要</em>），此时<strong>会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</strong>，然后 MySQL 恢复正常运行，继续执行新的更新操作。<br>所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。</p><h3 id="⑥REDO日志的好处、特点"><a href="#⑥REDO日志的好处、特点" class="headerlink" title="⑥REDO日志的好处、特点"></a>⑥REDO日志的好处、特点</h3><p><strong>1. 好处</strong><br><strong>redo日志降低了刷盘频率</strong><br><strong>redo日志占用的空间非常小</strong><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649856862466-b297deb7-8eb0-4e96-87f6-32567718b0f7.png#averageHue=%23e9e9e6&amp;clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=39&amp;id=fLnyE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=49&amp;originWidth=801&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=34384&amp;status=done&amp;style=none&amp;taskId=u58ff35fd-24f3-4ed0-8fa7-e76819241ca&amp;title=&amp;width=640.8" alt="image.png"><br><strong>2. 特点</strong><br><strong>redo日志是顺序写入磁盘的</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649856923077-628dbcd7-a008-4570-bcf4-9040b5de35c4.png#averageHue=%23f3efea&amp;clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=46&amp;id=VQhWU&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=58&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=176760&amp;status=done&amp;style=none&amp;taskId=u2119e165-f378-4ee4-9ddb-056c9a411c6&amp;title=&amp;width=608" alt="image.png"><br><strong>事务执行过程中，redo log不断记录</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649856930279-15f67492-43f1-4c9f-abd4-5f425b11e7d6.png#averageHue=%23f4f1eb&amp;clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=59&amp;id=CmyrA&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=74&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=225493&amp;status=done&amp;style=none&amp;taskId=u218530bd-d5c5-44eb-87ef-a7961b3b2e3&amp;title=&amp;width=608" alt="image.png"><br>redo log 为什么可以保证crash safe机制，那binlog可以做crash safe吗.先介绍下 crash safe的基本概念<br>它是指MySQL服务器宕机重启后，能够保证：</p><ul><li>所有已经提交的事务的数据仍然存在。</li><li>所有没有提交的事务的数据自动回滚。</li></ul><p><strong>redo log 是什么？</strong><br>一个固定大小，“循环写”的日志文件，记录的是物理日志——“在某个数据页上做了某个修改”。<br><strong>binlog 是什么？</strong><br>一个无限大小，“追加写”的日志文件，记录的是逻辑日志——“给 ID=2 这一行的 c 字段加1”。</p><p>第一点：redo log 可确保 innoDB 判断哪些数据已经刷盘，哪些数据还没有</p><ul><li>redo log和 binlog 有一个很大的区别就是，一个是循环写，一个是追加写。也就是说 redo log只会记录未刷盘的日志，已经刷入磁盘的数据都会从 redo log这个有限大小的日志文件里删除。binlog 是追加日志，保存的是全量的日志。</li><li>当数据库 crash 后，想要恢复未刷盘但已经写入 redo log 和 binlog的数据到内存时，binlog是无法恢复的。虽然 binlog拥有全量的日志，但没有一个标志让 innoDB 判断哪些数据已经刷盘，哪些数据还没有。</li></ul><p>举个栗子，binlog 记录了两条日志：</p><p>给 ID=2 这一行的 c 字段加1<br>给 ID=2 这一行的 c 字段加1<br>在记录1刷盘后，记录2未刷盘时，数据库 crash。重启后，只通过binlog数据库无法判断这两条记录哪条已经写入磁盘，哪条没有写入磁盘，不管是两条都恢复至内存，还是都不恢复，对 ID=2 这行数据来说，都不对。<br>但 redo log 不一样，只要刷入磁盘的数据，都会从redo log中抹掉，数据库重启后，直接把 redo log中的数据都恢复至内存就可以了。这就是为什么 redo log具有 crash-safe 的能力，而 binlog不具备。<br>第二点：如果 redo log 写入失败，说明此次操作失败，事务也不可能提交</p><ul><li>redo log 每次更新操作完成后，就一定会写入日志，如果<strong>写入失败</strong>，说明此次操作失败，事务也不可能提交。</li><li>redo log 内部结构是基于页的，记录了这个页的字段值变化，只要crash后读取redo log进行重放，就可以恢复数据。</li><li><p>这就是为什么 redo log 具有 crash-safe 的能力，而 binlog 不具备。<br>redo的组成Redo log可以简单分为以下两个部分：<br>重做日志的缓冲(redo log buffer) ，保存在内存中，是易失的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857018763-33ec717c-6f0a-4d89-ba31-4e2851dce9fe.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=50&amp;id=K6LNK&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=63&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=191737&amp;status=done&amp;style=none&amp;taskId=uc4dcc9ee-6979-43ec-a907-b294bc8bc84&amp;title=&amp;width=607.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857023664-ca743e0c-fa8e-4dab-bde0-ae529dff3c50.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=221&amp;id=fx6R6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=276&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=840770&amp;status=done&amp;style=none&amp;taskId=ue882445d-d87a-4e3b-88a4-c04502eeb2d&amp;title=&amp;width=608" alt="image.png"><br><strong>参数设置：innodb_log_buffer_size：</strong><br>redo log buffer 大小，默认16M ，最大值是4096M，最小值为1M。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857072215-edb58770-8299-41e8-bf1d-08b8a3fbe37c.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=134&amp;id=cBOel&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=167&amp;originWidth=805&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=8137&amp;status=done&amp;style=none&amp;taskId=u5856f0d4-5d90-4cad-bcd1-8d630d628b1&amp;title=&amp;width=644" alt="image.png"><br>重做日志文件(redo log file) ，保存在硬盘中，是持久的。</p><h3 id="redo-log日志格式"><a href="#redo-log日志格式" class="headerlink" title="redo log日志格式"></a>redo log日志格式</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652174395109-03215e80-92ea-4423-ab8d-497185c09bd1.png#clientId=uc6d7e8c9-8aaf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=411&amp;id=kXQDM&amp;margin=%5Bobject%20Object%5D&amp;originHeight=810&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue9347261-d52e-4f32-b9cd-a5ea8404499&amp;title=&amp;width=548" alt=""><br>redo log buffer (内存中)是由首尾相连的四个文件组成的，它们分别是：ib_logfile_1、ib_logfile_2、ib_logfile_3、ib_logfile_4。</p></li><li><p>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。</p></li><li>checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</li><li>write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。</li><li>如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</li><li>有了 redo log，当数据库发生宕机重启后，可通过 redo log将未落盘的数据（check point之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为<strong>crash-safe</strong>。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857832925-49d1c430-7169-4f57-a172-34ead4932378.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=158&amp;id=qBxgd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=198&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=602397&amp;status=done&amp;style=none&amp;taskId=u0cee4032-7319-46af-aa4c-b3435fe1ee8&amp;title=&amp;width=607.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857840051-0192eae0-74f7-4c0b-8141-c7fff718797e.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=374&amp;id=PqdPK&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=467&amp;originWidth=266&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=498255&amp;status=done&amp;style=none&amp;taskId=ue66b7dd4-c98c-4b47-aefa-ffce8049619&amp;title=&amp;width=212.8" alt="image.png"><br>如果write pos 追上checkpoint ，表示<strong>日志文件组</strong>满了，这时候不能再写入新的redo log记录，MySQL 得停下来，清空一些记录，把checkpoint 推进一下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857852852-5ffc0329-d7f0-43ff-bddd-b39e48e09b77.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=297&amp;id=Tah4d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=371&amp;originWidth=422&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=627726&amp;status=done&amp;style=none&amp;taskId=ue806e8bb-47a4-4967-ba78-d8240f1399f&amp;title=&amp;width=337.6" alt="image.png"><br>redo的整体流程以一个更新事务为例，redo log 流转过程，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857124788-1d1c7143-f3d9-4da4-a3d2-9f95d9124b06.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=196&amp;id=VD1NF&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=245&amp;originWidth=742&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=728676&amp;status=done&amp;style=none&amp;taskId=u0d166957-16de-424c-a790-ee8de4f22fc&amp;title=&amp;width=593.6" alt="image.png"><br>第1步：先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝<br>第2步：生成一条重做日志并写入<strong>redo log buffer</strong>，记录的是数据被修改后的值<br>第3步：当事务commit时，将redo log buffer中的内容刷新到redo log file，对redo log file采用追加写的方式<br>第4步：定期将内存中修改的数据刷新到磁盘中</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857177219-03baf226-014c-42ee-8b9c-850cbfde567d.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=78&amp;id=P2Gqe&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=98&amp;originWidth=803&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6815&amp;status=done&amp;style=none&amp;taskId=udafc39ce-5edf-42b4-ba39-d8783969fc3&amp;title=&amp;width=642.4" alt="image.png"><br>redo log的刷盘策略redo log的写入并不是直接写入磁盘的，InnoDB引擎会在写redo log的时候先写redo log buffer，之后以<br>一定的频率刷入到真正的redo log file 中。这里的一定频率怎么看待呢？这就是我们要说的刷盘策略。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857214180-3996fa3a-2bd7-4612-8a88-888d47a8382a.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=282&amp;id=AqzU2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=352&amp;originWidth=635&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=895980&amp;status=done&amp;style=none&amp;taskId=u3d5fe9bd-a13f-4309-8144-468b0c1ec68&amp;title=&amp;width=508" alt="image.png"></p><blockquote><p>注意，redo log buffer刷盘到redo log file的过程并不是真正的刷到磁盘中去，只是刷入到文件系统缓存<br>（page    cache）中去（这是现代操作系统为了提高文件写入效率做的一个优化），真正的写入会交给系统自己来决定（比如page   cache足够大了）。那么对于InnoDB来说就存在一个问题，如果交给系统来同步，同样如果系统宕机，那么数据也丢失了（虽然整个系统宕机的概率还是比较小的）。</p></blockquote><p>针对这种情况，InnoDB给出innodb_flush_log_at_trx_commit 参数，该参数控制commit提交事务时，如何将redo log buffer 中的日志刷新到redo log file 中。它支持三种策略：<br>设置为0：表示每次事务提交时不进行刷盘操作。（系统默认master  thread每隔1s进行一次重做日志的同步）innobd存储引擎有一个后台线程<br>设置为1 ：表示每次事务提交时都将进行同步，刷盘操作（默认值）<br>设置为2 ：表示每次事务提交时都只把redo log buffer 内容写入page cache，不进行同步。由os自己决定什么时候同步到磁盘文件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857288357-d5a17573-d4e1-4299-89e9-f20f62922e5f.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=184&amp;id=pnO7D&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=230&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=700655&amp;status=done&amp;style=none&amp;taskId=u557dd7fb-b849-4e67-9dc3-6765f2b66c3&amp;title=&amp;width=608" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857300194-965429aa-52e6-4943-aec6-91edbbacfe1d.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=283&amp;id=Q0UUo&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=354&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1078351&amp;status=done&amp;style=none&amp;taskId=u0a3b1ad4-3b55-496a-b424-4c1f0de2f99&amp;title=&amp;width=608" alt="image.png"><br><strong>后台线程！！！！！！！！</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857330133-04cd41b3-d9c0-48d7-9aac-8f571916533c.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=51&amp;id=galFJ&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=64&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=194774&amp;status=done&amp;style=none&amp;taskId=u6c9f6c52-64ff-4355-82e0-928b8185419&amp;title=&amp;width=607.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857334317-1b7bcb69-6191-43d8-a040-e860e269c520.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=71&amp;id=c6Bl3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=89&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=271190&amp;status=done&amp;style=none&amp;taskId=u65af8ec2-fd03-4105-83bd-c39af7ac407&amp;title=&amp;width=608" alt="image.png"><br>不同刷盘策略演示#### 流程图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857381036-6d181d9a-145f-43de-9a90-5acef9a9b787.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=495&amp;id=anuEM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=619&amp;originWidth=847&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=77550&amp;status=done&amp;style=none&amp;taskId=u5968c310-5a2b-4cb5-9e99-95b126e3406&amp;title=&amp;width=677.6" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857458848-71070dda-6d68-429d-b430-6498390e09bf.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=170&amp;id=S7fxv&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=213&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=648017&amp;status=done&amp;style=none&amp;taskId=u27a116b0-9cdb-4e7f-ba6b-a6413545de5&amp;title=&amp;width=607.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857508244-f3b2a14d-aa27-4663-be36-26ceb7b8216d.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=456&amp;id=bxrcB&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=570&amp;originWidth=736&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1681453&amp;status=done&amp;style=none&amp;taskId=u19a0ddac-b4ef-43ac-9864-2ec8cfd2747&amp;title=&amp;width=588.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857540427-20c9c990-99e2-4304-9f87-133ed0befe1a.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=124&amp;id=Qiw9T&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=155&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=471594&amp;status=done&amp;style=none&amp;taskId=u3416563b-839c-4c78-a144-6e603d314b7&amp;title=&amp;width=607.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857562774-98259928-f8aa-4a60-928e-e5598b1bf8db.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=456&amp;id=SlIWP&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=570&amp;originWidth=734&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1676893&amp;status=done&amp;style=none&amp;taskId=u60491e40-8389-436a-b86f-6aeaebe65a0&amp;title=&amp;width=587.2" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857566145-34f94f4a-3bad-4da4-89d0-dac0f9ebfdef.png#clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=130&amp;id=E9kgq&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=163&amp;originWidth=759&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=495926&amp;status=done&amp;style=none&amp;taskId=u3517a214-45ac-446d-911c-148cc869db9&amp;title=&amp;width=607.2" alt="image.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649857957429-c2468b6a-7b06-49e1-9832-ffd8f45365b4.png#averageHue=%23e7dfc6&amp;clientId=ub50e3b2a-5cc3-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=324&amp;id=shxDg&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=405&amp;originWidth=760&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1233690&amp;status=done&amp;style=none&amp;taskId=u6edb3d5d-3349-4947-b4d7-efa2435e6fb&amp;title=&amp;width=608" alt="image.png"></p><h2 id="Ⅲbinlog"><a href="#Ⅲbinlog" class="headerlink" title="Ⅲbinlog"></a>Ⅲbinlog</h2><p>前面介绍的 undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。</p><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。</p><p>binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。<br>为什么有了 binlog， 还要有 redo log？<br>这个问题跟 MySQL 的时间线有关系。</p><p>最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。</p><p>而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。</p><h3 id="①binlog的概念是什么-起到什么作用"><a href="#①binlog的概念是什么-起到什么作用" class="headerlink" title="①binlog的概念是什么, 起到什么作用?"></a>①binlog的概念是什么, 起到什么作用?</h3><p><strong>概念：</strong></p><ul><li>binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑。记录对MySQL数据库执行修改的所有操作，不会记录select和show语句。可以实现<strong>主从复制</strong>和<strong>数据恢复</strong>两个作用。（在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原）</li><li>当需要<strong>恢复数据</strong>时，可以取出某个时间范围内的 binlog 进行重放恢复。</li><li>但是 binlog 不可以做 crash safe，因为 crash 之前，binlog <strong>可能没有写入完全</strong> MySQL 就挂了。所以需要配合 <strong>redo log</strong> 才可以进行 crash safe。</li></ul><h3 id="②binlog-日志的三种格式"><a href="#②binlog-日志的三种格式" class="headerlink" title="②binlog 日志的三种格式"></a>②binlog 日志的三种格式</h3><p>binlog 日志有三种格式</p><ul><li>Statement：基于SQL语句的复制((statement-based replication,SBR))</li><li>Row：基于行的复制。(row-based replication,RBR)</li><li>Mixed：混合模式复制。(mixed-based replication,MBR)</li></ul><p><strong>Statement格式</strong><br>每一条会修改数据的 SQL 都会记录在 binlog 中</p><ul><li>优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。</li><li>缺点：由于记录的只是执行语句，为了这些语句能在备库上正确运行，还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在备库得到和在主库端执行时候相同的结果。</li></ul><p><strong>Row格式</strong><br>不记录 SQL 语句上下文相关信息，仅保存哪条记录被修改。</p><ul><li>优点：binlog 中可以不记录执行的 SQL 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。不会出现某些特定情况下的存储过程、或 function、或trigger的调用和触发无法被正确复制的问题。</li><li>缺点:可能会产生大量的日志内容。</li></ul><p><strong>Mixed格式</strong><br>实际上就是 Statement 与 Row 的结合。一般的语句修改使用 statment 格式保存 binlog，如一些函数，statement 无法完成主从复制的操作，则采用 row 格式保存 binlog，MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式。</p><h3 id="③redo-log-和-binlog-有什么区别？"><a href="#③redo-log-和-binlog-有什么区别？" class="headerlink" title="③redo log 和 binlog 有什么区别？"></a>③redo log 和 binlog 有什么区别？</h3><p>这两个日志有四个区别。<br><em>1、适用对象不同：</em></p><ul><li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li><li>redo log 是 Innodb 存储引擎实现的日志；</li></ul><p><em>2、文件格式不同：</em></p><ul><li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul><li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li><li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li><li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li></ul></li><li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li></ul><p><em>3、写入方式不同：</em></p><ul><li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li><li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li></ul><p><em>4、用途不同：</em></p><ul><li>binlog 用于备份恢复、主从复制；</li><li>redo log 用于掉电等故障恢复。</li></ul><p>如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？<br>不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。<br>因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。<br>binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。</p><h3 id="④主从复制是怎么实现？"><a href="#④主从复制是怎么实现？" class="headerlink" title="④主从复制是怎么实现？"></a>④主从复制是怎么实现？</h3><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p><p>这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859467091-bb67e3f7-a7e2-4333-ac56-08eda3abd9c5.png#averageHue=%23f5efe3&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=245&amp;id=u95739a9b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=401&amp;originWidth=991&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=141410&amp;status=done&amp;style=none&amp;taskId=ub829d1a6-67d4-461b-83bc-2c01f556c20&amp;title=&amp;width=604.2857666015625" alt="image.png"><br>MySQL 集群的主从复制过程梳理成 3 个阶段：</p><ul><li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li><li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li><li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li></ul><p>具体详细过程如下：</p><ul><li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li><li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li></ul><p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859467054-a47073da-3282-45e8-8403-e5f940d5b64f.png#averageHue=%23f8f4f0&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=377&amp;id=uaa48523f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=471&amp;originWidth=451&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=65129&amp;status=done&amp;style=none&amp;taskId=uf3ba6c30-907f-4452-b1fd-9ed9061c06b&amp;title=&amp;width=361.0000305175781" alt="image.png"><br>从库是不是越多越好？<br>不是的。</p><p>因为从库数量增加，从库连接上来的 I/O 线程也比较多，<strong>主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽</strong>。</p><p>所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。<br>MySQL 主从复制还有哪些模型？<br>主要有三种：</p><ul><li><strong>同步复制</strong>：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</li><li><strong>异步复制</strong>（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。</li><li><strong>半同步复制</strong>：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种<strong>半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险</strong>。<h3 id="⑤binlog-什么时候刷盘？"><a href="#⑤binlog-什么时候刷盘？" class="headerlink" title="⑤binlog 什么时候刷盘？"></a>⑤binlog 什么时候刷盘？</h3>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</li></ul><p>MySQL 给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。<br>什么时候 binlog cache 会写到 binlog 文件？<br>在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859467097-45bd9af3-a4c0-4627-9bf8-df7eb9348128.png#averageHue=%23f6f3ed&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=264&amp;id=u1acb63f8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=461&amp;originWidth=721&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=66538&amp;status=done&amp;style=none&amp;taskId=u3ae00ae2-7667-4d3d-bf63-59b1ed42fac&amp;title=&amp;width=413" alt="image.png"><br>虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件：</p><ul><li>图中的 write，指的就是指把日志写入到 binlog 文件，但是并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。</li><li>图中的 fsync，才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。</li></ul><p><strong>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：</strong></p><ul><li>sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li><li>sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li><li>sync_binlog =N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li></ul><p>在MySQL中系统默认的设置是 sync_binlog = 0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。</p><p>而当 sync_binlog 设置为 1 的时候，是最安全但是性能损耗最大的设置。因为当设置为 1 的时候，即使主机发生异常重启，最多丢失一个事务的 binlog，而已经持久化到磁盘的数据就不会有影响，不过就是对写入性能影响太大。</p><p>如果能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="①bin-log和redo-log有什么区别？"><a href="#①bin-log和redo-log有什么区别？" class="headerlink" title="①bin log和redo log有什么区别？"></a>①bin log和redo log有什么区别？</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652169545640-f9493470-8716-4a40-9c4e-391ef55a599e.png#averageHue=%23f3f3f2&amp;clientId=uc6d7e8c9-8aaf-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=405&amp;id=bGCdC&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=605&amp;originWidth=850&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=282472&amp;status=done&amp;style=none&amp;taskId=ud2a8d66a-9fa7-4e64-98e7-98b5b3984f4&amp;title=&amp;width=569" alt="image.png"><br>作用：</p><ol><li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都<br>可以使用。 </li><li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日<br>志记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。</li><li><p>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指<br>binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p><h3 id="②三个日志讲完了，至此我们可以先小结下，update-语句的执行过程。"><a href="#②三个日志讲完了，至此我们可以先小结下，update-语句的执行过程。" class="headerlink" title="②三个日志讲完了，至此我们可以先小结下，update 语句的执行过程。"></a>②三个日志讲完了，至此我们可以先小结下，update 语句的执行过程。</h3><p>当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。<br>具体更新一条记录 UPDATE t_user SET name = ‘xiaolin’ WHERE id = 1; 的流程如下:</p></li><li><p>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：</p><ul><li>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li></ul></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li></ul></li><li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在修改该 Undo 页面前需要先记录对应的 redo log，所以<strong>先记录修改 Undo 页面的 redo log ，然后再真正的修改 Undo 页面</strong>。</li><li>InnoDB 层开始更新记录，根据 WAL 技术，<strong>先记录修改数据页面的 redo log ，然后再真正的修改数据页面</strong>。修改数据页面的过程是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li><li>至此，一条记录更新完了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li><li>事务提交，剩下的就是「两阶段提交」的事情了，接下来就讲这个。<h3 id="②什么是两阶段提交"><a href="#②什么是两阶段提交" class="headerlink" title="②什么是两阶段提交,"></a>②什么是两阶段提交,</h3><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651565431904-2bfddc77-94d4-4078-8c0b-4e526f2c8be9.png#averageHue=%23faf9f7&amp;clientId=u032535be-8a03-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=380&amp;id=F7gNs&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=516&amp;originWidth=729&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=185894&amp;status=done&amp;style=none&amp;taskId=uce59947e-aa27-4fa7-a51a-484c13d9acc&amp;title=&amp;width=536.2857666015625" alt="image.png"><br>从图中可看出，事务的提交过程有两个阶段，就是将redo log的写入拆成了两个步骤：prepare和commit，中间再穿插写入binlog。</li></ol><p>而两阶段提交就是让这两个状态保持逻辑上的一致。redolog 用于恢复主机故障时的未更新的物理数据，binlog 用于备份操作。两者本身就是两个独立的个体，要想保持一致，就必须使用分布式事务的解决方案来处理。<a href="https://blog.csdn.net/qq_48825548/article/details/120482321"></a></p><h2 id="Ⅳ-两阶段提交内容"><a href="#Ⅳ-两阶段提交内容" class="headerlink" title="Ⅳ 两阶段提交内容"></a>Ⅳ 两阶段提交内容</h2><h3 id="①为什么需要两阶段提交？"><a href="#①为什么需要两阶段提交？" class="headerlink" title="①为什么需要两阶段提交？"></a>①为什么需要两阶段提交？</h3><p>事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。<br>举个例子，假设 id = 1 这行数据的字段 name 的值原本是 ‘jay’，然后执行 UPDATE t_user SET name = ‘xiaolin’ WHERE id = 1; 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：</p><ul><li><strong>如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入</strong>。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；</li><li><strong>如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入</strong>。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；</li></ul><p>可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。<br><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。<br><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。</p><blockquote><p>举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？</p><ul><li><strong>准备阶段</strong>：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。</li><li><strong>提交阶段</strong>：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。</li></ul></blockquote><h4 id="两阶段提交的过程是怎样的？"><a href="#两阶段提交的过程是怎样的？" class="headerlink" title="两阶段提交的过程是怎样的？"></a>两阶段提交的过程是怎样的？</h4><p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。<br>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859467298-b1173b33-4e0b-4395-a82b-0721459d5bcc.png#averageHue=%23cce78e&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=307&amp;id=u3f09c16d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=842&amp;originWidth=1157&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=202864&amp;status=done&amp;style=none&amp;taskId=u72645a40-8b3d-4f97-9c20-841d2f6e7f5&amp;title=&amp;width=422.2857360839844" alt="image.png"><br>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p><ul><li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li><li><p><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，所以 commit 状态也是会刷盘的）；</p><h4 id="异常重启会出现什么现象？"><a href="#异常重启会出现什么现象？" class="headerlink" title="异常重启会出现什么现象？"></a>异常重启会出现什么现象？</h4><p>我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859467329-7042219c-d341-473c-bdf1-d87f4ed7e334.png#averageHue=%23cde58f&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1f5cab82&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=842&amp;originWidth=1175&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=233477&amp;status=done&amp;style=none&amp;taskId=u457fb78b-3eb7-4e8e-8218-84548c9f67c&amp;title=" alt="image.png"><br>不管是时刻 A（已经 redo log，还没写入 binlog），还是时刻 B （已经写入 redo log 和 binlog，还没写入 commit 标识）崩溃，<strong>此时的 redo log 都处于 prepare 状态</strong>。<br>在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p></li><li><p><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</p></li><li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li></ul><p>可以看到，<strong>对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。<br>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。<br>处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?<br>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。<br>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。<br>事务没提交的时候，redo log 会被持久化到磁盘吗？<br>会的。<br>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。<br>也就是说，事务没提交的时候，redo log 也是可能被持久化到磁盘的。<br>有的同学可能会问，如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？<br>放心，这种情况 mysql 重启会进行回滚操作，因为事务没提交的时候，binlog 是还没持久化到磁盘的。<br>所以， redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。</p><h3 id="②两阶段提交有什么问题？"><a href="#②两阶段提交有什么问题？" class="headerlink" title="②两阶段提交有什么问题？"></a>②两阶段提交有什么问题？</h3><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><strong>磁盘 I/O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li><li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li></ul><p>为什么两阶段提交的磁盘 I/O 次数会很高？<br>binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：</p><ul><li>当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</li><li>当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</li></ul><p>可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。<br>为什么锁竞争激烈？<br>在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。<br>通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。</p><h4 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h4><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。<br>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p><ul><li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li><li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li><li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li></ul><p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859469408-8982f8b1-004f-4d4b-b316-82998d2bbccf.png#averageHue=%2392ac63&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=548&amp;id=ueaff12a9&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=828&amp;originWidth=852&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84311&amp;status=done&amp;style=none&amp;taskId=ua42d2578-d699-40b6-8030-603deadd2a4&amp;title=&amp;width=564.2857666015625" alt="image.png"><br>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。<br>有 binlog 组提交，那有 redo log 组提交吗？<br>这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。<br>在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。<br>所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。<br>这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。<br>接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。<br>flush 阶段<br>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower ：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859469829-f5a8dabc-81c6-4d47-9d6c-eeef9c861665.png#averageHue=%23fefefe&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue55014c1&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=862&amp;originWidth=1192&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=270808&amp;status=done&amp;style=none&amp;taskId=u04ddc7b7-f539-4f30-be04-9e2dd462369&amp;title=" alt="image.png"><br>接着，获取队列中的事务组，由绿色事务组的 Leader 对 rodo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859469797-019345af-0710-4468-a9a0-5dc564d96a51.png#averageHue=%23fefefb&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u86a91a1b&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=494&amp;originWidth=1144&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=186931&amp;status=done&amp;style=none&amp;taskId=u072583e3-cf99-4b79-aae8-307af682502&amp;title=" alt="image.png"><br>完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859469792-c50a96d5-b4d9-4dee-bdf1-336cc5b3e2ae.png#averageHue=%23fefefc&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u443fb310&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=478&amp;originWidth=1392&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=215428&amp;status=done&amp;style=none&amp;taskId=ueb8ae60c-4cf0-4be2-b68c-4c0e359ec61&amp;title=" alt="image.png"><br>从上面这个过程，可以知道 flush 阶段队列的作用是<strong>用于支撑 redo log 的组提交</strong>。<br>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。<br>sync 阶段<br>绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是<strong>会等待一段时间</strong>，这个等待的时长由 Binlog_group_commit_sync_delay 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘</strong>，如下过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859470168-92e4f211-1a3d-496a-a92b-6c9b4d04c27c.png#averageHue=%23fefefe&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf9196fac&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1876&amp;originWidth=1268&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=694957&amp;status=done&amp;style=none&amp;taskId=u9ceed3a6-e856-4c90-b683-e0837cc82c5&amp;title=" alt="image.png"><br>不过，在等待的过程中，如果事务的数量提前达到了 Binlog_group_commit_sync_no_delay_count 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859470965-0a1f7d56-6932-4bb8-a0ec-ee4ab90e4b2e.png#averageHue=%23fbf8f0&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5f3a7721&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=702&amp;originWidth=1910&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=394399&amp;status=done&amp;style=none&amp;taskId=u64e6848c-dd2e-4049-a0b4-6529fcbf74e&amp;title=" alt="image.png"><br>从上面的过程，可以知道 sync 阶段队列的作用是<strong>用于支持 binlog 的组提交</strong>。<br>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p><ul><li>binlog_group_commit_sync_delay= N，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li><li>binlog_group_commit_sync_no_delay_count = N，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li></ul><p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。<br>commit 阶段<br>最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659859471225-14256b0c-dff2-4bf9-a1f1-63ba0952dc3a.png#averageHue=%23fefefd&amp;clientId=u4c16ca43-52af-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uee394f6f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1107&amp;originWidth=1020&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=383240&amp;status=done&amp;style=none&amp;taskId=u85bbec8d-6921-451c-82b6-d1e5c02975c&amp;title=" alt="image.png"><br>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。</p><h3 id="③MySQL-磁盘-I-O-很高，有什么优化的方法？"><a href="#③MySQL-磁盘-I-O-很高，有什么优化的方法？" class="headerlink" title="③MySQL 磁盘 I/O 很高，有什么优化的方法？"></a>③MySQL 磁盘 I/O 很高，有什么优化的方法？</h3><p>现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：</p><ul><li>设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。</li><li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。</li><li>将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。<h2 id="Ⅴ更新一条语句流程"><a href="#Ⅴ更新一条语句流程" class="headerlink" title="Ⅴ更新一条语句流程"></a>Ⅴ更新一条语句流程</h2>具体更新一条记录 UPDATE t_user SET name = ‘xiaolin’ WHERE id = 1; 的流程如下:</li></ul><ol><li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：<ul><li>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li></ul></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li></ul></li><li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在修改该 Undo 页面前需要先记录对应的 redo log，所以<strong>先记录修改 Undo 页面的 redo log ，然后再真正的修改 Undo 页面</strong>。</li><li>InnoDB 层开始更新记录，根据 WAL 技术，<strong>先记录修改数据页面的 redo log ，然后再真正的修改数据页面</strong>。修改数据页面的过程是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。</li><li>至此，一条记录更新完了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li><li>事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：<ul><li><strong>prepare 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li><li><strong>commit 阶段</strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li></ul></li><li>至此，一条更新语句执行完成。[</li></ol><p>](<a href="https://blog.csdn.net/qq_48825548/article/details/120482321">https://blog.csdn.net/qq_48825548/article/details/120482321</a>)</p><h2 id="日志相关问题"><a href="#日志相关问题" class="headerlink" title="日志相关问题"></a>日志相关问题</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651632858993-93cbd99a-fe8b-495b-9b0f-bc05144e8030.jpeg#averageHue=%23e9ecdf&amp;clientId=uee8de687-a63b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=660&amp;id=u604e3892&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1522&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=68167&amp;status=done&amp;style=none&amp;taskId=u2d8c40d4-4711-4a67-82c5-e3c767a28dd&amp;title=&amp;width=495" alt="image.png"><br>图 1 两阶段提交示意图</p><p>接下来，我们就一起分析一下<strong>在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。</strong><br>如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。<br>大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？<br>我们先来看一下崩溃恢复时的判断规则。</p><ol><li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li><li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：<br>a. 如果是，则提交事务；<br>b. 否则，回滚事务。</li></ol><p>这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。<br>现在，我们继续延展一下这个问题。<br>日志相关问题### 追问 1：MySQL 怎么知道 binlog 是完整的?<br>回答：一个事务的 binlog 是有完整格式的：</p><ul><li>statement 格式的 binlog，最后会有 COMMIT；</li><li>row 格式的 binlog，最后会有一个 XID event。</li></ul><p>另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。</p><h3 id="追问-2：redo-log-和-binlog-是怎么关联起来的"><a href="#追问-2：redo-log-和-binlog-是怎么关联起来的" class="headerlink" title="追问 2：redo log 和 binlog 是怎么关联起来的?"></a>追问 2：redo log 和 binlog 是怎么关联起来的?</h3><p>回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：</p><ul><li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；</li><li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。<h3 id="追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计"><a href="#追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计" class="headerlink" title="追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?"></a>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</h3>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。<br>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。<h3 id="追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？"><a href="#追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？" class="headerlink" title="追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？"></a>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</h3>回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。<br>如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。<br>对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。<br>两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。<h3 id="追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？"><a href="#追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？" class="headerlink" title="追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？"></a>追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？</h3>回答：这位同学的意思是，只保留 binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt; “提交事务”，是不是也可以提供崩溃恢复的能力？<br>答案是不可以。<br>如果说<strong>历史原因</strong>的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。<br>InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。<br>InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。<br>而如果说<strong>实现上的原因</strong>的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651632858998-59e987de-4f34-4198-aa3e-cc4fafcb343f.jpeg#averageHue=%23f1f1ea&amp;clientId=uee8de687-a63b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tVyBM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=856&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=17367&amp;status=done&amp;style=none&amp;taskId=u55139db0-9f6b-4774-974d-c15f156d2f7&amp;title=" alt="image.png"><br>图 2 只用 binlog 支持崩溃恢复<br>这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。<br>如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。<br>重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。<br>但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。<br>也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。<br>你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。<br>所以，至少现在的 binlog 能力，还不能支持崩溃恢复。<h3 id="追问-6：那能不能反过来，只用-redo-log，不要-binlog？"><a href="#追问-6：那能不能反过来，只用-redo-log，不要-binlog？" class="headerlink" title="追问 6：那能不能反过来，只用 redo log，不要 binlog？"></a>追问 6：那能不能反过来，只用 redo log，不要 binlog？</h3>回答：如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。<br>但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。<br>一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。<br>一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。<br>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。<br>总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。<h3 id="追问-7：redo-log-一般设置多大？"><a href="#追问-7：redo-log-一般设置多大？" class="headerlink" title="追问 7：redo log 一般设置多大？"></a>追问 7：redo log 一般设置多大？</h3>回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。<br>所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。<h3 id="追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？"><a href="#追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？" class="headerlink" title="追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？"></a>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</h3>回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么”的问题。<br>实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。</li></ul><ol><li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。</li><li>在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。<h3 id="追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？"><a href="#追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？" class="headerlink" title="追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？"></a>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？</h3>回答：这两个问题可以一起回答。<br>在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：<br>复制代码<br>begin;<br>insert into t1 …<br>insert into t2 …<br>commit;<br>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。<br>所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。<br>但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。<br>（这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在后面第 22 篇文章《MySQL 有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。<br>单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。</li></ol><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h1 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h1>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>数据结构篇</title>
      <link href="/2022/08/09/redis/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/2022/08/09/redis/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="ⅠRedis-常见数据类型以及使用场景分析"><a href="#ⅠRedis-常见数据类型以及使用场景分析" class="headerlink" title="ⅠRedis 常见数据类型以及使用场景分析"></a>ⅠRedis 常见数据类型以及使用场景分析</h2><p>我们都知道 Redis 提供了丰富的数据类型，常见的有五种：<strong>String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）</strong>。<br>随着 Redis 版本的更新，后面又支持了四种数据类型： <strong>BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）</strong>。<br><strong>使用场景就介绍数据类型所对应的</strong></p><h3 id="①string"><a href="#①string" class="headerlink" title="①string"></a>①string</h3><p><strong>介绍</strong><br>String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 512M。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657938150802-34efb932-fb99-44bd-8494-a7bd81459103.png#averageHue=%23faf6ec&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=217&amp;id=uff79b11e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=724&amp;originWidth=1698&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=168330&amp;status=done&amp;style=none&amp;taskId=ubbeef3ed-33fc-462a-9e31-662bde4449c&amp;title=&amp;width=509.00006103515625" alt="image.png"><br><strong>内部实现</strong><br>String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。</p><ol><li><strong>SDS讲解</strong></li></ol><p>a:数据结构<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652455986932-b05c833e-a686-4171-8089-c8006a3fd232.png#averageHue=%23fcefee&amp;clientId=u491e6a16-565a-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=249&amp;id=ztYMW&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=311&amp;originWidth=700&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=46430&amp;status=done&amp;style=none&amp;taskId=u772ca62a-b152-47a0-bf40-8a72cb73b6e&amp;title=&amp;width=560" alt="image.png"><br>b:Redis为什么重新设计一个 SDS 数据结构？<br>C语言没有Java里面的String类型，只能是靠自己的char[]来实现，字符串在 C 语言中的存储方式，想要获取 「Redis」的长度，需要从头开始遍历，直到遇到 ‘\0’ 为止。所以，Redis 没有直接使用 C 语言传统的字符串标识，而是自己构建了一种名为简单动态字符串 SDS（simple dynamic string）的抽象类型，并将 SDS 作为 Redis 的默认字符串。<br>补充c:优点：</p><ul><li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li><li>获取字符串长度的时间复杂度是常数时间复杂度O(1)</li><li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。<blockquote><ul><li>空间预分配：SDS 修改后，len 长度小于 1M，那么将会额外分配与 len 相同长度的未使用空间。如果修改后长度大于 1M，那么将分配1M的使用空间。</li><li>惰性空间释放：</li></ul><p>有空间分配对应的就有空间释放。SDS 缩短时并不会回收多余的内存空间，而是使用 free 字段将多        出来的空间记录下来。如果后续有变更操作，直接使用 free 中记录的空间，减少了内存的分配。</p></blockquote></li></ul><ol><li><strong>字符串对象</strong>的内部编码（encoding）有 3 种 ：<strong>int、raw和 embstr</strong>。</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657938150848-c3142824-f0e3-4a28-8e67-fd211f8148b7.png#averageHue=%23d99045&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=219&amp;id=anzyE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=622&amp;originWidth=1570&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=235941&amp;status=done&amp;style=none&amp;taskId=u8edbdeb9-5c66-4ae0-8fed-e984dde710d&amp;title=&amp;width=553.0000610351562" alt="image.png"><br>int<br>如果一个<strong>字符串对象</strong>保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成 long），并将字符串对象的编码设置为int。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657938150706-ef09656b-e6bc-4612-b040-e2aa2be992d1.png#averageHue=%23fae3e3&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=186&amp;id=Qld4g&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=502&amp;originWidth=1198&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=79686&amp;status=done&amp;style=none&amp;taskId=uac2d33ba-ff75-49ec-b88a-1ba8102afdd&amp;title=&amp;width=444" alt="image.png"><br>数字最多为19位。<br>注意：只有整数才会使用 int，如果是浮点数， Redis 内部其实先将浮点数转化为字符串值，然后再保存。</p><ul><li>示例：set k1 123  set k2 123</li></ul><p>embstr<br>如果字符串对象保存的是一个字符串，<strong>并且这个字符串的长度小于等于 32 字节</strong>（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为embstr， embstr编码是专门用于保存短字符串的一种优化编码方式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657938150673-bb605ac0-3380-42b4-bf91-7d3c88d92b42.png#averageHue=%23f9ebeb&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=CYgMs&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=261&amp;originWidth=1804&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=113365&amp;status=done&amp;style=none&amp;taskId=uc2e1dcbc-6585-4310-92e4-511429b0955&amp;title=" alt="image.png"><br>EMBSTR 顾名思义即：embedded string，表示嵌入式的String。从内存结构上来讲 即字符串 sds结构体与其对应的 redisObject 对象分配在同一块连续的内存空间，字符串sds嵌入在redisObject对象之中一样。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648362218021-18ad2ea1-f359-4b0e-9454-b1a2558fe87d.png#averageHue=%2368f166&amp;clientId=u4da6a76f-331d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=329&amp;id=Kk0Oe&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=588&amp;originWidth=458&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=98690&amp;status=done&amp;style=none&amp;taskId=u0153b1e9-ec41-403c-9442-127d287d64a&amp;title=&amp;width=256.39288330078125" alt="image.png"><br>raw<br>如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为raw：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657938150738-ea26ee36-5755-4fb0-baeb-4341cae8c301.png#averageHue=%23fbf1f1&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uPyKz&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=510&amp;originWidth=2068&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=144223&amp;status=done&amp;style=none&amp;taskId=ude21c03f-069c-4134-882b-078e72b0192&amp;title=" alt="image.png"><br>与OBJ_ENCODING_EMBSTR编码方式的不同之处在于，此时动态字符串sds的内存与其依赖的redisObject的内存不再连续了<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648362309099-edcf0c34-27ea-4c23-9b62-03610df36a16.png#averageHue=%23e8aa67&amp;clientId=u4da6a76f-331d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=260&amp;id=Xd6gA&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=362&amp;originWidth=730&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=78038&amp;status=done&amp;style=none&amp;taskId=u3c83d2b4-89bf-47b6-8c60-51b266bab0a&amp;title=&amp;width=524" alt="image.png"></p><p>注意，embstr 编码和 raw 编码的边界在 redis 不同版本中是不一样的：</p><ul><li>redis 2.+ 是 32 字节</li><li>redis 3.0-4.0 是 39 字节</li><li>redis 5.0 是 44 字节<blockquote><p>可以看到embstr和raw编码都会使用SDS来保存值，但不同之处在于embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS，而raw编码会通过调用两次内存分配函数来分别分配两块空间来保存redisObject和SDS。Redis这样做会有很多好处：</p><ul><li>embstr编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次；</li><li>释放 embstr编码的字符串对象同样只需要调用一次内存释放函数；</li><li>因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。</li></ul><p>但是 embstr 也有缺点的：</p><ul><li>如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以<strong>embstr编码的字符串对象实际上是只读的</strong>，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。</li></ul></blockquote></li></ul><p><strong>常用命令</strong><br>普通字符串的基本操作：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 设置 key-value 类型的值</span><br><span class="line">&gt; SET name lin</span><br><span class="line">OK</span><br><span class="line"># 根据 key 获得对应的 value</span><br><span class="line">&gt; GET name</span><br><span class="line"><span class="string">&quot;lin&quot;</span></span><br><span class="line"># 判断某个 key 是否存在</span><br><span class="line">&gt; EXISTS <span class="title function_">name</span></span><br><span class="line"><span class="params">(integer)</span> 1</span><br><span class="line"># 返回 key 所储存的字符串值的长度</span><br><span class="line">&gt; STRLEN <span class="title function_">name</span></span><br><span class="line"><span class="params">(integer)</span> 3</span><br><span class="line"># 删除某个 key 对应的值</span><br><span class="line">&gt; DEL <span class="title function_">name</span></span><br><span class="line"><span class="params">(integer)</span> 1</span><br></pre></td></tr></table></figure><br>批量设置 :<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 批量设置 key-value 类型的值</span><br><span class="line">&gt; MSET key1 value1 key2 value2 </span><br><span class="line">OK</span><br><span class="line"># 批量获取多个 key 对应的 value</span><br><span class="line">&gt; MGET key1 key2 </span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;value1&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;value2&quot;</span></span><br></pre></td></tr></table></figure><br>计数器（字符串的内容为整数的时候可以使用）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 设置 key-value 类型的值</span><br><span class="line">&gt; SET number <span class="number">0</span></span><br><span class="line">OK</span><br><span class="line"># 将 key 中储存的数字值增一</span><br><span class="line">&gt; INCR <span class="title function_">number</span></span><br><span class="line"><span class="params">(integer)</span> 1</span><br><span class="line"># 将key中存储的数字值加 10</span><br><span class="line">&gt; INCRBY number 10</span><br><span class="line"><span class="params">(integer)</span> 11</span><br><span class="line"># 将 key 中储存的数字值减一</span><br><span class="line">&gt; DECR <span class="title function_">number</span></span><br><span class="line"><span class="params">(integer)</span> 10</span><br><span class="line"># 将key中存储的数字值键 10</span><br><span class="line">&gt; DECRBY number 10</span><br><span class="line"><span class="params">(integer)</span> 0</span><br></pre></td></tr></table></figure><br>过期（默认为永不过期）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 设置 key 在 <span class="number">60</span> 秒后过期（该方法是针对已经存在的key设置过期时间）</span><br><span class="line">&gt; EXPIRE name  <span class="number">60</span> </span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"># 查看数据还有多久过期</span><br><span class="line">&gt; TTL <span class="title function_">name</span> </span><br><span class="line"><span class="params">(integer)</span> 51</span><br><span class="line"></span><br><span class="line">#设置 key-value 类型的值，并设置该key的过期时间为 60 秒</span><br><span class="line">&gt; SET key  value EX 60</span><br><span class="line">OK</span><br><span class="line">&gt; SETEX key  60 value</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><br>不存在就插入：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 不存在就插入（not exists）</span><br><span class="line">&gt;SETNX key <span class="title function_">value</span></span><br><span class="line"><span class="params">(integer)</span> 1</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong></p><ol><li>缓存对象</li><li>常规计数</li></ol><ul><li>因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量、计算文章的阅读量等等。</li></ul><ol><li>分布式锁</li><li>共享 Session 信息<br>通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。</li></ol><p>例如用户一的 Session 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 Session 信息，就会出现需要重复登录的问题，问题在于分布式系统每次会把请求随机分配到不同的服务器。<br>分布式系统单独存储 Session 流程图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939313906-e02322b4-7c44-4f86-a935-543fa60fa6db.png#averageHue=%23fefefe&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=229&amp;id=uea7a48b8&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=308&amp;originWidth=820&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=67880&amp;status=done&amp;style=none&amp;taskId=u3eb66f2a-3c38-45bd-b91f-c28d9f71e66&amp;title=&amp;width=611.0000610351562" alt="image.png"><br>因此，我们需要借助 Redis 对这些 Session 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去同一个 Redis 获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。<br>分布式系统使用同一个 Redis 存储 Session 流程图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939313919-4c3e0ea1-c73a-4cda-8ac9-efdef2d2c896.png#averageHue=%23fefefc&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=344&amp;id=u68582f95&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=412&amp;originWidth=473&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=71982&amp;status=done&amp;style=none&amp;taskId=uf2dfb005-ed8a-4c85-b29f-520de28ad6d&amp;title=&amp;width=395.0000305175781" alt="image.png"></p><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h3 id="②list"><a href="#②list" class="headerlink" title="②list"></a>②list</h3><p><strong>介绍</strong><br>List 列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 列表添加元素。<br>列表的最大长度为 2^32 - 1，也即每个列表支持超过 40 亿个元素。<br><strong>内部实现</strong><br>List 类型的底层数据结构是由<strong>压缩列表或双向链表</strong>实现的：</p><ul><li>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li><li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li></ul><p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。<br><strong>常用命令</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939602314-7bea6dec-3340-4146-ab68-501aeec0ad3c.png#averageHue=%23fbfafa&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=196&amp;id=u2721563f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=684&amp;originWidth=1936&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=126997&amp;status=done&amp;style=none&amp;taskId=u7797b1a5-72ab-45c2-ab4f-87e7e1660d2&amp;title=&amp;width=555.0000610351562" alt="image.png"><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面</span><br><span class="line">LPUSH key value [value ...] </span><br><span class="line"># 将一个或多个值value插入到key列表的表尾(最右边)</span><br><span class="line">RPUSH key value [value ...]</span><br><span class="line"># 移除并返回key列表的头元素</span><br><span class="line">LPOP key     </span><br><span class="line"># 移除并返回key列表的尾元素</span><br><span class="line">RPOP key </span><br><span class="line"></span><br><span class="line"># 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从<span class="number">0</span>开始</span><br><span class="line">LRANGE key start stop</span><br><span class="line"></span><br><span class="line"># 从key列表表头弹出一个元素，没有就阻塞timeout秒，如果timeout=<span class="number">0</span>则一直阻塞</span><br><span class="line">BLPOP key [key ...] timeout</span><br><span class="line"># 从key列表表尾弹出一个元素，没有就阻塞timeout秒，如果timeout=<span class="number">0</span>则一直阻塞</span><br><span class="line">BRPOP key [key ...] timeout</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>消息队列<br>List 作为消息队列有什么缺陷？<br><strong>List 不支持多个消费者消费同一条消息</strong>，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。<br>要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 <strong>List 类型并不支持消费组的实现</strong>。<br>这就要说起 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。<br>详细内容消息队列在存取消息时，必须要满足三个需求，分别是<strong>消息保序、处理重复的消息和保证消息可靠性</strong>。<br>Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于 List 的消息队列实现方法，后面在介绍 Stream 数据类型时候，在详细说说 Stream。<br><em>1、如何满足消息保序需求？</em><br>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。<br>List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939645629-f4242a8b-38f0-4a97-b21a-9b51fc7245d1.png#averageHue=%23f1f1f1&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=FAotf&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=374&amp;originWidth=1642&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=110824&amp;status=done&amp;style=none&amp;taskId=ue02d2007-a0fe-439f-b5d2-091d7356eb6&amp;title=" alt="image.png"></p><ul><li>生产者使用 LPUSH key value[value…] 将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。</li><li>消费者使用 RPOP key 依次读取队列的消息，先进先出。</li></ul><p>不过，在消费者读取数据时，有一个潜在的性能风险点。<br>在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。<br>所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。<br>为了解决这个问题，Redis提供了 BRPOP 命令。<strong>BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong>。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939645826-4303dd7f-27b4-4cf9-84af-ee9037668f75.png#averageHue=%23fcfafa&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=255&amp;id=UW0z3&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=902&amp;originWidth=1552&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=245237&amp;status=done&amp;style=none&amp;taskId=u9ee4b969-de7c-4d18-a9d4-9d6542adeac&amp;title=&amp;width=438" alt="image.png"><br><em>2、如何处理重复的消息？</em><br>消费者要实现重复消息的判断，需要 2 个方面的要求：</p><ul><li>每个消息都有一个全局的 ID。</li><li>消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。</li></ul><p>但是 <strong>List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID</strong>，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。<br>例如，我们执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：</p><blockquote><p>LPUSH mq “111000102:stock:99” (integer) 1<br><em>3、如何保证消息可靠性？</em><br>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。<br>为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的<strong>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存</strong>。<br>这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。<br>好了，到这里可以知道基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。</p></blockquote><ul><li>消息保序：使用 LPUSH + RPOP；</li><li>阻塞读取：使用 BRPOP；</li><li>重复消息处理：生产者自行实现全局唯一 ID；</li><li>消息的可靠性：使用 BRPOPLPUSH</li></ul><h3 id="③hash"><a href="#③hash" class="headerlink" title="③hash"></a>③hash</h3><p><strong>介绍</strong><br>Hash 是一个键值对（key - value）集合，其中 value 的形式入： value=[{field1，value1}，…{fieldN，valueN}]。Hash 特别适合用于存储对象。<br>Hash 与 String 对象的区别如下图所示:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939806927-1cadf805-359c-4d93-bbbf-4d414c979018.png#averageHue=%239bd465&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=297&amp;id=u45a599ba&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=888&amp;originWidth=1240&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=182966&amp;status=done&amp;style=none&amp;taskId=u61e54fd7-59ce-4a29-bbc1-898a56d8928&amp;title=&amp;width=415" alt="image.png"><br><strong>内部实现</strong><br>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p><ul><li>如果<strong>哈希类型元素个数</strong>小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li><li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的 底层数据结构。</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。<br><strong>常用命令</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 存储一个哈希表key的键值</span><br><span class="line">HSET key field value   </span><br><span class="line"># 获取哈希表key对应的field键值</span><br><span class="line">HGET key field</span><br><span class="line"></span><br><span class="line"># 在一个哈希表key中存储多个键值对</span><br><span class="line">HMSET key field value [field value...] </span><br><span class="line"># 批量获取哈希表key中多个field键值</span><br><span class="line">HMGET key field [field ...]       </span><br><span class="line"># 删除哈希表key中的field键值</span><br><span class="line">HDEL key field [field ...]    </span><br><span class="line"></span><br><span class="line"># 返回哈希表key中field的数量</span><br><span class="line">HLEN key       </span><br><span class="line"># 返回哈希表key中所有的键值</span><br><span class="line">HGETALL key </span><br><span class="line"></span><br><span class="line"># 为哈希表key中field键的值加上增量n</span><br><span class="line">HINCRBY key field n             </span><br></pre></td></tr></table></figure><br><strong>应用场景 </strong><br>以购物车为例，用户id设为key，购物车里的<strong>所有商品</strong>就是用户key对应的值了，每个商品有商品id和购买数量</p><h3 id="④set"><a href="#④set" class="headerlink" title="④set"></a>④set</h3><p><strong>介绍</strong><br>Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。</p><blockquote><p>一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。</p></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657939997662-15e15598-a722-4a03-8e62-f6f156d78732.png#averageHue=%23fcf6f6&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=295&amp;id=uca82cf4c&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=654&amp;originWidth=1268&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=167910&amp;status=done&amp;style=none&amp;taskId=u1d97a284-3564-4d8a-a62d-9c77d8de711&amp;title=&amp;width=571.0000610351562" alt="image.png"><br>Set 类型和 List 类型的区别如下：</p><ul><li>List 可以存储重复元素，Set 只能存储非重复元素；</li><li>List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。</li></ul><p><strong>内部实现</strong><br>Set 类型的底层数据结构是由<strong>整数集合或哈希表</strong>实现的：</p><ul><li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li><li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li></ul><p><strong>常用命令</strong><br>set常用操作<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 往集合key中存入元素，元素存在则忽略，若key不存在则新建</span><br><span class="line">SADD key member [member ...]</span><br><span class="line"># 从集合key中删除元素</span><br><span class="line">SREM key member [member ...] </span><br><span class="line"># 获取集合key中所有元素</span><br><span class="line">SMEMBERS key</span><br><span class="line"># 获取集合key中的元素个数</span><br><span class="line">SCARD key</span><br><span class="line"></span><br><span class="line"># 判断member元素是否存在于集合key中</span><br><span class="line">SISMEMBER key member</span><br><span class="line"></span><br><span class="line"># 从集合key中随机选出count个元素，元素不从key中删除</span><br><span class="line">SRANDMEMBER key [count]</span><br><span class="line"># 从集合key中随机选出count个元素，元素从key中删除</span><br><span class="line">SPOP key [count]</span><br></pre></td></tr></table></figure><br>set集合操作<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 交集运算</span><br><span class="line">SINTER key [key ...]</span><br><span class="line"># 将交集结果存入新集合destination中</span><br><span class="line">SINTERSTORE destination key [key ...]</span><br><span class="line"></span><br><span class="line"># 并集运算</span><br><span class="line">SUNION key [key ...]</span><br><span class="line"># 将并集结果存入新集合destination中</span><br><span class="line">SUNIONSTORE destination key [key ...]</span><br><span class="line"></span><br><span class="line"># 差集运算</span><br><span class="line">SDIFF key [key ...]</span><br><span class="line"># 将差集结果存入新集合destination中</span><br><span class="line">SDIFFSTORE destination key [key ...]</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>集合的主要几个特性，无序、不可重复、支持并交差等操作。</p><blockquote><p>因此 Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。<br>但是要提醒你一下，这里有一个潜在的风险。<strong>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞</strong>。<br>在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。</p></blockquote><p>点赞<br>Set 类型可以保证一个用户只能点一个赞。<br>补充这里举例子一个场景，key 是文章id，value 是用户id。<br>uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。<br> uid:1 用户对文章 article:1 点赞 </p><blockquote><p>SADD article:1 uid:1 (integer) 1<br> uid:2 用户对文章 article:1 点赞<br>SADD article:1 uid:2 (integer) 1<br> uid:3 用户对文章 article:1 点赞<br>SADD article:1 uid:3 (integer) 1<br>uid:1 取消了对 article:1 文章点赞。<br>SREM article:1 uid:1 (integer) 1<br>获取 article:1 文章所有点赞用户 :<br>SMEMBERS article:1 1) “uid:3” 2) “uid:2”<br>获取 article:1 文章的点赞用户数量：<br>SCARD article:1 (integer) 2<br>判断用户 uid:1 是否对文章 article:1 点赞了：<br>SISMEMBER article:1 uid:1 (integer) 0   返回0说明没点赞，返回1则说明点赞了<br>共同关注<br>Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。<br>补充key 可以是用户id，value 则是已关注的公众号的id。<br>uid:1 用户关注公众号 id 为 5、6、7、8、9，uid:2 用户关注公众号 id 为 7、8、9、10、11。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># uid:1 用户关注公众号 id 为 5、6、7、8、9</span></span><br><span class="line">&gt; SADD uid:<span class="number">1</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span></span><br><span class="line">(integer) <span class="number">5</span></span><br><span class="line"><span class="meta"># uid:2  用户关注公众号 id 为 7、8、9、10、11</span></span><br><span class="line">&gt; SADD uid:<span class="number">2</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span></span><br><span class="line">(integer) <span class="number">5</span></span><br></pre></td></tr></table></figure><br>uid:1 和 uid:2 共同关注的公众号：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 获取共同关注</span><br><span class="line">&gt; SINTER uid:<span class="number">1</span> uid:<span class="number">2</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;7&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;8&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;9&quot;</span></span><br></pre></td></tr></table></figure><br>给 uid:2 推荐 uid:1 关注的公众号：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; SDIFF uid:<span class="number">1</span> uid:<span class="number">2</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;5&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;6&quot;</span></span><br></pre></td></tr></table></figure><br>验证某个公众号是否同时被 uid:1 或 uid:2 关注:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; SISMEMBER uid:<span class="number">1</span> <span class="number">5</span></span><br><span class="line">(integer) <span class="number">1</span> # 返回<span class="number">0</span>，说明关注了</span><br><span class="line">&gt; SISMEMBER uid:<span class="number">2</span> <span class="number">5</span></span><br><span class="line">(integer) <span class="number">0</span> # 返回<span class="number">0</span>，说明没关注</span><br></pre></td></tr></table></figure><br>抽奖活动<br>存储某活动中中奖的用户名 ，Set 类型因为有去重功能，<strong>可以保证同一个用户不会中奖两次。</strong><br>补充key为抽奖活动名，value为员工名称，把所有员工名称放入抽奖箱 ：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;SADD lucky Tom Jerry John Sean Marry Lindy Sary <span class="title function_">Mark</span></span><br><span class="line"><span class="params">(integer)</span> 5</span><br></pre></td></tr></table></figure><br>如果允许重复中奖，可以使用 SRANDMEMBER 命令。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 抽取 <span class="number">1</span> 个一等奖：</span><br><span class="line">&gt; SRANDMEMBER lucky <span class="number">1</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Tom&quot;</span></span><br><span class="line"># 抽取 <span class="number">2</span> 个二等奖：</span><br><span class="line">&gt; SRANDMEMBER lucky <span class="number">2</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Mark&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Jerry&quot;</span></span><br><span class="line"># 抽取 <span class="number">3</span> 个三等奖：</span><br><span class="line">&gt; SRANDMEMBER lucky <span class="number">3</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Sary&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Tom&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;Jerry&quot;</span></span><br></pre></td></tr></table></figure><br>如果不允许重复中奖，可以使用 SPOP 命令。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 抽取一等奖<span class="number">1</span>个</span><br><span class="line">&gt; SPOP lucky <span class="number">1</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Sary&quot;</span></span><br><span class="line"># 抽取二等奖<span class="number">2</span>个</span><br><span class="line">&gt; SPOP lucky <span class="number">2</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Jerry&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Mark&quot;</span></span><br><span class="line"># 抽取三等奖<span class="number">3</span>个</span><br><span class="line">&gt; SPOP lucky <span class="number">3</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;John&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Sean&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;Lindy&quot;</span></span><br></pre></td></tr></table></figure></p><h3 id="⑤zset"><a href="#⑤zset" class="headerlink" title="⑤zset"></a>⑤zset</h3><p><strong>介绍</strong></p></blockquote><ul><li>Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。</li><li>有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657940423210-938acfac-fe08-45a8-a694-78cff315db1a.png#averageHue=%23fcf9f9&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=241&amp;id=u25df2dcd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=616&amp;originWidth=1226&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=114856&amp;status=done&amp;style=none&amp;taskId=u14077ca3-3454-4e54-848e-743dc0190e1&amp;title=&amp;width=480.00006103515625" alt="image.png"><br><strong>内部实现</strong><br>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p><ul><li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong><br><strong>常用命令</strong><br>Zset 常用操作：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 往有序集合key中加入带分值元素</span><br><span class="line">ZADD key score member [[score member]...]   </span><br><span class="line"># 往有序集合key中删除元素</span><br><span class="line">ZREM key member [member...]                 </span><br><span class="line"># 返回有序集合key中元素member的分值</span><br><span class="line">ZSCORE key member</span><br><span class="line"># 返回有序集合key中元素个数</span><br><span class="line">ZCARD key </span><br><span class="line"></span><br><span class="line"># 为有序集合key中元素member的分值加上increment</span><br><span class="line">ZINCRBY key increment member </span><br><span class="line"></span><br><span class="line"># 正序获取有序集合key从start下标到stop下标的元素</span><br><span class="line">ZRANGE key start stop [WITHSCORES]</span><br><span class="line"># 倒序获取有序集合key从start下标到stop下标的元素</span><br><span class="line">ZREVRANGE key start stop [WITHSCORES]</span><br><span class="line"></span><br><span class="line"># 返回有序集合中指定分数区间内的成员，分数由低到高排序。</span><br><span class="line">ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]</span><br><span class="line"></span><br><span class="line"># 返回指定成员区间内的成员，按字典正序排列, 分数必须相同。</span><br><span class="line">ZRANGEBYLEX key min max [LIMIT offset count]</span><br><span class="line"># 返回指定成员区间内的成员，按字典倒序排列, 分数必须相同</span><br><span class="line">ZREVRANGEBYLEX key max min [LIMIT offset count]</span><br></pre></td></tr></table></figure><br>Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积</span><br><span class="line">ZUNIONSTORE destkey numberkeys key [key...] </span><br><span class="line"># 交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积</span><br><span class="line">ZINTERSTORE destkey numberkeys key [key...]</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>Zset 类型（Sorted Set，有序集合） 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。<br>在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set。<br>排行榜<br>有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。<br>例子我们以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># arcticle:1 文章获得了200个赞</span></span><br><span class="line">&gt; ZADD user:xiaolin:ranking <span class="number">200</span> arcticle:<span class="number">1</span></span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="meta"># arcticle:2 文章获得了40个赞</span></span><br><span class="line">&gt; ZADD user:xiaolin:ranking <span class="number">40</span> arcticle:<span class="number">2</span></span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="meta"># arcticle:3 文章获得了100个赞</span></span><br><span class="line">&gt; ZADD user:xiaolin:ranking <span class="number">100</span> arcticle:<span class="number">3</span></span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="meta"># arcticle:4 文章获得了50个赞</span></span><br><span class="line">&gt; ZADD user:xiaolin:ranking <span class="number">50</span> arcticle:<span class="number">4</span></span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="meta"># arcticle:5 文章获得了150个赞</span></span><br><span class="line">&gt; ZADD user:xiaolin:ranking <span class="number">150</span> arcticle:<span class="number">5</span></span><br><span class="line">(integer) <span class="number">1</span></span><br></pre></td></tr></table></figure><br>文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZINCRBY user:xiaolin:ranking <span class="number">1</span> arcticle:<span class="number">4</span></span><br><span class="line"><span class="string">&quot;51&quot;</span></span><br></pre></td></tr></table></figure><br>查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZSCORE user:xiaolin:ranking arcticle:<span class="number">4</span></span><br><span class="line"><span class="string">&quot;50&quot;</span></span><br></pre></td></tr></table></figure><br>获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># WITHSCORES 表示把 score 也显示出来</span><br><span class="line">&gt; ZREVRANGE user:xiaolin:ranking <span class="number">0</span> <span class="number">2</span> WITHSCORES</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;arcticle:1&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;200&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;arcticle:5&quot;</span></span><br><span class="line"><span class="number">4</span>) <span class="string">&quot;150&quot;</span></span><br><span class="line"><span class="number">5</span>) <span class="string">&quot;arcticle:3&quot;</span></span><br><span class="line"><span class="number">6</span>) <span class="string">&quot;100&quot;</span></span><br></pre></td></tr></table></figure><br>获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYSCORE user:xiaolin:ranking <span class="number">100</span> <span class="number">200</span> WITHSCORES</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;arcticle:3&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;100&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;arcticle:5&quot;</span></span><br><span class="line"><span class="number">4</span>) <span class="string">&quot;150&quot;</span></span><br><span class="line"><span class="number">5</span>) <span class="string">&quot;arcticle:1&quot;</span></span><br><span class="line"><span class="number">6</span>) <span class="string">&quot;200&quot;</span></span><br></pre></td></tr></table></figure><br>补充电话、姓名排序<br>使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序，我们以 ZRANGEBYLEX （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。<br><strong>注意：不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。</strong><br><em>1、电话排序</em><br>我们可以将电话号码存储到 SortSet 中，然后根据需要来获取号段：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZADD phone <span class="number">0</span> <span class="number">13100111100</span> <span class="number">0</span> <span class="number">13110114300</span> <span class="number">0</span> <span class="number">13132110901</span> </span><br><span class="line">(integer) <span class="number">3</span></span><br><span class="line">&gt; ZADD phone <span class="number">0</span> <span class="number">13200111100</span> <span class="number">0</span> <span class="number">13210414300</span> <span class="number">0</span> <span class="number">13252110901</span> </span><br><span class="line">(integer) <span class="number">3</span></span><br><span class="line">&gt; ZADD phone <span class="number">0</span> <span class="number">13300111100</span> <span class="number">0</span> <span class="number">13310414300</span> <span class="number">0</span> <span class="number">13352110901</span> </span><br><span class="line">(integer) <span class="number">3</span></span><br></pre></td></tr></table></figure><br>获取所有号码:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX phone - +</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;13100111100&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;13110114300&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;13132110901&quot;</span></span><br><span class="line"><span class="number">4</span>) <span class="string">&quot;13200111100&quot;</span></span><br><span class="line"><span class="number">5</span>) <span class="string">&quot;13210414300&quot;</span></span><br><span class="line"><span class="number">6</span>) <span class="string">&quot;13252110901&quot;</span></span><br><span class="line"><span class="number">7</span>) <span class="string">&quot;13300111100&quot;</span></span><br><span class="line"><span class="number">8</span>) <span class="string">&quot;13310414300&quot;</span></span><br><span class="line"><span class="number">9</span>) <span class="string">&quot;13352110901&quot;</span></span><br></pre></td></tr></table></figure><br>获取 132 号段的号码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX phone [<span class="number">132</span> (<span class="number">133</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;13200111100&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;13210414300&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;13252110901&quot;</span></span><br></pre></td></tr></table></figure><br>获取132、133号段的号码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX phone [<span class="number">132</span> (<span class="number">134</span></span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;13200111100&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;13210414300&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;13252110901&quot;</span></span><br><span class="line"><span class="number">4</span>) <span class="string">&quot;13300111100&quot;</span></span><br><span class="line"><span class="number">5</span>) <span class="string">&quot;13310414300&quot;</span></span><br><span class="line"><span class="number">6</span>) <span class="string">&quot;13352110901&quot;</span></span><br></pre></td></tr></table></figure><br><em>2、姓名排序</em><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; zadd names <span class="number">0</span> Toumas <span class="number">0</span> Jake <span class="number">0</span> Bluetuo <span class="number">0</span> Gaodeng <span class="number">0</span> Aimini <span class="number">0</span> Aidehua </span><br><span class="line">(integer) <span class="number">6</span></span><br></pre></td></tr></table></figure><br>获取所有人的名字:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX names - +</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Aidehua&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Aimini&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;Bluetuo&quot;</span></span><br><span class="line"><span class="number">4</span>) <span class="string">&quot;Gaodeng&quot;</span></span><br><span class="line"><span class="number">5</span>) <span class="string">&quot;Jake&quot;</span></span><br><span class="line"><span class="number">6</span>) <span class="string">&quot;Toumas&quot;</span></span><br></pre></td></tr></table></figure><br>获取名字中大写字母A开头的所有人：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX names [A (B</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Aidehua&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Aimini&quot;</span></span><br></pre></td></tr></table></figure><br>获取名字中大写字母 C 到 Z 的所有人：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; ZRANGEBYLEX names [C [Z</span><br><span class="line"><span class="number">1</span>) <span class="string">&quot;Gaodeng&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;Jake&quot;</span></span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;Toumas&quot;</span></span><br></pre></td></tr></table></figure></p><hr><p>新数据类型<br>详细内容## 新数据类型<br>为什么会出现这三种类型：<br>涉及到亿级数据的收集+统计<br>亿级系统中常见的四种统计：</p><h3 id="聚合统计："><a href="#聚合统计：" class="headerlink" title="聚合统计："></a>聚合统计：</h3><p>所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。</p><h3 id="排序统计："><a href="#排序统计：" class="headerlink" title="排序统计："></a>排序统计：</h3><p><strong>这就要求集合类型能对元素保序</strong>，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。<br>在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），List 和 Sorted Set 就属于有序集合。<br><strong>List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序</strong>，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。</p><h3 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h3><p>集合元素的取值就只有0和1两种。在钉钉上班签到打卡的场景中，我们只用记录有签到(1)或没签到(0)</p><h3 id="基数统计："><a href="#基数统计：" class="headerlink" title="基数统计："></a>基数统计：</h3><p>基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV。<br>网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。<br>我们来结合一个例子看一看用 Set 的情况。<br>有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中：<br>SADD page1:uv user1<br>用户 1 再来访问时，Set 的去重功能就保证了不会重复记录用户 1 的访问次数，这样，用户 1 就算是一个独立访客。当你需要统计 UV 时，可以直接用 SCARD 命令，这个命令会返回一个集合中的元素个数。<br>但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。<br>当然，你也可以用 Hash 类型记录 UV。<br>例如，你可以把用户 ID 作为 Hash 集合的 key，当用户访问页面时，就用 HSET 命令（用于设置 Hash 集合元素的值），对这个用户 ID 记录一个值“1”，表示一个独立访客，用户 1 访问 page1 后，我们就记录为 1 个独立访客，如下所示：</p><p>HSET page1:uv user1 1<br>即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记为 1 个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数。<br>但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？<br>这时候，就要用到 Redis 提供的 HyperLogLog 了。<br>HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。<br>在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。<br>在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。<br>PFADD page1:uv user1 user2 user3 user4 user5<br>接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。<br>PFCOUNT page1:uv</p><p>不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>我把 Set、Sorted Set、Hash、List、Bitmap、HyperLogLog 的支持情况和优缺点汇总在了下面的表格里，希望你把这张表格保存下来，时不时地复习一下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651908314109-381291db-53fd-4c7a-a948-5fc3f2976a17.png#clientId=u3acb0c99-da74-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Zb3hH&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1739&amp;originWidth=2866&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=2463682&amp;status=done&amp;style=none&amp;taskId=uc3c9203f-42af-41c6-86ef-dcd6f55bdd1&amp;title=" alt="image.png"><br>可以看到，Set 和 Sorted Set 都支持多种聚合统计，不过，对于差集计算来说，只有 Set 支持。Bitmap 也能做多个 Bitmap 间的聚合计算，包括与、或和异或操作。<br>当需要进行排序统计时，List 中的元素虽然有序，但是一旦有新元素插入，原来的元素在 List 中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而 Sorted Set 本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。<br>如果我们记录的数据只有 0 和 1 两个值的状态，Bitmap 会是一个很好的选择，这主要归功于 Bitmap 对于一个数据只用 1 个 bit 记录，可以节省内存。<br>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用 HyperLogLog。<br>当然，Redis 的应用场景非常多，这张表中的总结不一定能覆盖到所有场景。我建议你也试着自己画一张表，把你遇到的其他场景添加进去。长久积累下来，你一定能够更加灵活地把集合类型应用到合适的实践项目中。</p><h3 id="⑥bitmap"><a href="#⑥bitmap" class="headerlink" title="⑥bitmap"></a>⑥bitmap</h3><p><strong>介绍</strong></p><ul><li>Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。</li><li>由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用<strong>二值统计的场景</strong>。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657940963212-c134f267-4e86-40be-9173-9a22a84a4e20.png#averageHue=%23efefef&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua14d8168&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=144&amp;originWidth=1500&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=45914&amp;status=done&amp;style=none&amp;taskId=u6b8db264-a8db-473c-95a4-3b990d1fcef&amp;title=" alt="image.png"><br><strong>内部实现</strong><br>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。<br>String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。<br><strong>常用命令</strong><br>bitmap 基本操作：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 设置值，其中value只能是 <span class="number">0</span> 和 <span class="number">1</span></span><br><span class="line">SETBIT key offset value</span><br><span class="line"></span><br><span class="line"># 获取值</span><br><span class="line">GETBIT key offset</span><br><span class="line"></span><br><span class="line"># 获取指定范围内值为 <span class="number">1</span> 的个数</span><br><span class="line"><span class="meta"># start 和 end 以字节为单位</span></span><br><span class="line">BITCOUNT key start end</span><br></pre></td></tr></table></figure><br>bitmap 运算操作：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># BitMap间的运算</span><br><span class="line"><span class="meta"># operations 位移操作符，枚举值</span></span><br><span class="line">  AND 与运算 &amp;</span><br><span class="line">  OR 或运算 |</span><br><span class="line">  XOR 异或 ^</span><br><span class="line">  NOT 取反 ~</span><br><span class="line"><span class="meta"># result 计算的结果，会存储在该key中</span></span><br><span class="line"># key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key</span><br><span class="line"># 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 <span class="number">0</span>。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。</span><br><span class="line">BITOP [operations] [result] [key1] [keyn…]</span><br><span class="line"></span><br><span class="line"># 返回指定key中第一次出现指定value(<span class="number">0</span>/<span class="number">1</span>)的位置</span><br><span class="line">BITPOS [key] [value]</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。<br>签到统计<br>在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。<br>签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。<br>补充假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。<br>第一步，执行下面的命令，记录该用户 6 月 3 号已签到。<br>SETBIT uid:sign:100:202206 2 1<br>第二步，检查该用户 6 月 3 日是否签到。<br>GETBIT uid:sign:100:202206 2<br>第三步，统计该用户在 6 月份的签到次数。<br>BITCOUNT uid:sign:100:202206<br>这样，我们就知道该用户在 6 月份的签到情况了。<br>如何统计这个月首次打卡时间呢？<br>Redis 提供了 BITPOS key bitValue [start] [end]指令，返回数据表示 Bitmap 中第一个值为 bitValue 的 offset 位置。<br>在默认情况下， 命令将检测整个位图， 用户可以通过可选的 start 参数和 end 参数指定要检测的范围。所以我们可以通过执行这条命令来获取 userID = 100 在 2022 年 6 月份<strong>首次打卡</strong>日期：<br>BITPOS uid:sign:100:202206 1<br>需要注意的是，因为 offset 从 0 开始的，所以我们需要将返回的 value + 1 。<br>判断用户登陆态<br>Bitmap 提供了 GETBIT、SETBIT 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。<br>只需要一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 GETBIT判断对应的用户是否在线。 50000 万 用户只需要 6 MB 的空间。<br>假如我们要判断 ID = 10086 的用户的登陆情况：<br>第一步，执行以下指令，表示用户已登录。<br>SETBIT login_status 10086 1<br>第二步，检查该用户是否登陆，返回值 1 表示已登录。<br>GETBIT login_status 10086<br>第三步，登出，将 offset 对应的 value 设置成 0。<br>SETBIT login_status 10086 0<br>连续签到用户总数<br>补充如何统计出这连续 7 天连续打卡用户总数呢？<br>我们把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。<br>key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。<br>一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit = 1 就说明该用户 7 天连续打卡。<br>结果保存到一个新 Bitmap 中，我们再通过 BITCOUNT 统计 bit = 1 的个数便得到了连续打卡 3 天的用户总数了。<br>Redis 提供了 BITOP operation destkey key [key …]这个指令用于对一个或者多个 key 的 Bitmap 进行位元操作。</p><ul><li>opration 可以是 and、OR、NOT、XOR。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。</li></ul><p>举个例子，比如将三个 bitmap 进行 AND 操作，并将结果保存到 destmap 中，接着对 destmap 执行 BITCOUNT 统计。<br> 与操作 BITOP AND destmap bitmap:01 bitmap:02 bitmap:03  统计 bit 位 =  1 的个数 BITCOUNT destmap<br>即使一天产生一个亿的数据，Bitmap 占用的内存也不大，大约占 12 MB 的内存（10^8/8/1024/1024），7 天的 Bitmap 的内存开销约为 84 MB。同时我们最好给 Bitmap 设置过期时间，让 Redis 删除过期的打卡数据，节省内存。</p><h3 id="⑦hyperloglog"><a href="#⑦hyperloglog" class="headerlink" title="⑦hyperloglog"></a>⑦hyperloglog</h3><p><strong>介绍</strong></p><ul><li>Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。</li><li>所以，简单来说 HyperLogLog <strong>提供不精确的去重计数</strong>。</li></ul><p>通过牺牲准确率来换取空间，对于不要求绝对准确率的场景下可以使用，因为概率算法不直接存储数据本身，通过一定的概率统计方法预估基数值，同时保证误差在一定范围内，由于又不储存数据故此可以大大节约内存。</p><blockquote><p>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。<br>在 Redis 里面，<strong>每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数</strong>，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。</p></blockquote><p><strong>内部实现</strong><br>HyperLogLog 的实现涉及到很多数学问题，太费脑子了，我也没有搞懂，如果你想了解一下，课下可以看看这个：<a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog(opens new window)</a>。<br><strong> 原理说明：</strong>只是进行不重复的基数统计，不是集合也不保存数据，只记录数量而不是具体的内容。<br>HyperLogLog就是一种概率算法的实现。<br><strong>常见命令</strong><br>HyperLogLog 命令很少，就三个。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 添加指定元素到 HyperLogLog 中</span><br><span class="line">PFADD key element [element ...]</span><br><span class="line"></span><br><span class="line"># 返回给定 HyperLogLog 的基数估算值。</span><br><span class="line">PFCOUNT key [key ...]</span><br><span class="line"></span><br><span class="line"># 将多个 HyperLogLog 合并为一个 HyperLogLog</span><br><span class="line">PFMERGE destkey sourcekey [sourcekey ...]</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>百万级网页 UV 计数<br>Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。<br>所以，非常适合统计百万级以上的网页 UV 的场景。</p><blockquote><p>在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。<br>PFADD page1:uv user1 user2 user3 user4 user5<br>接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。<br>PFCOUNT page1:uv<br>不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。<br>这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</p></blockquote><p><strong>为什么redis集群的最大槽数是16384个？</strong><br>(1)如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。浪费带宽<br>在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。 当槽位为65536时，这块的大小是: 65536÷8÷1024=8kb<br>因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。<br>(2)redis的集群主节点数量基本不可能超过1000个。<br>集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。(因为16384/2=8192  8192/8/1024=1，所以使用16384的槽位刚刚好)<br>(3)槽位越小，节点少的情况下，压缩比高，容易传输</p><h3 id="⑧GEO"><a href="#⑧GEO" class="headerlink" title="⑧GEO"></a>⑧GEO</h3><p><strong>介绍</strong><br>Redis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。<br>在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。<br><strong>内部实现</strong><br>GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。<br>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。<br>这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。<br><strong>常用命令</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。</span><br><span class="line">GEOADD key longitude latitude member [longitude latitude member ...]</span><br><span class="line"></span><br><span class="line"># 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。</span><br><span class="line">GEOPOS key member [member ...]</span><br><span class="line"></span><br><span class="line"># 返回两个给定位置之间的距离。</span><br><span class="line">GEODIST key member1 member2 [m|km|ft|mi]</span><br><span class="line"></span><br><span class="line"># 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。</span><br><span class="line">GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]</span><br></pre></td></tr></table></figure><br><strong>应用场景</strong><br>滴滴叫车<br>这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。<br>假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。<br>执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：<br>GEOADD cars:locations 116.034579 39.030452 33<br>当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。<br>例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。<br>GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10</p><h3 id="👌⑨Stream"><a href="#👌⑨Stream" class="headerlink" title="👌⑨Stream"></a>👌⑨Stream</h3><p><strong>介绍</strong><br>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。</p><p>在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p><ul><li>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；</li><li>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</li></ul><p>基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。<br><strong>常见命令</strong><br>Stream 消息队列操作命令：</p><ul><li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li><li>XLEN ：查询消息长度；</li><li>XREAD：用于读取消息，可以按 ID 读取数据；</li><li>XDEL ： 根据消息 ID 删除消息；</li><li>DEL ：删除整个 Stream；</li><li>XRANGE ：读取区间消息</li><li>XREADGROUP：按消费组形式读取消息；</li><li>XPENDING 和 XACK：<ul><li>XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；</li><li>XACK 命令用于向消息队列确认消息处理已完成；</li></ul></li></ul><p><strong>应用场景</strong><br>消息队列<br>生产者通过 XADD 命令插入一条消息：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># * 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID</span><br><span class="line"># 往名称为 mymq 的消息队列中插入一条消息，消息的键是 name，值是 xiaolin</span><br><span class="line">&gt; XADD mymq * name xiaolin</span><br><span class="line"><span class="string">&quot;1654254953808-0&quot;</span></span><br></pre></td></tr></table></figure><br>插入成功后会返回全局唯一的 ID：”1654254953808-0”。消息的全局唯一 ID 由两部分组成：</p><ul><li>第一部分“1654254953808”是数据插入时，以毫秒为单位计算的当前服务器时间；</li><li>第二部分表示插入消息在当前毫秒内的消息序号，这是从 0 开始编号的。例如，“1654254953808-0”就表示在“1654254953808”毫秒内的第 1 条消息。</li></ul><p>消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取（注意是输入消息 ID 的下一条信息开始读取，不是查询输入ID的消息）。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 从 ID 号为 <span class="number">1654254953807</span><span class="number">-0</span> 的消息开始，读取后续的所有消息（示例中一共 <span class="number">1</span> 条）。</span><br><span class="line">&gt; XREAD STREAMS mymq <span class="number">1654254953807</span><span class="number">-0</span></span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654254953808-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;xiaolin&quot;</span></span><br></pre></td></tr></table></figure><br>如果<strong>想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项</strong>，实现类似于 BRPOP 的阻塞读取操作。<br>比如，下面这命令，设置了 BLOCK 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 命令最后的“$”符号表示读取最新的消息</span><br><span class="line">&gt; XREAD BLOCK <span class="number">10000</span> STREAMS mymq $</span><br><span class="line">(nil)</span><br><span class="line">(<span class="number">10.00</span>s)</span><br></pre></td></tr></table></figure><br>Stream 的基础方法，使用 xadd 存入消息和 xread 循环阻塞读取消息的方式可以实现简易版的消息队列，交互流程如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657941776181-dc798275-e90c-4044-aa87-62cfbb410458.png#averageHue=%23ebebeb&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9b9159bb&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=123&amp;originWidth=577&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=26096&amp;status=done&amp;style=none&amp;taskId=u39feb68e-2677-4c73-ae88-58976febc64&amp;title=" alt="image.png"><br>前面介绍的这些操作 List 也支持的，接下来看看 Stream 特有的功能。<br>Stream 可以以使用 <strong>XGROUP 创建消费组</strong>，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。<br>创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个名为 group1 的消费组，<span class="number">0</span><span class="number">-0</span> 表示从第一条消息开始读取。</span><br><span class="line">&gt; XGROUP CREATE mymq group1 <span class="number">0</span><span class="number">-0</span></span><br><span class="line">OK</span><br><span class="line"># 创建一个名为 group2 的消费组，<span class="number">0</span><span class="number">-0</span> 表示从第一条消息开始读取。</span><br><span class="line">&gt; XGROUP CREATE mymq group2 <span class="number">0</span><span class="number">-0</span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure><br>消费组 group1 内的消费者 consumer1 从 mymq 消息队列中读取所有消息的命令如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 命令最后的参数“&gt;”，表示从第一条尚未被消费的消息开始读取。</span><br><span class="line">&gt; XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654254953808-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;xiaolin&quot;</span></span><br></pre></td></tr></table></figure><br><strong>消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息</strong>。<br>比如说，我们执行完刚才的 XREADGROUP 命令后，再执行一次同样的命令，此时读到的就是空值了：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><br>但是，<strong>不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）</strong>。<br>比如说，刚才 group1 消费组里的 consumer1 消费者消费了一条 id 为 1654254953808-0 的消息，现在用 group2 消费组里的 consumer1 消费者消费消息：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; XREADGROUP GROUP group2 consumer1 STREAMS mymq &gt;</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654254953808-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;xiaolin&quot;</span></span><br></pre></td></tr></table></figure><br>因为我创建两组的消费组都是从第一条消息开始读取，所以可以看到第二组的消费者依然可以消费 id 为 1654254953808-0 的这一条消息。因此，不同的消费组的消费者可以消费同一条消息。<br>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。<br>例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 让 group2 中的 consumer1 从 mymq 消息队列中消费一条消息</span><br><span class="line">&gt; XREADGROUP GROUP group2 consumer1 COUNT <span class="number">1</span> STREAMS mymq &gt;</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654254953808-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;xiaolin&quot;</span></span><br><span class="line"># 让 group2 中的 consumer2 从 mymq 消息队列中消费一条消息</span><br><span class="line">&gt; XREADGROUP GROUP group2 consumer2 COUNT <span class="number">1</span> STREAMS mymq &gt;</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654256265584-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;xiaolincoding&quot;</span></span><br><span class="line"># 让 group2 中的 consumer3 从 mymq 消息队列中消费一条消息</span><br><span class="line">&gt; XREADGROUP GROUP group2 consumer3 COUNT <span class="number">1</span> STREAMS mymq &gt;</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;mymq&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654256271337-0&quot;</span></span><br><span class="line">         <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line">            <span class="number">2</span>) <span class="string">&quot;Tom&quot;</span></span><br></pre></td></tr></table></figure><br>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？<br>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。<br>消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657941776237-e25d7b00-e3fe-4826-922d-3d9371c9650b.png#averageHue=%23fcfcfc&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u82e18720&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=482&amp;originWidth=1170&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=96365&amp;status=done&amp;style=none&amp;taskId=ub690502f-37bb-4c52-9b11-a7d49fed4cd&amp;title=" alt="image.png"><br>如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，<strong>消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息</strong>。<br>例如，我们来查看一下 group2 中各个消费者已读取、但尚未确认的消息个数，命令如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; XPENDING mymq group2</span><br><span class="line"><span class="number">1</span>) (integer) <span class="number">3</span></span><br><span class="line"><span class="number">2</span>) <span class="string">&quot;1654254953808-0&quot;</span>  # 表示 group2 中所有消费者读取的消息最小 ID</span><br><span class="line"><span class="number">3</span>) <span class="string">&quot;1654256271337-0&quot;</span>  # 表示 group2 中所有消费者读取的消息最大 ID</span><br><span class="line"><span class="number">4</span>) <span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;consumer1&quot;</span></span><br><span class="line">      <span class="number">2</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;consumer2&quot;</span></span><br><span class="line">      <span class="number">2</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line">   <span class="number">3</span>) <span class="number">1</span>) <span class="string">&quot;consumer3&quot;</span></span><br><span class="line">      <span class="number">2</span>) <span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure><br>如果想查看某个消费者具体读取了哪些数据，可以执行下面的命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查看 group2 里 consumer2 已从 mymq 消息队列中读取了哪些消息</span><br><span class="line">&gt; XPENDING mymq group2 - + <span class="number">10</span> consumer2</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;1654256265584-0&quot;</span></span><br><span class="line">   <span class="number">2</span>) <span class="string">&quot;consumer2&quot;</span></span><br><span class="line">   <span class="number">3</span>) (integer) <span class="number">410700</span></span><br><span class="line">   <span class="number">4</span>) (integer) <span class="number">1</span></span><br></pre></td></tr></table></figure><br>可以看到，consumer2 已读取的消息的 ID 是 1654256265584-0。<br><strong>一旦消息 1654256265584-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除</strong>。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; XACK mymq group2 <span class="number">1654256265584</span><span class="number">-0</span></span><br><span class="line">(integer) <span class="number">1</span></span><br></pre></td></tr></table></figure><br>当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; XPENDING mymq group2 - + <span class="number">10</span> consumer2</span><br><span class="line">(empty <span class="built_in">array</span>)</span><br></pre></td></tr></table></figure><br>好了，基于 Stream 实现的消息队列就说到这里了，小结一下：</p><ul><li>消息保序：XADD/XREAD</li><li>阻塞读取：XREAD block</li><li>重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；</li><li>消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；</li><li>支持消费组形式消费数据</li></ul><p>Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？<br>一个专业的消息队列，必须要做到两大块：</p><ul><li>消息不丢。</li><li>消息可堆积。</li></ul><p><em>1、Redis Stream 消息会丢失吗？</em><br>使用一个消息队列，其实就分为三大块：<strong>生产者、队列中间件、消费者</strong>，所以要保证消息就是保证三个环节都不能丢失数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657941776245-13f308ac-fec6-40d0-87f9-a4b8e254cbfd.png#averageHue=%23eddbda&amp;clientId=u0e0f5fcd-dcf9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uea17c3de&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=396&amp;originWidth=1494&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=116441&amp;status=done&amp;style=none&amp;taskId=u2cb5fbea-e319-481c-8300-1b060809b8b&amp;title=" alt="image.png"><br>Redis Stream 消息队列能不能保证三个环节都不丢失数据？</p><ul><li>Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。 从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。</li><li>Redis 消费者会不会丢消息？不会，因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。</li><li>Redis 消息中间件会不会丢消息？<strong>会</strong>，Redis 在以下 2 个场景下，都会导致数据丢失：<ul><li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li><li>主从复制也是异步的，<a href="https://xiaolincoding.com/redis/cluster/master_slave_replication.html#redis-%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1">主从切换时，也存在丢失数据的可能(opens new window)</a>。</li></ul></li></ul><p>可以看到，Redis 在队列中间件环节无法保证消息不丢。像 RabbitMQ 或 Kafka 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。<br><em>2、Redis Stream 消息可堆积吗？</em><br>Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。<br>所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。<br>当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。<br>但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。<br>因此，把 Redis 当作队列来使用时，会面临的 2 个问题：</p><ul><li>Redis 本身可能会丢数据；</li><li>面对消息挤压，内存资源会紧张；</li></ul><p>所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：</p><ul><li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li><li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li></ul><p>补充：Redis 发布/订阅机制为什么不可以作为消息队列？<br>发布订阅机制存在以下缺点，都是跟丢失数据有关：</p><ol><li>发布/订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布/订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布/订阅机制的数据也会全部丢失。</li><li>发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。</li><li>当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 client-output-buffer-limit pubsub 32mb 8mb 60。</li></ol><p>所以，发布/订阅机制只适合即使通讯的场景，比如<a href="https://xiaolincoding.com/redis/cluster/sentinel.html#%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%84%E6%88%90%E7%9A%84">构建哨兵集群(opens new window)</a>的场景采用了发布/订阅机制。</p><h2 id="Ⅱredis数据结构"><a href="#Ⅱredis数据结构" class="headerlink" title="Ⅱredis数据结构"></a>Ⅱredis数据结构</h2><p>注意，<strong>Redis 数据结构并不是指 String（字符串）对象、List（列表）对象、Hash（哈希）对象、Set（集合）对象和 Zset（有序集合）对象，因为这些是 Redis 键值对中值的数据类型，也就是数据的保存形式，这些对象的底层实现的方式就用到了数据结构</strong>。<br>我画了一张 Redis 数据类型（也叫 Redis 对象）和底层数据结构的对应关图，左边是 Redis 3.0版本的，也就是《Redis 设计与实现》这本书讲解的版本，现在看还是有点过时了，右边是现在 Github 最新的 Redis 代码的（还未发布正式版本）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042150021-b5d246c7-19ee-464b-85e1-5f2f224bc038.png#averageHue=%23faf7ed&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=360&amp;id=u64594139&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=830&amp;originWidth=1352&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=94050&amp;status=done&amp;style=none&amp;taskId=u926c332e-b7f4-4f9c-a7ed-5f73258b5f1&amp;title=&amp;width=586.0000610351562" alt="image.png"></p><h3 id="我们平时说redis是字典数据库KV键值对到底是什么"><a href="#我们平时说redis是字典数据库KV键值对到底是什么" class="headerlink" title="我们平时说redis是字典数据库KV键值对到底是什么"></a>我们平时说redis是字典数据库KV键值对到底是什么</h3><ol><li>redis 是 key-value 存储系统，其中key类型一般为字符串，value 类型则为redis对象(redisObject)</li><li>Redis定义了<strong>redisObjec结构体</strong>来表示string、hash、list、set、zset等数据类型，Redis 中每个对象都是一个 redisObject 结构</li></ol><p><strong>redisObjec结构的作用：</strong></p><ul><li>为了便于操作，Redis采用redisObjec结构来统一五种不同的数据类型，这样所有的数据类型就都可以以相同的形式在函数间传递而不用使用特定的类型结构。</li><li>同时，为了识别不同的数据类型，redisObjec中定义了type和encoding字段对不同的数据类型加以区别。简单地说，redisObject就是string、hash、list、set、zset的父类。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648361437557-b6066b96-a526-491b-94b4-c3fd7c4cbf84.png#averageHue=%23eeeeee&amp;clientId=u4da6a76f-331d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=289&amp;id=Ohd84&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=361&amp;originWidth=628&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=70592&amp;status=done&amp;style=none&amp;taskId=u3bf40ddc-8a65-4f6b-acae-da085504213&amp;title=&amp;width=502.4" alt="image.png"></p><ol><li>每个键值对都会有一个dictEntry(源码位置：dict.h)，里面指向了key和value的指针，next 指向下一个 dictEntry。key 是字符串，但是 Redis 没有直接使用 C 的字符数组，而是存储在redis自定义的 SDS中。value 既不是直接作为字符串存储，也不是直接存储在 SDS 中，而是存储在redisObject 中。</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1648361313947-02064ffa-9620-43d0-b3fb-5e904c6b4876.png#averageHue=%23afacaa&amp;clientId=u4da6a76f-331d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=355&amp;id=rUQrm&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=444&amp;originWidth=621&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=83069&amp;status=done&amp;style=none&amp;taskId=u7a84d8da-35ba-4b5d-8844-78595dbd13e&amp;title=&amp;width=496.8" alt="image.png"></p><h3 id="👌键值对数据库是怎么实现的？"><a href="#👌键值对数据库是怎么实现的？" class="headerlink" title="👌键值对数据库是怎么实现的？"></a>👌键值对数据库是怎么实现的？</h3><p>这些键值对是如何保存在 Redis 中的呢？<br>Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。<br>Redis 的哈希桶是怎么保存键值对数据的呢？<br>哈希桶存放的是指向键值对数据的指针（dictEntry<em>），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void </em> key 和 void <em> value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void </em> value 指针找到。<br>补充在开始讲数据结构之前，先给介绍下 Redis 是怎样实现键值对（key-value）数据库的。<br>Redis 的键值对中的 key 就是字符串对象，而 <strong>value 可以是字符串对象，也可以是集合数据类型的对象</strong>，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。<br>举个例子，我这里列出几种 Redis 新增键值对的命令：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; SET name <span class="string">&quot;xiaolincoding&quot;</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&gt; HSET person name <span class="string">&quot;xiaolincoding&quot;</span> age <span class="number">18</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"></span><br><span class="line">&gt; RPUSH stu <span class="string">&quot;xiaolin&quot;</span> <span class="string">&quot;xiaomei&quot;</span></span><br><span class="line">(integer) <span class="number">4</span></span><br></pre></td></tr></table></figure><br>这些命令代表着：</p><ul><li>第一条命令：name 是一个<strong>字符串键</strong>，因为键的<strong>值是一个字符串对象</strong>；</li><li>第二条命令：person 是一个<strong>哈希表键</strong>，因为键的<strong>值是一个包含两个键值对的哈希表对象</strong>；</li><li>第三条命令：stu 是一个<strong>列表键</strong>，因为键的<strong>值是一个包含两个元素的列表对象</strong>；</li></ul><p>我这里画了一张 Redis 保存键值对所涉及到的数据结构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042276185-f1ceaeac-c70f-401f-be78-6cc703f801d5.png#averageHue=%23f9f6f3&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Gch75&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=662&amp;originWidth=1637&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=127108&amp;status=done&amp;style=none&amp;taskId=u0ce52ac2-e76f-4a93-b7fe-237ce751e0f&amp;title=" alt="image.png"><br>这些数据结构的内部细节，我先不展开讲，后面在讲哈希表数据结构的时候，在详细的说说，因为用到的数据结构是一样的。这里先大概说下图中涉及到的数据结构的名字和用途：</p><ul><li>redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针；</li><li>dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用，具体什么是 rehash，我在本文的哈希表数据结构会讲；</li><li>ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；</li><li>dictEntry 结构，表示哈希表节点的结构，结构里存放了 <em>*void </em> key 和 void * value 指针， <em>key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象</em>。</li></ul><p>特别说明下，void <em> key 和 void </em> value 指针指向的是 <strong>Redis 对象</strong>，Redis 中的每个对象都由 redisObject 结构表示，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042276078-21083371-6795-40d0-8233-743716e0d48b.png#averageHue=%23eff2df&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=415&amp;id=ujSNY&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=587&amp;originWidth=647&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54078&amp;status=done&amp;style=none&amp;taskId=u85c1f966-bcee-4b88-b9bd-4d9ebf0bc37&amp;title=&amp;width=457" alt="image.png"><br>对象结构里包含的成员变量：</p><ul><li>type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；</li><li>encoding，标识该对象使用了哪种底层的数据结构；</li><li><strong>ptr，指向底层数据结构的指针</strong>。</li></ul><p>我画了一张 Redis 键值对数据库的全景图，你就能清晰知道 Redis 对象和数据结构的关系了：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042276275-b708a542-6342-455c-8f57-bcd5c5191412.png#averageHue=%23f8f5ed&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=EPE90&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=684&amp;originWidth=1889&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=189181&amp;status=done&amp;style=none&amp;taskId=ude84c003-892c-4197-9604-14b4598a01f&amp;title=" alt="image.png"><br>接下里，就好好聊一下底层数据结构！</p><h3 id="①SDS"><a href="#①SDS" class="headerlink" title="①SDS"></a>①SDS</h3><ul><li>字符串在 Redis 中是很常用的，键值对中的键是字符串类型，值有时也是字符串类型。</li><li>Redis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串，也就是 Redis 的 String 数据类型的底层数据结构是 SDS。</li></ul><p><strong>C 语言字符串的缺陷</strong><br>补充既然 Redis 设计了 SDS 结构来表示字符串，肯定是 C 语言的 char<em> 字符数组存在一些缺陷。<br>要了解这一点，得先来看看 char</em> 字符数组的结构。<br>C 语言的字符串其实就是一个字符数组，即数组中每个元素是字符串中的一个字符。<br>比如，下图就是字符串“xiaolin”的 char* 字符数组的结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042615477-f80a045f-d2b2-442a-9322-9d837fd1a41f.png#averageHue=%23e5e7ee&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=zShzv&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=182&amp;originWidth=482&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=17158&amp;status=done&amp;style=none&amp;taskId=u3eeb4e15-c9eb-45aa-a23b-c2f24caaa65&amp;title=" alt="image.png"></p><ul><li>在 C 语言里，对字符串操作时，char <em> 指针只是指向字符数组的起始位置，而<em>*字符数组的结尾位置就用“\0”表示，意思是指字符串的结束</em></em>。</li><li>因此，C 语言标准库中的字符串操作函数就通过判断字符是不是 “\0” 来决定要不要停止操作，如果当前字符不是 “\0” ，说明字符串还没结束，可以继续操作，如果当前字符是 “\0” 是则说明字符串结束了，就要停止操作。</li></ul><p>举个例子，C 语言获取字符串长度的函数 strlen，就是通过字符数组中的每一个字符，并进行计数，等遇到字符为 “\0” 后，就会停止遍历，然后返回已经统计到的字符个数，即为字符串长度。下图显示了 strlen 函数的执行流程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042615584-6484bbab-f2da-4a65-a708-85a0938dd701.png#averageHue=%231e1918&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=384&amp;id=j1MyN&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=542&amp;originWidth=602&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=31811&amp;status=done&amp;style=none&amp;taskId=u98987a53-8ed3-402d-9c3f-9bfbd238d94&amp;title=&amp;width=427" alt="image.png"><br>很明显，<strong>C 语言获取字符串长度的时间复杂度是 O（N）（<em>这是一个可以改进的地方</em></strong>）<br>C 语言字符串用 “\0” 字符作为结尾标记有个缺陷。假设有个字符串中有个 “\0” 字符，这时在操作这个字符串时就会<strong>提早结束</strong>，比如 “xiao\0lin” 字符串，计算字符串长度的时候则会是 4，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042615756-9a19fae1-a08e-40c5-afdc-a970e82f3e47.png#averageHue=%230d0b0a&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=UVR2j&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=542&amp;originWidth=557&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=33477&amp;status=done&amp;style=none&amp;taskId=u765c2f73-cb57-4d42-a816-1ac6e154850&amp;title=" alt="image.png"><br>因此，除了字符串的末尾之外，<strong>字符串里面不能含有 “\0” 字符</strong>，否则最先被程序读入的 “\0” 字符将被误认为是字符串结尾，这个限制使得 C 语言的字符串只能保存文本数据，<strong>不能保存像图片、音频、视频文化这样的二进制数据（<em>这也是一个可以改进的地方</em>）</strong><br>另外， C 语言标准库中字符串的操作函数是很不安全的，对程序员很不友好，稍微一不注意，就会导致缓冲区溢出。<br>举个例子，strcat 函数是可以将两个字符串拼接在一起。<br><strong>C 语言的字符串是不会记录自身的缓冲区大小的</strong>，所以 strcat 函数假定程序员在执行这个函数时，已经为 dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容，而<strong>一旦这个假定不成立，就会发生缓冲区溢出将可能会造成程序运行终止，（<em>这是一个可以改进的地方</em></strong>）。<br>而且，strcat 函数和 strlen 函数类似，时间复杂度也很高，也都需要先通过遍历字符串才能得到目标字符串的末尾。然后对于 strcat 函数来说，还要再遍历源字符串才能完成追加，<strong>对字符串的操作效率不高</strong>。</p><ul><li>获取字符串长度的时间复杂度为 O（N）；</li><li>字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；</li><li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；</li></ul><p>Redis 实现的 SDS 的结构就把上面这些问题解决了，接下来我们一起看看 Redis 是如何解决的。<br><strong>SDS 结构设计</strong><br>补充下图就是 Redis 5.0 的 SDS 的数据结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042615507-a5516be9-ccc3-4316-91b1-3f248fb59846.png#averageHue=%23eaeaea&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=toQQd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=347&amp;originWidth=407&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=27511&amp;status=done&amp;style=none&amp;taskId=u84a772d5-c0e4-4a43-87d5-036c5fb8faa&amp;title=" alt="image.png"><br>结构中的每个成员变量分别介绍下：</p><ul><li><strong>len，记录了字符串长度</strong>。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。</li><li><strong>alloc，分配给字符数组的空间长度</strong>。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li><li><strong>flags，用来表示不同类型的 SDS</strong>。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。</li><li><strong>buf[]，字符数组，用来保存实际数据</strong>。不仅可以保存字符串，也可以保存二进制数据。</li></ul><p>总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。<br><strong>O（1）复杂度获取字符串长度</strong><br>Redis 的 SDS 结构因为加入了 len 成员变量，那么<strong>获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）</strong>。<br><strong>二进制安全</strong></p><ul><li>因为 SDS 不需要用 “\0” 字符来标识字符串结尾了，而是<strong>有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据</strong>。</li><li>因此， SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。</li><li>通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。</li></ul><p><strong>不会发生缓冲区溢出</strong></p><ul><li>Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 alloc - len 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。<ul><li>而且，<strong>当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容）</strong>，以满足修改所需的大小。</li></ul></li><li>这样的好处是，能<strong>有效的减少内存分配次数</strong>。</li><li>所以，使用 SDS 即不需要手动修改 SDS 的空间大小，也不会出现缓冲区溢出的问题。</li></ul><p><strong>节省内存空间</strong><br>补充SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。<br>Redis 一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。<br>这 5 种类型的主要<strong>区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同</strong>。<br>比如 sdshdr16 和 sdshdr32 这两个类型，它们的定义分别如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr16</span> &#123;</span></span><br><span class="line">    <span class="type">uint16_t</span> len;</span><br><span class="line">    <span class="type">uint16_t</span> alloc; </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags; </span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr32</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> len;</span><br><span class="line">    <span class="type">uint32_t</span> alloc; </span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags;</span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><br>可以看到：</p><ul><li>sdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。</li><li>sdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。</li></ul><p><strong>之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间</strong>。比如，在保存小字符串时，结构头占用空间也比较少。<br>除了设计不同类型的结构体，Redis 在编程上还<strong>使用了专门的编译优化来节省内存空间</strong>，即在 struct 声明了 <strong>attribute</strong> ((packed)) ，它的作用是：<strong>告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐</strong>。<br>比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 2 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 2 个字节，编译器也会给它分配 2 个字节。<br>举个例子，假设下面这个结构体，它有两个成员变量，类型分别是 char 和 int，如下所示：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">test1</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line"> &#125; test1;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test1));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>大家猜猜这个结构体大小是多少？我先直接说答案，这个结构体大小计算出来是 8。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042615650-20bcda21-7372-4281-829d-12b6bb1baf79.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PqAZd&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=182&amp;originWidth=542&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=16013&amp;status=done&amp;style=none&amp;taskId=u7d6b2945-3bec-466a-aec1-dd520577792&amp;title=" alt="image.png"><br>这是因为默认情况下，编译器是使用「字节对齐」的方式分配内存，虽然 char 类型只占一个字节，但是由于成员变量里有 int 类型，它占用了 4 个字节，所以在成员变量为 char 类型分配内存时，会分配 4 个字节，其中这多余的 3 个字节是为了字节对齐而分配的，相当于有 3 个字节被浪费掉了。<br>如果不想编译器使用字节对齐的方式进行分配内存，可以采用了 <strong>attribute</strong> ((packed)) 属性定义结构体，这样一来，结构体实际占用多少内存空间，编译器就分配多少空间。<br>比如，我用 <strong>attribute</strong> ((packed)) 属性定义下面的结构体 ，同样包含 char 和 int 两个类型的成员变量，代码如下所示：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span>((<span class="title">packed</span>)) <span class="title">test2</span>  &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line"> &#125; test2;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test2));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这时打印的结果是 5（1 个字节 char + 4 字节 int）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658042616693-62b8d731-5772-4fff-9252-649e0b2b6cf5.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=XjB2h&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=197&amp;originWidth=309&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=11033&amp;status=done&amp;style=none&amp;taskId=u4d38d2af-f3ee-4cb8-9067-764ebc8d551&amp;title=" alt="image.png"><br>可以看得出，这是按照实际占用字节数进行分配内存的，这样可以节省内存空间。</p><h3 id="②链表"><a href="#②链表" class="headerlink" title="②链表"></a>②链表</h3><p>Redis 的 List 对象的底层实现之一就是链表。C 语言本身没有链表这个数据结构的，所以 Redis 自己设计了一个链表数据结构。<br><strong>链表节点结构设计</strong>先来看看「链表节点」结构的样子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//前置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="comment">//后置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="comment">//节点的值</span></span><br><span class="line">    <span class="type">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure><br>有前置节点和后置节点，可以看的出，这个是一个双向链表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043573311-993176a4-e204-42b4-b572-03a6242e2015.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=a9BcE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=272&amp;originWidth=1127&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=22478&amp;status=done&amp;style=none&amp;taskId=udb23db4d-4c94-4204-885c-3c1d5745736&amp;title=" alt="image.png"><br><strong>链表结构设计</strong><br>不过，Redis 在 listNode 结构体基础上又封装了 list 这个数据结构，这样操作起来会更方便，链表结构如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span></span><br><span class="line">    <span class="comment">//链表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">//链表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">//节点值复制函数</span></span><br><span class="line">    <span class="type">void</span> *(*dup)(<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">//节点值释放函数</span></span><br><span class="line">    <span class="type">void</span> (*<span class="built_in">free</span>)(<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">//节点值比较函数</span></span><br><span class="line">    <span class="type">int</span> (*match)(<span class="type">void</span> *ptr, <span class="type">void</span> *key);</span><br><span class="line">    <span class="comment">//链表节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;</span><br><span class="line">&#125; <span class="built_in">list</span>;</span><br></pre></td></tr></table></figure><br>list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。<br>举个例子，下面是由 list 结构和 3 个 listNode 结构组成的链表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043573354-a3c72484-26d3-469f-b2fe-11adf72e0589.png#averageHue=%23f9f3f2&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1044e508&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=512&amp;originWidth=1449&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48956&amp;status=done&amp;style=none&amp;taskId=uf811a283-9c25-403a-b41e-793f07f0cd4&amp;title=" alt="image.png"><br><strong>链表的优势与缺陷</strong><br>Redis 的链表实现优点如下：</p><ul><li>listNode 链表节点的结构里带有 prev 和 next 指针，<strong>获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表</strong>；</li><li>list 结构因为提供了表头指针 head 和表尾节点 tail，所以<strong>获取链表的表头节点和表尾节点的时间复杂度只需O(1)</strong>；</li><li>list 结构因为提供了链表节点数量 len，所以<strong>获取链表中的节点数量的时间复杂度只需O(1)</strong>；</li><li>listNode 链表节使用 void<em> 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<em>*链表节点可以保存各种不同类型的值</em></em>；</li></ul><p>链表的缺陷也是有的：</p><ul><li>链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong>。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。</li><li>还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong>。<blockquote><ul><li>因此，Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。</li><li>不过，压缩列表存在性能问题（具体什么问题，下面会说），所以 Redis 在 3.2 版本设计了新的数据结构 quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。</li><li>然后在 Redis 5.0 设计了新的数据结构 listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis 版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由 listpack 实现。</li></ul></blockquote></li></ul><h3 id="③压缩列表"><a href="#③压缩列表" class="headerlink" title="③压缩列表"></a>③压缩列表</h3><p>压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。</p><p>接下来，就跟大家详细聊下压缩列表。<br><strong>压缩列表结构设计</strong><br>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong>，有点类似于数组。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043820515-e0b71a13-751f-4e75-890c-934b60a01310.png#averageHue=%23cce1ca&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue5abc222&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=62&amp;originWidth=962&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=12885&amp;status=done&amp;style=none&amp;taskId=ubbda3dcc-cca2-49b8-9a4b-971e5a6d008&amp;title=" alt="image.png"><br><strong>压缩列表具体字段</strong>（了解即可）压缩列表在表头有三个字段：</p><ul><li><em><strong>zlbytes</strong></em>，记录整个压缩列表占用对内存字节数；</li><li><em><strong>zltail</strong></em>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</li><li><em><strong>zllen</strong></em>，记录压缩列表包含的节点数量；</li><li><em><strong>zlend</strong></em>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li></ul><p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而<strong>查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素</strong>。<br>另外，压缩列表节点（entry）的构成如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043820396-22c35dae-6e5f-4dec-984f-d7f44694b8b4.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ziyZE&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=302&amp;originWidth=962&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28590&amp;status=done&amp;style=none&amp;taskId=ufd779b8c-bddc-4b8c-a386-7736d0f0e7a&amp;title=" alt="image.png"><br>压缩列表节点包含三部分内容：</p><ul><li><em><strong>prevlen</strong></em>，记录了「前一个节点」的长度；</li><li><em><strong>encoding</strong></em>，记录了当前节点实际数据的类型以及长度；</li><li><em><strong>data</strong></em>，记录了当前节点的实际数据；</li></ul><p>当我们往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，<strong>这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的</strong>。<br>分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。<br>压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如：</p><ul><li>如果<strong>前一个节点的长度小于 254 字节</strong>，那么 prevlen 属性需要用 <strong>1 字节的空间</strong>来保存这个长度值；</li><li>如果<strong>前一个节点的长度大于等于 254 字节</strong>，那么 prevlen 属性需要用 <strong>5 字节的空间</strong>来保存这个长度值；</li></ul><p>encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关：</p><ul><li>如果<strong>当前节点的数据是整数</strong>，则 encoding 会使用 <strong>1 字节的空间</strong>进行编码。</li><li>如果<strong>当前节点的数据是字符串，根据字符串的长度大小</strong>，encoding 会使用 <strong>1 字节/2字节/5字节的空间</strong>进行编码。</li></ul><p><strong>连锁更新</strong><br>压缩列表除了查找复杂度高的问题，还有一个问题。<br><strong>压缩列表新增某个元素或修改某个元素时，如果空间不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降</strong>。<br>类似多米诺效应<br>连锁更新具体例子前面提到，压缩列表节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配：</p><ul><li>如果前一个<strong>节点的长度小于 254 字节</strong>，那么 prevlen 属性需要用 <strong>1 字节的空间</strong>来保存这个长度值；</li><li>如果前一个<strong>节点的长度大于等于 254 字节</strong>，那么 prevlen 属性需要用 <strong>5 字节的空间</strong>来保存这个长度值；</li></ul><p>现在假设一个压缩列表中有多个连续的、长度在 250～253 之间的节点，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043820338-f4b2261b-a837-480f-8bb2-b6f9125752e7.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=JD7Lm&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=144&amp;originWidth=962&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=18454&amp;status=done&amp;style=none&amp;taskId=u1dd443db-2978-4f59-a651-c272a02537d&amp;title=" alt="image.png"><br>因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值。<br>这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为 e1 的前置节点，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043820390-832d1549-d50a-48ac-8610-0624459becec.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ObAFn&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=204&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=26914&amp;status=done&amp;style=none&amp;taskId=ufdac6009-f34a-4585-83ca-e4222ccefc5&amp;title=" alt="image.png"><br>因为 e1 节点的 prevlen 属性只有 1 个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作，并将 e1 节点的 prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。<br>多米诺牌的效应就此开始。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658043820576-b0b284d6-0813-4398-ae65-066e2631a292.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=blw0a&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=782&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=106165&amp;status=done&amp;style=none&amp;taskId=u01613c1b-b3db-4b10-98c0-0c5979cb6a7&amp;title=" alt="image.png"><br>e1 原本的长度在 250～253 之间，因为刚才的扩展空间，此时 e1 的长度就大于等于 254 了，因此原本 e2 保存 e1 的 prevlen 属性也必须从 1 字节扩展至 5 字节大小。<br>正如扩展 e1 引发了对 e2 扩展一样，扩展 e2 也会引发对 e3 的扩展，而扩展 e3 又会引发对 e4 的扩展…. 一直持续到结尾。<br><strong>这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」</strong>，就像多米诺牌的效应一样，第一张牌倒下了，推动了第二张牌倒下；第二张牌倒下，又推动了第三张牌倒下….，<br><strong>压缩列表的缺陷</strong></p><ul><li>不能保存过多的元素，否则查询效率就会降低；</li><li>新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。</li></ul><p>因此，<strong>压缩列表只会用于保存的节点数量不多的场景</strong>，只要节点数量足够小，即使发生连锁更新，也是能接受的。</p><blockquote><p>虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。</p></blockquote><h3 id="④哈希表"><a href="#④哈希表" class="headerlink" title="④哈希表"></a>④哈希表</h3><p>前置知识Redis 的哈希表结构如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    <span class="comment">//哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;  </span><br><span class="line">    <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">    <span class="comment">//该哈希表已有的节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure><br>可以看到，哈希表是一个数组（dictEntry **table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044114380-11f56602-99c9-497d-92e4-f93cdc10cc3c.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=222&amp;id=yKDK2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=587&amp;originWidth=1052&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60736&amp;status=done&amp;style=none&amp;taskId=ua9ebf31e-b21a-4cd5-afb9-67108e299ba&amp;title=&amp;width=397" alt="image.png"><br>哈希表节点的结构如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="comment">//键值对中的键</span></span><br><span class="line">    <span class="type">void</span> *key;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//键值对中的值</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *val;</span><br><span class="line">        <span class="type">uint64_t</span> u64;</span><br><span class="line">        <span class="type">int64_t</span> s64;</span><br><span class="line">        <span class="type">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure></p><blockquote><p>dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。<br>另外，这里还跟你提一下，dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或double 类的值。这么做的好处是可以节省内存空间，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。</p></blockquote><p><strong>哈希冲突</strong></p><blockquote><p>哈希表实际上是一个数组，数组里多每一个元素就是一个哈希桶。<br>当一个键值对的键经过 Hash 函数计算后得到哈希值，再将(哈希值 % 哈希表大小)取模计算，得到的结果值就是该 key-value 对应的数组元素位置，也就是第几个哈希桶。</p></blockquote><p>什么是哈希冲突呢？<br>补充举个例子，有一个可以存放 8 个哈希桶的哈希表。key1 经过哈希函数计算后，再将「哈希值 % 8 」进行取模计算，结果值为 1，那么就对应哈希桶 1，类似的，key9 和 key10 分别对应哈希桶 1 和桶 6。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044114425-0b5f8060-3931-43e1-8c36-70d3dcdbed38.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=412&amp;id=NmMXM&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=527&amp;originWidth=812&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=80437&amp;status=done&amp;style=none&amp;taskId=uc36d3aaa-f8af-436a-a90d-2f04b34c39b&amp;title=&amp;width=635.0000610351562" alt="image.png"><br>此时，key1 和 key9 对应到了相同的哈希桶中，这就发生了哈希冲突。<br>因此，<strong>当有两个以上数量的 kay 被分配到了哈希表中同一个哈希桶上时，此时称这些 key 发生了冲突。</strong><br><strong>链式哈希</strong><br>Redis 采用了「<strong>链式哈希</strong>」的方法来解决哈希冲突。<br>链式哈希是怎么实现的？</p><ul><li><p>实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，<strong>被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来</strong>，这样就解决了哈希冲突。<br>补充还是用前面的哈希冲突例子，key1 和 key9 经过哈希计算后，都落在同一个哈希桶，链式哈希的话，key1 就会通过 next 指针指向 key9，形成一个单向链表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044114433-1c3bb766-8ac4-41fd-bd95-a7871570f927.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Kmd9q&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=527&amp;originWidth=1067&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=83003&amp;status=done&amp;style=none&amp;taskId=u364acf89-c043-439b-9df0-de834e3d568&amp;title=" alt="image.png"></p></li><li><p>不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。</p></li></ul><p>要想解决这一问题，就需要进行 rehash，也就是对哈希表的大小进行扩展。<br>接下来，看看 Redis 是如何实现的 rehash 的。<br><strong>rehash</strong><br>哈希表结构设计的这一小节，我给大家介绍了 Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了<strong>两个哈希表（ht[2]）</strong>。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">    …</span><br><span class="line">    <span class="comment">//两个Hash表，交替使用，用于rehash操作</span></span><br><span class="line">    dictht ht[<span class="number">2</span>]; </span><br><span class="line">    …</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure><br>之所以定义了 2 个哈希表，是因为进行 rehash 的时候，需要用上 2 个哈希表了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044114380-62609414-004e-42ec-af81-3608ee4536b7.png#averageHue=%23fbf4f1&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub14ea007&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=699&amp;originWidth=1502&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=97406&amp;status=done&amp;style=none&amp;taskId=uf91ccff5-c1ad-4c8d-96cc-864bb68a68d&amp;title=" alt="image.png"><br>在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。<br>随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：</p><ul><li><strong>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；</strong></li><li><strong>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</strong></li><li><strong>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。</strong><blockquote><p>为了方便你理解，我把 rehash 这三个过程画在了下面这张图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044114433-fef44fe0-ff63-445c-9e96-05d805309f44.png#averageHue=%23f8f6f0&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=314&amp;id=u39ff3ec6&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=699&amp;originWidth=1344&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=93716&amp;status=done&amp;style=none&amp;taskId=u0c4b5850-690d-466a-9830-6ec4f093ba8&amp;title=&amp;width=603.0000610351562" alt="image.png"></p></blockquote></li></ul><p>这个过程看起来简单，但是其实第二步很有问题，<strong>如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求</strong>。<br><strong>渐进式 rehash</strong><br>为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了<strong>渐进式 rehash</strong>，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。<br>渐进式 rehash 步骤如下：</p><ul><li>给「哈希表 2」 分配空间；</li><li><strong>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li><li>随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。</li></ul><p>这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。</p><p>在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。</p><p>比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p><p>另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。<br><strong>rehash 触发条件</strong><br>介绍了 rehash 那么多，还没说什么时情况下会触发 rehash 操作呢？<br>rehash 的触发条件跟<strong>负载因子（load factor）</strong>有关系。<br>负载因子可以通过下面这个公式计算：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044117324-066cddba-2096-41d6-9f9c-afad2b9b61d9.png#averageHue=%23ead1b4&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u98a26a17&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=77&amp;originWidth=617&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=10325&amp;status=done&amp;style=none&amp;taskId=uac43eae8-86a9-443e-8d1b-e3482798f32&amp;title=" alt="image.png"><br>触发 rehash 操作的条件，主要有两个：</p><ul><li><strong>当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。</strong></li><li><strong>当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。</strong><h3 id="⑤整数集合"><a href="#⑤整数集合" class="headerlink" title="⑤整数集合"></a>⑤整数集合</h3>整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。<br><strong>整数集合结构设计</strong><br>整数集合本质上是一块连续内存空间，它的结构定义如下：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="comment">//编码方式</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;</span><br><span class="line">    <span class="comment">//集合包含的元素数量</span></span><br><span class="line">    <span class="type">uint32_t</span> length;</span><br><span class="line">    <span class="comment">//保存元素的数组</span></span><br><span class="line">    <span class="type">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><blockquote><p>可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如：</p><ul><li>如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t；</li><li>如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t；</li><li>如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t；</li></ul><p>不同类型的 contents 数组，意味着数组的大小也会不同。</p></blockquote></li></ul><p><strong>整数集合的升级操作</strong><br>整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。<br>整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。<br>升级的例子举个例子，假设有一个整数集合里有 3 个类型为 int16_t 的元素。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044596494-5ac5770a-5fad-4c49-a351-72b8d7c29552.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=GwmTF&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=242&amp;originWidth=444&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=19695&amp;status=done&amp;style=none&amp;taskId=u071a4733-430e-4c47-8bf8-45c030aab4a&amp;title=" alt="image.png"><br>现在，往这个整数集合中加入一个新元素 65535，这个新元素需要用 int32_t 类型来保存，所以整数集合要进行升级操作，首先需要为 contents 数组扩容，<strong>在原本空间的大小之上再扩容多 80 位（4x32-3x16=80），这样就能保存下 4 个类型为 int32_t 的元素</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044596613-7173423a-4322-4ea4-8e50-221c4ebd4758.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=LYSQW&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=242&amp;originWidth=924&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28899&amp;status=done&amp;style=none&amp;taskId=uee391570-167f-4fa5-8e04-a21d1c68d60&amp;title=" alt="image.png"><br>扩容完 contents 数组空间大小后，需要将之前的三个元素转换为 int32_t 类型，并将转换后的元素放置到正确的位上面，并且需要维持底层数组的有序性不变，整个转换过程如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044596705-19c46d8a-deb6-401a-9ab1-68ca0edae66e.png#clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=yRfAY&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=1023&amp;originWidth=1097&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=156616&amp;status=done&amp;style=none&amp;taskId=uf2237281-0b13-4c15-82e4-6a611a6b429&amp;title=" alt="image.png"><br>整数集合升级有什么好处呢？</p><blockquote><p>如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。<br>整数集合升级就能避免这种情况，如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组，只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作。</p></blockquote><p>因此，整数集合升级的好处是<strong>节省内存资源</strong>。<br>整数集合支持降级操作吗？<br><strong>不支持降级操作</strong>，一旦对数组进行了升级，就会一直保持升级后的状态。比如前面的升级操作的例子，如果删除了 65535 元素，整数集合的数组还是 int32_t 类型的，并不会因此降级为 int16_t 类型。</p><hr><h3 id="⑥跳表✊"><a href="#⑥跳表✊" class="headerlink" title="⑥跳表✊"></a>⑥跳表✊</h3><p>Redis 只有在 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。<br>Zset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    dict *dict;</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure><br>Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了哈希表进行索引。<br>接下来，详细的说下跳表。<br><strong>跳表结构设计</strong><br>链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。<strong>跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表</strong>，这样的好处是能快读定位数据。跳表的优势是能支持平均 O(logN) 复杂度的节点查找。</p><blockquote><p>那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044596594-e4e9630c-6815-4535-9c56-98a9ced007c6.png#averageHue=%23f8f5f3&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf4a4c6c0&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=287&amp;originWidth=1164&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29556&amp;status=done&amp;style=none&amp;taskId=u4fd97ad4-c98e-4410-94c2-5ed5d72d362&amp;title=" alt="image.png"><br>图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：</p><ul><li>L0 层级共有 5 个节点，分别是节点1、2、3、4、5；</li><li>L1 层级共有 3 个节点，分别是节点 2、3、5；</li><li>L2 层级只有 1 个节点，也就是节点 3 。</li></ul><p>如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。<br>可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。</p></blockquote><hr><p><strong>那跳表节点是怎么实现多层级的呢？</strong><br>这就需要看<strong>「跳表节点」</strong>的数据结构了，如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure></p><ul><li>Zset 对象要同时保存元素和元素的权重，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。</li><li>跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的<strong>zskiplistLevel 结构体类型的 level 数组</strong>。</li><li>level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。<blockquote><p>比如，下面这张图，展示了各个节点的跨度。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044596676-bfb51ef2-7db8-4952-a5c6-9c11d0790334.png#averageHue=%23f5f3f0&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uaaecded5&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=317&amp;originWidth=1947&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=65501&amp;status=done&amp;style=none&amp;taskId=u000df285-cc53-4d74-80c7-6090e5b0ee5&amp;title=" alt="image.png"><br>第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针就可以完成了。<br><strong>跨度实际上是为了计算这个节点在跳表中的排位</strong>。具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。<br>举个例子，查找图中节点 3 在跳表中的排位，从头节点开始查找节点 3，查找的过程只经过了一个层（L3），并且层的跨度是 3，所以节点 3 在跳表中的排位是 3。<br>另外，图中的头节点其实也是 zskiplistNode 跳表节点，只不过头节点的后向指针、权重、元素值都未被用到，所以图中省略了这部分。</p></blockquote></li></ul><p>问题来了，由谁定义哪个跳表节点是头节点呢？这就介绍<strong>「跳表」</strong>结构体了，如下所示：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> length;</span><br><span class="line">    <span class="type">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><br>跳表结构里包含了：</p><ul><li>跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点；</li><li>跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量；</li><li>跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；</li></ul><p><strong>跳表节点查询过程</strong><br>查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：</p><ul><li>如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。</li><li>如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。</li></ul><p>如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。</p><blockquote><p>举个例子，下图有个 3 层级的跳表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044598825-7aa1f4be-2e26-4075-93ee-8727dd574b83.png#averageHue=%23fce6cd&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc80645db&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=437&amp;originWidth=2387&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=238513&amp;status=done&amp;style=none&amp;taskId=u75ccd34f-f4d1-4a4b-92af-0242c8b1bba&amp;title=" alt="image.png"><br>如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：</p><ul><li>先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；</li><li>但是该层的下一个节点是空节点（ leve[2]指向的是空节点），于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];</li><li>「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；</li><li>「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。</li></ul></blockquote><p><strong>跳表节点层数设置</strong><br>跳表的相邻两层的节点数量的比例会影响跳表的查询性能。</p><blockquote><p>举个例子，下图的跳表，第二层的节点数量只有 1 个，而第一层的节点数量有 6 个。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044598734-d7a0545b-75b0-49cf-aa77-28a0316f1a72.png#averageHue=%23faf9f7&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uabbea45d&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=287&amp;originWidth=1524&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=31057&amp;status=done&amp;style=none&amp;taskId=u6141e207-481c-4354-b859-db6828c27e2&amp;title=" alt="image.png"><br>这时，如果想要查询节点 6，那基本就跟链表的查询复杂度一样，就需要在第一层的节点中依次顺序查找，复杂度就是 O(N) 了。所以，为了降低查询复杂度，我们就需要维持相邻层结点数间的关系。<br><strong>跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)</strong>。<br>下图的跳表就是，相邻两层的节点数量的比例是 2 : 1。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044598950-883066cc-46e6-4c02-804d-ffec596f23cc.png#averageHue=%23f8f7f5&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u89d654e4&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=287&amp;originWidth=1532&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=34132&amp;status=done&amp;style=none&amp;taskId=u6fb50f3b-7d45-488d-9a2b-8527e255292&amp;title=" alt="image.png"></p></blockquote><p>那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？跳表何时增加高度</p><ul><li>[ ] 如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。</li><li>[ ] Redis 则采用一种巧妙的方法是，<strong>跳表在创建节点的时候，随机生成每个节点的层数</strong>，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。</li><li>[ ] 具体的做法是，<strong>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</strong>。</li><li>[ ] 这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</li></ul><p>为什么使用跳表不使用红黑树</p><ul><li>按照区间来查找数据这个操作，红黑树的效率没有跳表高。</li><li>跳表代码容易实现，红黑树不容易实现<h3 id="⑦quicklist"><a href="#⑦quicklist" class="headerlink" title="⑦quicklist"></a>⑦quicklist</h3>在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。<br>其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。</li></ul><p>在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。</p><p>quicklist 解决办法，<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。</strong><br><strong>quicklist 结构设计</strong><br>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    <span class="comment">//quicklist的链表头</span></span><br><span class="line">    quicklistNode *head;      <span class="comment">//quicklist的链表头</span></span><br><span class="line">    <span class="comment">//quicklist的链表头</span></span><br><span class="line">    quicklistNode *tail; </span><br><span class="line">    <span class="comment">//所有压缩列表中的总元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> count;</span><br><span class="line">    <span class="comment">//quicklistNodes的个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;       </span><br><span class="line">    ...</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure><br>接下来看看，quicklistNode 的结构定义：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>     <span class="comment">//前一个quicklistNode</span></span><br><span class="line">    <span class="comment">//下一个quicklistNode</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>     <span class="comment">//后一个quicklistNode</span></span><br><span class="line">    <span class="comment">//quicklistNode指向的压缩列表</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zl;              </span><br><span class="line">    <span class="comment">//压缩列表的的字节大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;                </span><br><span class="line">    <span class="comment">//压缩列表的元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;        <span class="comment">//ziplist中的元素个数 </span></span><br><span class="line">    ....</span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure><br>可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。<br>我画了一张图，方便你理解 quicklist 数据结构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044598958-f02fb275-753b-4363-b937-f9cca6da631f.png#averageHue=%23f6f5f2&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud1d28a4e&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=299&amp;originWidth=944&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=26170&amp;status=done&amp;style=none&amp;taskId=uc6369358-e4fc-4436-992f-3ec342f6de5&amp;title=" alt="image.png"><br>在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。<br>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。</p><h3 id="⑧listpack"><a href="#⑧listpack" class="headerlink" title="⑧listpack"></a>⑧listpack</h3><p>quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</p><p>因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。</p><p>于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p><p><strong>我看了 Redis 的 Github，在最新 6.2 发行版本中，Redis Hash 对象、ZSet 对象的底层数据结构的压缩列表还未被替换成 listpack，而 Redis 的最新代码（还未发布版本）已经将所有用到压缩列表底层数据结构的 Redis 对象替换成 listpack 数据结构来实现，估计不久将来，Redis 就会发布一个将压缩列表为 listpack 的发行版本</strong>。<br><strong>listpack 结构设计</strong><br>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。<br>我们先看看 listpack 结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044598948-09753421-ce9a-492b-9f24-b7728d2d8bec.png#averageHue=%238893a2&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9a1aacdf&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=77&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=16885&amp;status=done&amp;style=none&amp;taskId=ua95bf85c-59e1-44e7-9f34-9bec5a2f5e1&amp;title=" alt="image.png"><br>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。<br>每个 listpack 节点结构如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658044600893-ad9ee8f9-4354-40ff-a7c5-5e6ca17cfbaf.png#averageHue=%23faedc8&amp;clientId=ua37e2371-a0dd-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udb3ec698&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=317&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=35709&amp;status=done&amp;style=none&amp;taskId=u5803cdbe-b3d5-4d14-8c20-557e7b03c28&amp;title=" alt="image.png"><br>主要包含三个方面内容：</p><ul><li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li><li>data，实际存放的数据；</li><li>len，encoding+data的总长度；</li></ul><p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p><h1 id="三、布隆过滤器"><a href="#三、布隆过滤器" class="headerlink" title="三、布隆过滤器"></a>三、布隆过滤器</h1><p><strong>①是什么：</strong><br>由一个初值都为零的bit数组和多个哈希函数构成，用来快速判断某个数据是否存在<br><strong>②特点</strong></p><ol><li>高效的插入和查询，占用空间少，返回的结果是不确定的</li><li>一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在。</li><li>布隆过滤器可以添加元素，但是不能删除元素。因为删掉元素会导致误判率增加。</li><li>误判只会发生在过滤器没有添加过的元素，对于添加过的元素不会发生误判。</li></ol><p>结论：有，是可能有，无是肯定无。可以保证的是，如果布隆过滤器判断一个元素不在一个集合中，那这个元素一定不会在集合中<br>Redis实现的布隆过滤器bigkey问题：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。<br><strong>③应用场景</strong></p><ul><li>缓存穿透</li><li>黑名单校验</li></ul><p><strong>④原理：</strong><br><strong>添加key时</strong><br>使用多个hash函数对key进行hash运算得到一个整数索引值，对位数组长度进行取模运算得到一个位置，<br>每个hash函数都会得到一个不同的位置，将这几个位置都置1就完成了add操作。<br><strong>查询key时</strong><br>只要有其中一位是零就表示这个key不存在，但如果都是1，则不一定存在对应的key。<br>结论：<br>有，是可能有<br>无，是肯定无</p><p>这种情况也造成了布隆过滤器的删除问题，因为布隆过滤器的每一个 bit 并不是独占的，很有可能多个元素共享了某一位。<br>优点：高效的插入和查询<br>缺点：不能删除元素。<br>因为删掉元素会导致误判率增加，因为hash冲突同一个位置可能存的东西是多个共有的，<br>你删除一个元素的同时可能也把其它的删除了。<br>存在误判：不同的数据可能hash运算出来的结果一致。<br>布谷鸟过滤器解决了不能删除的问题</p><h1 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h1><h2 id="-2"><a href="#-2" class="headerlink" title=" "></a> </h2>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>HTTP篇</title>
      <link href="/2022/08/09/%E8%AE%A1%E7%BD%91/HTTP%E7%AF%87/"/>
      <url>/2022/08/09/%E8%AE%A1%E7%BD%91/HTTP%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="一、HTTP常见面试题"><a href="#一、HTTP常见面试题" class="headerlink" title="一、HTTP常见面试题"></a>一、HTTP常见面试题</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651461268890-51f432ca-17d6-4cb6-ba01-50d152aa238c.png#averageHue=%23fcf8f4&amp;clientId=u4ab6ccf6-f116-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=674&amp;id=udb823b4b&amp;name=image.png&amp;originHeight=1614&amp;originWidth=1646&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=304651&amp;status=done&amp;style=none&amp;taskId=u250408e1-f272-431b-be2f-356f9b6737a&amp;title=&amp;width=687" alt="image.png"></p><h3 id="ⅠHTTP基本概念"><a href="#ⅠHTTP基本概念" class="headerlink" title="ⅠHTTP基本概念"></a>ⅠHTTP基本概念</h3><h4 id="①HTTP-是什么？"><a href="#①HTTP-是什么？" class="headerlink" title="①HTTP 是什么？"></a>①HTTP 是什么？</h4><p><strong>HTTP </strong>是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和 规范」。</p><h4 id="②HTTP-常⻅的状态码，有哪些？✊"><a href="#②HTTP-常⻅的状态码，有哪些？✊" class="headerlink" title="②HTTP 常⻅的状态码，有哪些？✊"></a>②HTTP 常⻅的状态码，有哪些？✊</h4><p>1xx 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。<br>2xx 类状态码表示服务器<strong>成功</strong>处理了客户端的请求。</p><ul><li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。</li><li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li><li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li></ul><p>3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p><ul><li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li><li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</li></ul><p>301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p><ul><li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li></ul><p>4xx 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p><ul><li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</li><li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</li><li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li></ul><p>5xx 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><ul><li>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li><li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li><li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li><li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。<h4 id="③http报文格式详解✊"><a href="#③http报文格式详解✊" class="headerlink" title="③http报文格式详解✊"></a>③http报文格式详解✊</h4>HTTP有两种报文：请求报文和响应报文。<h5 id="请求报文"><a href="#请求报文" class="headerlink" title="请求报文"></a>请求报文</h5>请求报文由三部分组成：请求行、首部行、空行、实体主体。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650349647173-6cdfa2aa-3f05-428c-865b-662fb20c8247.png#averageHue=%23bcbcbc&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=305&amp;id=u334f2f4b&amp;originHeight=467&amp;originWidth=824&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u697d9ab4-48aa-43ea-84c6-1ba48083c86&amp;title=&amp;width=538" alt=""></li></ul><ol><li><p><strong>请求行</strong></p><p>请求行有三个字段：方法、URL、HTTP版本<br>（1）方法：可以取不同的值，包括GET、POST、HEAD、PUT和DELETE等。绝大部分HTTP请求报文使用GET方法。<br>（2）URL：请求对象的标识。示例中请求对象标识就是：/dir1/dir2/hello.html<br>（3）HTTP版本：略。示例中HTTP版本为1.1。</p></li><li><p><strong>首部行</strong></p></li></ol><p>首部行由多组键值对（首部字段名：首部字段值）组成。下面分析示例：<br>Host：指明请求对象所在主机。示例中主机为www.test.com。<br>Connection：浏览器告知服务器是否使用持续连接。示例中close代表不使用持续连接。</p><blockquote><p>User-agent：指明用户代理，即浏览器类型。示例中浏览器类型为Mozilla/5.0。<br>Accept-language：指明用户希望得到请求对象的语言版本。示例中zh-cn代表中文版本。</p></blockquote><ol><li><strong>空行</strong></li></ol><p>请求头部的最后会有一个空行，表示请求头部结束，接下来为请求数据。</p><ol><li><strong>实体主体（body）</strong></li></ol><ul><li>使用GET方法时，请求数据为空；</li><li>而使用POST方法时才使用请求数据，举例说明：</li></ul><p>当用户提交表单时，HTTP使用POST方法，则实体体内包含的就是用户在表单的输入值。</p><h5 id="响应报文"><a href="#响应报文" class="headerlink" title="响应报文"></a>响应报文</h5><p>响应报文由三部分组成：状态行、首部行、空行、实体体。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650349526695-619f9cda-2401-4fbb-9e58-4b908cde842f.png#averageHue=%23b9b9b9&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=289&amp;id=u55476c58&amp;originHeight=468&amp;originWidth=797&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u1105e6a1-5746-4b88-b84f-2c91d54a147&amp;title=&amp;width=493" alt=""></p><p><strong>1、状态行：</strong><br>状态行有三个字段：状态码及状态信息、HTTP版本<br>（1）HTTP版本：略。<br>（2）状态码及状态信息：下面列出常见状态码及状态信息</p><ul><li>200   OK：请求成功，信息在返回的响应报文中。</li><li>301   Moved Permanently：请求对象被永久转移了，新的URL定义在响应报文的首部行Location中。客户端自动获取新的URL。</li><li>404   Not Found：被请求的文档不在服务器上。</li><li>505   HTTP Version Not Supported：服务器不支持请求报文使用的HTTP协议版本。</li></ul><p><strong>2、首部行</strong><br>同样的，首部行由多组键值对（首部字段名：首部字段值）组成。下面分析示例：<br>Connection：服务器通知客户，发送完报文后是否持续该TCP连接。示例中close代表发送完报文后关闭该TCP连接。<br>Content-Length：被发送对象中的字节数。<br>Content-Type：实体体中对象类型。示例中 text/html 代表HTML文件。<br>Date：服务器产生并发送该响应报文的日期时间。<br>Server：指明产生响应报文的服务器类型，类似于请求报文首部行中User-agent字段。示例中为Apache Web服务器。<br>Last-Modified：对象创建或者最后修改的日期时间。<br><strong>3、实体体</strong><br>服务器响应客户端的数据对象，在请求示例中，请求对象为hello.html，那么该实体体内容就是hello.html。</p><h4 id="④http-常⻅字段有哪些？"><a href="#④http-常⻅字段有哪些？" class="headerlink" title="④http 常⻅字段有哪些？"></a>④http 常⻅字段有哪些？</h4><p><em>Host </em>字段<br>客户端发送请求时，⽤来指定服务器的域名。<br><em>Connection </em>字段<br>Connection 字段最常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。<br>HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 Connection 首部字段的值为 Keep-Alive。<br>Connection: keep-alive<br>一个可以复用的 TCP 连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。<br><em>Content-Length </em>字段<br>服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。<br><em>Content-Type </em>字段<br>Content-Type 字段⽤于服务器回应时，告诉客户端，本次数据是什么格式。<br><em>Content-Encoding </em>字段<br>Content-Encoding 字段说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650349837059-dba81b53-543c-464a-9824-eeebcf0a3f34.png#averageHue=%23f5edd0&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=236&amp;id=u7267e0a4&amp;name=image.png&amp;originHeight=302&amp;originWidth=677&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=127659&amp;status=done&amp;style=none&amp;taskId=uee2f93cd-ec77-4ab8-adbd-2d5f1bd339f&amp;title=&amp;width=530" alt="image.png"><br>Content-Encoding: gzip<br>上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。<br>客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。<br>Accept-Encoding: gzip, deflate</p><h3 id="ⅡGET与POST"><a href="#ⅡGET与POST" class="headerlink" title="ⅡGET与POST"></a>ⅡGET与POST</h3><h4 id="①GET与POST区别"><a href="#①GET与POST区别" class="headerlink" title="①GET与POST区别"></a>①GET与POST区别</h4><p><strong>请方缓产编</strong><br>请求参数—方法的url—缓存—产生的数据包—编码</p><ul><li>GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。</li></ul><p>POST 的语义是根据请求数据对指定的资源做出处理，具体的处理方式视资源类型而不同。POST         不安全，不幂等，（大部分实现）不可缓存。<br>补充注意， 上面是从 RFC 规范定义的语义来分析的。<br>但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：</p><ul><li>可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。</li><li>可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。</li></ul><p>曾经有个笑话，有人写了个博客，删除博客用的是GET请求，他觉得没人访问就连鉴权都没做。然后Google服务器爬虫爬了一遍，他所有博文就没了。。。<br>如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。<br>因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了。<br>所以，要避免传输过程中数据被窃取，就要使用 HTTPS 协议，这样所有 HTTP 的数据都会被加密传输。<br>GET 请求可以带 body 吗？<br>RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。<br>另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。</p><ul><li>GET请求参数通过URL传递，请求的数据会附在 URL 之后（放在请求行中），以 ? 分割 URL 和传输数据，多个参数用 &amp; 连接。POST的参数放在请求体中，因为 POST 方法的请求信息是放置在请求数据中的，所以它的请求信息是没有长度限制的。</li><li>GET 方法的 URL 一般都具有长度限制，但是需要注意的是 HTTP 协议中并未规定 GET 请求的长度。这个长度限制主要是由浏览器和 Web 服务器所决定的，并且各个浏览器对长度的限制也各不相同。</li><li>GET请求会被浏览器主动缓存，而POST不会，除非手动设置。</li><li>GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把请求头和请求体一并发送出去；而对于POST，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体，服务器响应200 ok(返回数据)。</li><li>GET请求只能进行url编码，而POST支持多种编码方式。</li><li>它们都是HTTP 请求协议的请求方法，而 HTTP 又是基于TCP/IP的协议，所以 GET/POST 实际上都是 TCP 链接。区分出来就是为了方便管理。<br>补充&gt; 既然 GET 和 POST 的底层都是 TCP，那么为什么 HTTP 还要特别将它们区分出来呢？<blockquote><p>其实可以想象一下，如果我们直接使用 TCP 进行数据的传输，那么无论是单纯获取资源的请求还是修改服务器资源的请求在外观上看起来都是 TCP 链接，这样就非常不利于进行管理。所以在 HTTP 协议中，就会对这些不同的请求设置不同的类别进行管理，例如单纯获取资源的请求就规定为 GET、修改服务器资源的请求就规定为 POST，并且也对它们的请求报文的格式做出了相应的要求（例如请求参数 GET 位于 URL 而 POST 则位于请求数据中）。</p><p>当然，如果我们想将 GET 的请求参数放置在请求数据中或者将 POST 的请求数据放置在 URL 中，这是完全可以的，虽然这样子做并不符合 HTTP 的规范。但是这样子做是否能得到我们期望的响应数据呢？答案是未必，这取决于服务器的行为。</p><p>以 GET 方法在请求数据中放置请求参数为例，有些服务器会将请求数据中的参数读出，在这种情况下我们依然能获得我们期望的响应数据；而有些服务器则会选择直接忽略，这种情况下我们就无法获取期望的响应数据了。</p><p>所以，对于 GET 和 POST 的区别，总结来说就是：它们的本质都是 TCP 链接，并无区别。但是由于 HTTP 的规定以及浏览器/服务器的限制，导致它们在应用过程中可能会有所不同。</p></blockquote></li></ul><h4 id="②GET-和-POST-方法都是安全和幂等的吗？"><a href="#②GET-和-POST-方法都是安全和幂等的吗？" class="headerlink" title="②GET 和 POST 方法都是安全和幂等的吗？"></a>②GET 和 POST 方法都是安全和幂等的吗？</h4><p>先说明下安全和幂等的概念：</p><ul><li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</li><li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li></ul><p>如果从 RFC 规范定义的语义来看：</p><ul><li><strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，<strong>可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存位书签</strong>。</li><li><p><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。所以，<strong>浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签</strong>。</p><h3 id="ⅢHTTP缓存技术"><a href="#ⅢHTTP缓存技术" class="headerlink" title="ⅢHTTP缓存技术"></a>ⅢHTTP缓存技术</h3><h4 id="①HTTP-缓存有哪些实现方式？"><a href="#①HTTP-缓存有哪些实现方式？" class="headerlink" title="①HTTP 缓存有哪些实现方式？"></a>①HTTP 缓存有哪些实现方式？</h4></li><li><p>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</p></li><li>所以，避免发送 HTTP 请求的方法就是通过<strong>缓存技术</strong>，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的<strong>头部</strong>有不少是针对缓存的字段。</li></ul><p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p><h5 id="强制缓存"><a href="#强制缓存" class="headerlink" title="强制缓存"></a>强制缓存</h5><p><strong>是什么</strong><br>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><blockquote><p>如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650350134003-838915b8-0085-4268-86b9-92031c30c040.png#averageHue=%23f8f2f1&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=158&amp;id=u15dc2301&amp;name=image.png&amp;originHeight=652&amp;originWidth=1882&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=249770&amp;status=done&amp;style=none&amp;taskId=u05288d05-ae47-487f-ab00-92ff676885c&amp;title=&amp;width=457" alt="image.png"></p></blockquote><p><strong>如何实现</strong><br>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p><ul><li>Cache-Control， 是一个相对时间；</li><li>Expires，是一个绝对时间；</li></ul><p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control的优先级高于 Expires</strong> 。</p><p>Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：</p><ul><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li><li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</li><li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。<h5 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h5><strong>是什么</strong><br>在浏览器使用开发者工具的时候，会看到过某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。<blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650350133995-953c7a1c-661b-4714-98e6-31838c551bc6.png#averageHue=%23f7f5f3&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=488&amp;id=u4bab795a&amp;name=image.png&amp;originHeight=1127&amp;originWidth=1017&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=212936&amp;status=done&amp;style=none&amp;taskId=u1445cbec-cb9e-4ffe-b390-c1105540c3f&amp;title=&amp;width=440" alt="image.png"><br>上图就是一个协商缓存的过程，所以<strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p></blockquote></li></ul><p><strong>如何实现</strong><br>协商缓存可以基于两种头部来实现。<br>第一种：<strong>请求头部</strong>中的 If-Modified-Since 字段与<strong>响应头部</strong>中的 Last-Modified 字段实现，这两个字段的意思是：</p><ul><li>响应头部中的 Last-Modified：标示这个响应资源的最后修改时间；</li><li>请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li></ul><p>第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是：</p><ul><li>响应头部中 Etag：唯一标识响应资源；</li><li>请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。<blockquote><p>使用 ETag 字段实现的协商缓存的过程如下；</p><ul><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；</li><li>当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期，如果没有过期，则直接使用本地缓存；如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；</li><li>服务器再次收到请求后，<strong>会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较</strong>：<ul><li><strong>如果值相等，则返回 304 Not Modified，不会返回资源</strong>；</li><li>如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；</li></ul></li><li>如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。</li></ul></blockquote></li></ul><p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。<br>如果 HTTP 响应头部同时有 Etag 和 Last-Modified 字段的时候， Etag 的优先级更高，也就是先会判断 Etag 是否变化了，如果 Etag 没有变化，然后再看 Last-Modified。<br>注意，<strong>协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</strong>。</p><h3 id="ⅣHTTP特性"><a href="#ⅣHTTP特性" class="headerlink" title="ⅣHTTP特性"></a>ⅣHTTP特性</h3><h4 id="①HTTP-1-1-的优点"><a href="#①HTTP-1-1-的优点" class="headerlink" title="①HTTP(1.1) 的优点"></a>①HTTP(1.1) 的优点</h4><p>HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。<br><em>1. </em>简单<br>HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，<br><em>2. </em>灵活和易于扩展 </p><ul><li>HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。 </li><li>同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。 </li><li>HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的 QUIC。 </li></ul><p><em>3. </em>应⽤⼴泛和跨平台<br>互联⽹发展⾄今，HTTP 的应⽤范围⾮常的⼴泛，从台式机的浏览器到⼿机上的各种 APP，从看新闻、刷贴吧到购 物、理财、吃鸡，HTTP 的应⽤⽚地开花，同时天然具有跨平台的优越性。</p><h4 id="②HTTP-1-1-有哪些缺点"><a href="#②HTTP-1-1-有哪些缺点" class="headerlink" title="②HTTP(1.1)有哪些缺点"></a>②HTTP(1.1)有哪些缺点</h4><p><em>1. </em>⽆状态双刃剑 </p><ul><li>⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的 负担。</li><li><p>⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。 </p><blockquote><p>例如登录-&gt;添加购物⻋-&gt;下单-&gt;结算-&gt;⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有 关联的，每次都要问⼀遍身份信息。这样每操作⼀次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！ </p></blockquote></li><li><p>对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ <strong>Cookie </strong>技术。 </p></li><li>Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。 </li></ul><p><em>2. </em>明⽂传输双刃剑<br>通过打开f12控制台或使用抓包工具就可以看见相关的信息了<br>好处：方面阅读信息<br>坏处：信息毫无隐私可言容易被窃取<br><em>3. </em>不安全<br>通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。<br>不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。<br>⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。</p><h4 id="③那你再说下-HTTP-1-1-的性能如何？"><a href="#③那你再说下-HTTP-1-1-的性能如何？" class="headerlink" title="③那你再说下 HTTP/1.1 的性能如何？"></a>③那你再说下 HTTP/1.1 的性能如何？</h4><p>HTTP 协议是基于 <strong>TCP/IP</strong>，并且使⽤了「<strong>请求 - 应答</strong>」的通信模式，所以性能的关键就在这<strong>两点</strong>⾥。 </p><h5 id="1-⻓连接"><a href="#1-⻓连接" class="headerlink" title="1. ⻓连接"></a>1. ⻓连接</h5><ul><li>早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），增加了通信开销。 </li><li>为了解决上述 TCP 连接问题，HTTP/1.1 提出了<strong>⻓连接</strong>的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了 TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。 </li><li>持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。 </li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647566280378-d26a3e66-58e0-4f79-8ec7-f4b2d52fc2fb.png#averageHue=%23f5f3f1&amp;clientId=u8e6115f2-f264-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=356&amp;id=u948e56c2&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=665&amp;originWidth=1030&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=308092&amp;status=done&amp;style=none&amp;taskId=uf1614507-0df2-4ae1-bcac-56a9e66c9f2&amp;title=&amp;width=552" alt="image.png"></p><h5 id="2-管道⽹络传输"><a href="#2-管道⽹络传输" class="headerlink" title="2. 管道⽹络传输"></a>2. 管道⽹络传输</h5><ul><li>即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第 ⼆个请求出去，可以减少整体的响应时间。 </li><li>但是<strong>服务器必须按照接收请求的顺序发送对这些管道化请求的响应</strong>。如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。</li></ul><p>所以，<strong>HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞</strong>。</p><blockquote><p>举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做 出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647566343327-6e0bb876-ddf8-4fb1-bae1-0d9a4c7364b7.png#averageHue=%23faf9f9&amp;clientId=u8e6115f2-f264-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=526&amp;id=ue884eb91&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=658&amp;originWidth=606&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=118755&amp;status=done&amp;style=none&amp;taskId=ua5b2a3e8-513b-4b28-8b7e-78a8b3e4817&amp;title=&amp;width=484.8" alt="image.png"></p></blockquote><h5 id="3-队头阻塞"><a href="#3-队头阻塞" class="headerlink" title="3. 队头阻塞"></a>3. 队头阻塞</h5><p>「请求 - 应答」的模式加剧了 HTTP 的性能问题。<br>因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致 客户端⼀直请求不到数据，这也就是「队头阻塞」。总之 HTTP/1.1 的性能⼀般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647566510331-c7b39b16-1e0c-41e1-b14c-2463637d0b94.png#averageHue=%23f8f4ef&amp;clientId=u8e6115f2-f264-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=579&amp;id=u59fbc366&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=724&amp;originWidth=662&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=168496&amp;status=done&amp;style=none&amp;taskId=u2d52459c-6ba9-4e4a-8438-cecbde4adaa&amp;title=&amp;width=529.6" alt="image.png"></p><h3 id="ⅤHTTPS✊"><a href="#ⅤHTTPS✊" class="headerlink" title="ⅤHTTPS✊"></a>ⅤHTTPS✊</h3><h4 id="①HTTPS-是如何建立连接的？其间交互了什么？https的连接过程"><a href="#①HTTPS-是如何建立连接的？其间交互了什么？https的连接过程" class="headerlink" title="①HTTPS 是如何建立连接的？其间交互了什么？https的连接过程"></a>①HTTPS 是如何建立连接的？其间交互了什么？https的连接过程</h4><p>SSL/TLS 协议基本流程：</p><ul><li>客户端向服务器索要并验证服务器的公钥。</li><li>双方协商生产「会话秘钥」。</li><li>双方采用「会话秘钥」进行加密通信。</li></ul><p>前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。</p><p>SSL/TLS 的「握手阶段」涉及<strong>四次</strong>通信，可见下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652767785192-d07ce5b3-771d-4e60-ace0-1041a3a2d36d.png#averageHue=%23fcf6e5&amp;clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=1303&amp;id=IDwh7&amp;name=image.png&amp;originHeight=2807&amp;originWidth=1545&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1369686&amp;status=done&amp;style=none&amp;taskId=ua8e7b173-1eb1-4f4b-aeb1-a3339c52d2b&amp;title=&amp;width=717" alt="image.png"><br>SSL/TLS 协议建立的详细流程：<br><em>1. ClientHello</em><br>首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。<br>在这一步，客户端主要向服务器发送以下信息：<br>（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。<br>（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。<br>（3）客户端支持的密码套件列表，如 RSA 加密算法。<br><em>2. SeverHello</em><br>服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：<br>（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。<br>（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。<br>（3）确认的密码套件列表，如 RSA 加密算法。<br><strong>（4）服务器的数字证书。</strong><br><em>3.客户端回应</em><br>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。<br>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：<br>（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。<br>（2）<strong>加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</strong><br>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。<br>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。<br><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。<br><em>4. 服务器的最后回应</em><br>服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。<br>然后，向客户端发送最后的信息：<br>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。<br>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。<br>至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><blockquote><p>数字证书的工作流程<br>我也画了一张图，方便大家理解：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658458709449-32dc022a-3d68-4910-888e-823236723513.png#averageHue=%23e1d6a2&amp;clientId=u6dc524c5-d932-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=367&amp;id=n9qle&amp;name=image.png&amp;originHeight=577&amp;originWidth=779&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=362582&amp;status=done&amp;style=none&amp;taskId=ud1415ba0-9255-4a51-910f-12268030aab&amp;title=&amp;width=495.00006103515625" alt="image.png"><br>通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。</p></blockquote><h4 id="②客户端校验数字证书的流程是怎样的？"><a href="#②客户端校验数字证书的流程是怎样的？" class="headerlink" title="②客户端校验数字证书的流程是怎样的？"></a>②客户端校验数字证书的流程是怎样的？</h4><p>接下来，详细说一下实际中数字证书签发和验证流程。<br>如下图图所示，为数字证书签发和验证流程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851948294-29038a02-1356-490c-8a67-5b1c821f3f90.png#averageHue=%23f7f3eb&amp;clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=nUKU9&amp;name=image.png&amp;originHeight=740&amp;originWidth=1337&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=302911&amp;status=done&amp;style=none&amp;taskId=u4ff6ef86-073c-4794-b0a6-fbdae2a7b62&amp;title=" alt="image.png"><br>CA 签发证书的过程，如上图左边部分：</p><ul><li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li><li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature（证书签名），也就是 CA 对证书做了签名；</li><li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li></ul><p>客户端校验服务端的数字证书的过程，如上图右边部分：</p><ul><li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li><li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li><li><p>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。<br>补充但事实上，证书的验证过程中<strong>还存在一个证书信任链的问题</strong>，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851948150-a848c5d0-7f84-479f-81ad-5b867485d0de.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=VXplK&amp;name=image.png&amp;originHeight=217&amp;originWidth=567&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49216&amp;status=done&amp;style=none&amp;taskId=u11e9659d-15db-470c-a9ca-a5c7c4b35ba&amp;title=" alt="image.png"><br>对于这种三级层级关系的证书的验证过程如下：</p></li><li><p>客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。</p></li><li>请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。</li><li>“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。</li></ul><p>在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。<br>总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851948267-f6b51de7-bd03-42db-a0be-69bbbf1a69b3.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=faxlW&amp;name=image.png&amp;originHeight=891&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=127318&amp;status=done&amp;style=none&amp;taskId=u37d6a485-b67f-4515-945c-cc0ee5e0cf7&amp;title=" alt="image.png"><br>操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851948303-0366c395-8c5c-44df-8b5f-24d15e843e4b.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=YVC18&amp;name=image.png&amp;originHeight=534&amp;originWidth=867&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=240019&amp;status=done&amp;style=none&amp;taskId=uba8bbdef-ebf1-4a50-9869-c8ffa6c24db&amp;title=" alt="image.png"><br>这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851948276-aa979ff2-c308-4d52-bdc6-5794c445f06b.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=pfdfk&amp;name=image.png&amp;originHeight=452&amp;originWidth=1478&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=149739&amp;status=done&amp;style=none&amp;taskId=u5c63c07d-e1c6-4319-96c5-231699b1ae0&amp;title=" alt="image.png"><br>最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？<br><strong>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</strong></p><h4 id="③ssl原理👌"><a href="#③ssl原理👌" class="headerlink" title="③ssl原理👌"></a>③ssl原理👌</h4><p>RSA 算法的缺陷<strong>使用 RSA 密钥协商算法的最大问题是不支持前向保密</strong>。<br>因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。<br>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法，关于 ECDHE 握手的过程，将在下一篇揭晓。<br>HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。<br>其中，RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法具有前向安全，所以被广泛使用。<br>我在上一篇已经介绍了 <a href="https://mp.weixin.qq.com/s/U9SRLE7jZTB6lUZ6c8gTKg">RSA 握手的过程(opens new window)</a>，今天这一篇就「从理论再到实战抓包」介绍 <strong>ECDHE 算法</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061663655-cff70fbd-9a1c-4f91-80c6-5d0d33c6947f.png#averageHue=%23eff1f4&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=482&amp;id=ubdd6a341&amp;name=image.png&amp;originHeight=1566&amp;originWidth=1388&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=351233&amp;status=done&amp;style=none&amp;taskId=u284d660d-07f0-4ea3-ae1d-9e3af7906d1&amp;title=&amp;width=427.00006103515625" alt="image.png"></p><hr><p><strong>离散对数</strong><br>ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。<br>DH 算法是非对称加密算法， 因此它可以用于密钥交换，该算法的核心数学思想是<strong>离散对数</strong>。</p><blockquote><p>是不是听到这个数学概念就怂了？不怕，这次不会说离散对数推到的过程，只简单提一下它的数学公式。<br>离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习一遍对数。<br>要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。<br>举个栗子，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061663353-cd1d6188-015e-449a-8d00-ae5760012c5c.png#averageHue=%23e7dda8&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u80201dcd&amp;name=image.png&amp;originHeight=257&amp;originWidth=437&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=53630&amp;status=done&amp;style=none&amp;taskId=ua18f841b-3877-4e9e-9f5d-0df1ff4ba45&amp;title=" alt="image.png"><br>那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061663382-61db7129-5fce-409e-8665-90a04c9fff24.png#averageHue=%23f8f5ee&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7c5438fd&amp;name=image.png&amp;originHeight=279&amp;originWidth=702&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=51557&amp;status=done&amp;style=none&amp;taskId=ud849760d-9f47-4e76-a4d7-30bf611cf20&amp;title=" alt="image.png"><br>对数运算的取值是可以连续的，而离散对数的取值是不能连续的，因此也以「离散」得名，<br>离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语言的操作符是「%」，也可以用 mod 表示。离散对数的概念如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061663500-e51375e5-4967-4448-a882-d925d012ec83.png#averageHue=%23ede0bd&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7cd245ce&amp;name=image.png&amp;originHeight=227&amp;originWidth=692&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=104925&amp;status=done&amp;style=none&amp;taskId=u6e21052f-714a-4636-9ffd-8297a8a6ab4&amp;title=" alt="image.png"><br>上图的，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。<br><strong>特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。</strong></p></blockquote><hr><p><strong>DH 算法</strong><br>认识了离散对数，我们来看看 DH 算法是如何密钥交换的。<br>现假设小红和小明约定使用 DH 算法来交换密钥，那么基于离散对数，小红和小明需要先确定模数和底数作为算法的参数，这两个参数是公开的，用 P 和 G 来代称。<br>然后小红和小明各自生成一个随机整数作为<strong>私钥</strong>，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称。<br>现在小红和小明双方都有了 P 和 G 以及各自的私钥，于是就可以计算出<strong>公钥</strong>：</p><ul><li>小红的公钥记作 A，A = G ^ a ( mod P )；</li><li>小明的公钥记作 B，B = G ^ b ( mod P )；</li></ul><p>A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有计算机的计算能力是无法破解的，如果量子计算机出来了，那就有可能被破解，当然如果量子计算机真的出来了，那么密钥协商算法就要做大的升级了。<br>双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。<br>然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061663605-d19b8d57-0815-40fd-b320-148df9371c76.png#averageHue=%23f5f4b2&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue78c59c5&amp;name=image.png&amp;originHeight=429&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=132593&amp;status=done&amp;style=none&amp;taskId=u194a0887-2273-42b4-afdb-545210c6bb6&amp;title=" alt="image.png"><br>这个 K 就是小红和小明之间用的<strong>对称加密密钥</strong>，可以作为会话密钥使用。<br>可以看到，整个密钥协商过程中，小红和小明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B 是公钥，而 a、b 是双方各自保管的私钥，黑客无法获取这 2 个私钥，因此黑客只能从公开的 P、G、A、B 入手，计算出离散对数（私钥）。<br>前面也多次强调， 根据离散对数的原理，如果 P 是一个大数，在现有的计算机的计算能力是很难破解出 私钥 a、b 的，破解不出私钥，也就无法计算出会话密钥，因此 DH 密钥交换是安全的。</p><hr><p><strong>DHE 算法</strong><br>根据私钥生成的方式，DH 算法分为两种实现：</p><ul><li>static DH 算法，这个是已经被废弃了；</li><li>DHE 算法，现在常用的；</li></ul><p>static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。<br>于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 <strong>static DH 算法不具备前向安全性</strong>。<br>既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。<br>所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为<strong>每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」</strong>。</p><hr><p><strong>ECDHE 算法</strong><br>DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— <strong>ECDHE 算法</strong>。<br>ECDHE 算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。<br>小红和小明使用 ECDHE 密钥交换算法的过程：</p><ul><li>双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；</li><li>双方各自随机生成一个随机数作为<strong>私钥d</strong>，并与基点 G相乘得到<strong>公钥Q</strong>（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；</li><li>双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此<strong>双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥</strong>。</li></ul><p>这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。</p><hr><p><strong>ECDHE 握手过程</strong><br>知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。<br>我用 Wireshark 工具抓了用 ECDHE 密钥协商算法的 TSL 握手过程，可以看到是四次握手：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061665965-ddbe79ab-9365-4930-a360-6279a6d84616.png#averageHue=%23c6cade&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1b726704&amp;name=image.png&amp;originHeight=362&amp;originWidth=1005&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=382969&amp;status=done&amp;style=none&amp;taskId=uf6f5c1c4-57ca-4d2b-bad7-e72c5231a3f&amp;title=" alt="image.png"><br>细心的小伙伴应该发现了，<strong>使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据</strong>，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。<br>所以，<strong>ECDHE 相比 RSA 握手过程省去了一个消息往返的时间</strong>，这个有点「抢跑」的意思，它被称为是「<em>TLS False Start</em>」，跟「<em>TCP Fast Open</em>」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。<br>接下来，分析每一个 ECDHE 握手过程。<br><strong>TLS 第一次握手</strong><br>客户端首先会发一个「<strong>Client Hello</strong>」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（<em>Client Random</em>）</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061665910-8ad1180e-027f-4144-9ca3-551d8bebc4c5.png#averageHue=%23e9e8e7&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u47c24a64&amp;name=image.png&amp;originHeight=476&amp;originWidth=917&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=231904&amp;status=done&amp;style=none&amp;taskId=u101e46f2-6e97-49cf-a115-cfd3fa0b58b&amp;title=" alt="image.png"><br><strong>TLS 第二次握手</strong><br>服务端收到客户端的「打招呼」，同样也要回礼，会返回「<strong>Server Hello</strong>」消息，消息面有服务器确认的 TLS 版本号，也给出了一个<strong>随机数（<em>Server Random</em>）</strong>，然后从客户端的密码套件列表选择了一个合适的密码套件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061666015-e220b70b-572c-4fc7-a0df-192ad8069ced.png#averageHue=%23e9e6e6&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucfc977a2&amp;name=image.png&amp;originHeight=445&amp;originWidth=897&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=218668&amp;status=done&amp;style=none&amp;taskId=u3a67aa49-de93-4b73-9b37-c320193c2fc&amp;title=" alt="image.png"><br>不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。<br>「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」</p><ul><li>密钥协商算法使用 ECDHE；</li><li>签名算法使用 RSA；</li><li>握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM；</li><li>摘要算法使用 SHA384；</li></ul><p>接着，服务端为了证明自己的身份，发送「<strong>Certificate</strong>」消息，会把证书也发给客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061665880-515168e0-9eac-4bc0-ad59-644698db022e.png#averageHue=%23f1f0f0&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua28582c2&amp;name=image.png&amp;originHeight=256&amp;originWidth=1015&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=106905&amp;status=done&amp;style=none&amp;taskId=u3c76ae23-4c64-4f66-81e0-aba0c2f100b&amp;title=" alt="image.png"><br>这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「<strong>Server Key Exchange</strong>」消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061665963-dfcbc21d-e580-4d8a-b249-b13d78683a64.png#averageHue=%23efeded&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua44903f8&amp;name=image.png&amp;originHeight=343&amp;originWidth=1000&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=164937&amp;status=done&amp;style=none&amp;taskId=uc627c15a-898c-497a-b1bb-a7a5c15da46&amp;title=" alt="image.png"><br>这个过程服务器做了三件事：</p><ul><li>选择了<strong>名为 x25519 的椭圆曲线</strong>，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；</li><li>生成随机数作为服务端椭圆曲线的私钥，保留到本地；</li><li>根据基点 G 和私钥计算出<strong>服务端的椭圆曲线公钥</strong>，这个会公开给客户端。</li></ul><p>为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。<br>随后，就是「<strong>Server Hello Done</strong>」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061669012-c1dc9fe6-e689-4d11-bf4f-313362025a0f.png#averageHue=%23f2f2f2&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u98ed42a0&amp;name=image.png&amp;originHeight=116&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50836&amp;status=done&amp;style=none&amp;taskId=uc79eb2ee-e984-42db-bfd0-0a4b69822cc&amp;title=" alt="image.png"><br>至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息：<strong>Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥</strong>，这几个信息很重要，是后续生成会话密钥的材料。<br><strong>TLS 第三次握手</strong><br>客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。<br>客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成<strong>客户端的椭圆曲线公钥</strong>，然后用「<strong>Client Key Exchange</strong>」消息发给服务端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061669064-a1682f38-57b9-4abc-8840-166149d1f14c.png#averageHue=%23eeebeb&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u8a170ca5&amp;name=image.png&amp;originHeight=235&amp;originWidth=880&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=113710&amp;status=done&amp;style=none&amp;taskId=u44c4b7f1-c4d6-4f18-8126-6dd0268139d&amp;title=" alt="image.png"><br>至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，<strong>但实际应用中，x 还不是最终的会话密钥</strong>。<br>还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？<br><strong>最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的</strong>。<br>之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。<br>算好会话密钥后，客户端会发一个「<strong>Change Cipher Spec</strong>」消息，告诉服务端后续改用对称算法加密通信。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061669048-497d8ecb-603a-4e25-8f59-91885cf530ac.png#averageHue=%23f7f7f5&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u6a02dd89&amp;name=image.png&amp;originHeight=118&amp;originWidth=777&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=53802&amp;status=done&amp;style=none&amp;taskId=u858ba33e-b36a-4e5e-90cc-e5f591aa3ba&amp;title=" alt="image.png"><br>接着，客户端会发「<strong>Encrypted Handshake Message</strong>」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659061668962-af404965-edda-49e7-9741-9cb09b965a3b.png#averageHue=%23f7f7f5&amp;clientId=u46bf6d88-797b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u43e3122b&amp;name=image.png&amp;originHeight=122&amp;originWidth=794&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=56493&amp;status=done&amp;style=none&amp;taskId=uc137221b-add2-4365-876c-2a104e5dcfd&amp;title=" alt="image.png"><br><strong>TLS 第四次握手</strong><br>最后，服务端也会有一个同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。</p><hr><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>RSA 和 ECDHE 握手过程的区别：</p><ul><li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li><li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；</li><li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；</li></ul><hr><h4 id="④HTTP-与-HTTPS-有哪些区别？"><a href="#④HTTP-与-HTTPS-有哪些区别？" class="headerlink" title="④HTTP 与 HTTPS 有哪些区别？"></a>④HTTP 与 HTTPS 有哪些区别？</h4><ol><li>HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP 层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。</li><li>HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。</li><li>HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。 </li><li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。 <h4 id="⑤HTTPS-解决了-HTTP-的哪些问题？"><a href="#⑤HTTPS-解决了-HTTP-的哪些问题？" class="headerlink" title="⑤HTTPS 解决了 HTTP 的哪些问题？"></a>⑤HTTPS 解决了 HTTP 的哪些问题？</h4>HTTP 由于是明文传输，所以安全上存在以下三个风险：</li></ol><ul><li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li><li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li><li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650350875452-8d6748bd-4aa3-4777-8b69-2f3e7a972c95.png#averageHue=%23d4d9d5&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=243&amp;id=uf5b81068&amp;name=image.png&amp;originHeight=275&amp;originWidth=596&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=77363&amp;status=done&amp;style=none&amp;taskId=uad6a8250-0d91-4565-b7fd-de10e6db171&amp;title=&amp;width=526" alt="image.png"><br>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：</p><ul><li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li><li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li><li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li></ul><p>可见，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。<br>HTTPS 是如何解决上⾯的三个⻛险的？</p><ul><li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li><li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li><li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li></ul><p><em>1. 混合加密</em><br>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650350967084-bd96be4c-8cf3-496e-aea0-11cf463abf4f.png#averageHue=%23f3dd9b&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=348&amp;id=u723be3e9&amp;name=image.png&amp;originHeight=471&amp;originWidth=613&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=246207&amp;status=done&amp;style=none&amp;taskId=ue264ccfe-192b-41ef-ad0e-3faf0c7524a&amp;title=&amp;width=453" alt="image.png"><br>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p><ul><li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li></ul><p>采用「混合加密」的方式的原因：</p><ul><li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li><li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li></ul><p><em>2. 摘要算法+数字签名</em><br><strong>摘要算法</strong>用来实现<strong>完整性</strong>，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。<br>摘要算法</p><ul><li>为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。</li><li>对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。</li><li>那么，在计算机里会<strong>用摘要算法（哈希函数）来计算出内容的哈希值</strong>，也就是内容的「指纹」，这个<strong>哈希值是唯一的，且无法通过哈希值推导出内容</strong>。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851053014-810aa66c-2393-41d6-9a19-1e9b1071fd17.png#averageHue=%23f7f4ea&amp;clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=325&amp;id=ueb304f81&amp;name=image.png&amp;originHeight=636&amp;originWidth=1276&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=245192&amp;status=done&amp;style=none&amp;taskId=u8446140e-c4b4-478b-aa56-c32a988bbde&amp;title=&amp;width=653.0000610351562" alt="image.png"><br>通过哈希算法可以确保内容不会被篡改，<strong>但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明</strong>。</p><blockquote><p>举个例子，你想向老师请假，一般来说是要求由家长写一份请假理由并签名，老师才能允许你请假。<br>但是你有模仿你爸爸字迹的能力，你用你爸爸的字迹写了一份请假理由然后签上你爸爸的名字，老师一看到这个请假条，查看字迹和签名，就误以为是你爸爸写的，就会允许你请假。<br>那作为老师，要如何避免这种情况发生呢？现实生活中的，可以通过电话或视频来确认是否是由父母发出的请假，但是计算机里可没有这种操作。</p></blockquote><p>数字签名（公钥，私钥）<br>那为了避免这种情况，计算机里会用<strong>非对称加密算法</strong>来解决，共有两个密钥：</p><ul><li>一个是公钥，这个是可以公开给所有人的；</li><li>一个是私钥，这个必须由本人管理，不可泄露。</li></ul><p>这两个密钥可以<strong>双向加解密</strong>的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。<br>流程的不同，意味着目的也不相同：</p><ul><li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；</li><li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</li></ul><p>一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。<br>所以非对称加密的用途主要在于<strong>通过「私钥加密，公钥解密」的方式，来确认消息的身份</strong>，我们常说的<strong>数字签名算法</strong>，就是用的是这种方式，不过私钥加密内容不是内容本身，而是<strong>对内容的哈希值加密</strong>。<br>私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657851053043-ecbc49f8-d23c-41fc-a365-6cbaf5ff8b02.png#averageHue=%23faf9f4&amp;clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=277&amp;id=uc52ad979&amp;name=image.png&amp;originHeight=652&amp;originWidth=1282&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=219722&amp;status=done&amp;style=none&amp;taskId=ubb4534c5-8b25-4aa7-9cf4-037aa96c067&amp;title=&amp;width=545.0000610351562" alt="image.png"><br>引入了数字签名算法后，你就无法模仿你爸爸的字迹来请假了，你爸爸手上持有着私钥，你老师持有着公钥。<br>这样只有用你爸爸手上的私钥才对请假条进行「签名」，老师通过公钥看能不能解出这个「签名」，如果能解出并且确认内容的完整性，就能证明是由你爸爸发起的请假条，这样老师才允许你请假，否则老师就不认。</p></blockquote><p><em>3. 数字证书</em><br>前面我们知道：</p><ul><li>可以通过哈希算法来保证消息的完整性；</li><li>可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；</li></ul><p>但是这还远远不够，<strong>还缺少身份验证的环节</strong>，万一公钥是被伪造的呢？<br>所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将<strong>服务器公钥放在数字证书</strong>（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650350967301-93893cb3-3218-4700-9f34-bbfed195b644.png#averageHue=%23dfd395&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=307&amp;id=u97d415cb&amp;name=image.png&amp;originHeight=577&amp;originWidth=779&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=371816&amp;status=done&amp;style=none&amp;taskId=u20968e18-253c-4b17-a104-796cea154e7&amp;title=&amp;width=414" alt="image.png"><br>通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。<br>数字证书的工作流程，我也画了一张图，方便大家理解：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1658458709449-32dc022a-3d68-4910-888e-823236723513.png#averageHue=%23e1d6a2&amp;clientId=u6dc524c5-d932-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=367&amp;id=u681ac3e9&amp;name=image.png&amp;originHeight=577&amp;originWidth=779&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=362582&amp;status=done&amp;style=none&amp;taskId=ud1415ba0-9255-4a51-910f-12268030aab&amp;title=&amp;width=495.00006103515625" alt="image.png"><br>通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。<br>详细内容还是拿请假的例子，虽然你爸爸持有私钥，老师通过是否能用公钥解密来确认这个请假条是不是来源你父亲的。<br>但是我们还可以自己伪造出一对公私钥啊！<br>你找了个夜晚，偷偷把老师桌面上和你爸爸配对的公钥，换成了你的公钥，那么下次你在请假的时候，你继续模仿你爸爸的字迹写了个请假条，然后用你的私钥做个了「数字签名」。<br>但是老师并不知道自己的公钥被你替换过了，所以他还是按照往常一样用公钥解密，由于这个公钥和你的私钥是配对的，老师当然能用这个被替换的公钥解密出来，并且确认了内容的完整性，于是老师就会以为是你父亲写的请假条，又允许你请假了。<br>好家伙，为了一个请假，真的是斗智斗勇。<br>后面你的老师和父亲发现了你伪造公私钥的事情后，决定重新商量一个对策来应对你这个臭家伙。<br>正所谓魔高一丈，道高一尺。<br>既然伪造公私钥那么随意，所以你爸把他的公钥注册到<strong>警察局</strong>，警察局用他们自己的私钥对你父亲的公钥做了个数字签名，然后把你爸爸的「个人信息 + 公钥 + 数字签名」打包成一个<strong>数字证书，也就是说这个数字证书包含你爸爸的公钥。</strong><br>这样，你爸爸如果因为家里确实有事要向老师帮你请假的时候，不仅会用自己的私钥对内容进行签名，还会把数字证书给到老师。<br>老师拿到了数字证书后，<strong>首先会去警察局验证这个数字证书是否合法</strong>，因为数字证书里有警察局的数字签名，警察局要验证证书合法性的时候，用自己的公钥解密，如果能解密成功，就说明这个数字证书是在警察局注册过的，就认为该数字证书是合法的，然后就会把数字证书里头的公钥（你爸爸的）给到老师。<br><strong>由于通过警察局验证了数字证书是合法的，那么就能证明这个公钥就是你父亲的</strong>，于是老师就可以安心的用这个公钥解密出清教条，如果能解密出，就证明是你爸爸写的请假条。<br>正是通过了一个权威的机构来证明你爸爸的身份，所以你的伪造公私钥这个小伎俩就没用了。<br>在计算机里，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><h3 id="ⅥHTTP-1-1、HTTP-2、HTTP-3-演变✊"><a href="#ⅥHTTP-1-1、HTTP-2、HTTP-3-演变✊" class="headerlink" title="ⅥHTTP/1.1、HTTP/2、HTTP/3 演变✊"></a>ⅥHTTP/1.1、HTTP/2、HTTP/3 演变✊</h3><h4 id="①说说-HTTP-1-1-相⽐-HTTP-1-0-提⾼了什么性能？"><a href="#①说说-HTTP-1-1-相⽐-HTTP-1-0-提⾼了什么性能？" class="headerlink" title="①说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？"></a>①说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？</h4><p>HTTP/1.1 相⽐ HTTP/1.0 性能上的改进： </p><ul><li>使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。 </li><li>⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以 减少整体的响应时间。 <h4 id="②HTTP-1-1的性能瓶颈："><a href="#②HTTP-1-1的性能瓶颈：" class="headerlink" title="②HTTP/1.1的性能瓶颈："></a>②HTTP/1.1的性能瓶颈：</h4>1.请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；<br>2.发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；<br>3.服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直接收不到数据，也就是队头阻塞；<br>4.没有请求优先级控制；<br>5.请求只能从客户端开始，服务器只能被动响应。<h4 id="③那上⾯的-HTTP-1-1-的性能瓶颈，HTTP-2-做了什么优化？"><a href="#③那上⾯的-HTTP-1-1-的性能瓶颈，HTTP-2-做了什么优化？" class="headerlink" title="③那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？"></a>③那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？</h4><h5 id="1-头部压缩"><a href="#1-头部压缩" class="headerlink" title="1. 头部压缩"></a>1. 头部压缩</h5>HTTP 协议的报文是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使用头字段 「Content-Encoding」指定 Body 的压缩方式，比如用 gzip 压缩，这样可以节约带宽，但报文中的另外一部分 Header，是没有针对它的优化手段。<blockquote><p>HTTP/1.1 报文中 Header 部分存在的问题：</p><ul><li>含很多固定的字段，比如Cookie、User Agent、Accept 等，这些字段加起来也高达几百字节甚至上千字节，所以有必要<strong>压缩</strong>；</li><li>大量的请求和响应的报文里有很多字段值都是重复的，这样会使得大量带宽被这些冗余的数据占用了，所以有必须要<strong>避免重复性</strong>；</li><li>字段是 ASCII 编码的，虽然易于人类观察，但效率低，所以有必要改成<strong>二进制编码</strong>；</li></ul></blockquote></li></ul><p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。<br>比如使用HPACK算法来压缩头部<br>压缩头部的详细内容HTTP/2 对 Header 部分做了大改造，把以上的问题都解决了。<br>HTTP/2 没使用常见的 gzip 压缩方式来压缩头部，而是开发了 <strong>HPACK</strong> 算法，HPACK 算法主要包含三个组成部分：</p><ul><li>静态字典；</li><li>动态字典；</li><li>Huffman 编码（压缩算法）；</li></ul><p>客户端和服务器两端都会建立和维护「<strong>字典</strong>」，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，<strong>可达到 50%~90% 的高压缩率</strong>。</p><h3 id="静态表编码"><a href="#静态表编码" class="headerlink" title="静态表编码"></a>静态表编码</h3><p>HTTP/2 为高频出现在头部的字符串和字段建立了一张<strong>静态表</strong>，它是写入到 HTTP/2 框架里的，不会变化的，静态表里共有 61 组，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853819267-6ec0c7ba-4486-4f4b-a79e-ab1aaa76c11a.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u42d06d91&amp;name=image.png&amp;originHeight=850&amp;originWidth=635&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=218361&amp;status=done&amp;style=none&amp;taskId=ueb48c736-80d8-4fbb-aabb-899dbb674ef&amp;title=" alt="image.png"><br>表中的 Index 表示索引（Key），Header Value 表示索引对应的 Value，Header Name 表示字段的名字，比如 Index 为 2 代表 GET，Index 为 8 代表状态码 200。<br>你可能注意到，表中有的 Index 没有对应的 Header Value，这是因为这些 Value 并不是固定的而是变化的，这些 Value 都会经过 Huffman 编码后，才会发送出去。<br>这么说有点抽象，我们来看个具体的例子，下面这个 server 头部字段，在 HTTP/1.1 的形式如下：<br>server: nghttpx\r\n<br>算上冒号空格和末尾的\r\n，共占用了 17 字节，<strong>而使用了静态表和 Huffman 编码，可以将它压缩成 8 字节，压缩率大概 47 %</strong>。<br>我抓了个 HTTP/2 协议的网络包，你可以从下图看到，高亮部分就是 server 头部字段，只用了 8 个字节来表示 server 头部数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853819342-91296135-ce8a-433c-beba-da502090d488.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9d61cc51&amp;name=image.png&amp;originHeight=500&amp;originWidth=1726&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=335454&amp;status=done&amp;style=none&amp;taskId=ue9f27afc-f7a7-4618-bea5-0d58c3905d3&amp;title=" alt="image.png"><br>根据 RFC7541 规范，如果头部字段属于静态表范围，并且 Value 是变化，那么它的 HTTP/2 头部前 2 位固定为 01，所以整个头部格式如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853819129-e09c603a-184f-4a39-b595-d7ac7933a4c9.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucca5bdf4&amp;name=image.png&amp;originHeight=348&amp;originWidth=752&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=94813&amp;status=done&amp;style=none&amp;taskId=u7375fc57-71c2-4d24-b3f0-6a86010f7fd&amp;title=" alt="image.png"><br>HTTP/2 头部由于基于<strong>二进制编码</strong>，就不需要冒号空格和末尾的\r\n作为分隔符，于是改用表示字符串长度（Value Length）来分割 Index 和 Value。<br>接下来，根据这个头部格式来分析上面抓包的 server 头部的二进制数据。<br>首先，从静态表中能查到 server 头部字段的 Index 为 54，二进制为 110110，再加上固定 01，头部格式第 1 个字节就是 01110110，这正是上面抓包标注的红色部分的二进制数据。<br>然后，第二个字节的首个比特位表示 Value 是否经过 Huffman 编码，剩余的 7 位表示 Value 的长度，比如这次例子的第二个字节为 10000110，首位比特位为 1 就代表 Value 字符串是经过 Huffman 编码的，经过 Huffman 编码的 Value 长度为 6。<br>最后，字符串 nghttpx 经过 Huffman 编码后压缩成了 6 个字节，Huffman 编码的原理是将高频出现的信息用「较短」的编码表示，从而缩减字符串长度。<br>于是，在统计大量的 HTTP 头部后，HTTP/2 根据出现频率将 ASCII 码编码为了 Huffman 编码表，可以在 RFC7541 文档找到这张<strong>静态 Huffman 表</strong>，我就不把表的全部内容列出来了，我只列出字符串 nghttpx 中每个字符对应的 Huffman 编码，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853819148-8b4cced2-a2c9-403e-8dee-b93d15f249fe.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5ef577a1&amp;name=image.png&amp;originHeight=452&amp;originWidth=617&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=59485&amp;status=done&amp;style=none&amp;taskId=u627623ad-a0eb-4198-8b3b-e8dd10caecc&amp;title=" alt="image.png"><br>通过查表后，字符串 nghttpx 的 Huffman 编码在下图看到，共 6 个字节，每一个字符的 Huffman 编码，我用相同的颜色将他们对应起来了，最后的 7 位是补位的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853819118-bc798bd0-9fdb-4679-8bbe-f57139c6b149.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue75afdf3&amp;name=image.png&amp;originHeight=99&amp;originWidth=722&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=46259&amp;status=done&amp;style=none&amp;taskId=u10bc4081-fef3-4ed1-a21a-5a1e15a31af&amp;title=" alt="image.png"><br>最终，server 头部的二进制数据对应的静态头部格式如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853820848-cdf3f3c5-6f43-4567-90b3-e7bf52c4f9c1.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u44a5d761&amp;name=image.png&amp;originHeight=812&amp;originWidth=947&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=236624&amp;status=done&amp;style=none&amp;taskId=u30658b24-cb51-49ed-90c3-6f2b8fed6df&amp;title=" alt="image.png"></p><h3 id="动态表编码"><a href="#动态表编码" class="headerlink" title="动态表编码"></a>动态表编码</h3><p>静态表只包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建<strong>动态表</strong>，它的 Index 从 62 起步，会在编码解码的时候随时更新。<br>比如，第一次发送时头部中的「user-agent 」字段数据有上百个字节，经过 Huffman 编码发送出去后，客户端和服务器双方都会更新自己的动态表，添加一个新的 Index 号 62。<strong>那么在下一次发送的时候，就不用重复发这个字段的数据了，只用发 1 个字节的 Index 号就好了，因为双方都可以根据自己的动态表获取到字段的数据</strong>。<br>所以，使得动态表生效有一个前提：<strong>必须同一个连接上，重复传输完全相同的 HTTP 头部</strong>。如果消息字段在 1 个连接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。<br>因此，随着在同一 HTTP/2 连接上发送的报文越来越多，客户端和服务器双方的「字典」积累的越来越多，理论上最终每个头部字段都会变成 1 个字节的 Index，这样便避免了大量的冗余数据的传输，大大节约了带宽。<br>理想很美好，现实很骨感。动态表越大，占用的内存也就越大，如果占用了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类似 http2_max_requests 的配置，用于限制一个连接上能够传输的请求数量，避免动态表无限增大，请求数量到达上限后，就会关闭 HTTP/2 连接来释放内存。<br>综上，HTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657853820836-0feacfe9-5dbe-43e7-9ce9-d4f0666895ae.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue5ea7e15&amp;name=image.png&amp;originHeight=339&amp;originWidth=1117&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=189157&amp;status=done&amp;style=none&amp;taskId=u230dfe3a-8ea2-48fe-ae26-28748c27bb5&amp;title=" alt="image.png"></p><h5 id="2-二进制格式"><a href="#2-二进制格式" class="headerlink" title="2. 二进制格式"></a>2. 二进制格式</h5><ul><li>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</li><li>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351310887-0dabbfef-60dc-4f87-9a7e-b6855033f482.png#averageHue=%23e3ded9&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=257&amp;id=u292edd0d&amp;name=image.png&amp;originHeight=564&amp;originWidth=1111&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=183065&amp;status=done&amp;style=none&amp;taskId=u2a622da4-2311-48a3-89a2-9e0c0757959&amp;title=&amp;width=507" alt="image.png"></p><p>补充&gt; 比如状态码 200 ，在 HTTP/1.1 是用 ‘2’’0’’0’ 三个字符来表示（二进制：110010 110000 110000），如图：</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351311285-b92f53ce-6a65-40ea-bae5-db02e09bb78c.png#clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=378&amp;id=fQtVV&amp;name=image.png&amp;originHeight=1454&amp;originWidth=2436&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=469814&amp;status=done&amp;style=none&amp;taskId=uc6cbde3c-0c26-419a-8376-23d14b93410&amp;title=&amp;width=633" alt="image.png"><br>在 HTTP/2 是用数字 200 表示（二进制：11001000），如图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351311371-0a7fcf63-9de7-41ea-b80c-f24183901cf7.png#clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=351&amp;id=AkQNI&amp;name=image.png&amp;originHeight=1424&amp;originWidth=2622&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=472502&amp;status=done&amp;style=none&amp;taskId=u63a4f304-6189-4391-9475-641f8c0364f&amp;title=&amp;width=646" alt="image.png"></p></blockquote><h5 id="3-并发传输"><a href="#3-并发传输" class="headerlink" title="3. 并发传输"></a><em>3. 并发传输</em></h5><p>我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了<strong>队头阻塞</strong>的问题。<br>而 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1662552433390-e6e94271-277e-4b0d-becc-8d1d5e902d9f.png#averageHue=%235b99d5&amp;clientId=u850fb9e4-c8da-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=479&amp;id=u7ffef7be&amp;name=image.png&amp;originHeight=535&amp;originWidth=464&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=155920&amp;status=done&amp;style=none&amp;taskId=uff3f80d4-d3d1-4700-8a32-61ac0a60797&amp;title=&amp;width=415.0000305175781" alt="image.png"></p><ul><li>从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。</li><li><strong>针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应</strong>。<blockquote><p>比如下图，服务端<strong>并行交错地</strong>发送了两个响应： Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1662552433672-5245d296-fbf6-4566-a80b-1c181b2d544c.png#averageHue=%23e8e6e4&amp;clientId=u850fb9e4-c8da-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucdfc8d5d&amp;name=image.png&amp;originHeight=228&amp;originWidth=787&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=98598&amp;status=done&amp;style=none&amp;taskId=u670433a2-a3ee-4e44-8e5a-2b656f32d3a&amp;title=" alt="image.png"></p></blockquote></li></ul><p>数据流详解</p><ul><li>在 HTTP/2 中每个请求或响应的所有数据包，称为一个数据流（Stream）。每个数据流都标记着一个独一无二的编号（Stream ID），<strong>不同 Stream 的帧(frame)是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息</li><li>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</li><li>客户端还可以<strong>指定数据流的优先级</strong>。优先级高的请求，服务器就先响应该请求。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351310696-f5f8bf71-07a0-4e26-bbfe-a4f8e9e4dc3a.png#clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=219&amp;id=SMHCN&amp;name=image.png&amp;originHeight=598&amp;originWidth=1482&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=100405&amp;status=done&amp;style=none&amp;taskId=uf8eff75a-7525-431e-bfa5-b38f4a54c67&amp;title=&amp;width=542" alt="image.png"></p><p>为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657854152614-7e32cc77-9004-48e4-9174-953dc247d28d.png#clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=can1W&amp;name=image.png&amp;originHeight=535&amp;originWidth=464&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=155920&amp;status=done&amp;style=none&amp;taskId=ueb11f002-6c4f-418d-8b61-874c521350e&amp;title=" alt="image.png"><br>你可以从上图中看到：<br>Stream表示一个请求<strong>和</strong>响应</p><ul><li>1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；</li><li>Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；</li><li>Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；</li></ul><p>因此，我们可以得出 2 个结论：HTTP 消息可以由多个 Frame 构成，以及 1 个 Frame 可以由多个 TCP 报文构成。<br>在 HTTP/2 连接上，<strong>不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而<strong>同一 Stream 内部的帧必须是严格有序的</strong>。</p><h5 id="4-服务器推送"><a href="#4-服务器推送" class="headerlink" title="4. 服务器推送"></a>4. 服务器推送</h5><p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以<strong>主动</strong>向客户端发送消息。</p><blockquote><p>比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351311625-b3a055a8-cc75-4bc5-9256-e6770a4bdbf4.png#averageHue=%23f7f7f7&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=262&amp;id=uc5526f25&amp;name=image.png&amp;originHeight=402&amp;originWidth=800&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49116&amp;status=done&amp;style=none&amp;taskId=u43f3164c-79a2-4a6b-b5a9-c34f93a1c2a&amp;title=&amp;width=522" alt="image.png"><br>如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。</p></blockquote><h4 id="④HTTP-2-有什么缺陷？-可以看下述有详细的讲解"><a href="#④HTTP-2-有什么缺陷？-可以看下述有详细的讲解" class="headerlink" title="④HTTP/2 有什么缺陷？(可以看下述有详细的讲解)"></a>④HTTP/2 有什么缺陷？(可以看下述有详细的讲解)</h4><p>HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，<strong>只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。</strong><br><strong>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</strong><br>例子举个例子，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1650351462789-1690f1a3-7b60-4248-9d8c-afa0e03b1609.gif#clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=oPjQ8&amp;originHeight=502&amp;originWidth=521&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u30fd503a-0ecc-4dc1-90d1-905d98ffe10&amp;title=" alt=""><br>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。<br>所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><h4 id="③HTTP-3-做了哪些优化？"><a href="#③HTTP-3-做了哪些优化？" class="headerlink" title="③HTTP/3 做了哪些优化？"></a>③HTTP/3 做了哪些优化？</h4><p>前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：</p><ul><li>HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等相应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。</li><li>HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 TCP 层队头阻塞。</li></ul><p>HTTP/2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351562403-261c57ec-9eaf-4b7a-8744-14e67dda93f9.png#averageHue=%23d0d492&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=318&amp;id=u0055327b&amp;name=image.png&amp;originHeight=366&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=158562&amp;status=done&amp;style=none&amp;taskId=u796e761e-8e3c-4127-b400-3b6f303540a&amp;title=&amp;width=679" alt="image.png"><br>UDP 发生是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题<br>大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。<br><strong>QUIC 有以下 3 个特点。</strong></p><h5 id="1、无队头阻塞"><a href="#1、无队头阻塞" class="headerlink" title="1、无队头阻塞"></a>1、无队头阻塞</h5><p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。<br>由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。<br>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。<br>而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。<br>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。<strong>因此不存在队头阻塞问题</strong>。</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351562609-13cb6ee9-48b7-4891-a6a2-9ad6bfafc8b9.png#averageHue=%23bbb7a3&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=328&amp;id=ue6e51392&amp;name=image.png&amp;originHeight=504&amp;originWidth=700&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=216836&amp;status=done&amp;style=none&amp;taskId=u0d2d4ada-0240-45c7-ae72-e9ebd827488&amp;title=&amp;width=455" alt="image.png"></p></blockquote><h5 id="2、更快的连接建立"><a href="#2、更快的连接建立" class="headerlink" title="2、更快的连接建立"></a>2、更快的连接建立</h5><ul><li>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</li><li>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</li><li>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong>。</li></ul><p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1651480815000-e39cc13a-10ca-42d4-b5eb-d0f78bc5a628.gif#averageHue=%23f9f9f9&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=utRiE&amp;originHeight=381&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc04b7814-a4a6-4a7a-ba73-a7c83abc92d&amp;title=" alt=""></p><h5 id="3、连接迁移"><a href="#3、连接迁移" class="headerlink" title="3、连接迁移"></a>3、连接迁移</h5><ul><li><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p></li><li><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p></li></ul><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP/2 的多路复用的协议。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351562734-f5cc49d8-46a2-44bc-b65d-0f2cf512ef99.png#averageHue=%23dbd1c8&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=255&amp;id=u96ebb144&amp;name=image.png&amp;originHeight=327&amp;originWidth=700&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=119078&amp;status=done&amp;style=none&amp;taskId=u3322b97a-f357-4af2-aafe-af08e7d70c7&amp;title=&amp;width=546" alt="image.png"><br>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。<br>所以，HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。<br>接着就看下述！！！</p><h2 id="二、HTTP-3-强势来袭✊"><a href="#二、HTTP-3-强势来袭✊" class="headerlink" title="二、HTTP/3 强势来袭✊"></a>二、HTTP/3 强势来袭✊</h2><p>HTTP/3 现在还没正式推出，不过自 2017 年起， HTTP/3 已经更新到 34 个草案了，基本的特性已经确定下来了，对于包格式可能后续会有变化。<br>所以，这次 HTTP/3 介绍不会涉及到包格式，只说它的特性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480814514-44600702-9be0-4326-a3c2-008cb15f1a08.png#averageHue=%23fcfcfc&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=YkVLe&amp;originHeight=589&amp;originWidth=926&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u4eb48d79-7261-43e1-8a45-d057170dee5&amp;title=" alt=""></p><hr><p>HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。<br><strong>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</strong><br>有没有什么解决方案呢？既然是 TCP 协议自身的问题，那干脆放弃 TCP 协议，转而使用 UDP 协议作为传输层协议，这个大胆的决定， HTTP/3 协议做了！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657854262741-6c1f714d-edbd-4d74-9a95-aa2d3ac58e6d.png#averageHue=%23d8cf5f&amp;clientId=uce657f4e-0d26-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=A0Wvj&amp;name=image.png&amp;originHeight=366&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=179959&amp;status=done&amp;style=none&amp;taskId=u0fefeae8-01e5-4ce7-8718-9c7defb9b3c&amp;title=" alt="image.png"></p><h3 id="ⅠHTTP-2存在的缺陷"><a href="#ⅠHTTP-2存在的缺陷" class="headerlink" title="ⅠHTTP/2存在的缺陷"></a>ⅠHTTP/2存在的缺陷</h3><p>HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。</p><ul><li>队头阻塞；</li><li>TCP 与 TLS 的握手时延迟；</li><li><p>网络迁移需要重新连接；</p><h4 id="①队头阻塞"><a href="#①队头阻塞" class="headerlink" title="①队头阻塞"></a>①队头阻塞</h4></li><li><p>HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。</p></li><li>因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。<blockquote><p>举个例子，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1651480813595-015050a4-3f9b-4b7a-a72e-4901aee95afd.gif#averageHue=%23f6f4f3&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ORZka&amp;originHeight=502&amp;originWidth=521&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7696d465-a102-4fb0-8b5e-cfe41483dad&amp;title=" alt=""><br>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。</p></blockquote></li></ul><h4 id="②TCP-与-TLS-的握手时延迟"><a href="#②TCP-与-TLS-的握手时延迟" class="headerlink" title="②TCP 与 TLS 的握手时延迟"></a>②TCP 与 TLS 的握手时延迟</h4><p>发起 HTTP 请求时，需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1651480813651-d8444cae-75f2-4a91-bd3b-1a681bc69454.gif#averageHue=%23f6f2ed&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=443&amp;id=bbQR9&amp;originHeight=693&amp;originWidth=777&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u17c3ab9e-a786-47e2-a5b5-7a26e491e81&amp;title=&amp;width=497.00006103515625" alt=""><br>另外， TCP 由于具有「拥塞控制」的特性，所以刚建立连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产生”减速”效果。</p><h4 id="③网络迁移需要重新连接"><a href="#③网络迁移需要重新连接" class="headerlink" title="③网络迁移需要重新连接"></a>③网络迁移需要重新连接</h4><ul><li>一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WIFI。</li></ul><p>这些问题都是 TCP 协议固有的问题，无论应用层的 HTTP/2 在怎么设计都无法逃脱。要解决这个问题，就必须把<strong>传输层协议替换成 UDP</strong>，这个大胆的决定，HTTP/3 做了！<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651480814426-76c19339-bda8-495f-a308-127e816a5c2b.jpeg#averageHue=%23dcd1c9&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Lpq49&amp;originHeight=327&amp;originWidth=700&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u288ed105-a409-4f15-a319-ec12c803ff9&amp;title=" alt=""></p><hr><h3 id="ⅡQUIC-协议的特点"><a href="#ⅡQUIC-协议的特点" class="headerlink" title="ⅡQUIC 协议的特点"></a>ⅡQUIC 协议的特点</h3><p>我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。<br>而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。<br>当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在<strong>「应用层」</strong>实现了 <strong>QUIC 协议</strong>，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。<br>QUIC 协议的优点有很多，这里举例几个，比如：</p><ul><li>无队头阻塞；</li><li>更快的连接建立；</li><li>连接迁移；<h4 id="①无队头阻塞"><a href="#①无队头阻塞" class="headerlink" title="①无队头阻塞"></a>①无队头阻塞</h4>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。<br>由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。<br>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。<br>而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。<br>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。<strong>因此不存在队头阻塞问题</strong>。<blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650351562609-13cb6ee9-48b7-4891-a6a2-9ad6bfafc8b9.png#averageHue=%23bbb7a3&amp;clientId=u101e6d59-e57c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=328&amp;id=USZWg&amp;name=image.png&amp;originHeight=504&amp;originWidth=700&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=216836&amp;status=done&amp;style=none&amp;taskId=u0d2d4ada-0240-45c7-ae72-e9ebd827488&amp;title=&amp;width=455" alt="image.png"></p></blockquote></li></ul><h4 id="②更快的连接建立"><a href="#②更快的连接建立" class="headerlink" title="②更快的连接建立"></a>②更快的连接建立</h4><ul><li>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</li><li>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</li><li>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong>。</li></ul><p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1651480815000-e39cc13a-10ca-42d4-b5eb-d0f78bc5a628.gif#averageHue=%23f9f9f9&amp;clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=rC5lM&amp;originHeight=381&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc04b7814-a4a6-4a7a-ba73-a7c83abc92d&amp;title=" alt=""></p><h4 id="③连接迁移"><a href="#③连接迁移" class="headerlink" title="③连接迁移"></a>③连接迁移</h4><ul><li><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p></li><li><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p></li></ul><hr><h3 id="ⅢHTTP-3-协议"><a href="#ⅢHTTP-3-协议" class="headerlink" title="ⅢHTTP/3 协议"></a>ⅢHTTP/3 协议</h3><p>了解完 QUIC 协议的特点后，我们再来看看 HTTP/3 协议在 HTTP 这一层做了什么变化。<br>HTTP/3 同 HTTP/2 一样采用二进制帧的结构，不同的地方在于 HTTP/2 的二进制帧里需要定义 Stream，而 HTTP/3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP/3 的帧的结构也变简单了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480815271-a14f2331-c31c-4019-8ac8-07b06fb530b1.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=x2LQc&amp;originHeight=590&amp;originWidth=1727&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uf2b5bd7c-7811-44d2-b496-a42d7b4f54a&amp;title=" alt=""><br>从上图可以看到，HTTP/3 帧头只有两个字段：类型和长度。<br>根据帧类型的不同，大体上分为数据帧和控制帧两大类，HEADERS 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。<br>HTTP/3 在头部压缩算法这一方便也做了升级，升级成了 <strong>QPACK</strong>。与 HTTP/2 中的 HPACK 编码方式相似，HTTP/3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。<br>对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，而 HTTP/3 中的 QPACK 的静态表扩大到 91 项。<br>HTTP/2 和 HTTP/3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。<br>所谓的动态表，在首次请求-响应后，双方会将未包含在静态表中的 Header 项更新各自的动态表，接着后续传输时仅用 1 个数字表示，然后对方可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，大大提升了编码效率。<br>可以看到，<strong>动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来</strong>。<br>HTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？<br>QUIC 会有两个特殊的单向流，所谓的单项流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：</p><ul><li>一个叫 QPACK Encoder Stream， 用于将一个字典（key-value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；</li><li>一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。</li></ul><p>这两个特殊的单向流是用来<strong>同步双方的动态表</strong>，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部。</p><hr><p><strong>期待，HTTP/3 正式推出的那一天！</strong><br><strong>聊聊 QUIC 是如何实现可靠传输的？又是如何解决上面 TCP 协议四个方面的缺陷</strong>？</p><h3 id="Ⅳ如何用UDP实现可靠传输"><a href="#Ⅳ如何用UDP实现可靠传输" class="headerlink" title="Ⅳ如何用UDP实现可靠传输"></a>Ⅳ如何用UDP实现可靠传输</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772966367-332a2c61-6031-427f-bb92-3adf3f4555eb.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=501&amp;id=FwMia&amp;originHeight=798&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0b4a284c-3d49-4d44-8c13-575882aec7f&amp;title=&amp;width=678" alt=""></p><h4 id="①QUIC-是如何实现可靠传输的？"><a href="#①QUIC-是如何实现可靠传输的？" class="headerlink" title="①QUIC 是如何实现可靠传输的？"></a>①QUIC 是如何实现可靠传输的？</h4><p>要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要设计好协议的头部字段。<br>拿 HTTP/3 举例子，在 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772966475-07abdab4-554c-494e-aad1-669101513f88.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=261&amp;id=qhSkG&amp;originHeight=371&amp;originWidth=554&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u4d53fa8f-f93f-44df-b19e-b97a4e4af43&amp;title=&amp;width=390" alt=""><br>整体看的视角是这样的：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772966689-ef745b01-af91-4998-b48f-f04e1e42f4de.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=248&amp;id=CjIld&amp;originHeight=516&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u304a6f40-fb98-48e2-b1d7-3273798573e&amp;title=&amp;width=520.0000610351562" alt=""><br>接下来，分别对每一个 Header 做个介绍。</p></blockquote><h5 id="Packet-Header"><a href="#Packet-Header" class="headerlink" title="Packet Header"></a>Packet Header</h5><p>Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。</p><blockquote><p>如下图，注意我没有把 Header 所有字段都画出来，只是画出了重要的字段：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772966304-cd7076fb-60d2-49dc-a371-5b958f1a862d.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=249&amp;id=tbs1k&amp;originHeight=471&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ud86dfa5d-e577-4651-86f7-986f328c66c&amp;title=&amp;width=571.0000610351562" alt=""></p></blockquote><p>Packet Header<br>细分这两种：</p><ul><li>Long Packet Header 用于首次建立连接。</li><li>Short Packet Header 用于日常传输数据。</li></ul><p>QUIC 也是需要三次握手来建立连接的，主要目的是为了确定连接 ID。<br>建立连接时，连接 ID 是由服务器根据客户端的 Source Connection ID 字段生成的，这样后续传输时，双方只需要固定住 Destination Connection ID（连接 ID ），从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了。<br>Short Packet Header 中的 Packet Number 是每个报文独一无二的编号，它是严格递增的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772966372-7f7dfbe1-484c-4d4a-8013-537277521a52.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=276&amp;id=auLdE&amp;originHeight=592&amp;originWidth=990&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uda1d8f33-1afe-46d4-a7cd-2650468b8a1&amp;title=&amp;width=462.00006103515625" alt=""><br>为什么要这么设计呢？<br>我们先来看看  TCP 的问题，TCP 在重传报文时的序列号和原始报文的序列号是一样的，也正是由于这个特性，引入了 TCP 重传的歧义问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772971640-56dc6987-6a0f-4be6-b4d1-23dbda501543.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=sMsxq&amp;originHeight=396&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue544843e-d5ae-4ab5-8a5d-9f8e37c1671&amp;title=" alt=""><br>TCP 重传的歧义问题<br>比如上图，当 TCP 发生超时重传后，客户端发起重传，然后接收到了服务端确认 ACK 。由于客户端原始报文和重传报文序列号都是一样的，那么服务端针对这两个报文回复的都是相同的 ACK。<br>这样的话，客户端就无法判断出是原始报文的响应还是重传报文的响应，这样在计算 RTT（往返时间） 时应该选择从发送原始报文开始计算，还是重传原始报文开始计算呢？</p><ul><li>如果算成原始报文的响应，但实际上是重传报文的响应（上图右），会导致采样 RTT 变大；</li><li>如果算成重传报文的响应，但实际上是原始报文的响应（上图左），又很容易导致采样 RTT 过小；</li></ul><p>RTT 计算不精确的话，那么 RTO （超时时间）也就不精确，因为 RTO 是基于 RTT 来计算的，RTO 计算不准确可能导致重传的概率事件增大。<br>QUIC 报文中的 Pakcet Number 是严格递增的， 即使是重传报文，它的 Pakcet Number 也是递增的，这样就能更加精确计算出报文的 RTT。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772971667-1dce02e5-c30f-4a9f-bed9-ddde13c414f0.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=MD4Sb&amp;originHeight=360&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ud13cbc88-bd87-4ae5-a813-f656308dcfc&amp;title=" alt=""><br>如果 ACK 的 Packet Number 是 N+M，就根据重传报文计算采样 RTT。如果 ACK 的 Pakcet Number 是 N，就根据原始报文的时间计算采样 RTT，没有歧义性的问题。<br>另外，还有一个好处，<strong>QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动</strong>。<br>待发送端超过一定时间没收到 Packet N 的确认报文后，会将需要重传的数据包放到待发送队列，重新编号比如数据包 Packet N+M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。<br>所以，Packet Number 单调递增的两个好处：</p><ul><li>可以更加精确计算 RTT，没有 TCP 重传的歧义性问题；</li><li>可以支持乱序确认，防止因为丢包重传将当前窗口阻塞在原地，而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动；<h5 id="QUIC-Frame-Header"><a href="#QUIC-Frame-Header" class="headerlink" title="QUIC Frame Header"></a>QUIC Frame Header</h5><blockquote><p>一个 Packet 报文中可以存放多个 QUIC Frame。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772972004-654ca0ec-9598-42e2-af75-74dc8a408c35.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=293&amp;id=oSnV2&amp;originHeight=482&amp;originWidth=696&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue49a2811-f05a-4789-af21-611f57c4bcf&amp;title=&amp;width=423" alt=""><br>每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。<br>我这里只举例  Stream 类型的 Frame 格式，Stream 可以认为就是一条 HTTP 请求，它长这样：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772972417-11bd8f4f-935a-439b-81ac-7b23ba6a5fab.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=275&amp;id=ZZP4j&amp;originHeight=606&amp;originWidth=660&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u6b8aa8d4-1c02-440e-9027-50e2d1f3b69&amp;title=&amp;width=300.0000305175781" alt=""></p></blockquote></li></ul><p>它里面有：</p><ul><li>Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别；</li><li>Offset 作用：类似于 TCP 协议中的 Seq 序号，<strong>保证数据的顺序性和可靠性</strong>；</li><li>Length 作用：指明了 Frame 数据的长度。</li></ul><p>在前面介绍 Packet Header 时，说到 Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？<br>所以引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p><blockquote><p>举个例子，下图中，数据包 Packet N 丢失了，后面重传该数据包的编号为 Packet N+2，丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致。这些数据包传输到接收端后，接收端能根据 Stream ID 与 Offset 字段信息将  Stream x 和 Stream x+y 按照顺序组织起来，然后交给应用程序处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772973427-9011c1e4-7e34-4779-ac16-d497a4f93187.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uhJPY&amp;originHeight=312&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u969526c3-8c5b-4a5e-9bef-1bd7d57ab75&amp;title=" alt=""></p></blockquote><p>总的来说，<strong>QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装</strong>，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。</p><h4 id="②QUIC-是如何解决-TCP-队头阻塞问题的？"><a href="#②QUIC-是如何解决-TCP-队头阻塞问题的？" class="headerlink" title="②QUIC 是如何解决 TCP 队头阻塞问题的？"></a>②QUIC 是如何解决 TCP 队头阻塞问题的？</h4><h5 id="什么是-TCP-队头阻塞问题？"><a href="#什么是-TCP-队头阻塞问题？" class="headerlink" title="什么是 TCP 队头阻塞问题？"></a>什么是 TCP 队头阻塞问题？</h5><p>TCP 队头阻塞的问题要从两个角度看，一个是<strong>发送窗口的队头阻塞</strong>，另外一个是<strong>接收窗口的队头阻塞</strong>。<br><em>先来说说发送窗口的队头阻塞。</em><br>详细内容TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。<br>举个例子，比如下图的发送方把发送窗口内的数据全部都发出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772973876-3e69e172-0571-4f00-96f9-e0c5d9b69fd2.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ddg6R&amp;originHeight=297&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u214c1fd6-c9ab-4f29-b82d-5b789699494&amp;title=" alt=""><br>可用窗口耗尽<br>接着，当发送方收到对第 32~36 字节的 ACK 确认应答后，则<strong>滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认</strong>，接下来第 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772973805-3b710f7c-ab3c-44fe-9d03-59bfeb7b3291.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=EDZyC&amp;originHeight=274&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ubde576da-d5ea-43ad-8938-112ea06c887&amp;title=" alt=""><br>32 ~ 36 字节已确认<br>但是如果某个数据报文丢失或者其对应的 ACK 报文在网络中丢失，会导致发送方无法移动发送窗口，这时就无法再发送新的数据，只能超时重传这个数据报文，直到收到这个重传报文的 ACK，发送窗口才会移动，继续后面的发送行为。<br>举个例子，比如下图，客户端是发送方，服务器是接收方。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772974701-f33d6abc-2432-4892-a3d8-d15853455612.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=QwtsO&amp;originHeight=446&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u61af77a7-7e6e-4dc0-8378-db255926cc0&amp;title=" alt=""><br>客户端发送了第 5～9 字节的数据，但是第 5 字节的 ACK 确认报文在网络中丢失了，那么即使客户端收到第 6～9 字节的 ACK 确认报文，发送窗口也不会往前移动。<br><strong>此时的第 5 字节相当于“队头”，因为没有收到“队头”的 ACK 确认报文，导致发送窗口无法往前移动，此时发送方就无法继续发送后面的数据，相当于按下了发送行为的暂停键，这就是发送窗口的队头阻塞问题</strong>。<br><em>再来说说接收窗口的队头阻塞。</em><br>详细内容接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，比如下图接收窗口的范围是 32 ～ 51 字节，如果收到第 52 字节以上数据都会被丢弃。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772974598-c28a37a0-b74f-43c1-8e5e-a27d6e5cf2da.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=YLbEK&amp;originHeight=376&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3c217dfc-72ea-4215-aa67-ccc055e7a74&amp;title=" alt=""><br>接收窗口<br>接收窗口什么时候才能滑动？当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。<br>但是，当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， 接收窗口无法向前滑动，那么即使先收到第 33～40 字节的数据，这些数据也无法被应用层读取的。只有当发送方重传了第 32 字节数据并且被接收方收到后，接收窗口才会往前滑动，然后应用层才能从内核读取第 32～40 字节的数据。<br>好了，至此发送窗口和接收窗口的队头阻塞问题都说完了，这两个问题的原因都是因为 TCP 必须按序处理数据，也就是 TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留。</p><ul><li>停留「发送窗口」会使得发送方无法继续发送数据。</li><li>停留「接收窗口」会使得应用层无法读取新的数据。</li></ul><p>其实也不能怪 TCP 协议，它本来设计目的就是为了保证数据的有序性。</p><h5 id="HTTP-2-的队头阻塞"><a href="#HTTP-2-的队头阻塞" class="headerlink" title="HTTP/2  的队头阻塞"></a>HTTP/2  的队头阻塞</h5><p>详细内容HTTP/2 通过抽象出 Stream 的概念，实现了 HTTP 并发传输，一个 Stream 就代表 HTTP/1.1 里的请求和响应。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772980790-807e1e61-30bc-4c90-8895-62490f2f43d0.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=410&amp;id=SFNcD&amp;originHeight=565&amp;originWidth=694&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue8aaeaed-4d44-4ac6-ac77-0913823bf42&amp;title=&amp;width=504.00006103515625" alt=""><br>HTTP/2<br>在 HTTP/2 连接上，不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 Stream 内部的帧必须是严格有序的。<br><strong>但是 HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772981841-493af2b5-5f72-4352-b038-9f2779be849b.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=jA17P&amp;originHeight=377&amp;originWidth=1011&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub03d6828-139f-4f82-9039-661270f716b&amp;title=" alt=""></p><h5 id="没有队头阻塞的-QUIC"><a href="#没有队头阻塞的-QUIC" class="headerlink" title="没有队头阻塞的 QUIC"></a>没有队头阻塞的 QUIC</h5><p>QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。<br>但是 <strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。<br>假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1652772982554-60bc0820-5045-4001-8124-f655317a6032.jpeg#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=221&amp;id=lRSsF&amp;originHeight=377&amp;originWidth=1011&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc7127775-6a10-4577-9475-c52ec65c178&amp;title=&amp;width=593.0000610351562" alt=""></p><h4 id="③QUIC-是如何做流量控制的？"><a href="#③QUIC-是如何做流量控制的？" class="headerlink" title="③QUIC 是如何做流量控制的？"></a>③QUIC 是如何做流量控制的？</h4><p>TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。<br>在前面说到，TCP 的接收窗口在收到有序的数据后，接收窗口才能往前滑动，否则停止滑动；TCP 的发送窗口在收到对已发送数据的顺序确认 ACK后，发送窗口才能往前滑动，否则停止滑动。</p><p>QUIC 是基于 UDP 传输的，而 UDP 没有流量控制，因此 QUIC 实现了自己的流量控制机制。不过，<strong>QUIC 的滑动窗口滑动的条件跟 TCP 有所差别的</strong>。<br>QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：</p><ul><li><strong>Stream 级别的流量控制</strong>：每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。</li><li><p><strong>Connection 流量控制</strong>：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。</p><h5 id="Stream-级别的流量控制"><a href="#Stream-级别的流量控制" class="headerlink" title="Stream 级别的流量控制"></a>Stream 级别的流量控制</h5><p>回想一下 TCP，当发送方发送 seq1、seq2、seq3 报文，由于 seq2 报文丢失了，接收方收到 seq1 后会 ack1，然后接收方收到 seq3 后还是回 ack1（因为没有收到 seq2），这时发送窗口无法往前滑动。<br>但是，<strong>QUIC 就不一样了，即使中途有报文丢失，发送窗口依然可以往前滑动</strong>，具体怎么做到的呢？我们来看看。<br>最开始，接收方的接收窗口初始状态如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772983445-ae5c658c-59fa-44d6-b147-5c4d8e91b838.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=211&amp;id=uI0Xm&amp;originHeight=253&amp;originWidth=741&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u61bca390-38ee-4309-8762-13eed15ff81&amp;title=&amp;width=617.0000610351562" alt=""><br>接着，接收方收到了发送方发送过来的数据，有的数据被上层读取了，有的数据丢包了，此时的接收窗口状况如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772983914-27e8f27f-f9e6-4b4b-b1f0-ea94ed30893c.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=243&amp;id=YM5D5&amp;originHeight=331&amp;originWidth=741&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub7421f21-588c-4ee7-9aed-2977e5f7c2d&amp;title=&amp;width=543" alt=""><br>可以看到，<strong>接收窗口的左边界取决于接收到的最大偏移字节数</strong>，此时的接收窗口 = 最大窗口数 - 接收到的最大偏移数，这里就跟 TCP 不一样了。<br>那接收窗口触发的滑动条件是什么呢？看下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772983865-97ed3615-ee23-46e6-9299-9f3dc6558048.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=404&amp;id=TGrd2&amp;originHeight=778&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3ea7ffe5-00a2-4797-bbc4-7066eefbf18&amp;title=&amp;width=561.0000610351562" alt=""><br>接收窗口触发的滑动<br><strong>当图中的绿色部分数据超过最大接收窗口的一半后，最大接收窗口向右移动，同时给对端发送「窗口更新帧」。当发送方收到接收方的窗口更新帧后，发送窗口也会往前滑动，即使中途有丢包，依然也会滑动</strong>，这样就防止像 TCP 那样在出现丢包的时候，导致发送窗口无法移动，从而避免了无法继续发送数据。<br>在前面我们说过，<strong>每个 Stream 都有各自的滑动窗口，不同 Stream 互相独立，队头的 Stream A 被阻塞后，不妨碍 StreamB、C的读取</strong>。而对于 TCP 而言，其不知道将不同的 Stream 交给上层哪一个请求，因此同一个Connection内，Stream A 被阻塞后，StreamB、C 必须等待。<br>经过了解完 QUIC 的流量控制机制后，对于队头阻塞问题解决得更加彻底。<br><strong>QUIC 协议中同一个 Stream 内，滑动窗口的移动仅取决于接收到的最大字节偏移（尽管期间可能有部分数据未被接收）</strong>，而对于 TCP 而言，窗口滑动必须保证此前的 packet 都有序的接收到了，其中一个 packet 丢失就会导致窗口等待。</p><h5 id="Connection-流量控制"><a href="#Connection-流量控制" class="headerlink" title="Connection 流量控制"></a>Connection 流量控制</h5><p>而对于 Connection 级别的流量窗口，其接收窗口大小就是各个 Stream 接收窗口大小之和。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772983921-4a2f612d-cc84-4824-9e97-6f667ad129fb.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=hVrsZ&amp;originHeight=459&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7727c558-7907-4a7c-9aff-f5bfd601a89&amp;title=" alt=""><br>Connection 流量控制<br>上图所示的例子，所有 Streams 的最大窗口数为 120，其中：</p></li><li><p>Stream 1 的最大接收偏移为 100，可用窗口 = 120 - 100 = 20</p></li><li>Stream 2 的最大接收偏移为 90，可用窗口 = 120 - 90 = 30</li><li>Stream 3 的最大接收偏移为 110，可用窗口 = 120 - 110 = 10</li></ul><p>那么整个 Connection 的可用窗口 = 20 + 30 + 10 = 60<br>可用窗口 = Stream 1 可用窗口 + Stream 2 可用窗口 + Stream 3 可用窗口</p><h4 id="④QUIC-对拥塞控制改进"><a href="#④QUIC-对拥塞控制改进" class="headerlink" title="④QUIC 对拥塞控制改进"></a>④QUIC 对拥塞控制改进</h4><p>QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法（我们熟知的慢开始、拥塞避免、快重传、快恢复策略），同时也支持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法，相当于将 TCP 的拥塞控制算法照搬过来了，QUIC 是如何改进 TCP 的拥塞控制算法的呢？<br>QUIC 是处于应用层的，应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，所以 TCP 拥塞控制算法迭代速度是很慢的。而 <strong>QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度</strong>。<br>TCP 更改拥塞控制算法是对系统中所有应用都生效，无法根据不同应用设定不同的拥塞控制策略。但是因为 QUIC 处于应用层，所以就<strong>可以针对不同的应用设置不同的拥塞控制算法</strong>，这样灵活性就很高了。</p><h4 id="⑤QUIC-更快的连接建立"><a href="#⑤QUIC-更快的连接建立" class="headerlink" title="⑤QUIC 更快的连接建立"></a>⑤QUIC 更快的连接建立</h4><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据，就算 Session 会话服用，也需要至少 2 个 RTT。<br>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。<br>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong>。<br>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772984578-e279d14f-7296-4535-9de5-54493528fefc.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=670&amp;id=ZVftW&amp;originHeight=1266&amp;originWidth=900&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ufafa667d-cd6a-42d1-9864-67737a6af07&amp;title=&amp;width=476.00006103515625" alt=""></p><h4 id="⑥QUIC-是如何迁移连接的？"><a href="#⑥QUIC-是如何迁移连接的？" class="headerlink" title="⑥QUIC 是如何迁移连接的？"></a>⑥QUIC 是如何迁移连接的？</h4><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652772985177-cf83631f-5182-4082-b1c7-4dddf155148a.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=It4ky&amp;originHeight=228&amp;originWidth=821&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua5fec705-f30a-468d-9e5c-bee27fb9b04&amp;title=" alt=""><br>图片<br>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。<br>而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。<br>QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><h2 id="三、优化-HTTP-1-1-协议的思路。"><a href="#三、优化-HTTP-1-1-协议的思路。" class="headerlink" title="三、优化 HTTP/1.1 协议的思路。"></a>三、优化 HTTP/1.1 协议的思路。</h2><p>我们可以从下面这三种优化思路来优化 HTTP/1.1 协议：</p><ul><li><em>尽量避免发送 HTTP 请求</em>；</li><li><em>在需要发送 HTTP 请求时，考虑如何减少请求次数</em>；</li><li><em>减少服务器的 HTTP 响应的数据大小</em>；</li></ul><p>下面，就针对这三种思路具体看看有哪些优化方法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768804704-51a6f7cb-be86-47e5-999d-88332652cd88.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u6f664363&amp;name=image.png&amp;originHeight=1442&amp;originWidth=2760&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=647522&amp;status=done&amp;style=none&amp;taskId=u5a8835b9-d345-42fb-a048-bb8940610e3&amp;title=" alt="image.png"></p><hr><h3 id="Ⅰ如何避免发送-HTTP-请求？"><a href="#Ⅰ如何避免发送-HTTP-请求？" class="headerlink" title="Ⅰ如何避免发送 HTTP 请求？"></a>Ⅰ如何避免发送 HTTP 请求？</h3><ul><li>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</li><li>所以，避免发送 HTTP 请求的方法就是通过<strong>缓存技术</strong>，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。<br>补充那缓存是如何做到的呢？<br>客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系。<br>这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本地磁盘的速度肯定比网络请求快得多，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768795031-35ebc93b-0c45-4cd9-9223-e136db63c2a6.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=621&amp;id=QQO6j&amp;name=image.png&amp;originHeight=1127&amp;originWidth=977&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=269425&amp;status=done&amp;style=none&amp;taskId=u5e7ff292-bfe7-4cbf-b553-3ab48d613ed&amp;title=&amp;width=538" alt="image.png"><br>聪明的你可能想到了，万一缓存的响应不是最新的，而客户端并不知情，那么该怎么办呢？<br>放心，这个问题 HTTP 设计者早已考虑到。<br>所以，服务器在发送 HTTP 响应时，会估算一个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求。</li></ul><p>如果客户端从第一次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是老样子，那么你觉得还要在服务器的响应带上这个资源吗？<br>很显然不带的话，可以提高 HTTP 协议的性能，那具体如何做到呢？<br>只需要客户端在重新发送请求时，在请求的 Etag 头部带上第一次请求的响应头部中的摘要，这个摘要是唯一标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个比较。<br>如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。<br>如果相同，说明客户端的缓存还是可以继续使用的，那么服务器<strong>仅返回不含有包体的 304 Not Modified 响应</strong>，告诉客户端仍然有效，这样就可以减少响应资源在网络中传输的延时，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768795140-a8bfe307-97ef-445d-86a1-dad399037d2f.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=598&amp;id=DJ59v&amp;name=image.png&amp;originHeight=1127&amp;originWidth=1017&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=371699&amp;status=done&amp;style=none&amp;taskId=u1e2b04dc-3668-444c-b22c-1f9e05cf472&amp;title=&amp;width=540" alt="image.png"><br>缓存真的是性能优化的一把万能钥匙，小到 CPU Cache、Page Cache、Redis Cache，大到 HTTP 协议的缓存。</p><h3 id="Ⅱ如何减少-HTTP-请求次数？"><a href="#Ⅱ如何减少-HTTP-请求次数？" class="headerlink" title="Ⅱ如何减少 HTTP 请求次数？"></a>Ⅱ如何减少 HTTP 请求次数？</h3><p>减少 HTTP 请求次数自然也就提升了 HTTP 性能，可以从这 3 个方面入手：</p><ul><li><em>减少重定向请求次数</em>；</li><li><em>合并请求</em>；</li><li><em>延迟发送请求</em>；<h4 id="①减少重定向请求次数"><a href="#①减少重定向请求次数" class="headerlink" title="①减少重定向请求次数"></a>①减少重定向请求次数</h4>将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；<br>补充&gt; 我们先来看看什么是<strong>重定向请求</strong>？<blockquote><p>服务器上的一个资源可能由于迁移、维护等原因从 url1 移至 url2 后，而客户端不知情，它还是继续请求 url1，这时服务器不能粗暴地返回错误，而是通过 302 响应码和 Location 头部，告诉客户端该资源已经迁移至 url2 了，于是客户端需要再发送 url2 请求以获得服务器的资源。<br>那么，如果重定向请求越多，那么客户端就要多次发起 HTTP 请求，每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能。</p></blockquote></li></ul><p>另外，服务端这一方往往不只有一台服务器，比如源服务器上一级是代理服务器，然后代理服务器才与客户端通信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768794912-98c35913-201d-40de-8b33-975a56489381.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=407&amp;id=EK4cp&amp;name=image.png&amp;originHeight=605&amp;originWidth=750&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=125800&amp;status=done&amp;style=none&amp;taskId=uc53e5ee9-19a4-4f51-abac-49b38a01614&amp;title=&amp;width=504" alt="image.png"><br>如果<strong>重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了</strong>，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768794877-a4207a4d-1093-41f2-8ce2-60a5dcb40211.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=402&amp;id=njirT&amp;name=image.png&amp;originHeight=605&amp;originWidth=750&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=105223&amp;status=done&amp;style=none&amp;taskId=ua2a735c4-2f22-4c37-8e80-8791ae52ed0&amp;title=&amp;width=498" alt="image.png"><br>而且当代理服务器知晓了重定向规则后，可以进一步减少消息传递次数，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768803374-d156b233-9ff2-4c15-b722-889557a9b04c.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=329&amp;id=LJk8h&amp;name=image.png&amp;originHeight=485&amp;originWidth=750&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84813&amp;status=done&amp;style=none&amp;taskId=u8de43bd4-556c-4ce6-96fa-bd8c83e9c51&amp;title=&amp;width=509" alt="image.png"><br>除了 302 重定向响应码，还有其他一些重定向的响应码，你可以从下图看到：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768804216-a7db6796-b299-4e5c-81ed-7b8eb0a5fa50.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ypKRw&amp;name=image.png&amp;originHeight=512&amp;originWidth=917&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=230491&amp;status=done&amp;style=none&amp;taskId=u1244ccea-9c12-4c18-9a7a-8414bb06819&amp;title=" alt="image.png"><br>其中，301 和 308 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就自动用 url2 替代 url1 访问服务器的资源。</p><h4 id="②合并请求"><a href="#②合并请求" class="headerlink" title="②合并请求"></a>②合并请求</h4><p>将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；<br>补充</p><ul><li>如果把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着<strong>减少了重复发送的 HTTP 头部</strong>。</li><li>另外由于 HTTP/1.1 是请求响应模型，如果第一个发送的请求，未收到对应的响应，那么后续的请求就不会发送，于是为了防止单个请求的阻塞，所以一般浏览器会同时发起 5-6 个请求，每一个请求都是不同的 TCP 连接，那么如果合并了请求，也就会<strong>减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间</strong>。<blockquote><p>接下来，具体看看合并请求的几种方式。<br>有的网页会含有很多小图片、小图标，有多少个小图片，客户端就要发起多少次请求。那么对于这些小图片，我们可以考虑使用 CSS Image Sprites 技术把它们合成一个大图片，这样浏览器就可以用一次请求获得一个大图片，然后再根据 CSS 数据把大图片切割成多张小图片。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768804234-ead4d028-c56c-46e8-9ae3-e3d2a949f0b6.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=233&amp;id=HxNpQ&amp;name=image.png&amp;originHeight=628&amp;originWidth=1502&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=215417&amp;status=done&amp;style=none&amp;taskId=u799af03d-9d22-4b2f-bd14-c06fc860c42&amp;title=&amp;width=557" alt="image.png"><br>这种方式就是<strong>通过将多个小图片合并成一个大图片来减少 HTTP 请求的次数，以减少 HTTP 请求的次数，从而减少网络的开销</strong>。<br>除了将小图片合并成大图片的方式，还有服务端使用 webpack 等打包工具将 js、css 等资源合并打包成大文件，也是能达到类似的效果。<br>另外，还可以将图片的二进制数据用 base64 编码后，以 URL 的形式潜入到 HTML 文件，跟随 HTML 文件一并发送.<br>&lt;image src=”data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA … /&gt;<br>这样客户端收到 HTML 后，就可以直接解码出数据，然后直接显示图片，就不用再发起图片相关的请求，这样便减少了请求的次数。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652768803878-b08f74f7-d390-4176-a4d8-b3aef13b9015.png#clientId=u25c32a85-e1cc-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=271&amp;id=Elcps&amp;name=image.png&amp;originHeight=531&amp;originWidth=1042&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=155752&amp;status=done&amp;style=none&amp;taskId=ua6639fcb-6493-4691-90d9-0c46606e004&amp;title=&amp;width=532" alt="image.png"><br>可以看到，<strong>合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求</strong>。<br>但是这样的合并请求会带来新的问题，<strong>当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件</strong>，这显然带来了额外的网络消耗。</p></blockquote></li></ul><h4 id="③延迟发送请求"><a href="#③延迟发送请求" class="headerlink" title="③延迟发送请求"></a>③延迟发送请求</h4><ul><li>一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「<strong>按需获取</strong>」的方式，来减少第一时间的 HTTP 请求次数。</li><li><p>请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。</p><h3 id="Ⅲ如何减少-HTTP-响应的数据大小？"><a href="#Ⅲ如何减少-HTTP-响应的数据大小？" class="headerlink" title="Ⅲ如何减少 HTTP 响应的数据大小？"></a>Ⅲ如何减少 HTTP 响应的数据大小？</h3><p>对响应的资源进行<strong>压缩</strong>，这样就可以减少响应的数据大小，从而提高网络传输的效率。<br>压缩的方式一般分为 2 种，分别是：</p></li><li><p><em>无损压缩</em>；</p></li><li><em>有损压缩</em>；<h4 id="①无损压缩"><a href="#①无损压缩" class="headerlink" title="①无损压缩"></a>①无损压缩</h4>无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。<blockquote><p>gzip 就是比较常见的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字段告诉服务器：<br>Accept-Encoding: gzip, deflate, br<br>服务器收到后，会从中选择一个服务器支持的或者合适的压缩算法，然后使用此压缩算法对响应资源进行压缩，最后通过响应头部中的 content-encoding 字段告诉客户端该资源使用的压缩算法。<br>content-encoding: gzip </p></blockquote></li></ul><h4 id="②有损压缩"><a href="#②有损压缩" class="headerlink" title="②有损压缩"></a>②有损压缩</h4><p>与无损压缩相对的就是有损压缩，经过此方法压缩，解压的数据会与原始数据不同但是非常接近。<br>有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。</p><blockquote><p>可以通过 HTTP 请求头部中的 Accept 字段里的「 q 质量因子」，告诉服务器期望的资源质量。<br>Accept: audio/*; q=0.2, audio/basic </p></blockquote><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这次主要从 3 个方面介绍了优化 HTTP/1.1 协议的思路。</p><p>第⼀个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第⼀个请求的响应后，可以将其缓存在本地磁 盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候 带上响应数据的摘要，服务器⽐对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。<br>第⼆个思路是，减少 HTTP 请求的次数，有以下的⽅法： </p><ol><li>将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少᯿定向请求的次数； </li><li>将多个⼩资源合并成⼀个⼤资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连 接数ᰁ，进⽽省去 TCP 握⼿和慢启动的⽹络消耗； </li><li>按需访问资源，只访问当前⽤户看得到/⽤得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同⼀时间的 HTTP 请求次数。<br>第三思路是，通过压缩响应资源，降低传输资源的⼤⼩，从⽽提⾼传输效率，所以应当选择更优秀的压缩算法。<h2 id="👌四、深入HTTPS"><a href="#👌四、深入HTTPS" class="headerlink" title="👌四、深入HTTPS"></a>👌四、深入HTTPS</h2><h3 id="ⅠHTTPS-RSA-握手解析"><a href="#ⅠHTTPS-RSA-握手解析" class="headerlink" title="ⅠHTTPS RSA 握手解析"></a>ⅠHTTPS RSA 握手解析</h3>详细内容我前面讲，简单给大家介绍了的 HTTPS 握手过程，但是还不够细！<br>只讲了比较基础的部分，所以这次我们再来深入一下 HTTPS，用<strong>实战抓包</strong>的方式，带大家再来窥探一次 HTTPS。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479762947-07f3c9a8-799d-4adf-a0ad-f2eb0f773ec8.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=363&amp;id=kcGWw&amp;originHeight=1110&amp;originWidth=1824&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0acf54b3-a35c-4c4e-b94a-4de9d20edac&amp;title=&amp;width=597" alt=""></li></ol><hr><h4 id="①TLS-握手过程"><a href="#①TLS-握手过程" class="headerlink" title="①TLS 握手过程"></a>①TLS 握手过程</h4><p>HTTP 由于是明文传输，所谓的明文，就是说客户端与服务端通信的信息都是肉眼可见的，随意使用一个抓包工具都可以截获通信的内容。<br>所以安全上存在以下三个风险：</p><ul><li><em>窃听风险</em>，比如通信链路上可以获取通信内容，用户号容易没。</li><li><em>篡改风险</em>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li><li><em>冒充风险</em>，比如冒充淘宝网站，用户钱容易没。</li></ul><p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 TLS 协议，来解决上述的风险。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479762205-58960f94-6df0-43be-b248-9095ef48c78d.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=PkuoT&amp;originHeight=275&amp;originWidth=596&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u60f67a7f-7172-40b3-8162-81437bdaa0a&amp;title=" alt=""><br>TLS 协议是如何解决 HTTP 的风险的呢？</p><ul><li><em>信息加密</em>： HTTP 交互信息是被加密的，第三方就无法被窃取；</li><li><em>校验机制</em>：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示；</li><li><em>身份证书</em>：证明淘宝是真的淘宝网；</li></ul><p>可见，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进行 HTTP 通信前，需要先进行 TLS 握手。TLS 的握手过程，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479763057-3866738c-e5e1-4eb4-803b-59d57c3fcdcf.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=647&amp;id=hRyZJ&amp;originHeight=1260&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u95a2635d-49f1-44b7-87e9-df678bda4ec&amp;title=&amp;width=556" alt=""><br>上图简要概述了 TLS 的握手过程，其中每一个「框」都是一个记录（<em>record</em>），记录是 TLS 收发数据的基本单位，类似于 TCP 里的 segment。多个记录可以组合成一个 TCP 包发送，所以<strong>通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延</strong>，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。<br>所以可以发现，HTTPS 是应用层协议，需要先完成 TCP 连接建立，然后走 TLS 握手过程后，才能建立通信安全的连接。<br>事实上，不同的密钥交换算法，TLS 的握手过程可能会有一些区别。<br>这里先简单介绍下密钥交换算法，因为考虑到性能的问题，所以双方在加密应用信息时使用的是对称加密密钥，而对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使用非对称加密的方式来保护对称加密密钥的协商，这个工作就是密钥交换算法负责的。<br>接下来，我们就以最简单的 RSA 密钥交换算法，来看看它的 TLS 握手过程。</p><hr><h4 id="②RSA-握手过程"><a href="#②RSA-握手过程" class="headerlink" title="②RSA 握手过程"></a>②RSA 握手过程</h4><p>传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件中包含一对公私钥，其中公钥会在 TLS 握手阶段传递给客户端，私钥则一直留在服务端，一定要确保私钥不能被窃取。<br>在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。<br>我用 Wireshark 工具抓了用 RSA 密钥交换的 TLS 握手过程，你可以从下面看到，一共经历来四次握手：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479762564-1551f6ad-64d4-4399-b84f-014cd595d7bf.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=CYqqc&amp;originHeight=380&amp;originWidth=1083&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue1cab88a-0e77-4488-ae8a-ecd624a9cae&amp;title=" alt=""><br>对应 Wireshark 的抓包，我也画了一幅图，你可以从下图很清晰地看到该过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479763725-e1962f6e-257f-472d-a812-9dd27e89896b.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=kRv01&amp;originHeight=2957&amp;originWidth=1859&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u509693af-c671-48d3-bfcf-2d677227751&amp;title=" alt=""><br>那么，接下来针对每一个 TLS 握手做进一步的介绍。</p><h5 id="TLS-第一次握手"><a href="#TLS-第一次握手" class="headerlink" title="TLS 第一次握手"></a>TLS 第一次握手</h5><p>客户端首先会发一个「<strong>Client Hello</strong>」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479763417-8076ddf7-4d04-4c29-bf12-bcdfad75b6a5.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=317&amp;id=hZM5q&amp;originHeight=353&amp;originWidth=734&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u96e82e06-df96-4188-9f12-b264bac2ed3&amp;title=&amp;width=659" alt=""><br>消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（<em>Client Random</em>）</strong>，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。</p><h5 id="TLS-第二次握手"><a href="#TLS-第二次握手" class="headerlink" title="TLS 第二次握手"></a>TLS 第二次握手</h5><p>当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成<strong>随机数（<em>Server Random</em>）</strong>。<br>接着，返回「<strong>Server Hello</strong>」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479763955-b76939b5-fed5-4dbf-a3c1-b731d38c48d1.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=nstlE&amp;originHeight=310&amp;originWidth=682&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uae007a46-a8d5-464b-a321-3512b1f9930&amp;title=" alt=""></p><blockquote><p>可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。<br>这个密码套件看起来真让人头晕，好一大串，但是其实它是有固定格式和规范的。基本的形式是「<strong>密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法</strong>」， 一般 WITH 单词前面有两个单词，第一个单词是约定密钥交换的算法，第二个单词是约定证书的验证算法。比如刚才的密码套件的意思就是：</p><ul><li>由于 WITH 单词只有一个 RSA，则说明握手时密钥交换算法和签名算法都是使用 RSA；</li><li>握手后的通信使用 AES 对称算法，密钥长度 128 位，分组模式是 GCM；</li><li>摘要算法 SHA256 用于消息认证和产生随机数；</li></ul></blockquote><p>就前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使用的密码套件，而且你可能发现客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方。<br>那这个随机数有啥用呢？其实这两个随机数是后续作为生成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使用的对称加密密钥。<br>然后，服务端为了证明自己的身份，会发送「<strong>Server Certificate</strong>」给客户端，这个消息里含有数字证书。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479764092-6df5578c-71b0-4d57-b819-c34ecdc7e6b0.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=R30Dc&amp;originHeight=202&amp;originWidth=751&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u1bbe17de-6955-4403-abe7-46a6e30046c&amp;title=" alt=""><br>随后，服务端发了「<strong>Server Hello Done</strong>」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479766165-5b61966d-5b98-4142-a637-0de3f2032f93.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=XbkgG&amp;originHeight=98&amp;originWidth=594&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u507e18c3-9327-4e43-95c4-fd698b84af9&amp;title=" alt=""></p><h5 id="客户端验证证书"><a href="#客户端验证证书" class="headerlink" title="客户端验证证书"></a>客户端验证证书</h5><p>在这里刹个车，客户端拿到了服务端的数字证书后，要怎么校验该数字证书是真实有效的呢？</p><h6 id="数字证书和-CA-机构"><a href="#数字证书和-CA-机构" class="headerlink" title="数字证书和 CA 机构"></a>数字证书和 CA 机构</h6><p>在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，一个数字证书通常包含了：</p><ul><li>公钥；</li><li>持有者信息；</li><li>证书认证机构（CA）的信息；</li><li>CA 对这份文件的数字签名及使用的算法；</li><li>证书有效期；</li><li>还有一些其他额外信息；</li></ul><p>那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。<br>我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？<br>为了让服务端的公钥被大家信任，服务端的证书都是由 CA （<em>Certificate Authority</em>，证书认证机构）签名的，CA 就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，那必然证书也是被信任的。<br>之所以要签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改。</p><h6 id="数字证书签发和验证流程"><a href="#数字证书签发和验证流程" class="headerlink" title="数字证书签发和验证流程"></a>数字证书签发和验证流程</h6><p>如下图图所示，为数字证书签发和验证流程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479766485-01eb0910-270c-4b41-81f9-f57c86de6e5a.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=JsBRd&amp;originHeight=740&amp;originWidth=1337&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u258568b6-c91a-4d62-ab47-282869b1cf6&amp;title=" alt=""><br>CA 签发证书的过程，如上图左边部分：</p><ul><li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li><li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li><li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li></ul><p>客户端校验服务端的数字证书的过程，如上图右边部分：</p><ul><li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li><li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li><li><p>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</p><h6 id="证书链"><a href="#证书链" class="headerlink" title="证书链"></a>证书链</h6><p>但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479766666-247d5e63-043a-4d71-a5a5-b9d7d0b24ad9.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=QaORa&amp;originHeight=217&amp;originWidth=567&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub53d0d6d-2fda-4e57-b1f5-2cc063676b8&amp;title=" alt=""><br>对于这种三级层级关系的证书的验证过程如下：</p></li><li><p>客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。</p></li><li>请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。</li><li>“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。</li></ul><p>在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。<br>总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479766778-4bd6575b-8d9d-412e-a9dc-03026dd6eba8.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=664&amp;id=Mc9u1&amp;originHeight=891&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u415f3721-2faf-4dea-a53d-4dea8c70396&amp;title=&amp;width=527" alt=""><br>操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479767139-a067f413-7335-4990-8d10-b3e3a4cae4ad.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=362&amp;id=ViekE&amp;originHeight=534&amp;originWidth=867&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u5ecc8aee-e396-4379-a145-a126c68d400&amp;title=&amp;width=588" alt=""><br>这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479767203-ad8bb93e-22b3-4d36-b536-02288e1f694d.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=173&amp;id=JB4RZ&amp;originHeight=452&amp;originWidth=1478&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u4f18f402-a671-45be-a2d7-28247a6b69f&amp;title=&amp;width=565" alt=""><br>最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？<br>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</p><h5 id="TLS-第三次握手"><a href="#TLS-第三次握手" class="headerlink" title="TLS 第三次握手"></a>TLS 第三次握手</h5><p>客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的<strong>随机数 (<em>pre-master</em>)</strong>，用服务器的 RSA 公钥加密该随机数，通过「<strong>Change Cipher Key Exchange</strong>」消息传给服务端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479767698-98852719-067e-4fb0-a95f-ba634ca39734.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=W5jiY&amp;originHeight=190&amp;originWidth=836&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u04724166-13a8-422b-801e-361c9e18ffb&amp;title=" alt=""><br>服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。<br>至此，<strong>客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master</strong>。<br>于是，双方根据已经得到的三个随机数，生成<strong>会话密钥（Master Secret）</strong>，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。<br>生成完会话密钥后，然后客户端发一个「<strong>Change Cipher Spec</strong>」，告诉服务端开始使用加密方式发送消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479768026-15632718-014a-4d8d-88c3-bb1bb095597c.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=jStT9&amp;originHeight=95&amp;originWidth=630&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u15bef019-bc75-4ff5-8ed7-dc3d251dc1e&amp;title=" alt=""><br>然后，客户端再发一个「<strong>Encrypted Handshake Message（Finishd）</strong>」消息，把之前所有发送的数据做个摘要，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479768284-70ab404d-e893-450f-b3dc-406bbe362584.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=aRcin&amp;originHeight=103&amp;originWidth=635&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uefb61905-0cd6-43cc-85ea-00d10f6aecc&amp;title=" alt=""><br>可以发现，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。</p><h5 id="TLS-第四次握手"><a href="#TLS-第四次握手" class="headerlink" title="TLS 第四次握手"></a>TLS 第四次握手</h5><p>服务器也是同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。<br>最后，就用「会话密钥」加解密 HTTP 请求和响应了。</p><hr><h4 id="RSA-算法的缺陷"><a href="#RSA-算法的缺陷" class="headerlink" title="RSA 算法的缺陷"></a>RSA 算法的缺陷</h4><p><strong>使用 RSA 密钥协商算法的最大问题是不支持前向保密</strong>。<br>因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。<br>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法，关于 ECDHE 握手的过程，将在下一篇揭晓。</p><h3 id="ⅡHTTPS-ECDHE-握手解析"><a href="#ⅡHTTPS-ECDHE-握手解析" class="headerlink" title="ⅡHTTPS ECDHE 握手解析"></a>ⅡHTTPS ECDHE 握手解析</h3><p>详细内容HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。<br>其中，RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法具有前向安全，所以被广泛使用。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479941180-91a72cca-173e-454e-9313-8410874146de.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=480&amp;id=xNhrH&amp;originHeight=1566&amp;originWidth=1388&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u449d6d65-26d1-42c5-a08f-e1fb385c130&amp;title=&amp;width=425" alt=""></p><hr><h4 id="离散对数"><a href="#离散对数" class="headerlink" title="离散对数"></a>离散对数</h4><p>ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。<br>DH 算法是非对称加密算法， 因此它可以用于密钥交换，该算法的核心数学思想是<strong>离散对数</strong>。</p><p>离散对数是「离散 + 对数」的两个数学概念的组合。<br>要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。<br>举个栗子，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479940869-5eb0369f-796f-47d7-aecb-3bfb69490382.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=U55hz&amp;originHeight=257&amp;originWidth=437&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u835e2e41-02cc-4a51-9ae6-2987480c9d9&amp;title=" alt=""><br>那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479940868-9206e676-c6e2-416f-a482-b6283c4976e6.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=202&amp;id=sUYaM&amp;originHeight=279&amp;originWidth=702&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u037a782e-0d42-41eb-ab28-3fd8c5ac8c0&amp;title=&amp;width=507" alt=""><br>对数运算的取值是可以连续的，而离散对数的取值是不能连续的，因此也以「离散」得名，<br>离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语言的操作符是「%」，也可以用 mod 表示。离散对数的概念如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479940962-aa95b1e3-aff9-4242-a1bc-ddf045fe3ca9.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=H4xxp&amp;originHeight=227&amp;originWidth=692&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u1624e6f6-eccf-4e34-b32c-9fdfab36fad&amp;title=" alt=""><br>上图的，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。<br><strong>特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。</strong></p><hr><h4 id="DH-算法"><a href="#DH-算法" class="headerlink" title="DH 算法"></a>DH 算法</h4><p>认识了离散对数，我们来看看 DH 算法是如何密钥交换的。<br>现假设小红和小明约定使用 DH 算法来交换密钥，那么基于离散对数，小红和小明需要先确定模数和底数作为算法的参数，这两个参数是公开的，用 P 和 G 来代称。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480210806-016e8653-b330-4ea2-b1b7-e887b8494815.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=55&amp;id=Kq1fg&amp;name=image.png&amp;originHeight=69&amp;originWidth=286&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=7371&amp;status=done&amp;style=none&amp;taskId=ud14b6b0b-b1a2-47ec-9dda-9616621accb&amp;title=&amp;width=228.8" alt="image.png">也就是a和p<br>然后小红和小明各自生成一个随机整数作为<strong>私钥（对数，指数）</strong>，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称。<br>现在小红和小明双方都有了 P 和 G 以及各自的私钥，于是就可以计算出<strong>公钥</strong>：</p><ul><li>小红的公钥记作 A，A = G ^ a ( mod P )；</li><li>小明的公钥记作 B，B = G ^ b ( mod P )；</li></ul><p>A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有计算机的计算能力是无法破解的，如果量子计算机出来了，那就有可能被破解，当然如果量子计算机真的出来了，那么密钥协商算法就要做大的升级了。<br>双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。<br>然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479941025-c8b92cb5-848e-4521-9e51-b6275f69d53c.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=348&amp;id=WGcs0&amp;originHeight=429&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua350ff4a-9217-4efb-a2b1-7060b7f97bb&amp;title=&amp;width=635" alt=""><br>这个 K 就是小红和小明之间用的<strong>对称加密密钥</strong>，可以作为会话密钥使用。<br>可以看到，整个密钥协商过程中，小红和小明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B 是公钥，而 a、b 是双方各自保管的私钥，黑客无法获取这 2 个私钥，因此黑客只能从公开的 P、G、A、B 入手，计算出离散对数（私钥）。<br>前面也多次强调， 根据离散对数的原理，如果 P 是一个大数，在现有的计算机的计算能力是很难破解出 私钥 a、b 的，破解不出私钥，也就无法计算出会话密钥，因此 DH 密钥交换是安全的。</p><hr><h4 id="DHE-算法"><a href="#DHE-算法" class="headerlink" title="DHE 算法"></a>DHE 算法</h4><p>根据私钥生成的方式，DH 算法分为两种实现：</p><ul><li>static DH 算法，这个是已经被废弃了；</li><li>DHE 算法，现在常用的；</li></ul><p>static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。<br>于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 <strong>static DH 算法不具备前向安全性</strong>。<br>既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。<br>所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为<strong>每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」</strong>。</p><hr><h4 id="ECDHE-算法"><a href="#ECDHE-算法" class="headerlink" title="ECDHE 算法"></a>ECDHE 算法</h4><p>DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— <strong>ECDHE 算法</strong>。<br>ECDHE 算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。<br>小红和小明使用 ECDHE 密钥交换算法的过程：</p><ul><li>双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；</li><li>双方各自随机生成一个随机数作为<strong>私钥d</strong>，并与基点 G相乘得到<strong>公钥Q</strong>（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；</li><li>双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此<strong>双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥</strong>。</li></ul><p>这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。</p><hr><h4 id="ECDHE-握手过程"><a href="#ECDHE-握手过程" class="headerlink" title="ECDHE 握手过程"></a>ECDHE 握手过程</h4><p>知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。<br>我用 Wireshark 工具抓了用 ECDHE 密钥协商算法的 TSL 握手过程，可以看到是四次握手：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479942157-5534c99a-50ed-4ab3-a905-8d643e833a14.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=BG7Lg&amp;originHeight=362&amp;originWidth=1005&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u48eb7e6b-21d0-4db9-b66f-eae3fdaffa9&amp;title=" alt=""><br>细心的小伙伴应该发现了，<strong>使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据</strong>，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。<br>所以，<strong>ECDHE 相比 RSA 握手过程省去了一个消息往返的时间</strong>，这个有点「抢跑」的意思，它被称为是「<em>TLS False Start</em>」，跟「<em>TCP Fast Open</em>」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。<br>接下来，分析每一个 ECDHE 握手过程。</p><h5 id="TLS-第一次握手-1"><a href="#TLS-第一次握手-1" class="headerlink" title="TLS 第一次握手"></a>TLS 第一次握手</h5><p>客户端首先会发一个「<strong>Client Hello</strong>」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（<em>Client Random</em>）</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479942945-2ed2e0c0-b288-4ef2-aa4a-a0fecb7a38ac.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=276&amp;id=Msugu&amp;originHeight=476&amp;originWidth=917&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u51dc4cc6-be45-424a-afa8-d1e96a9245a&amp;title=&amp;width=531" alt=""></p><h5 id="TLS-第二次握手-1"><a href="#TLS-第二次握手-1" class="headerlink" title="TLS 第二次握手"></a>TLS 第二次握手</h5><p>服务端收到客户端的「打招呼」，同样也要回礼，会返回「<strong>Server Hello</strong>」消息，消息面有服务器确认的 TLS 版本号，也给出了一个<strong>随机数（<em>Server Random</em>）</strong>，然后从客户端的密码套件列表选择了一个合适的密码套件。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479942980-ce8dc9f5-d9bb-4fc8-860f-df350c8263e0.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=283&amp;id=RdDaL&amp;originHeight=445&amp;originWidth=897&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u2883b76a-2c42-44ee-9a0f-a24705bd412&amp;title=&amp;width=571" alt=""><br>不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。<br>「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」</p><ul><li>密钥协商算法使用 ECDHE；</li><li>签名算法使用 RSA；</li><li>握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM；</li><li>摘要算法使用 SHA384；</li></ul><p>接着，服务端为了证明自己的身份，发送「<strong>Certificate</strong>」消息，会把证书也发给客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479942960-54fc2103-d807-4157-bdfd-a172e6bd5b48.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=166&amp;id=uG1zo&amp;originHeight=256&amp;originWidth=1015&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uaa313ed4-4a4d-4985-9a99-721eeaece35&amp;title=&amp;width=658" alt=""><br>这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「<strong>Server Key Exchange</strong>」消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479943194-1ab94fe4-96fb-40d5-bb65-ee99a10583d2.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=228&amp;id=GA10p&amp;originHeight=343&amp;originWidth=1000&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua249648b-d1b5-443c-910d-3dc09a04997&amp;title=&amp;width=666" alt=""><br>这个过程服务器做了三件事：</p><ul><li>选择了<strong>名为 x25519 的椭圆曲线</strong>，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；</li><li>生成随机数作为服务端椭圆曲线的私钥，保留到本地；</li><li>根据基点 G 和私钥计算出<strong>服务端的椭圆曲线公钥</strong>，这个会公开给客户端。</li></ul><p>为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。<br>随后，就是「<strong>Server Hello Done</strong>」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479944331-75a4b1fa-1400-4512-8828-5eef0d8f9b03.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=KOptt&amp;originHeight=116&amp;originWidth=707&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u37600090-645f-450f-be3a-c4d76d29fb4&amp;title=" alt=""><br>至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息：<strong>Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥</strong>，这几个信息很重要，是后续生成会话密钥的材料。</p><h5 id="TLS-第三次握手-1"><a href="#TLS-第三次握手-1" class="headerlink" title="TLS 第三次握手"></a>TLS 第三次握手</h5><p>客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。<br>客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成<strong>客户端的椭圆曲线公钥</strong>，然后用「<strong>Client Key Exchange</strong>」消息发给服务端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479947360-5907630e-065c-4aa8-bce3-857382d038d8.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=aanod&amp;originHeight=235&amp;originWidth=880&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u24db2275-e465-44bd-9e26-26f44891e83&amp;title=" alt=""><br>至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，<strong>但实际应用中，x 还不是最终的会话密钥</strong>。<br>还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？<br><strong>最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的</strong>。<br>之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。<br>算好会话密钥后，客户端会发一个「<strong>Change Cipher Spec</strong>」消息，告诉服务端后续改用对称算法加密通信。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479947270-4b379374-7afc-4aae-8cc8-4bacf8e847cf.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=txkOe&amp;originHeight=118&amp;originWidth=777&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0e6cbccb-69c3-4aa0-927b-074341316ad&amp;title=" alt=""><br>接着，客户端会发「<strong>Encrypted Handshake Message</strong>」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651479947277-30387f5a-bb9a-4a26-9382-a4825445feb2.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=No8X0&amp;originHeight=122&amp;originWidth=794&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ue49e0bb0-9b91-405e-988d-ccdc4d28f9f&amp;title=" alt=""></p><h5 id="TLS-第四次握手-1"><a href="#TLS-第四次握手-1" class="headerlink" title="TLS 第四次握手"></a>TLS 第四次握手</h5><p>最后，服务端也会有一个同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。</p><hr><p>总结<br>RSA 和 ECDHE 握手过程的区别：</p><ul><li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li><li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；</li><li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息；<h3 id="ⅢHttps如何优化"><a href="#ⅢHttps如何优化" class="headerlink" title="ⅢHttps如何优化"></a>ⅢHttps如何优化</h3>由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应用数据套了个「保护伞」，提高安全性的同时也带来了性能消耗。<br>因为 HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，<strong>目的是为了通过非对称加密握手协商或者交换出对称加密密钥</strong>，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密/解密。<br>为了数据的安全性，我们不得不使用 HTTPS 协议，至今大部分网址都已从 HTTP 迁移至 HTTPS 协议，因此针对 HTTPS 的优化是非常重要的。<br>这次，就从多个角度来优化 HTTPS。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480770117-37d3709f-2469-4bda-b76f-b46653002550.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=697&amp;id=u38f68a85&amp;originHeight=979&amp;originWidth=824&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u2b536bf6-4e97-4d87-9a89-f6bdfefa802&amp;title=&amp;width=587" alt=""></li></ul><hr><h4 id="分析性能损耗"><a href="#分析性能损耗" class="headerlink" title="分析性能损耗"></a>分析性能损耗</h4><p>既然要对 HTTPS 优化，那得清楚哪些步骤会产生性能消耗，再对症下药。<br>产生性能消耗的两个环节：</p><ul><li>第一个环节， TLS 协议握手过程；</li><li>第二个环节，握手后的对称加密报文传输。</li></ul><p>对于第二环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说非常地小。<br>而第一个环节，TLS 协议握手过程不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：</p><ul><li>对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；</li><li>客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；</li><li>双方计算 Pre-Master，也就是对称加密密钥；</li></ul><p>为了大家更清楚这些步骤在 TLS 协议握手的哪一个阶段，我画出了这幅图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480770248-f263d594-f463-4acf-a6f4-5cddb22c0a36.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=666&amp;id=u5933d48b&amp;originHeight=1260&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u751cbbc2-d444-433e-a814-2bbddcba30f&amp;title=&amp;width=572" alt=""></p><hr><h4 id="硬件优化"><a href="#硬件优化" class="headerlink" title="硬件优化"></a>硬件优化</h4><p>软件都是跑在物理硬件上，硬件越牛逼，软件跑的也越快，所以如果要优化 HTTPS 优化，最直接的方式就是花钱买性能参数更牛逼的硬件。<br>但是花钱也要花对方向，<strong>HTTPS 协议是计算密集型，而不是 I/O 密集型</strong>，所以不能把钱花在网卡、硬盘等地方，应该花在 CPU 上。<br>一个好的 CPU，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速 TLS 握手过程。<br>另外，如果可以，应该选择可以<strong>支持 AES-NI 特性的 CPU</strong>，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。<br>如果你的服务器是 Linux 系统，那么你可以使用下面这行命令查看 CPU 是否支持 AES-NI 指令集：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480769966-18271c07-2c4b-4ba5-a696-32f1ebd3f7a4.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue158168e&amp;originHeight=220&amp;originWidth=812&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u9a8d6cdf-fb6a-41e6-8cb9-dae177f4bb9&amp;title=" alt=""><br>如果我们的 CPU 支持 AES-NI 特性，那么对于对称加密的算法应该选择 AES 算法。否则可以选择 ChaCha20 对称加密算法，因为 ChaCha20 算法的运算指令相比 AES 算法会对 CPU 更友好一点。</p><hr><h4 id="软件优化"><a href="#软件优化" class="headerlink" title="软件优化"></a>软件优化</h4><p>软件的优化方向可以分层两种，一个是<strong>软件升级</strong>，一个是<strong>协议优化</strong>。<br>先说第一个软件升级，软件升级就是将正在使用的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。比如：</p><ul><li>将 Linux 内核从 2.x 升级到 4.x；</li><li>将 OpenSSL 从 1.0.1 升级到 1.1.1；</li><li>…</li></ul><hr><h4 id="协议优化"><a href="#协议优化" class="headerlink" title="协议优化"></a>协议优化</h4><p>协议的优化就是对「密钥交换过程」进行优化。</p><h5 id="密钥交换算法优化"><a href="#密钥交换算法优化" class="headerlink" title="密钥交换算法优化"></a>密钥交换算法优化</h5><p>TLS 1.2 版本如果使用的是 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 2 RTT，才可以进行应用数据的传输，而且 RSA 密钥交换算法不具备前向安全性。<br>总之使用 <strong>RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高</strong>。<br>因此如果可以，尽量<strong>选用 ECDHE 密钥交换</strong>算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 <strong>TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性</strong>。<br>ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量<strong>选择 x25519 曲线</strong>，该曲线是目前最快的椭圆曲线。</p><h5 id="TLS-升级"><a href="#TLS-升级" class="headerlink" title="TLS 升级"></a>TLS 升级</h5><p>当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，<strong>完成 TLS 握手只要 1 RTT</strong>，而且安全性更高。<br>在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握手过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480771962-c35801cf-066d-4db0-a428-7815fcdd0bd4.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u9ede6802&amp;originHeight=1290&amp;originWidth=1832&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ueebe637f-45f9-444b-b71a-540afa46caf&amp;title=" alt=""><br>上图的右边部分就是 TLS 1.3 的握手过程，可以发现 <strong>TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手</strong>。</p><hr><h4 id="证书优化"><a href="#证书优化" class="headerlink" title="证书优化"></a>证书优化</h4><p>为了验证的服务器的身份，服务器会在 TSL 握手过程中，把自己的证书发给客户端，以此证明自己身份是可信的。<br>对于证书的优化，可以有两个方向：</p><ul><li>一个是<strong>证书传输</strong>，</li><li><p>一个是<strong>证书验证</strong>；</p><h5 id="证书传输优化"><a href="#证书传输优化" class="headerlink" title="证书传输优化"></a>证书传输优化</h5><p>要让证书更便于传输，那必然是减少证书的大小，这样可以节约带宽，也能减少客户端的运算量。所以，<strong>对于服务器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥长度比 RSA 短的多</strong>。</p><h5 id="证书验证优化"><a href="#证书验证优化" class="headerlink" title="证书验证优化"></a>证书验证优化</h5><p>客户端在验证证书时，是个复杂的过程，会走证书链逐级验证，验证的过程不仅需要「用 CA 公钥解密证书」以及「用签名算法验证证书的完整性」，而且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL 或者 OCSP 数据，以此确认证书的有效性。<br>这个访问过程是 HTTP 访问，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。</p><h6 id="CRL"><a href="#CRL" class="headerlink" title="CRL"></a>CRL</h6><p>CRL 称为证书吊销列表（<em>Certificate Revocation List</em>），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480771672-7a82759b-5e87-4059-8588-4fc6024e59d1.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=433&amp;id=u5f40ce15&amp;originHeight=588&amp;originWidth=894&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u9f9f3ab2-8670-4946-812e-4729ef00b93&amp;title=&amp;width=658" alt=""><br>但是 CRL 存在两个问题：</p></li><li><p>第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，<strong>实时性较差</strong>；</p></li><li>第二个问题，<strong>随着吊销证书的增多，列表会越来越大，下载的速度就会越慢</strong>，下载完客户端还得遍历这么大的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 HTTPS 连接。<h6 id="OCSP"><a href="#OCSP" class="headerlink" title="OCSP"></a>OCSP</h6>因此，现在基本都是使用 OCSP ，名为在线证书状态协议（<em>Online Certificate Status Protocol</em>）来查询证书的有效性，它的工作方式是<strong>向 CA 发送查询请求，让 CA 返回证书的有效状态</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480772293-ee3fe24a-2076-449d-ba33-3b836f6599a1.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u531c1191&amp;originHeight=569&amp;originWidth=852&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u60bade94-2f94-4e2b-a782-f13fcb8228f&amp;title=" alt=""><br>不必像 CRL 方式客户端需要下载大大的列表，还要从列表查询，同时因为可以实时查询每一张证书的有效性，解决了 CRL 的实时性问题。<br>OCSP 需要向 CA 查询，因此也是要发生网络请求，而且还得看 CA 服务器的“脸色”，如果网络状态不好，或者 CA 服务器繁忙，也会导致客户端在校验证书这一环节的延时变大。<h6 id="OCSP-Stapling"><a href="#OCSP-Stapling" class="headerlink" title="OCSP Stapling"></a>OCSP Stapling</h6>于是为了解决这一个网络开销，就出现了 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480772184-a8deb3eb-97d8-47f2-a579-fd916dae0e12.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5cf561c0&amp;originHeight=345&amp;originWidth=691&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u92fd9a63-c54c-443c-bbda-de11b78c150&amp;title=" alt=""><br>当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握手过程中发给客户端。由于有签名的存在，服务器无法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。</li></ul><hr><h4 id="会话复用"><a href="#会话复用" class="headerlink" title="会话复用"></a>会话复用</h4><p>TLS 握手的目的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把首次 TLS 握手协商的对称加密密钥缓存起来，待下次需要建立 HTTPS 连接时，直接「复用」这个密钥，不就减少 TLS 握手的性能损耗了吗？<br>这种方式就是<strong>会话复用</strong>（<em>TLS session resumption</em>），会话复用分两种：</p><ul><li>第一种叫 Session ID；</li><li><p>第二种叫 Session Ticket；</p><h5 id="Session-ID"><a href="#Session-ID" class="headerlink" title="Session ID"></a>Session ID</h5><p>Session ID 的工作原理是，<strong>客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识</strong>，Session ID 和会话密钥相当于 key-value 的关系。<br>当客户端再次连接时，hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然为了安全性，内存中的会话密钥会定期失效。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480773019-2dba1639-2740-4f20-abd4-8ee8c7ae75f5.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u137a9c85&amp;originHeight=518&amp;originWidth=1334&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u04585621-c4ff-40d7-b378-7409a4d6249&amp;title=" alt=""><br>但是它有两个缺点：</p></li><li><p>服务器必须保持每一个客户端的会话密钥，随着客户端的增多，<strong>服务器的内存压力也会越大</strong>。</p></li><li>现在网站服务一般是由多台服务器通过负载均衡提供服务的，<strong>客户端再次连接不一定会命中上次访问过的服务器</strong>，于是还要走完整的 TLS 握手过程；<h5 id="Session-Ticket"><a href="#Session-Ticket" class="headerlink" title="Session Ticket"></a>Session Ticket</h5>为了解决 Session ID 的问题，就出现了 Session Ticket，<strong>服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端</strong>，类似于 HTTP 的 Cookie。<br>客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。<br>客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480773952-7df4c559-08f3-4f1b-9a3c-6b2a4bd402e8.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u43d3a3e7&amp;originHeight=605&amp;originWidth=1297&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u73dea114-4e2c-46a2-a218-263cbb04500&amp;title=" alt=""><br>对于集群服务器的话，<strong>要确保每台服务器加密 「会话密钥」的密钥是一致的</strong>，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。<br>Session ID 和 Session Ticket <strong>都不具备前向安全性</strong>，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。<br>同时应对<strong>重放攻击</strong>也很困难，这里简单介绍下重放攻击工作的原理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480774880-f44bf018-b4af-4703-b30d-fbfa1941eeba.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=420&amp;id=u79e891a7&amp;originHeight=717&amp;originWidth=1060&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u27309c28-f050-472d-99cd-fac701fcaba&amp;title=&amp;width=621" alt=""><br>假设 Alice 想向 Bob 证明自己的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。<br>交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后一个会话中读取的 Alice 的密码（或哈希），从而授予 Eve 访问权限。<br>重放攻击的危险之处在于，如果中间人截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报文，而一般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数据库的数据被中间人改变了，而客户是不知情的。<br>避免重放攻击的方式就是需要<strong>对会话密钥设定一个合理的过期时间</strong>。<h5 id="Pre-shared-Key"><a href="#Pre-shared-Key" class="headerlink" title="Pre-shared Key"></a>Pre-shared Key</h5>前面的 Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。<br>而 TLS1.3 更为牛逼，对于重连 TLS1.3 只需要 <strong>0 RTT</strong>，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 <strong>Pre-shared Key</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480774520-d90ba095-b420-4651-aea7-5cf4708b4c11.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=480&amp;id=u44bdc3dd&amp;originHeight=600&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u32d8eb02-b211-4b2f-86ba-d20639bc23c&amp;title=&amp;width=480" alt=""><br>同样的，Pre-shared Key 也有重放攻击的危险。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651480774510-fc549b59-d41f-4dc9-b51e-58f992c6bda7.png#clientId=u41d3e988-663d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=327&amp;id=udbdee593&amp;originHeight=626&amp;originWidth=1273&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u93b34c56-f821-49ce-a047-b961c6dcd61&amp;title=&amp;width=664" alt=""><br>如上图，假设中间人通过某种方式，截获了客户端使用会话重用技术的 POST 请求，通常 POST 请求是会改变数据库的数据，然后中间人就可以把截获的这个报文发送给服务器，服务器收到后，也认为是合法的，于是就恢复会话，致使数据库的数据又被更改，但是此时用户是不知情的。<br>所以，应对重放攻击可以给会话密钥设定一个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使用会话重用。</li></ul><hr><h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>对于硬件优化的方向，因为 HTTPS 是属于计算密集型，应该选择计算力更强的 CPU，而且最好选择<strong>支持 AES-NI 特性的 CPU</strong>，这个特性可以在硬件级别优化 AES 对称加密算法，加快应用数据的加解密。<br>对于软件优化的方向，如果可以，把软件升级成较新的版本，比如将 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1 升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。<br>对于协议优化的方向：</p><ul><li>密钥交换算法应该选择 <strong>ECDHE 算法</strong>，而不用 RSA 算法，因为 ECDHE 算法具备前向安全性，而且客户端可以在第三次握手之后，就发送加密应用数据，节省了 1 RTT。</li><li>将 TSL1.2 升级 <strong>TSL1.3</strong>，因为 TSL1.3 的握手过程只需要 1 RTT，而且安全性更强。</li></ul><p>对于证书优化的方向：</p><ul><li>服务器应该选用 <strong>ECDSA 证书</strong>，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率；</li><li>服务器应该开启 <strong>OCSP Stapling</strong> 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；</li></ul><p>对于重连 HTTPS 时，我们可以使用一些技术让客户端和服务端使用上一次 HTTPS 连接使用的会话密钥，直接恢复会话，而不用再重新走完整的 TLS 握手过程。<br>常见的<strong>会话重用</strong>技术有 Session ID 和 Session Ticket，用了会话重用技术，当再次重连 HTTPS 时，只需要 1 RTT 就可以恢复会话。对于 TLS1.3 使用 Pre-shared Key 会话重用技术，只需要 0 RTT 就可以恢复会话。<br>这些会话重用技术虽然好用，但是存在一定的安全风险，它们不仅不具备前向安全，而且有重放攻击的风险，所以应当对会话密钥设定一个合理的过期时间。</p><h2 id="HTTP与RPC"><a href="#HTTP与RPC" class="headerlink" title="HTTP与RPC"></a>HTTP与RPC</h2><p>我想起了我刚工作的时候，第一次接触RPC协议，当时就很懵，<strong>我HTTP协议用的好好的，为什么还要用RPC协议？</strong><br>于是就到网上去搜。<br>不少解释显得非常官方，我相信大家在各种平台上也都看到过，解释了又好像没解释，都在<strong>用一个我们不认识的概念去解释另外一个我们不认识的概念</strong>，懂的人不需要看，不懂的人看了还是不懂。<br>这种看了，又好像没看的感觉，云里雾里的很难受，<strong>我懂</strong>。<br>为了避免大家有强烈的<strong>审丑疲劳</strong>，今天我们来尝试重新换个方式讲一讲。</p><h3 id="从-TCP-聊起"><a href="#从-TCP-聊起" class="headerlink" title="从 TCP 聊起"></a>从 TCP 聊起</h3><p>作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用socket 进行编程。<br>这时候，我们可选项一般也就<strong>TCP和UDP二选一。TCP可靠，UDP不可靠。</strong>除非是马总这种神级程序员（早期QQ大量使用UDP），否则，只要稍微对可靠性有些要求，普通人一般无脑选TCP就对了。<br>类似下面这样。<br>fd = socket(AF_INET,SOCK_STREAM,0);<br>其中SOCK_STREAM，是指使用<strong>字节流</strong>传输数据，说白了就是<strong>TCP协议</strong>。<br>在定义了socket之后，我们就可以愉快的对这个socket进行操作，比如用bind()绑定IP端口，用connect()发起建连。<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1659948267882-3a3b4614-c947-4440-ad8d-1df58fe08a5c.gif#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=299&amp;id=jncWV&amp;originHeight=607&amp;originWidth=1079&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc1a5d750-c8f2-4310-bec0-7877ffc0a1b&amp;title=&amp;width=532.0000610351562" alt=""><br>在连接建立之后，我们就可以使用send()发送数据，recv()接收数据。<br>光这样一个纯裸的TCP连接，就可以做到收发数据了，那是不是就够了？<br>不行，这么用会有问题。</p><h3 id="使用纯裸-TCP-会有什么问题"><a href="#使用纯裸-TCP-会有什么问题" class="headerlink" title="使用纯裸 TCP 会有什么问题"></a>使用纯裸 TCP 会有什么问题</h3><p>八股文常背，TCP是有三个特点，<strong>面向连接</strong>、<strong>可靠</strong>、基于<strong>字节流</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948268352-59d38e32-2bff-424f-80a8-46fa7989782c.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Znf5C&amp;name=image.png&amp;originHeight=540&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57366&amp;status=done&amp;style=none&amp;taskId=uaf8c7aa3-ee7b-4b02-9a2e-0c33080af74&amp;title=" alt="image.png"><br>这三个特点真的概括的<strong>非常精辟</strong>，这个八股文我们没白背。<br>每个特点展开都能聊一篇文章，而今天我们需要关注的是<strong>基于字节流</strong>这一点。<br>字节流可以理解为一个双向的通道里流淌的数据，这个<strong>数据</strong>其实就是我们常说的二进制数据，简单来说就是一大堆 <strong>01 串</strong>。纯裸TCP收发的这些 01 串之间是<strong>没有任何边界</strong>的，你根本不知道到哪个地方才算一条完整消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948268342-b82295ae-04f9-46b3-bc9f-1b4b1a4c1198.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=263&amp;id=TsW3B&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=30799&amp;status=done&amp;style=none&amp;taskId=u0034b6b8-8330-437d-ad4d-3b4003062fd&amp;title=&amp;width=632.0000610351562" alt="image.png"><br>正因为这个没有<strong>任何边界</strong>的特点，所以当我们选择使用TCP发送<strong>“夏洛”和”特烦恼”</strong>的时候，接收端收到的就是<strong>“夏洛特烦恼”</strong>，这时候接收端没发区分你是想要表达<strong>“夏洛”+”特烦恼”</strong>还是<strong>“夏洛特”+”烦恼”</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948268364-d20f30a4-656b-4150-91d5-14d6595aff68.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=258&amp;id=L4eDo&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=44598&amp;status=done&amp;style=none&amp;taskId=uc73dd8ea-fdbf-41e9-a00d-a5a7c6ec4d2&amp;title=&amp;width=618.0000610351562" alt="image.png"><br>这就是所谓的<strong>粘包问题</strong>，之前也写过一篇专门的<a href="https://xiaolincoding.com/network/3_tcp/tcp_stream.html">文章(opens new window)</a>聊过这个问题。<br>说这个的目的是为了告诉大家，纯裸TCP是不能直接拿来用的，你需要在这个基础上加入一些<strong>自定义的规则</strong>，用于区分<strong>消息边界</strong>。<br>于是我们会把每条要发送的数据都包装一下，比如加入<strong>消息头</strong>，<strong>消息头里写清楚一个完整的包长度是多少</strong>，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的<strong>消息体</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948268399-a6d6abae-3d3a-4a42-b37d-977aecd682bd.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tGTrg&amp;name=image.png&amp;originHeight=360&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=25350&amp;status=done&amp;style=none&amp;taskId=u8a6dbd6d-8388-489d-a95b-4ca40876c48&amp;title=" alt="image.png"><br>而这里头提到的<strong>消息头</strong>，还可以放各种东西，比如消息体是否被压缩过和消息体格式之类的，只要上下游都约定好了，互相都认就可以了，这就是所谓的<strong>协议。</strong><br>每个使用TCP的项目都可能会定义一套类似这样的协议解析标准，他们可能<strong>有区别，但原理都类似</strong>。<br><strong>于是基于TCP，就衍生了非常多的协议，比如HTTP和RPC。</strong></p><h3 id="HTTP-和-RPC"><a href="#HTTP-和-RPC" class="headerlink" title="HTTP 和 RPC"></a>HTTP 和 RPC</h3><p>我们回过头来看网络的分层图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948270835-07b8a058-d0f6-44ec-a9ab-7a46443207d0.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=gln8k&amp;name=image.png&amp;originHeight=576&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57673&amp;status=done&amp;style=none&amp;taskId=u4e2b481b-d48c-440d-bc79-fea8f6b8fa5&amp;title=" alt="image.png"><br><strong>TCP是传输层的协议</strong>，而基于TCP造出来的HTTP和<strong>各类</strong>RPC协议，它们都只是定义了不同消息格式的<strong>应用层协议</strong>而已。<br><strong>HTTP</strong>协议（<strong>H</strong>yper <strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol），又叫做<strong>超文本传输协议</strong>。我们用的比较多，平时上网在浏览器上敲个网址就能访问网页，这里用到的就是HTTP协议。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948271238-881dcfce-7db0-4c75-9132-8a45cca62f1d.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=vZ0BH&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=51916&amp;status=done&amp;style=none&amp;taskId=u57b110f2-a3a2-49aa-8709-dac0addd748&amp;title=" alt="image.png"><br>而<strong>RPC</strong>（<strong>R</strong>emote <strong>P</strong>rocedure <strong>C</strong>all），又叫做<strong>远程过程调用</strong>。它本身并不是一个具体的协议，而是一种<strong>调用方式</strong>。<br>举个例子，我们平时调用一个<strong>本地方法</strong>就像下面这样。<br> res = localFunc(req)<br>如果现在这不是个本地方法，而是个<strong>远端服务器</strong>暴露出来的一个方法remoteFunc，如果我们还能像调用本地方法那样去调用它，这样就可以<strong>屏蔽掉一些网络细节</strong>，用起来更方便，岂不美哉？<br> res = remoteFunc(req)<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948271217-c7bda087-3113-4438-aec5-90d99d3ee62f.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=VLYhh&amp;name=image.png&amp;originHeight=380&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61416&amp;status=done&amp;style=none&amp;taskId=ua9cc38af-077c-46b7-bd2b-002b57a8c8e&amp;title=" alt="image.png"><br>基于这个思路，大佬们造出了非常多款式的RPC协议，比如比较有名的gRPC，thrift。<br>值得注意的是，虽然大部分RPC协议底层使用TCP，但实际上<strong>它们不一定非得使用TCP，改用UDP或者HTTP，其实也可以做到类似的功能。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948271236-0b8b9c1f-512d-4ffa-aed8-4891fdb0b8bf.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=pc9uL&amp;name=image.png&amp;originHeight=540&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=42412&amp;status=done&amp;style=none&amp;taskId=u9ea44580-a3e0-41a4-aa25-fa8c7d12e84&amp;title=" alt="image.png"><br>到这里，我们回到文章标题的问题。<br>既然有HTTP协议，为什么还要有RPC？<br>其实，TCP是<strong>70年</strong>代出来的协议，而HTTP是<strong>90年代</strong>才开始流行的。而直接使用裸TCP会有问题，可想而知，这中间这么多年有多少自定义的协议，而这里面就有<strong>80年代</strong>出来的RPC。<br>所以我们该问的不是<strong>既然有HTTP协议为什么要有RPC</strong>，而是<strong>为什么有RPC还要有HTTP协议</strong>。<br>那既然有 RPC 了，为什么还要有HTTP呢？<br>现在电脑上装的各种<strong>联网</strong>软件，比如xx管家，xx卫士，它们都作为<strong>客户端（client）</strong>需要跟<strong>服务端（server）</strong>建立连接收发消息，此时都会用到应用层协议，在这种<strong>client/server (c/s)</strong>架构下，它们可以使用自家造的RPC协议，因为它只管连自己公司的服务器就ok了。<br>但有个软件不同，<strong>浏览器（browser）</strong>，不管是chrome还是IE，它们不仅要能访问自家公司的<strong>服务器（server）</strong>，还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP就是那个时代用于统一 <strong>browser/server (b/s)</strong> 的协议。<br>也就是说在多年以前，<strong>HTTP主要用于b/s架构，而RPC更多用于c/s架构。但现在其实已经没分那么清了，b/s和c/s在慢慢融合。很多软件同时支持多端，比如某度云盘，既要支持网页版</strong>，还要支持<strong>手机端和pc端</strong>，如果通信协议都用HTTP的话，那服务器只用同一套就够了。而RPC就开始退居幕后，一般用于公司内部集群里，各个微服务之间的通讯。<br>那这么说的话，<strong>都用HTTP得了，还用什么RPC？</strong><br>仿佛又回到了文章开头的样子，那这就要从它们之间的区别开始说起。</p><h3 id="HTTP-和-RPC-有什么区别"><a href="#HTTP-和-RPC-有什么区别" class="headerlink" title="HTTP 和 RPC 有什么区别"></a>HTTP 和 RPC 有什么区别</h3><p>我们来看看RPC和HTTP区别比较明显的几个点。</p><h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道<strong>IP地址和端口</strong>。这个找到服务对应的IP端口的过程，其实就是<strong>服务发现</strong>。<br>在<strong>HTTP</strong>中，你知道服务的域名，就可以通过<strong>DNS服务</strong>去解析得到它背后的IP地址，默认80端口。<br>而<strong>RPC</strong>的话，就有些区别，一般会有专门的<strong>中间服务</strong>去保存服务名和IP信息，比如<strong>consul或者etcd，甚至是redis</strong>。想要访问某个服务，就去这些中间服务去获得IP和端口信息。由于dns也是服务发现的一种，所以也有基于dns去做服务发现的组件，比如<strong>CoreDNS</strong>。<br>可以看出服务发现这一块，两者是有些区别，但不太能分高低。<br>底层连接形式<br>以主流的<strong>HTTP1.1</strong>协议为例，其默认在建立底层TCP连接之后会一直保持这个连接（<strong>keep alive</strong>），之后的请求和响应都会复用这条连接。<br>而<strong>RPC</strong>协议，也跟HTTP类似，也是通过建立TCP长链接进行数据交互，但不同的地方在于，RPC协议一般还会再建个<strong>连接池</strong>，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，<strong>用完放回去，下次再复用</strong>，可以说非常环保。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948271255-fb265d1b-d68c-4319-bbb6-0fcf6cc77dd0.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=NduU3&amp;name=image.png&amp;originHeight=405&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49661&amp;status=done&amp;style=none&amp;taskId=u6de82c2b-06c0-43e8-b4e8-9ad52b85443&amp;title=" alt="image.png"><br><strong>由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给HTTP加个连接池</strong>，比如<strong>go</strong>就是这么干的。<br>可以看出这一块两者也没太大区别，所以也不是关键。</p><h4 id="传输的内容"><a href="#传输的内容" class="headerlink" title="传输的内容"></a>传输的内容</h4><p>基于TCP传输的消息，说到底，无非都是<strong>消息头header和消息体body。</strong><br><strong>header</strong>是用于标记一些特殊信息，其中最重要的是<strong>消息体长度</strong>。<br><strong>body</strong>则是放我们真正需要传输的内容，而这些内容只能是二进制01串，毕竟计算机只认识这玩意。所以TCP传字符串和数字都问题不大，因为字符串可以转成编码再变成01串，而数字本身也能直接转为二进制。但结构体呢，我们得想个办法将它也转为二进制01串，这样的方案现在也有很多现成的，比如<strong>json，protobuf。</strong><br>这个将结构体转为二进制数组的过程就叫<strong>序列化</strong>，反过来将二进制数组复原成结构体的过程叫<strong>反序列化</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948272881-f10ce0a3-6cfe-48f4-ab74-2b2d04c8dbfc.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=sGncX&amp;name=image.png&amp;originHeight=360&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60838&amp;status=done&amp;style=none&amp;taskId=ubf2d7220-9636-44d2-9f1a-098704d4486&amp;title=" alt="image.png"><br>对于主流的HTTP1.1，虽然它现在叫<strong>超文本</strong>协议，支持音频视频，但HTTP设计初是用于做网页<strong>文本</strong>展示的，所以它传的内容以字符串为主。header和body都是如此。在body这块，它使用<strong>json</strong>来<strong>序列化</strong>结构体数据。<br>我们可以随便截个图直观看下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948272945-922ab477-b345-4129-89ad-73454749278f.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=451&amp;id=QmRpY&amp;name=image.png&amp;originHeight=682&amp;originWidth=886&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=121664&amp;status=done&amp;style=none&amp;taskId=u6f572438-ec99-4023-8500-b901d2c868d&amp;title=&amp;width=586.0000610351562" alt="image.png"><br>可以看到这里面的内容非常多的<strong>冗余</strong>，显得<strong>非常啰嗦</strong>。最明显的，像header里的那些信息，其实如果我们约定好头部的第几位是content-type，就<strong>不需要每次都真的把”content-type”这个字段都传过来</strong>，类似的情况其实在body的json结构里也特别明显。<br>而RPC，因为它定制化程度更高，可以采用体积更小的protobuf或其他序列化协议去保存结构体数据，同时也不需要像HTTP那样考虑各种浏览器行为，比如302重定向跳转啥的。<strong>因此性能也会更好一些，这也是在公司内部微服务中抛弃HTTP，选择使用RPC的最主要原因。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948272904-5bb70017-10c9-4910-84f6-fdbc8651c072.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=iaHHj&amp;name=image.png&amp;originHeight=432&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58932&amp;status=done&amp;style=none&amp;taskId=u8fc695ea-53d1-47e1-9b34-3d362cb7b46&amp;title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659948272975-98c5135f-accb-4548-82db-b0a546fbade0.png#clientId=uc4819b3b-b6a2-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=270&amp;id=P7r04&amp;name=image.png&amp;originHeight=422&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=75977&amp;status=done&amp;style=none&amp;taskId=u47113961-2f94-4c23-9dbe-ec069a7d432&amp;title=&amp;width=692.0000610351562" alt="image.png"><br>当然上面说的HTTP，其实<strong>特指的是现在主流使用的HTTP1.1</strong>，HTTP2在前者的基础上做了很多改进，所以<strong>性能可能比很多RPC协议还要好</strong>，甚至连gRPC底层都直接用的HTTP2。<br>那么问题又来了，为什么既然有了HTTP2，还要有RPC协议？<br>这个是由于 HTTP2 是2015年出来的。那时候很多公司内部的RPC协议都已经跑了好些年了，基于历史原因，一般也没必要去换了。</p><h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><ul><li>纯裸TCP是能收发数据，但它是个<strong>无边界</strong>的数据流，上层需要定义<strong>消息格式</strong>用于定义<strong>消息边界</strong>。于是就有了各种协议，HTTP和各类RPC协议就是在TCP之上定义的应用层协议。</li><li><strong>RPC本质上不算是协议，而是一种调用方式</strong>，而像gRPC和thrift这样的具体实现，才是协议，它们是实现了RPC调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时RPC有很多种实现方式，<strong>不一定非得基于TCP协议</strong>。</li><li>从发展历史来说，<strong>HTTP主要用于b/s架构，而RPC更多用于c/s架构。但现在其实已经没分那么清了，b/s和c/s在慢慢融合。</strong>很多软件同时支持多端，所以对外一般用HTTP协议，而内部集群的微服务之间则采用RPC协议进行通讯。</li><li>RPC其实比HTTP出现的要早，且比目前主流的HTTP1.1<strong>性能</strong>要更好，所以大部分公司内部都还在使用RPC。</li><li><strong>HTTP2.0</strong>在<strong>HTTP1.1</strong>的基础上做了优化，性能可能比很多RPC协议都要好，但由于是这几年才出来的，所以也不太可能取代掉RPC。</li></ul><p><a href="https://github.com/Zeb-D/my-review/blob/master/network/%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90--TCP%E7%B2%98%E5%8C%85%E4%B8%8E%E6%8B%86%E5%8C%85.md"></a></p><h2 id="既然有-HTTP-协议，为什么还要有-WebSocket？"><a href="#既然有-HTTP-协议，为什么还要有-WebSocket？" class="headerlink" title="既然有 HTTP 协议，为什么还要有 WebSocket？"></a>既然有 HTTP 协议，为什么还要有 WebSocket？</h2><p>平时我们打开网页，比如购物网站某宝。都是点一下「列表商品」，跳转一下网页就到了「商品详情」。<br>从 HTTP 协议的角度来看，就是点一下网页上的某个按钮，<strong>前端发一次 HTTP请 求，网站返回一次 HTTP 响应</strong>。这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。<br>但有没有发现，这种情况下，服务器从来就「不会主动」给客户端发一次消息。就像你喜欢的女生从来不会主动找你一样。<br>但如果现在，你在刷网页的时候「右下角」突然弹出一个小广告，提示你【一个人在家偷偷才能玩哦】。<br><strong>求知，好学，勤奋</strong>，这些刻在你 DNA 里的东西都动起来了。<br>你点开后发现。<br>长相平平无奇的古某提示你”道士 9 条狗，全服横着走”。<br>影帝某辉老师跟你说”系兄弟就来砍我”。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546960458-061051b7-ed0c-4988-8698-e1c316ea8df4.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=193&amp;id=u05bdde72&amp;name=image.png&amp;originHeight=396&amp;originWidth=396&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=190823&amp;status=done&amp;style=none&amp;taskId=u0f7f7db5-86a8-4d76-809d-7a40be44bda&amp;title=&amp;width=193.00003051757812" alt="image.png"><br>来都来了，你就选了个角色进到了游戏界面里。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546963131-3e98d5a8-b2dc-40d1-81ec-272b3b9a3b64.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=200&amp;id=ub6f4b210&amp;name=image.png&amp;originHeight=1456&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=1892582&amp;status=done&amp;style=none&amp;taskId=u59c9038a-21c8-444e-adb4-9864b9f96bf&amp;title=&amp;width=148.28573608398438" alt="image.png"><br>这时候，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。<br><strong>你全程没点任何一次鼠标</strong>。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。<br>这….太暖心了。<br>感动之余，问题就来了，<br>像这种<strong>看起来服务器主动发消息给客户端的场景</strong>，是怎么做到的？<br>在真正回答这个问题之前，我们先来聊下一些相关的知识背景。</p><h3 id="使用-HTTP-不断轮询"><a href="#使用-HTTP-不断轮询" class="headerlink" title="使用 HTTP 不断轮询"></a>使用 HTTP 不断轮询</h3><p>其实问题的痛点在于，<strong>怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。</strong><br>最常见的解决方案是，<strong>网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。</strong><br>这其实时一种「<strong>伪</strong>」服务器推的形式。<br>它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。<br>用这种方式的场景也有很多，最常见的就是<strong>扫码登录</strong>。<br>比如，某信公众号平台，登录页面二维码出现之后，<strong>前端</strong>网页根本不知道用户扫没扫，于是不断去向<strong>后端</strong>服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于<strong>等太久</strong>。<br>使用HTTP定时轮询<br>但这样，会有两个比较明显的问题：</p><ul><li>当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。</li><li>最坏情况下，用户在扫码后，需要等个 1~2 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到<strong>明显的卡顿</strong>。</li></ul><p>使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候<strong>卡顿等个 1~2 秒</strong>，页面才跳转。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546960919-f8695364-7ce1-42c3-bb5b-d67b762c2993.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub02d41ec&amp;name=image.png&amp;originHeight=540&amp;originWidth=1552&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=508465&amp;status=done&amp;style=none&amp;taskId=u3ae6a620-1d0f-4864-92ca-d87b77b2538&amp;title=" alt="image.png"><br>那么问题又来了，<strong>有没有更好的解决方案？</strong><br>有，而且实现起来成本还非常低。</p><h3 id="长轮询"><a href="#长轮询" class="headerlink" title="长轮询"></a>长轮询</h3><p>我们知道，HTTP 请求发出后，一般会给服务器留一定的时间做响应，比如 3 秒，规定时间内没返回，就认为是超时。<br>如果我们的 HTTP 请求<strong>将超时设置的很大</strong>，比如 30 秒，<strong>在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。</strong><br>这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546960329-71ddaca8-a620-4c8c-b0cf-e3b2028f4706.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc919c958&amp;name=image.png&amp;originHeight=792&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=96226&amp;status=done&amp;style=none&amp;taskId=u4c5035ae-45ff-457d-84c8-cf601df02b8&amp;title=" alt="image.png"><br>比如，某度云网盘就是这么干的。所以你会发现一扫码，手机上点个确认，电脑端网页就<strong>秒跳转</strong>，体验很好。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546960716-936d5aab-1761-42c9-8867-7ee4709426da.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u48d7560d&amp;name=image.png&amp;originHeight=650&amp;originWidth=1546&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=375590&amp;status=done&amp;style=none&amp;taskId=u995e9995-0b66-4b54-ae41-5a8f68991ae&amp;title=" alt="image.png"><br>像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的<strong>长训轮机制</strong>。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546961461-df863e4a-6de5-4551-8107-fbf926d4f7f6.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua1ef9336&amp;name=image.png&amp;originHeight=491&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=81683&amp;status=done&amp;style=none&amp;taskId=u812b548a-53d3-492b-95b3-3de617447f7&amp;title=" alt="image.png"><br>像这种，在用户不感知的情况下，服务器将数据推送给浏览器的技术，就是所谓的<strong>服务器推送</strong>技术，它还有个毫不沾边的英文名，<strong>comet</strong> 技术，大家听过就好。<br>上面提到的两种解决方案（不断轮询和长轮询），本质上，其实还是客户端主动去取数据。<br>对于像扫码登录这样的<strong>简单场景</strong>还能用用。但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。<br>这就得说下 <strong>WebSocket</strong> 了。</p><h3 id="WebSocket是什么"><a href="#WebSocket是什么" class="headerlink" title="WebSocket是什么"></a>WebSocket是什么</h3><p>我们知道 TCP 连接的两端，<strong>同一时间里</strong>，<strong>双方</strong>都可以<strong>主动</strong>向对方发送数据。这就是所谓的<strong>全双工</strong>。<br>而现在使用最广泛的HTTP/1.1，也是基于TCP协议的，<strong>同一时间里</strong>，客户端和服务器<strong>只能有一方主动</strong>发数据，这就是所谓的<strong>半双工</strong>。<br>也就是说，好好的全双工 TCP，被 HTTP/1.1 用成了半双工。<br>为什么？<br>这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到<strong>客户端发起请求再由服务器响应</strong>，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。<br>所以，为了更好的支持这样的场景，我们需要另外一个<strong>基于TCP的新协议</strong>。<br>于是新的应用层协议<strong>WebSocket</strong>就被设计出来了。<br>大家别被这个名字给带偏了。虽然名字带了个socket，但其实 <strong>socket 和 WebSocket 之间，就跟雷峰和雷峰塔一样，二者接近毫无关系</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546961644-08ca9785-76c7-4588-ba47-4a0bc361a567.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u45aa0da2&amp;name=image.png&amp;originHeight=576&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62779&amp;status=done&amp;style=none&amp;taskId=u553bf397-30b2-4bee-96ba-1b32b5e8c85&amp;title=" alt="image.png"></p><h4 id="怎么建立WebSocket连接"><a href="#怎么建立WebSocket连接" class="headerlink" title="怎么建立WebSocket连接"></a>怎么建立WebSocket连接</h4><p>我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是 <strong>HTTP 协议</strong>，一会打开网页游戏，这时候就得切换成我们新介绍的 <strong>WebSocket 协议</strong>。<br>为了兼容这些使用场景。浏览器在 <strong>TCP 三次握手</strong>建立连接之后，都<strong>统一使用 HTTP 协议</strong>先进行一次通信。</p><ul><li>如果此时是<strong>普通的 HTTP 请求</strong>，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。</li><li><p>如果这时候是<strong>想建立 WebSocket 连接</strong>，就会在 HTTP 请求里带上一些<strong>特殊的header 头</strong>，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Connection: Upgrade</span><br><span class="line">Upgrade: WebSocket</span><br><span class="line">Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n</span><br></pre></td></tr></table></figure><p>这些 header 头的意思是，浏览器想<strong>升级协议（Connection: Upgrade）</strong>，并且<strong>想升级成 WebSocket 协议（Upgrade: WebSocket）</strong>。同时带上一段<strong>随机生成的 base64 码（Sec-WebSocket-Key）</strong>，发给服务器。<br>如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个<strong>公开的</strong>算法变成另一段字符串，放在 HTTP 响应的 Sec-WebSocket-Accept 头里，同时带上101状态码，发回给浏览器。HTTP 的响应如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HTTP/<span class="number">1.1</span> <span class="number">101</span> Switching Protocols\r\n</span><br><span class="line">Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n</span><br><span class="line">Upgrade: WebSocket\r\n</span><br><span class="line">Connection: Upgrade\r\n</span><br></pre></td></tr></table></figure><p>HTTP 状态码=200（正常响应）的情况，大家见得多了。101 确实不常见，它其实是指<strong>协议切换</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546962243-56d6900d-e580-4162-b273-79e9c561a647.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u10a65873&amp;name=image.png&amp;originHeight=339&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=35909&amp;status=done&amp;style=none&amp;taskId=uec984665-b364-40f4-a145-2fa3f51a3e9&amp;title=" alt="image.png"><br>之后，浏览器也用同样的<strong>公开算法</strong>将base64码转成另一段字符串，如果这段字符串跟服务器传回来的<strong>字符串一致</strong>，那验证通过。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546963733-a24b5285-e002-4d22-b2e2-8133280ba5c1.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud72cc1f3&amp;name=image.png&amp;originHeight=432&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58813&amp;status=done&amp;style=none&amp;taskId=u452f0658-f41c-43e4-b391-679707f903a&amp;title=" alt="image.png"><br>就这样经历了一来一回两次 HTTP 握手，WebSocket就建立完成了，后续双方就可以使用 webscoket 的数据格式进行通信了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546964261-367869e2-7059-4a37-bfc9-ff49ebb45c2f.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uad358a29&amp;name=image.png&amp;originHeight=990&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=136719&amp;status=done&amp;style=none&amp;taskId=u050a43a0-fdc7-4768-b736-6058062fa32&amp;title=" alt="image.png"></p><h4 id="WebSocket抓包"><a href="#WebSocket抓包" class="headerlink" title="WebSocket抓包"></a>WebSocket抓包</h4><p>我们可以用wireshark抓个包，实际看下数据包的情况。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546965833-aef8e5a5-a209-4330-8e93-224074f67f34.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1d10d507&amp;name=image.png&amp;originHeight=487&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=244948&amp;status=done&amp;style=none&amp;taskId=ub4c84fbb-7ea8-44bc-8ccf-b094da4e4b2&amp;title=" alt="image.png"><br>上面这张图，注意画了红框的第2445行报文，是WebSocket的<strong>第一次握手</strong>，意思是发起了一次带有特殊Header的HTTP请求。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546964415-305c2f7c-e364-4065-918a-dbab07c38e92.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud70a0ed6&amp;name=image.png&amp;originHeight=472&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=243534&amp;status=done&amp;style=none&amp;taskId=u16f0ce0a-82fc-4ee7-acf9-542a8ea2db7&amp;title=" alt="image.png"><br>上面这个图里画了红框的4714行报文，就是服务器在得到第一次握手后，响应的<strong>第二次握手</strong>，可以看到这也是个 HTTP 类型的报文，返回的状态码是 101。同时可以看到返回的报文 header 中也带有各种WebSocket相关的信息，比如Sec-WebSocket-Accept。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546965525-530f0aee-7d94-45f8-acfa-80b13e11d8a2.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u35b229fb&amp;name=image.png&amp;originHeight=514&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=274679&amp;status=done&amp;style=none&amp;taskId=u703a3675-ee46-42dc-8255-d7f6e4c9302&amp;title=" alt="image.png"><br>上面这张图就是全貌了，从截图上的注释可以看出，WebSocket和HTTP一样都是基于TCP的协议。<strong>经历了三次TCP握手之后，利用 HTTP 协议升级为 WebSocket 协议</strong>。<br>你在网上可能会看到一种说法：”WebSocket 是基于HTTP的新协议”，<strong>其实这并不对</strong>，因为WebSocket只有在建立连接时才用到了HTTP，<strong>升级完成之后就跟HTTP没有任何关系了</strong>。<br>这就好像你喜欢的女生通过你要到了你大学室友的微信，然后他们自己就聊起来了。你能说这个女生是通过你去跟你室友沟通的吗？不能。你跟HTTP一样，都只是个<strong>工具人</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546965206-5cff50a3-65e4-41ce-a2cf-bf48c85e749e.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uac41784d&amp;name=image.png&amp;originHeight=442&amp;originWidth=444&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=127489&amp;status=done&amp;style=none&amp;taskId=u1ec365a9-aeeb-42c7-9b4e-5455195103f&amp;title=" alt="image.png"><br>这就有点”<strong>借壳生蛋</strong>“的那意思。<br>HTTP和WebSocket的关系</p><h4 id="WebSocket的消息格式"><a href="#WebSocket的消息格式" class="headerlink" title="WebSocket的消息格式"></a>WebSocket的消息格式</h4><p>上面提到在完成协议升级之后，两端就会用webscoket的数据格式进行通信。<br>数据包在WebSocket中被叫做<strong>帧</strong>，我们来看下它的数据格式长什么样子。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546965454-ecec3acf-0241-4ec2-9758-afc7e5bb6f17.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u6fa53197&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=71069&amp;status=done&amp;style=none&amp;taskId=u4696fa79-b71b-442e-9eb9-a5b7d87231d&amp;title=" alt="image.png"><br>这里面字段很多，但我们只需要关注下面这几个。<br><strong>opcode字段</strong>：这个是用来标志这是个<strong>什么类型</strong>的数据帧。比如。</p></li><li><p>等于 1 ，是指text类型（string）的数据包</p></li><li>等于 2 ，是二进制数据类型（[]byte）的数据包</li><li>等于 8 ，是关闭连接的信号</li></ul><p><strong>payload字段</strong>：存放的是我们<strong>真正想要传输的数据的长度</strong>，单位是<strong>字节</strong>。比如你要发送的数据是字符串”111”，那它的长度就是3。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546966558-da4abca3-2caa-4cf6-a4b8-9cf21185d9a8.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u85a1a5d0&amp;name=image.png&amp;originHeight=432&amp;originWidth=860&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60526&amp;status=done&amp;style=none&amp;taskId=ue830e39a-7da7-4080-bb85-998a5d0a39e&amp;title=" alt="image.png"><br>另外，可以看到，我们存放<strong> payload 长度的字段有好几个</strong>，我们既可以用最前面的7bit, 也可以用后面的7+16bit 或 7+64bit。<br>那么问题就来了。<br>我们知道，在数据层面，大家都是 01 二进制流。我怎么知道<strong>什么情况下应该读 7 bit，什么情况下应该读7+16bit呢？</strong><br>WebSocket会用最开始的7bit做标志位。不管接下来的数据有多大，都<strong>先读最先的7个bit</strong>，根据它的取值决定还要不要再读个 16bit 或 64bit。</p><ul><li>如果最开始的7bit的值是 0~125，那么它就表示了 <strong>payload 全部长度</strong>，只读最开始的7个bit就完事了。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546966718-41735f32-a696-4297-90f0-96923c8e9ca0.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub06a5092&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72427&amp;status=done&amp;style=none&amp;taskId=u0adde173-f942-40cc-93df-539b76646a5&amp;title=" alt="image.png"></p><ul><li>如果是126（0x7E）。那它表示payload的长度范围在 126~65535 之间，接下来还需要<strong>再读16bit</strong>。这16bit会包含payload的真实长度。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546967081-f9c5c6b8-f79b-4d0e-b9b0-598f752d3beb.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2772619e&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=70800&amp;status=done&amp;style=none&amp;taskId=u6855d65d-f29e-490e-87cb-1c91f2d3b68&amp;title=" alt="image.png"></p><ul><li>如果是127（0x7F）。那它表示payload的长度范围&gt;=65536，接下来还需要<strong>再读64bit</strong>。这64bit会包含payload的长度。这能放2的64次方byte的数据，换算一下好多个TB，肯定够用了。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546967366-5ae8a60f-b63b-4f6f-aca0-739efcca280e.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ud01f2711&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=71345&amp;status=done&amp;style=none&amp;taskId=u3e9a9321-6597-46eb-99bc-4c9cfa0ede3&amp;title=" alt="image.png"><br><strong>payload data字段</strong>：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。<br>大家有没有发现一个小细节，WebSocket的数据格式也是<strong>数据头（内含payload长度） + payload data</strong> 的形式。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546968100-f66ac318-73ac-4555-8365-d411a7257396.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u15237d51&amp;name=image.png&amp;originHeight=193&amp;originWidth=198&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=30410&amp;status=done&amp;style=none&amp;taskId=ud0cfb149-3fa9-4426-a57f-44666608c07&amp;title=" alt="image.png"><br>这是因为 TCP 协议本身就是全双工，但直接使用<strong>纯裸TCP</strong>去传输数据，会有<strong>粘包</strong>的”问题”。为了解决这个问题，上层协议一般会用<strong>消息头+消息体</strong>的格式去重新包装要发的数据。<br>而<strong>消息头</strong>里一般含有<strong>消息体的长度</strong>，通过这个长度可以去截取真正的消息体。<br>HTTP 协议和大部分 RPC 协议，以及我们今天介绍的WebSocket协议，都是这样设计的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546968103-bce149f7-1038-4131-acc7-5a4b238efcc1.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue10aa4b2&amp;name=image.png&amp;originHeight=360&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=25350&amp;status=done&amp;style=none&amp;taskId=u68287487-492e-4c32-970b-457356d615a&amp;title=" alt="image.png"></p><h4 id="WebSocket的使用场景"><a href="#WebSocket的使用场景" class="headerlink" title="WebSocket的使用场景"></a>WebSocket的使用场景</h4><p>WebSocket完美继承了 TCP 协议的<strong>全双工</strong>能力，并且还贴心的提供了解决粘包的方案。<br>它适用于<strong>需要服务器和客户端（浏览器）频繁交互</strong>的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。<br>回到文章开头的问题，在使用 WebSocket 协议的网页游戏里，怪物移动以及攻击玩家的行为是<strong>服务器逻辑</strong>产生的，对玩家产生的伤害等数据，都需要由<strong>服务器主动发送给客户端</strong>，客户端获得数据后展示对应的效果。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1667546968167-aedbba01-eee8-41c4-a65b-33ba22438608.png#clientId=u1ee1c508-e73b-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u81f84eed&amp;name=image.png&amp;originHeight=450&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61106&amp;status=done&amp;style=none&amp;taskId=u3b030f02-f9db-4c01-9e4e-544aa43fb51&amp;title=" alt="image.png"></p><h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><ul><li>TCP 协议本身是<strong>全双工</strong>的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是<strong>半双工</strong>的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。</li><li>在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用<strong>定时轮询或者长轮询</strong>的方式实现<strong>服务器推送</strong>(comet)的效果。</li><li>对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。</li><li>WebSocket 和 socket 几乎没有任何关系，只是叫法相似。</li><li>正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>TCP篇</title>
      <link href="/2022/08/09/%E8%AE%A1%E7%BD%91/TCP_IP%E7%AF%87/"/>
      <url>/2022/08/09/%E8%AE%A1%E7%BD%91/TCP_IP%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="一、TCP-三次握手与四次挥手面试题"><a href="#一、TCP-三次握手与四次挥手面试题" class="headerlink" title="一、TCP 三次握手与四次挥手面试题"></a>一、TCP 三次握手与四次挥手面试题</h2><h3 id="ⅠTCP基本认识"><a href="#ⅠTCP基本认识" class="headerlink" title="ⅠTCP基本认识"></a>ⅠTCP基本认识</h3><h4 id="TCP头部格式"><a href="#TCP头部格式" class="headerlink" title="TCP头部格式"></a>TCP头部格式</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647569136292-17411965-bd17-4f5a-a383-3e384f76cf2f.png#averageHue=%23f2ebe2&amp;clientId=u0bfb4db7-f767-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=369&amp;id=u0d5fa551&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=716&amp;originWidth=912&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=139959&amp;status=done&amp;style=none&amp;taskId=u9dd8988a-7f73-4913-9305-cf24d3f5377&amp;title=&amp;width=469.5982666015625" alt="image.png"><br>序列号：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就 「累加」⼀次该「数据字节数」的⼤⼩。⽤来解决⽹络包乱序问题。<br>确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数 据都已经被正常接收。⽤来解决不丢包的问题。<br>控制位：<br><em>ACK</em>：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必<br>须设置为 1 。<br><em>RST</em>：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。<br><em>SYN</em>：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。<br><em>FIN</em>：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。</p><h4 id="为什么需要-TCP-协议？-TCP-⼯作在哪⼀层？"><a href="#为什么需要-TCP-协议？-TCP-⼯作在哪⼀层？" class="headerlink" title="为什么需要 TCP 协议？ TCP ⼯作在哪⼀层？"></a>为什么需要 TCP 协议？ TCP ⼯作在哪⼀层？</h4><ul><li>IP 层是「不可靠」的，它不保证⽹络包的交付、不保证⽹络包的按序交付、也不保证⽹络包中的数据的完整性。</li><li><p>因为 TCP 是⼀个⼯作在传输层的可靠数据传输的服务，它能确保接收端接收的⽹络包是⽆损坏、⽆间隔、⾮冗余 和按序的。</p><h4 id="什么是-TCP-？"><a href="#什么是-TCP-？" class="headerlink" title="什么是 TCP ？"></a>什么是 TCP ？</h4><p>TCP 是⾯向连接的、可靠的、基于字节流的传输层通信协议。 </p></li><li><p>⾯向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀ 对多是⽆法做到的；</p></li><li>可靠的：⽆论的⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端； </li><li><p>字节流：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当 「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重 复」的报⽂会⾃动丢弃。</p><h4 id="什么是-TCP-连接？"><a href="#什么是-TCP-连接？" class="headerlink" title="什么是 TCP 连接？"></a>什么是 TCP 连接？</h4><p>简单来说就是，⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，<br>包括<strong>Socket</strong>、<strong>序列号</strong>和<strong>窗⼝⼤⼩</strong>称为连接。<br>所以我们可以知道，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。<br><strong>Socket</strong>：由 IP 地址和端⼝号组成<br><strong>序列号</strong>：⽤来解决乱序问题等<br><strong>窗⼝⼤⼩</strong>：⽤来做流量控制</p><h4 id="如何唯一确定一个-TCP-连接呢？"><a href="#如何唯一确定一个-TCP-连接呢？" class="headerlink" title="如何唯一确定一个 TCP 连接呢？"></a>如何唯一确定一个 TCP 连接呢？</h4><p>TCP 四元组可以唯一的确定一个连接，四元组包括如下：</p></li><li><p>源地址</p></li><li>源端口</li><li>目的地址</li><li>目的端口</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651539567509-1ac2bb7d-67b4-4b59-ad8c-825ea73fe831.png#averageHue=%23f1d6b8&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ucc7847cd&amp;originHeight=228&amp;originWidth=821&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u02e02e94-20c5-490e-9c56-c608f90f73f&amp;title=" alt=""><br>源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。<br>源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。</p><h4 id="有一个-IP-的服务器监听了一个端口，它的-TCP-的最大连接数是多少？"><a href="#有一个-IP-的服务器监听了一个端口，它的-TCP-的最大连接数是多少？" class="headerlink" title="有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？"></a>有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？</h4><p>服务器通常固定在某个本地端口上监听，等待客户端的连接请求。<br>因此，客户端 IP 和 端口是可变的，其理论值计算公式如下:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651539567559-85eceb10-1497-4c25-837f-7eff306ae6c5.png#averageHue=%23e8e77f&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1baa8d6e&amp;originHeight=41&amp;originWidth=601&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u091d52f6-543c-4eb2-bed7-e2e7b7a63ba&amp;title=" alt=""><br>对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。<br>补充当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：</p><ul><li><strong>文件描述符限制</strong>，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：<ul><li><strong>系统级</strong>：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看；</li><li><strong>用户级</strong>：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看；</li><li><strong>进程级</strong>：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看；</li></ul></li><li><p><strong>内存限制</strong>，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</p><h4 id="✊UDP-和-TCP-有什么区别呢？分别的应⽤场景是？"><a href="#✊UDP-和-TCP-有什么区别呢？分别的应⽤场景是？" class="headerlink" title="✊UDP 和 TCP 有什么区别呢？分别的应⽤场景是？"></a>✊UDP 和 TCP 有什么区别呢？分别的应⽤场景是？</h4><p>UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。<br>UDP 协议真的非常简，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649897896013-1537be17-a57a-4f4e-b54e-b55663b993e4.png#averageHue=%23e0e6ef&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=304&amp;id=u97d16b8a&amp;margin=%5Bobject%20Object%5D&amp;originHeight=468&amp;originWidth=783&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u55243f9b-e219-4257-826a-bd2dd3a5c1c&amp;title=&amp;width=509" alt=""></p></li><li><p>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。</p></li><li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。</li><li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。</li></ul><p><strong>连服可拥首传分</strong><br><em>1. 连接</em></p><ul><li>TCP 是面向连接的传输层协议，传输数据前先要建立连接。</li><li>UDP 是不需要连接，即刻传输数据。</li></ul><p><em>2. 服务对象</em></p><ul><li>TCP 是一对一的两点服务，即一条连接只有两个端点。</li><li>UDP 支持一对一、一对多、多对多的交互通信</li></ul><p><em>3. 可靠性</em></p><ul><li>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。</li><li>UDP 是尽最大努力交付，不保证可靠交付数据。</li></ul><p><em>4. 拥塞控制、流量控制</em></p><ul><li>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。</li><li>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</li></ul><p><em>5. 首部开销</em></p><ul><li>TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。</li><li>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</li></ul><p><em>6. 传输方式</em></p><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li><li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li></ul><p><em>7. 分片不同</em></p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li><li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li></ul><p><strong>TCP </strong>和<strong> UDP </strong>应⽤场景：<br>由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于： </p><ul><li>FTP ⽂件传输 </li><li>HTTP / HTTPS </li></ul><p>由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上UDP本身的处理既简单⼜⾼效，因此经常⽤于： </p><ul><li>包总量较少的通信，如 DNS 、 SNMP 等 </li><li>视频、⾳频等多媒体通信 ⼴播通信<h4 id="为什么-UDP-头部没有「首部长度」字段，而-TCP-头部有「首部长度」字段呢？"><a href="#为什么-UDP-头部没有「首部长度」字段，而-TCP-头部有「首部长度」字段呢？" class="headerlink" title="为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？"></a>为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？</h4>原因是 TCP 有<strong>可变长</strong>的「选项」字段，而 UDP 头部长度则是<strong>不会变化</strong>的，无需多一个字段去记录 UDP 的首部长度。<h3 id="Ⅱ-TCP连接建立"><a href="#Ⅱ-TCP连接建立" class="headerlink" title="Ⅱ TCP连接建立"></a>Ⅱ TCP连接建立</h3>先说明三次握手-&gt;对于的socket通信-&gt;引出半连接队列全连接队列-&gt;泛洪以及解决-&gt;溢出场景-&gt;<br>挥手过程-&gt;time_wait</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649904679728-64bf0172-ab76-4040-80ba-e62f03fa1d14.png#averageHue=%23e7f7f4&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=80&amp;id=u7fd3bb5b&amp;name=image.png&amp;originHeight=100&amp;originWidth=739&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=14522&amp;status=done&amp;style=none&amp;taskId=uaa4367f8-fd48-4573-8a8a-a1b3f6fb5df&amp;title=&amp;width=591.2" alt="image.png"></p><h4 id="①TCP三次握手过程"><a href="#①TCP三次握手过程" class="headerlink" title="①TCP三次握手过程"></a>①TCP三次握手过程</h4><p>三次握手流程-&gt;讲解过程中每一次握手就可以讲解到socket连接过程对应和这次握手丢失会怎么样-&gt;<br>然后开始讲解4.TCP半连接队列于全连接队列知识-&gt;syn泛洪<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1647569564330-46d16916-490c-410f-96a9-b0f6e4800581.png#averageHue=%23f8edd3&amp;clientId=u0bfb4db7-f767-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=451&amp;id=u6b62c26f&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=729&amp;originWidth=885&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=123866&amp;status=done&amp;style=none&amp;taskId=ub033beb2-2518-4769-8192-c1d22733c5e&amp;title=&amp;width=547" alt="image.png"><br><strong>记忆：序列号+确认应答号+标志位（syn，ack）发送完成后的状态</strong></p><ul><li>⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态</li><li>客户端会随机初始化序号（ client_isn ），将此序号置于 TCP ⾸部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报⽂。接着把第⼀个 SYN 报⽂发送给服务端，表示向服务端发起连接，该报⽂不 包含应⽤层数据，之后客户端处于 SYN-SENT 状态。 </li><li>服务端收到客户端的 SYN 报⽂后，首先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填⼊TCP ⾸部的「序号」字段中，其次把 TCP ⾸部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN 和 ACK 标志位置为 1 。最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于 SYN_RCVD 状态。也就是半连接队列</li><li>客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂，会把「确认应答号」字段填⼊ server_isn + 1 然后把该应答报⽂ TCP ⾸部 ACK 标志位 置为 1 ，其次，最后把报⽂发送给服务端，这次报⽂可以携带客 户到服务器的数据，之后客户端处于 ESTABLISHED 状态。</li><li>服务器收到客户端的应答报⽂后，从「 SYN 队列」移除放入到「 Accept 队列」；进⼊ ESTABLISHED 状态。 </li></ul><p>从上⾯的过程可以发现第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的，这也是⾯试常问的题。 ⼀旦完成三次握⼿，双⽅都处于 ESTABLISHED 状态，此时连接就已建⽴完成，客户端和服务端就可以相互发送 数据了。<br>如何在 Linux 系统中查看 TCP 状态？<br>TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649898315373-f15230dc-b00c-4a25-8754-1b71ba31a3dd.png#averageHue=%23f1e9d2&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5d5c07c3&amp;originHeight=327&amp;originWidth=1563&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0d2093eb-896d-42f6-95ef-2b569d9428d&amp;title=" alt=""></p><h4 id="✊②为什么是三次握⼿？不是两次、四次？"><a href="#✊②为什么是三次握⼿？不是两次、四次？" class="headerlink" title="✊②为什么是三次握⼿？不是两次、四次？"></a>✊②为什么是三次握⼿？不是两次、四次？</h4><p><strong>1.最主要的原因是防止历史连接初始化了连接</strong></p><ul><li>比如客户端连续发送多个SYN报文的时候，由于网络拥堵，导致了一个旧的syn报文比一个新的syn报文先到达了服务端，此时服务端会回一个syn+ack报文给客户端，<ul><li>如果是两次握手连接，那么就不能判断当前连接是否是历史连接，主要是因为<strong>在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费</strong>。也就是「被动发起方」在收到 SYN 报文后，就进入 ESTABLISHED 状态。</li><li>三次握手的话就可以在客户端准备<strong>发送第三次报文</strong>的时候，拥有足够的上下文环境来判断当前连接是否是历史连接。<ul><li>如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此中⽌历史连接；如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；<br>补充<strong>如果是两次握手连接，就无法阻止历史连接</strong>，那为什么 TCP 两次握手为什么无法阻止历史连接呢？<br>我先直接说结论，主要是因为<strong>在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费</strong>。也就是「被动发起方」在收到 SYN 报文后，就进入 ESTABLISHED 状态。<br>你想想，两次握手的情况下，「被动发起方」在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据给，但是「主动发起方」此时还没有进入 ESTABLISHED 状态，假设这次是历史连接，主动发起方判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而「被动发起方」在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651540322041-865a948d-9e32-47cb-8f6a-aadab48ce9dc.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=484&amp;id=A6HHm&amp;name=image.png&amp;originHeight=1097&amp;originWidth=1068&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=208213&amp;status=done&amp;style=none&amp;taskId=ud65049ca-1283-4478-a377-0b7e4df2653&amp;title=&amp;width=471" alt="image.png"><br>可以看到，上面这种场景下，「被动发起方」在向「主动发起方」发送数据前，并没有阻止掉历史连接，导致「被动发起方」建立了一个历史连接，又白白发送了数据，妥妥地浪费了「被动发起方」的资源。<br>因此，<strong>要解决这种现象，最好就是在「被动发起方」发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手</strong>。<br>所以，<strong>TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。</strong><br><strong>2.三次握手可以同步双方的初始序列号</strong><br>序列号是可靠传输的⼀个关键因素，它的作⽤：<br>①接收⽅可以去除重复的数据；<br>②接收⽅可以根据数据包的序列号按序接收；<br>③可以标识发送出去的数据包中， 哪些是已经被对⽅收到的；<blockquote><p>可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，<strong>这样一来一回，才能确保双方的初始序列号能被可靠的同步。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651540492356-720d8855-e53f-470d-b8c7-8c1e105fccf4.png#averageHue=%23fbf7f2&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=398&amp;id=u37952dbf&amp;originHeight=947&amp;originWidth=1442&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua54ac941-b210-435d-a285-6a7be6cc5e7&amp;title=&amp;width=606" alt=""><br>四次握手其实也能够可靠的同步双方的初始化序号，但由于<strong>第二步和第三步可以优化成一步</strong>，所以就成了「三次握手」。<br>而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p></blockquote></li></ul></li></ul></li></ul><p><strong>3.可以避免资源的浪费</strong><br>如果只有两次握手，由于服务器不清楚客户端是否收到了自己发送的ack确认信号，所以每收到一个syn报文就只能先主动建立一个连接，如果客户端的syn报文阻塞了，重复发送多个syn报文，那么服务器就会建立多个冗余的无效连接。</p><ul><li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号</li><li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。<h4 id="③为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？"><a href="#③为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？" class="headerlink" title="③为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？"></a>③为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</h4>主要原因有两个方面：</li></ul><ol><li><strong>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</strong><br>补充接下来，详细说说第一点。<br>假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651540757204-29d21172-9ba9-4309-b8ce-cc90f344f5e5.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=595&amp;id=y5bcz&amp;name=image.png&amp;originHeight=1112&amp;originWidth=1031&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=597049&amp;status=done&amp;style=none&amp;taskId=ue043bc17-580f-4aa8-accc-4362c52aded&amp;title=&amp;width=552" alt="image.png"><br>过程如下：</li></ol><ul><li>客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。</li><li>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；</li><li>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。<blockquote><p>比如：客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。<br>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；<br>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</p></blockquote></li></ul><p>可以看到，<strong>如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题</strong>。<br>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有<strong>大概率</strong>因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文，比如下图：<br>补充<img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651540757198-d14c247d-1c75-49ad-bba2-1183da1544d5.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=B8TfR&amp;name=image.png&amp;originHeight=927&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=531166&amp;status=done&amp;style=none&amp;taskId=u1dad5781-e8a0-41c2-a1e1-12ae62e0bdc&amp;title=" alt="image.png"><br>相反，如果每次建立连接客户端和服务端的初始化序列号都「一样」，就有大概率遇到历史报文的序列号刚「好在」对方的接收窗口内，从而导致历史报文被新连接成功接收。<br>所以，每次初始化序列号不一样能够很大程度上避免历史报文被下一个相同四元组的连接接收，注意是很大程度上，并不是完全避免了（因为序列号会有回绕的问题，所以需要用时间戳的机制来判断历史报文，详细看篇：<a href="https://mp.weixin.qq.com/s/ZQ51SmLopj-4OPhNkSL8Fw">TCP 是如何避免历史报文的？(opens new window)</a>）。（下述）<br>详细说明过程为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？<br>主要原因是为了防止历史报文被下一个相同四元组的连接接收。<br>TCP 四次挥手中的 TIME_WAIT 状态不是会持续 2 MSL 时长，历史报文不是早就在网络中消失了吗？<br>是的，如果能正常四次挥手，由于 TIME_WAIT 状态会持续 2 MSL 时长，历史报文会在下一个连接之前就会自然消失。<br>问题出现：但是来了，我们并不能保证每次连接都能通过四次挥手来正常关闭连接。<br>假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650589832101-554b3b0e-4644-435a-a4d8-395363f97888.png#clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=582&amp;id=AeHPT&amp;name=image.png&amp;originHeight=1112&amp;originWidth=1031&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=597049&amp;status=done&amp;style=none&amp;taskId=ub5fa8a18-ce63-430d-a12f-a95527f8ec4&amp;title=&amp;width=540" alt="image.png"><br>过程如下：</p><ul><li>客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。</li><li>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；</li><li>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</li></ul><p>可以看到，如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。<br>客户端和服务端的初始化序列号不一样不是也会发生这样的事情吗？<br>是的，即使客户端和服务端的初始化序列号不一样，也会存在收到历史报文的可能。<br>但是我们要清楚一点，历史报文能否被对方接收，还要看该历史报文的序列号是否正好在对方接收窗口内，如果不在就会丢弃，如果在才会接收。<br>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文，比如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650589831911-b6b61947-5ce0-4d6f-a938-34202edfbeda.png#clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=530&amp;id=KHOfo&amp;name=image.png&amp;originHeight=927&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=531166&amp;status=done&amp;style=none&amp;taskId=u3a88c6bc-03fa-4c78-946d-fe7510640a1&amp;title=&amp;width=617" alt="image.png"><br>相反，如果每次建立连接客户端和服务端的初始化序列号都「一样」，就有大概率遇到历史报文的序列号刚「好在」对方的接收窗口内，从而导致历史报文被新连接成功接收。<br>所以，每次初始化序列号不一样能够很大程度上避免历史报文被下一个相同四元组的连接接收，注意是很大程度上，并不是完全避免了。<br>那客户端和服务端的初始化序列号都是随机的，那还是有可能随机成一样的呀？<br>RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。</p><ul><li>M是一个计时器，这个计时器每隔 4 微秒加1。</li><li>F 是一个 Hash 算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。</li></ul><p>可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。<br>懂了，客户端和服务端初始化序列号都是随机生成的话，就能避免连接接收历史报文了。<br>是的，但是也不是完全避免了。<br>为了能更好的理解这个原因，我们先来了解序列号（SEQ）和初始序列号（ISN）。</p><ul><li><strong>序列号</strong>，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。<strong>序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0</strong>。</li><li><strong>初始序列号</strong>，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。<strong>初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时</strong>。</li></ul><p>给大家抓了一个包，下图中的 Seq 就是序列号，其中红色框住的分别是客户端和服务端各自生成的初始序列号。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650589832422-ae5c37ec-a568-463e-bca6-c768b7ba632b.png#clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=314&amp;id=LT1uy&amp;name=image.png&amp;originHeight=545&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=888038&amp;status=done&amp;style=none&amp;taskId=u20fc96fc-6085-4b1f-98f5-9128183703d&amp;title=&amp;width=623" alt="image.png"><br>图片<br>通过前面我们知道，<strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong>。<br>不要以为序列号的上限值是 4GB，就以为很大，很难发生回绕。在一个速度足够快的网络中传输大量数据时，序列号的回绕时间就会变短。如果序列号回绕的时间极短，我们就会再次面临之前延迟的报文抵达后序列号依然有效的问题。<br>为了解决这个问题，就需要有 TCP 时间戳。<strong>tcp_timestamps</strong> 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，<strong>一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）</strong>。</p><blockquote><p>试看下面的示例，假设 TCP 的发送窗口是 1 GB，并且使用了时间戳选项，发送方会为每个 TCP 报文分配时间戳数值，我们假设每个报文时间加 1，然后使用这个连接传输一个 6GB 大小的数据流。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650589831838-0c9fb0b2-109e-4dff-aa11-394673a206b6.png#clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=198&amp;id=f3Ise&amp;name=image.png&amp;originHeight=298&amp;originWidth=956&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=99998&amp;status=done&amp;style=none&amp;taskId=u3417d776-3220-439b-a8b8-36d81d722a4&amp;title=&amp;width=634" alt="image.png"><br>32 位的序列号在时刻 D 和 E 之间回绕。假设在时刻B有一个报文丢失并被重传，又假设这个报文段在网络上绕了远路并在时刻 F 重新出现。如果 TCP 无法识别这个绕回的报文，那么数据完整性就会遭到破坏。<br>使用时间戳选项能够有效的防止上述问题，如果丢失的报文会在时刻 F 重新出现，由于它的时间戳为 2，小于最近的有效时间戳（5 或 6），因此防回绕序列号算法（PAWS）会将其丢弃。<br>防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p></blockquote><p>懂了，客户端和服务端的初始化序列号都是随机生成，能很大程度上避免历史报文被下一个相同四元组的连接接收，然后又引入时间戳的机制，从而完全避免了历史报文被接收的问题。<br>嗯嗯，没错。<br>如果时间戳也回绕了怎么办？    了解</p><blockquote><p>时间戳的大小是 32 bit，所以理论上也是有回绕的可能性的。<br>时间戳回绕的速度只与对端主机时钟频率有关。<br>Linux 以本地时钟计数（jiffies）作为时间戳的值，不同的增长时间会有不同的问题：</p><ul><li>如果时钟计数加 1 需要1ms，则需要约 24.8 天才能回绕一半，只要报文的生存时间小于这个值的话判断新旧数据就不会出错。</li><li>如果时钟计数提高到 1us 加1，则回绕需要约71.58分钟才能回绕，这时问题也不大，因为网络中旧报文几乎不可能生存超过70分钟，只是如果70分钟没有报文收发则会有一个包越过PAWS（这种情况会比较多见，相比之下 24 天没有数据传输的TCP连接少之又少），但除非这个包碰巧是序列号回绕的旧数据包而被放入接收队列（太巧了吧），否则也不会有问题；</li><li>如果时钟计数提高到 0.1 us 加 1 回绕需要 7 分钟多一点，这时就可能会有问题了，连接如果 7 分钟没有数据收发就会有一个报文越过 PAWS，对于TCP连接而言这么短的时间内没有数据交互太常见了吧！这样的话会频繁有包越过 PAWS 检查，从而使得旧包混入数据中的概率大大增加；</li></ul><p>Linux 在 PAWS 检查做了一个特殊处理，如果一个 TCP 连接连续 24 天不收发数据则在接收第一个包时基于时间戳的 PAWS 会失效，也就是可以 PAWS 函数会放过这个特殊的情况，认为是合法的，可以接收该数据包。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650590086853-7eeba05e-950b-4fa2-a5f3-b503f40d4ca9.png#clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=298&amp;id=MfyMi&amp;name=image.png&amp;originHeight=373&amp;originWidth=903&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=21382&amp;status=done&amp;style=none&amp;taskId=u7dcb7602-ffdf-4167-8e77-d9453c28770&amp;title=&amp;width=722.4" alt="image.png"><br>要解决时间戳回绕的问题，可以考虑以下解决方案：<br>1）增加时间戳的大小，由32 bit扩大到64bit<br>这样虽然可以在能够预见的未来解决时间戳回绕的问题，但会导致新旧协议兼容性问题，像现在的IPv4与IPv6一样<br>2）将一个与时钟频率无关的值作为时间戳，时钟频率可以增加但时间戳的增速不变<br>随着时钟频率的提高，TCP在相同时间内能够收发的包也会越来越多。如果时间戳的增速不变，则会有越来越多的报文使用相同的时间戳。这种趋势到达一定程度则时间戳就会失去意义，除非在可预见的未来这种情况不会发生。<br>3）暂时没想到</p></blockquote><ol><li><strong>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</strong><h4 id="👌④初始序列号-ISN-是如何随机产生的？"><a href="#👌④初始序列号-ISN-是如何随机产生的？" class="headerlink" title="👌④初始序列号 ISN 是如何随机产生的？"></a>👌④初始序列号 ISN 是如何随机产生的？</h4>起始 ISN 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。<br>RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。</li></ol><ul><li>M 是一个计时器，这个计时器每隔 4 微秒加 1。</li><li>F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。</li></ul><p>可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。</p><h4 id="✊⑤既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？"><a href="#✊⑤既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？" class="headerlink" title="✊⑤既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？"></a>✊⑤既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</h4><p>我们先来认识下 MTU 和 MSS<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649898826164-38fd4615-ae0c-4514-894d-ad71bf62f3b2.png#averageHue=%23f4f4f4&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u4f51e6c7&amp;originHeight=422&amp;originWidth=1067&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u1d5f7527-9cbf-48ef-b1e5-ef8aff770f1&amp;title=" alt=""></p><ul><li>MTU：<strong>一个网络包</strong>的最大长度，以太网中一般为 1500 字节；</li><li>MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</li></ul><p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？</p><ul><li>当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。</li><li><strong>如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传</strong>。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</li><li>当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。</li></ul><p>因此，可以得知<strong>由 IP 层进行分片传输，是非常没有效率的。</strong><br>所以，为了达到最佳的传输效能 TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649898826196-11af3142-c155-4e4c-87d4-d8da3ad4309c.png#averageHue=%23ddfbc7&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u71da724c&amp;originHeight=71&amp;originWidth=564&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u563360cd-bad2-4466-b30a-73ebc277fef&amp;title=" alt=""><br>经过 TCP 层分片后，如果一个 TCP 分片丢失后，<strong>进行重发时也是以 MSS 为单位</strong>，而不用重传所有的分片，大大增加了重传的效率。</p><h4 id="⑥握手丢失的过程"><a href="#⑥握手丢失的过程" class="headerlink" title="⑥握手丢失的过程"></a>⑥握手丢失的过程</h4><h5 id="a-第一次握手丢失了，会发生什么？"><a href="#a-第一次握手丢失了，会发生什么？" class="headerlink" title="a.第一次握手丢失了，会发生什么？"></a>a.第一次握手丢失了，会发生什么？</h5><p>当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。<br>在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文。</p><blockquote><p>不同版本的操作系统可能超时时间不同，有的 1 秒的，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。</p></blockquote><p>当客户端在 1 秒后没收到服务端的 SYN-ACK 报文后，客户端就会重发 SYN 报文，那到底重发几次呢？<br>在 Linux 里，客户端的 SYN 报文最大重传次数由 <strong>tcp_syn_retries</strong>内核参数控制，这个参数是可以自定义的，默认值一般是 5。<br>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，<strong>每次超时的时间是上一次的 2 倍</strong>。<br>当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。<br>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。</p><h5 id="b-第二次握手丢失了，会发生什么？"><a href="#b-第二次握手丢失了，会发生什么？" class="headerlink" title="b.第二次握手丢失了，会发生什么？"></a>b.第二次握手丢失了，会发生什么？</h5><p>当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 SYN_RCVD 状态。<br>第二次握手的 SYN-ACK 报文其实有两个目的 ：</p><ul><li>第二次握手里的 ACK， 是对第一次握手的确认报文；</li><li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</li></ul><p><strong>所以，如果第二次握手丢了，就会发送比较有意思的事情，具体会怎么样呢？</strong><br>因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是<strong>客户端就会触发超时重传机制，重传 SYN 报文</strong>。<br>然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。<br>那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是<strong>服务端这边会触发超时重传机制，重传 SYN-ACK 报文</strong>。</p><p>所以，我们可以发现，当第二次握手的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传 SYN、ACK 包。</p><blockquote><p>在 Linux 下，SYN-ACK 报文的最大重传次数由 <strong>tcp_synack_retries</strong>内核参数决定，默认值是 5。<br>因此，当第二次握手丢失了，客户端和服务端都会重传：</p><ul><li>客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 tcp_syn_retries内核参数决定；</li><li>服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 tcp_synack_retries 内核参数决定。</li></ul></blockquote><h5 id="c-第三次握手丢失了，会发生什么？"><a href="#c-第三次握手丢失了，会发生什么？" class="headerlink" title="c.第三次握手丢失了，会发生什么？"></a>c.第三次握手丢失了，会发生什么？</h5><p>客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。<br>因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。<br>注意，<strong>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</strong>。<br><strong>实验三：TCP 第三次握手 ACK 丢包 ！！！！！</strong></p><blockquote><p>为了模拟 TCP 第三次握手 ACK 包丢，我的实验方法是在服务端配置防火墙，屏蔽客户端 TCP 报文中标志位是 ACK 的包，也就是当服务端收到客户端的 TCP ACK 的报文时就会丢弃，iptables 配置命令如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543755481-c46d1fba-860f-4de7-92c9-0a7964177461.jpeg#averageHue=%23565a76&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=156&amp;id=u244191bf&amp;originHeight=354&amp;originWidth=1340&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0c9641db-d010-4e59-98ca-6ac0c6fbafd&amp;title=&amp;width=591" alt=""><br>接着，在客户端执行如下 tcpdump 命令：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543755442-86d58a14-cf6f-4355-9100-74e30c10d09e.jpeg#averageHue=%23565975&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=141&amp;id=uea33a226&amp;originHeight=354&amp;originWidth=1560&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc68ac733-9aae-494f-8aa4-bb2558a2748&amp;title=&amp;width=621" alt=""><br>然后，客户端向服务端发起 telnet，因为 telnet 命令是会发起 TCP 连接，所以用此命令做测试：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543755473-44c33547-6bab-478a-a8e0-0f23b7874f43.jpeg#averageHue=%23515371&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=357&amp;id=u10ef8c82&amp;originHeight=498&amp;originWidth=818&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u0be183ee-9340-4e45-bccc-37e44e447c7&amp;title=&amp;width=586" alt=""><br>此时，由于服务端收不到第三次握手的 ACK 包，所以一直处于 SYN_RECV 状态：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543755458-2723dbf8-276d-4495-b072-049f610b4f28.jpeg#averageHue=%23525572&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=137&amp;id=u5802a309&amp;originHeight=390&amp;originWidth=1662&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7d06bac8-c13f-4f64-8cad-9b6c2582c24&amp;title=&amp;width=583" alt=""><br>而客户端是已完成 TCP 连接建立，处于 ESTABLISHED 状态：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543755467-a109621a-1f22-4fc7-93a3-004e4cbeca05.jpeg#averageHue=%23515472&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=134&amp;id=ue2281883&amp;originHeight=390&amp;originWidth=1830&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uf34bca43-31ac-49d1-a695-aff8469d47e&amp;title=&amp;width=629" alt=""><br>过了 1 分钟后，观察发现服务端的 TCP 连接不见了：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543756721-ea33bcf8-521f-401b-b6fa-1f3328b18286.jpeg#averageHue=%23525673&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=189&amp;id=u6c87673b&amp;originHeight=390&amp;originWidth=1314&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub62124a6-4176-4451-a790-a13c8ea028b&amp;title=&amp;width=638" alt=""><br>过了 30 分钟，客户端依然还是处于 ESTABLISHED 状态：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543756959-5f403bcc-98e0-4ee1-8596-f85bd7d27481.jpeg#averageHue=%23515472&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=129&amp;id=uc1add547&amp;originHeight=390&amp;originWidth=1830&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8be81500-ea5a-4ee7-86f1-6ed6a5920f0&amp;title=&amp;width=606" alt=""><br>接着，在刚才客户端建立的 telnet 会话，输入 123456 字符，进行发送：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543757465-7d11eaa9-4db5-4c12-b28e-13c39e52604e.jpeg#averageHue=%234e506f&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=352&amp;id=u5b0e90c2&amp;originHeight=534&amp;originWidth=862&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7250edff-0eb8-4cd7-a96c-05900c75610&amp;title=&amp;width=569" alt=""><br>持续「好长」一段时间，客户端的 telnet 才断开连接：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543757521-18b81491-fbc9-412c-bd66-c9a9b0e0c00c.jpeg#averageHue=%234d4f6e&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=317&amp;id=ua7357481&amp;originHeight=534&amp;originWidth=978&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u19dfeb56-94d1-472d-b496-6495c1ba346&amp;title=&amp;width=581" alt=""></p><p>以上就是本次的实现三的现象，这里存在两个疑点：</p><ul><li>为什么服务端原本处于 SYN_RECV 状态的连接，过 1 分钟后就消失了？</li><li>为什么客户端 telnet 输入 123456 字符后，过了好长一段时间，telnet 才断开连接？</li></ul><p>不着急，我们把刚抓的数据包，用 Wireshark 打开分析，显示的时序图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543757489-3990c170-fd9f-4d36-ac1c-bcdbb3b2ec46.jpeg#averageHue=%23abcb69&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=654&amp;id=u8ada7879&amp;originHeight=822&amp;originWidth=779&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ud221b26f-6829-4521-a4f1-8cdfdabb9bb&amp;title=&amp;width=620" alt=""><br>上图的流程：</p><ul><li>客户端发送 SYN 包给服务端，服务端收到后，回了个 SYN、ACK 包给客户端，此时服务端的 TCP 连接处于 SYN_RECV 状态；</li><li>客户端收到服务端的 SYN、ACK 包后，给服务端回了个 ACK 包，此时客户端的 TCP 连接处于 ESTABLISHED 状态；</li><li>由于服务端配置了防火墙，屏蔽了客户端的 ACK 包，所以服务端一直处于 SYN_RECV 状态，没有进入 ESTABLISHED 状态，tcpdump 之所以能抓到客户端的 ACK 包，是因为数据包进入系统的顺序是先进入 tcpudmp，后经过 iptables；</li><li>接着，服务端超时重传了 SYN、ACK 包，重传了 5 次后，也就是<strong>超过 tcp_synack_retries 的值（默认值是 5），然后就没有继续重传了，此时服务端的 TCP 连接主动中止了，所以刚才处于 SYN_RECV 状态的 TCP 连接断开了</strong>，而客户端依然处于ESTABLISHED 状态；</li><li>虽然服务端 TCP 断开了，但过了一段时间，发现客户端依然处于ESTABLISHED 状态，于是就在客户端的 telnet 会话输入了 123456 字符；</li><li>此时由于服务端已经断开连接，<strong>客户端发送的数据报文，一直在超时重传，每一次重传，RTO 的值是指数增长的，所以持续了好长一段时间，客户端的 telnet 才报错退出了，此时共重传了 15 次。</strong></li></ul><p>通过这一波分析，刚才的两个疑点已经解除了：</p><ul><li>服务端在重传 SYN、ACK 包时，超过了最大重传次数 tcp_synack_retries，于是服务端的 TCP 连接主动断开了。</li><li>客户端向服务端发送数据包时，由于服务端的 TCP 连接已经退出了，所以数据包一直在超时重传，共重传了 15 次， telnet 就断开了连接。</li></ul></blockquote><p><strong>TCP 第一次握手的 SYN 包超时重传最大次数是由 tcp_syn_retries 指定，TCP 第二次握手的 SYN、ACK 包超时重传最大次数是由 tcp_synack_retries 指定，那 TCP 建立连接后的数据包最大超时重传次数是由什么参数指定呢？</strong><br>TCP 建立连接后的数据包传输，最大超时重传次数是由 <strong>tcp_retries2</strong> 指定，默认值是 15 次，如下：<br>$ cat /proc/sys/net/ipv4/tcp_retries2 15<br>如果 15 次重传都做完了，TCP 就会告诉应用层说：“搞不定了，包怎么都传不过去！”<br><strong>那如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？</strong><br>这里就需要提到 TCP 的 <strong>保活机制</strong>。这个机制的原理是这样的：<br>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个「探测报文」，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。<br>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：<br>net.ipv4.tcp_keepalive_time=7200 net.ipv4.tcp_keepalive_intvl=75   net.ipv4.tcp_keepalive_probes=9 </p><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651543758200-12df3d82-3902-4a5d-b686-575c3fc09265.jpeg#averageHue=%23f7f7b3&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u206ff3c9&amp;originHeight=303&amp;originWidth=897&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3000fc3e-08d9-41de-84fb-aa2d9063bf6&amp;title=" alt=""><br>这个时间是有点长的，所以如果我抓包足够久，或许能抓到探测报文。</p><blockquote><p>实验三的实验小结<br>在建立 TCP 连接时，如果第三次握手的 ACK，服务端无法收到，则服务端就会短暂处于 SYN_RECV 状态，而客户端会处于 ESTABLISHED 状态。<br>由于服务端一直收不到 TCP 第三次握手的 ACK，则会一直重传 SYN、ACK 包，直到重传次数超过 tcp_synack_retries 值（默认值 5 次）后，服务端就会断开 TCP 连接。<br>而客户端则会有两种情况：</p><ul><li>如果客户端没发送数据包，一直处于 ESTABLISHED 状态，然后经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接，于是客户端连接就会断开连接。</li><li>如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 tcp_retries2 值（默认值 15 次）后，客户端就会断开 TCP 连接。</li></ul></blockquote><h4 id="⑦-什么是-SYN-攻击？如何避免-SYN-攻击？"><a href="#⑦-什么是-SYN-攻击？如何避免-SYN-攻击？" class="headerlink" title="⑦ 什么是 SYN 攻击？如何避免 SYN 攻击？"></a>⑦ 什么是 SYN 攻击？如何避免 SYN 攻击？</h4><p><em>SYN 攻击</em><br>TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会<strong>占满服务端的半连接队列</strong>，使得服务器不能为正常用户服务。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649898979656-ab11bd10-3ec6-457e-aa1e-fc288dccb7e9.png#averageHue=%23f5f2e5&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u89ae4bcc&amp;originHeight=348&amp;originWidth=500&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ua42cda1d-ca80-4291-baa3-acbbee1e3da&amp;title=" alt=""><br>这里给出几种防御 SYN 攻击的方法：</p><ul><li>增大半连接队列；</li><li>开启 tcp_syncookies 功能</li><li>减少 SYN+ACK 重传次数<h5 id="方式一：增大半连接队列"><a href="#方式一：增大半连接队列" class="headerlink" title="方式一：增大半连接队列"></a>方式一：增大半连接队列</h5><blockquote><p>在前面源码和实验中，得知<strong>要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列</strong>。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p></blockquote></li></ul><h5 id="方式二：开启-tcp-syncookies-功能"><a href="#方式二：开启-tcp-syncookies-功能" class="headerlink" title="方式二：开启 tcp_syncookies 功能"></a>方式二：开启 tcp_syncookies 功能</h5><p>开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649902871403-efd569da-1d78-410d-b47b-aae400cf49f3.png#averageHue=%23282c34&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=DB9gF&amp;name=image.png&amp;originHeight=456&amp;originWidth=1788&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72428&amp;status=done&amp;style=none&amp;taskId=u49c373ac-5dc8-4210-9541-229f4ae6a1f&amp;title=" alt="image.png"></p><ul><li>当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；</li><li>计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，</li><li>服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。</li><li><p>最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。</p><h5 id="方式三：减少-SYN-ACK-重传次数"><a href="#方式三：减少-SYN-ACK-重传次数" class="headerlink" title="方式三：减少 SYN+ACK 重传次数"></a>方式三：减少 SYN+ACK 重传次数</h5><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。<br>那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649902871808-4882fb0e-f01f-4373-b4ff-568d89d4b291.png#averageHue=%23282c34&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=151&amp;id=AbJew&amp;name=image.png&amp;originHeight=456&amp;originWidth=1888&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=70119&amp;status=done&amp;style=none&amp;taskId=u34847dde-13d6-4aae-9c8d-75412d7c83b&amp;title=&amp;width=627" alt="image.png"></p><h4 id="⑧-TCP半连接队列与全连接队列"><a href="#⑧-TCP半连接队列与全连接队列" class="headerlink" title="⑧ TCP半连接队列与全连接队列"></a>⑧ TCP半连接队列与全连接队列</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651544680143-029e752d-46d4-40b8-b4cb-75ddd1e21883.jpeg#averageHue=%23efeff3&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=KDpVi&amp;originHeight=925&amp;originWidth=1692&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3c5eb06b-fada-4b18-8ae2-f87a6c885d6&amp;title=" alt=""></p><h5 id="a-什么是-TCP-半连接队列和全连接队列？"><a href="#a-什么是-TCP-半连接队列和全连接队列？" class="headerlink" title="a: 什么是 TCP 半连接队列和全连接队列？"></a>a: 什么是 TCP 半连接队列和全连接队列？</h5><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p></li><li><p>半连接队列，也称 SYN 队列；</p></li><li>全连接队列，也称 accept 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649902431692-95602de5-a92b-4ad5-a6fd-43a572224de0.png#averageHue=%23fcfcfb&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=485&amp;id=UZWnG&amp;name=image.png&amp;originHeight=1083&amp;originWidth=1082&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=101020&amp;status=done&amp;style=none&amp;taskId=u4605eb9e-e6b5-4aef-871e-2e107bebfab&amp;title=&amp;width=485" alt="image.png"><br>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。</p><hr><h5 id="b-实战-TCP-全连接队列溢出"><a href="#b-实战-TCP-全连接队列溢出" class="headerlink" title="b: 实战 - TCP 全连接队列溢出"></a>b: 实战 - TCP 全连接队列溢出</h5><p><strong>当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649902546239-0f5877f5-8788-423c-ab67-36bf72652bc1.png#averageHue=%23faf4e8&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=219&amp;id=J51vj&amp;name=image.png&amp;originHeight=347&amp;originWidth=839&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=41009&amp;status=done&amp;style=none&amp;taskId=u40d338ad-b21e-4365-a4ce-94879dfcfc4&amp;title=&amp;width=530" alt="image.png"><br>Linux 有个参数可以指定当 TCP 全连接队列满了会使用什么策略来回应客户端。<br>实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649902647307-432aea22-a36b-47ab-a128-c3f9e6213981.png#averageHue=%23282c34&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=171&amp;id=HpYxQ&amp;name=image.png&amp;originHeight=456&amp;originWidth=1816&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=60390&amp;status=done&amp;style=none&amp;taskId=u8ff2c45d-94b6-4dcd-bc5d-acd64b4d773&amp;title=&amp;width=682" alt="image.png"><br><strong>tcp_abort_on_overflow</strong> 共有两个值分别是 0 和 1，其分别表示：</p><ul><li>0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；直接丢弃</li><li>1 ：如果全连接队列满了，server 发送一个 reset 包给 client，表示废掉这个握手过程和这个连接；发送RST报文</li></ul><p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 connection reset by peer 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。<br>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。<br>举个例子，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次<strong>重发</strong>。如果服务器上的进程只是<strong>短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong><br>所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。<br>如何增大 TCP 全连接队列呢？<br>是的，当发现 TCP 全连接队列发生溢出的时候，我们就需要增大该队列的大小，以便可以应对客户端大量的请求。<br><strong>TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)</strong>。<br><strong>如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</strong></p><h5 id="c-实战-TCP-半连接队列溢出"><a href="#c-实战-TCP-半连接队列溢出" class="headerlink" title="c: 实战 - TCP 半连接队列溢出"></a>c: 实战 - TCP 半连接队列溢出</h5><p>如何模拟 TCP 半连接队列溢出场景？<br>模拟 TCP 半连接溢出场景不难，实际上就是对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得服务端有大量的处于 SYN_RECV 状态的 TCP 连接。<br>这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。<br>如果 SYN 半连接队列已满，只能丢弃连接吗？<br>并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>，当开启了 syncookies 功能就不会丢弃连接。<br>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649903024171-44ba594b-1f58-41fe-b552-c85ff979321e.png#averageHue=%23f8f5ed&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Wtt14&amp;name=image.png&amp;originHeight=392&amp;originWidth=899&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50543&amp;status=done&amp;style=none&amp;taskId=uc4e204dd-8135-4de0-bfaa-28bfb021b28&amp;title=" alt="image.png"><br>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；<blockquote><p>“syncookies 启用后就不需要半链接了？那请求的数据会存在哪里？”<br>syncookies = 1 时，半连接队列满后，后续的请求就不会存放到半连接队列了，而是在第二次握手的时候，服务端会计算一个 cookie 值，放入到 SYN +ACK 包中的序列号发给客户端，客户端收到后并回 ack ，服务端就会校验连接是否合法，合法就直接把连接放入到全连接队列。</p></blockquote></li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649903024627-51a4b428-522f-425a-bd54-bd83a6572613.png#averageHue=%23282c34&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=zPXWC&amp;name=image.png&amp;originHeight=456&amp;originWidth=1788&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=72428&amp;status=done&amp;style=none&amp;taskId=u090acbbe-684f-4b55-8795-b64a1e584ca&amp;title=" alt="image.png"><br>如何调整 SYN 半连接队列大小？<br>要想增大半连接队列，不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p><blockquote><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657718803949-b33a166b-fc0e-40d8-ac99-ac693930546c.png#averageHue=%23302d56&amp;clientId=ue3ec5420-203d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=153&amp;id=I6Aej&amp;name=image.png&amp;originHeight=328&amp;originWidth=954&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=132817&amp;status=done&amp;style=none&amp;taskId=u8c764122-0238-405b-b9a2-39064d78496&amp;title=&amp;width=446.00006103515625" alt="image.png"><br>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1657718803947-ec4f6d69-5c71-424f-9473-c6fa9ae6991f.png#averageHue=%23302d56&amp;clientId=ue3ec5420-203d-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=223&amp;id=SJ1NN&amp;name=image.png&amp;originHeight=364&amp;originWidth=784&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=109166&amp;status=done&amp;style=none&amp;taskId=u4be575cd-a12c-453b-a81f-e86866b5866&amp;title=&amp;width=480.00006103515625" alt="image.png"></p></blockquote><h4 id="⑨TCP-快速建立连接"><a href="#⑨TCP-快速建立连接" class="headerlink" title="⑨TCP 快速建立连接"></a>⑨TCP 快速建立连接</h4><p>客户端在向服务端发起 HTTP GET 请求时，一个完整的交互过程，需要 2.5 个 RTT (从客户端到服务器一个往返的时间) 的时延。<br>由于第三次握手是可以携带数据的，这时如果在第三次握手发起 HTTP GET 请求，需要 2 个 RTT 的时延。<br>但是在下一次（不是同个 TCP 连接的下一次）发起 HTTP GET 请求时，经历的 RTT 也是一样，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650422060986-0961373c-a96e-477b-abef-77599db85059.png#averageHue=%23f7f7f5&amp;clientId=uebd955b7-5167-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=430&amp;id=Vcfac&amp;name=image.png&amp;originHeight=1061&amp;originWidth=1046&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=102801&amp;status=done&amp;style=none&amp;taskId=u9957b8f0-9078-45d4-9d2e-3508d2d3314&amp;title=&amp;width=424" alt="image.png"><br>在 Linux 3.7 内核版本中，提供了<strong> TCP Fast Open</strong> 功能，这个功能可以减少 TCP 连接建立的时延。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650422060335-c30ed8fc-5278-41f1-8158-300f0e156b0e.png#averageHue=%23f7f6f4&amp;clientId=uebd955b7-5167-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=531&amp;id=nP0Jw&amp;name=image.png&amp;originHeight=918&amp;originWidth=1052&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=103104&amp;status=done&amp;style=none&amp;taskId=u1a439667-a793-4d45-9206-031ac3560e7&amp;title=&amp;width=609" alt="image.png"></p><ul><li>在第一次建立连接的时候，服务端在第二次握手产生一个 Cookie （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 Cookie，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；</li><li>在下次请求的时候，客户端在 SYN 包带上 Cookie 发给服务端，就提前可以跳过三次握手的过程，因为 Cookie 中维护了一些信息，服务端可以从 Cookie 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；</li></ul><p>注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）</p><h3 id="ⅢTCP连接断开"><a href="#ⅢTCP连接断开" class="headerlink" title="ⅢTCP连接断开"></a>ⅢTCP连接断开</h3><h4 id="①TCP-四次挥⼿过程和状态变迁"><a href="#①TCP-四次挥⼿过程和状态变迁" class="headerlink" title="①TCP 四次挥⼿过程和状态变迁"></a>①TCP 四次挥⼿过程和状态变迁</h4><p>记忆：标志位  xx报文 状态<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649900067215-bf5b240b-0b8f-478d-8ed2-6818ab626c15.png#averageHue=%23f3e6cd&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=405&amp;id=uc555fbfa&amp;originHeight=794&amp;originWidth=753&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u71d555d2-0b9d-4bde-89d4-61f4cfa9f2e&amp;title=&amp;width=384" alt=""></p><ul><li>客户端打算关闭连接，此时会发送⼀个 TCP ⾸部 FIN 标志位被置为 1 的报⽂，也即 FIN 报⽂，之后客 </li></ul><p>户端进⼊ <strong>FIN_WAIT_1</strong> 状态。 </p><ul><li>服务端收到该报⽂后，就向客户端发送 ACK 应答报⽂，接着服务端进⼊ <strong>CLOSED_WAIT</strong> 状态。 </li><li><p>客户端收到服务端的 ACK 应答报⽂后，之后进⼊ <strong>FIN_WAIT_2</strong> 状态。 </p></li><li><p>等待服务端处理完数据后，也向客户端发送 FIN 报⽂，之后服务端进⼊<strong> LAST_ACK </strong>状态。 </p></li><li><p>客户端收到服务端的 FIN 报⽂后，回⼀个 ACK 应答报⽂，之后进⼊ <strong>TIME_WAIT</strong> 状态 </p></li><li><p>服务器收到了 ACK 应答报⽂后，就进⼊了 <strong>CLOSED </strong>状态，⾄此服务端已经完成连接的关闭。 </p></li><li>客户端在经过 2MSL ⼀段时间后，⾃动进⼊ <strong>CLOSED </strong>状态，⾄此客户端也完成连接的关闭。</li></ul><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><h4 id="②为什么挥⼿需要四次？"><a href="#②为什么挥⼿需要四次？" class="headerlink" title="②为什么挥⼿需要四次？"></a>②为什么挥⼿需要四次？</h4><ul><li>关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li><li>服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而<strong>服务端可能还有数据需要处理和发送</strong>，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。</li></ul><p>所以服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送(三次握手syn和ack是一起发送的)，从而比三次握手导致多了一次。</p><h4 id="③握手丢失的情况"><a href="#③握手丢失的情况" class="headerlink" title="③握手丢失的情况"></a>③握手丢失的情况</h4><h5 id="a-第一次挥手丢失了，会发生什么？"><a href="#a-第一次挥手丢失了，会发生什么？" class="headerlink" title="a.第一次挥手丢失了，会发生什么？"></a>a.第一次挥手丢失了，会发生什么？</h5><ul><li>当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。</li><li>正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。</li><li>如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会<strong>触发超时重传</strong>机制，重传 FIN 报文，重发次数由<strong> tcp_orphan_retries </strong>参数控制。</li><li><p>当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。</p><h5 id="b-第二次挥手丢失了，会发生什么？"><a href="#b-第二次挥手丢失了，会发生什么？" class="headerlink" title="b.第二次挥手丢失了，会发生什么？"></a>b.第二次挥手丢失了，会发生什么？</h5></li><li><p>当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。</p></li><li>在前面我们也提了，<strong>ACK 报文是不会重传的</strong>，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。</li></ul><p>下述讲解重点看：<br>这里提一下，当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 FIN_WAIT2 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。<br>对于 close 函数关闭的连接，由于无法再发送和接收数据，所以FIN_WAIT2 状态不可以持续太久，而 <strong>tcp_fin_timeout</strong> 控制了这个状态下连接的持续时长，默认值是 60 秒。<br>这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭。<br>但是注意，如果主动关闭方使用 shutdown 函数关闭连接且指定只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态（tcp_fin_timeout 无法控制 shutdown 关闭的连接）。</p><h5 id="c-第三次挥手丢失了，会发生什么？"><a href="#c-第三次挥手丢失了，会发生什么？" class="headerlink" title="c.第三次挥手丢失了，会发生什么？"></a>c.第三次挥手丢失了，会发生什么？</h5><blockquote><ul><li>当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</li><li>此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。</li><li>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。</li></ul></blockquote><ul><li><p>如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由<strong> tcp_orphan_retries</strong> 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。</p><h5 id="d-第四次挥手丢失了，会发生什么？"><a href="#d-第四次挥手丢失了，会发生什么？" class="headerlink" title="d.第四次挥手丢失了，会发生什么？"></a>d.第四次挥手丢失了，会发生什么？</h5></li><li><p>当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。</p></li><li>在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。</li><li>然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。</li></ul><p>如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p><h4 id="✊④timewait相关面试题"><a href="#✊④timewait相关面试题" class="headerlink" title="✊④timewait相关面试题"></a>✊④timewait相关面试题</h4><h5 id="a-为什么-TIME-WAIT-等待的时间是-2MSL？"><a href="#a-为什么-TIME-WAIT-等待的时间是-2MSL？" class="headerlink" title="a:为什么 TIME_WAIT 等待的时间是 2MSL？"></a>a:为什么 TIME_WAIT 等待的时间是 2MSL？</h5><ul><li><p>MSL 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</p><blockquote><ul><li>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 <strong>MSL 应该要大于等于 TTL 消耗为 0 的时间</strong>，以确保报文已被自然消亡。</li><li><strong>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong>。</li></ul></blockquote></li><li><p>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。</p><ul><li>比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。</li></ul></li></ul><p>可以看到 <strong>2MSL时长</strong> 这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。<br>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p><hr><p>2MSL 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong>。<br>在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。<strong>Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒</strong>。<br>其定义在 Linux 内核代码里的名称为 TCP_TIMEWAIT_LEN：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> TCP_TIMEWAIT_LEN (60*HZ) <span class="comment">/* how long to wait to destroy TIME-WAIT </span></span></span><br><span class="line"><span class="comment"><span class="meta">                                    state, about 60 seconds  */</span></span></span><br></pre></td></tr></table></figure><br>如果要修改 TIME_WAIT 的时间长度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux 内核。</p><h5 id="b-为什么需要-TIME-WAIT-状态？（结合5-gt-5-2tcp优化-gt-timewait）"><a href="#b-为什么需要-TIME-WAIT-状态？（结合5-gt-5-2tcp优化-gt-timewait）" class="headerlink" title="b:为什么需要 TIME_WAIT 状态？（结合5-&gt;5.2tcp优化-&gt;timewait）"></a>b:为什么需要 TIME_WAIT 状态？（结合5-&gt;5.2tcp优化-&gt;timewait）</h5><p>主动发起关闭连接的一方，才会有 TIME-WAIT 状态。<br><em><strong>原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收</strong></em><br>补充&gt; 为了能更好的理解这个原因，我们先来了解序列号（SEQ）和初始序列号（ISN）。</p><blockquote><ul><li><strong>序列号</strong>，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。<strong>序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0</strong>。</li><li><strong>初始序列号</strong>，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。<strong>初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时</strong>。</li></ul><p>给大家抓了一个包，下图中的 Seq 就是序列号，其中红色框住的分别是客户端和服务端各自生成的初始序列号。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659077930847-6cc6f94e-459a-493d-b6d8-6ec1a9c28c45.png#clientId=ub3ce7cf8-e5f6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=k352L&amp;name=image.png&amp;originHeight=545&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=888038&amp;status=done&amp;style=none&amp;taskId=u7b46737c-58e0-493e-92be-598740a6701&amp;title=" alt="image.png"><br>通过前面我们知道，<strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong>。</p></blockquote><p>假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659077930704-f1051c58-1585-4bd9-b84f-d1eeba24c536.png#clientId=ub3ce7cf8-e5f6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=GKray&amp;name=image.png&amp;originHeight=1295&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=731276&amp;status=done&amp;style=none&amp;taskId=uc58e57f4-0d83-4ea7-9f21-e1a2bc6d966&amp;title=" alt="image.png"><br>如上图：</p><ul><li>服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。</li><li>接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 SEQ = 301 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li></ul><p>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME<em>WAIT 状态，状态会持续 2MSL 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></em><strong>原因二：保证「被动关闭连接」的一方，能被正确的关闭</strong>_</p><blockquote><p>在 RFC 793 指出 TIME-WAIT 另一个重要的作用是：<br><em>TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.</em></p></blockquote><p>也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p><ul><li>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。</li><li>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</li><li>服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</li><li>为了防止这种情况出现，客户端必须等待足够长的时间确保对端收到 ACK，如果对端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659077930486-5b9d15ae-7acd-44f1-9cf9-655caafab328.png#averageHue=%23f4e2c6&amp;clientId=ub3ce7cf8-e5f6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=437&amp;id=u6008fd20&amp;name=image.png&amp;originHeight=903&amp;originWidth=903&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=449588&amp;status=done&amp;style=none&amp;taskId=ue1de13d9-2e54-4311-8016-06441e80967&amp;title=&amp;width=437.00006103515625" alt="image.png"><br>但是你可能会说重新发送的 ACK 还是有可能丢失啊，没错，但 TCP 已经等待了那么长的时间了，已经算仁至义尽了。</p><h5 id="c-👌TIME-WAIT-过多有什么危害？"><a href="#c-👌TIME-WAIT-过多有什么危害？" class="headerlink" title="c:👌TIME_WAIT 过多有什么危害？"></a>c:👌TIME_WAIT 过多有什么危害？</h5><p>过多的 TIME-WAIT 状态主要的危害有两种：</p><ul><li>第一是内存资源占用；</li><li>第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；</li></ul><p>第二个危害是会造成严重的后果的，要知道，端口资源也是有限的。<br><strong>如果「发起连接方」的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。</strong></p><blockquote><p>客户端（发起连接方）受端口资源限制：</p><ul><li>客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。</li></ul><p>服务端（被动连接方）受系统资源限制：</p><ul><li>由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，因为服务端只监听一个端口，不会因为 TCP 连接过多而导致端口资源受限。但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。</li></ul></blockquote><h5 id="d-👌如何优化-TIME-WAIT？-了解"><a href="#d-👌如何优化-TIME-WAIT？-了解" class="headerlink" title="d:👌如何优化 TIME_WAIT？(了解)"></a>d:👌如何优化 TIME_WAIT？(了解)</h5><p>这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：</p><ul><li>打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；</li><li>net.ipv4.tcp_max_tw_buckets</li><li><p>程序中使用 SO<em>LINGER ，应用强制使用 RST 关闭。<br>补充</em>方式一：net.ipv4.tcp<em>tw_reuse 和 tcp_timestamps</em><br>如下的 Linux 内核参数开启后，则可以<strong>复用处于 TIME_WAIT 的 socket 为新的连接所用</strong>。<br>有一点需要注意的是，<strong>tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。</strong><br>net.ipv4.tcp<em>tw_reuse = 1<br>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即<br>net.ipv4.tcp_timestamps=1（默认即为 1）<br>这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。<br>由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</em>方式二：net.ipv4.tcp<em>max_tw_buckets</em><br>这个值默认为 18000，<strong>当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置</strong>，这个方法比较暴力。<br><em>方式三：程序中使用 SO_LINGER</em><br>我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651542236229-b0dd3e0e-c54e-4c20-8095-19bf017560d2.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=141&amp;id=rt9oV&amp;name=image.png&amp;originHeight=176&amp;originWidth=946&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=11475&amp;status=done&amp;style=none&amp;taskId=u4ad53f5d-e6a5-41df-b8ee-9699a475687&amp;title=&amp;width=756.8" alt="image.png"><br>如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。<br>但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。<br>前面介绍的方法都是试图越过 TIME_WAIT状态的，这样其实不太好。虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。<br>《UNIX网络编程》一书中却说道：<strong>TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它</strong>。<br><strong>如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT</strong>。</p><h5 id="e-tcp-tw-reuse-为什么默认是关闭的？"><a href="#e-tcp-tw-reuse-为什么默认是关闭的？" class="headerlink" title="e:tcp_tw_reuse 为什么默认是关闭的？"></a>e:tcp_tw_reuse 为什么默认是关闭的？</h5><h6 id="tcp-tw-reuse-是什么？"><a href="#tcp-tw-reuse-是什么？" class="headerlink" title="tcp_tw_reuse 是什么？"></a>tcp_tw_reuse 是什么？</h6><p>在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768~61000 ，也可以通过如下参数设置指定范围：<br>net.ipv4.ip_local_port_range<br>那么，如果如果主动关闭连接方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。<br>不过，Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：</p></li><li><p>net.ipv4.<strong>tcp_tw_reuse</strong>，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，<strong>内核会随机找一个 TIME_WAIT 状态超过 1 秒的连接给新的连接复用</strong>，所以该选项只适用于连接发起方。</p></li><li>net.ipv4.<strong>tcp_tw_recycle</strong>，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收，该参数在 <strong>NAT 的网络下是不安全的！</strong>详细见这篇文章介绍：<a href="https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;mid=2247502230&amp;idx=1&amp;sn=5fb86772de17ab650088944d4d0adf62&amp;scene=21#wechat_redirect">字节面试：SYN 报文什么时候情况下会被丢弃？(opens new window)</a></li></ul><p>要使得上面这两个参数生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1）。<br>开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，<strong>一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）</strong>，我们先来介绍这个功能。<br>序列号是一个 32 位的无符号整型，上限值是 4GB，超过 4GB 后就需要将序列号回绕进行重用。这在以前网速慢的年代不会造成什么问题，但在一个速度足够快的网络中传输大量数据时，序列号的回绕时间就会变短。如果序列号回绕的时间极短，我们就会再次面临之前延迟的报文抵达后序列号依然有效的问题。<br>为了解决这个问题，就需要有 TCP 时间戳。<br>试看下面的示例，假设 TCP 的发送窗口是 1 GB，并且使用了时间戳选项，发送方会为每个 TCP 报文分配时间戳数值，我们假设每个报文时间加 1，然后使用这个连接传输一个 6GB 大小的数据流。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650783691056-bcef470a-d971-4738-9636-4004eba765e4.png#averageHue=%23e7e7e7&amp;clientId=u83577f3d-fd36-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=xYBBr&amp;name=image.png&amp;originHeight=298&amp;originWidth=956&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=99998&amp;status=done&amp;style=none&amp;taskId=u11ab82d1-91cd-4317-826b-ed56efa7806&amp;title=" alt="image.png"><br>32 位的序列号在时刻 D 和 E 之间回绕。假设在时刻B有一个报文丢失并被重传，又假设这个报文段在网络上绕了远路并在时刻 F 重新出现。如果 TCP 无法识别这个绕回的报文，那么数据完整性就会遭到破坏。<br>使用时间戳选项能够有效的防止上述问题，如果丢失的报文会在时刻 F 重新出现，由于它的时间戳为 2，小于最近的有效时间戳（5 或 6），因此防回绕序列号算法（PAWS）会将其丢弃。<br>防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p><h6 id="为什么-tcp-tw-reuse-默认是关闭的？"><a href="#为什么-tcp-tw-reuse-默认是关闭的？" class="headerlink" title="为什么 tcp_tw_reuse 默认是关闭的？"></a>为什么 tcp_tw_reuse 默认是关闭的？</h6><p>通过前面这么多铺垫，终于可以说这个问题了。<br>开启 tcp_tw_reuse 会有什么风险呢？我觉得会有 2 个问题。<br><strong>第一个问题</strong><br>我们知道开启 tcp_tw_reuse 的同时，也需要开启 tcp_timestamps，意味着可以用时间戳的方式有效的判断回绕序列号的历史报文。<br>历史 RST 报文可能会终止后面相同四元组的连接，因为 PAWS 检查到即使 RST 是过期的，也不会丢弃。<br>下面 tcp_validate_incoming 函数就是验证接收到的 TCP 报文是否合格的函数，其中第一步就会进行 PAWS 检查，由 tcp_paws_discard 函数负责。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">bool</span> <span class="title function_">tcp_validate_incoming</span><span class="params">(<span class="keyword">struct</span> sock *sk, <span class="keyword">struct</span> sk_buff *skb, <span class="type">const</span> <span class="keyword">struct</span> tcphdr *th, <span class="type">int</span> syn_inerr)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> =</span> tcp_sk(sk);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* RFC1323: H1. Apply PAWS check first. */</span></span><br><span class="line">    <span class="keyword">if</span> (tcp_fast_parse_options(sock_net(sk), skb, th, tp) &amp;&amp;</span><br><span class="line">        tp-&gt;rx_opt.saw_tstamp &amp;&amp;</span><br><span class="line">        tcp_paws_discard(sk, skb)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!th-&gt;rst) &#123;</span><br><span class="line">            ....</span><br><span class="line">            <span class="keyword">goto</span> discard;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* Reset is accepted even if it did not pass PAWS. */</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>当 tcp_paws_discard 返回 true，就代表报文是一个历史报文，于是就要丢弃这个报文。但是在丢掉这个报文的时候，会先判断是不是 RST 报文，如果不是 RST 报文，才会将报文丢掉。也就是说，即使 RST 报文是一个历史报文，并不会被丢弃。<br>假设有这样的场景，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650783691851-f8d5417e-49a8-457e-820f-ff99b27781cb.png#averageHue=%23e8d280&amp;clientId=u83577f3d-fd36-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=715&amp;id=tPcu9&amp;name=image.png&amp;originHeight=1268&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=695117&amp;status=done&amp;style=none&amp;taskId=u15d819ad-8abe-493f-9024-abc15ea4bf4&amp;title=&amp;width=609" alt="image.png"></p><ul><li>客户端向一个还没有被服务端监听的端口发起了 HTTP 请求，接着服务端就会回 RST 报文给对方，很可惜的是 <strong>RST 报文被网络阻塞了</strong>。</li><li>由于客户端迟迟没有收到 TCP 第二次握手，于是重发了 SYN 包，与此同时服务端已经开启了服务，监听了对应的端口。于是接下来，客户端和服务端就进行了 TCP 三次握手、数据传输（HTTP应答-响应）、四次挥手。</li><li>因为<strong>客户端开启了 tcp_tw_reuse，于是快速复用 TIME_WAIT 状态的端口，又与服务端建立了一个与刚才相同的四元组的连接</strong>。</li><li>接着，<strong>前面被网络延迟 RST 报文这时抵达了客户端，而且 RST 报文的序列号在客户端的接收窗口内，由于防回绕序列号算法不会防止过期的 RST，所以 RST 报文会被客户端接受了，于是客户端的连接就断开了</strong>。</li></ul><p>上面这个场景就是开启 tcp<em>tw_reuse 风险，<strong>因为快速复用 TIME_WAIT 状态的端口，导致新连接可能被回绕序列号的 RST 报文断开了，而如果不跳过 TIME_WAIT 状态，而是停留 2MSL 时长，那么这个 RST 报文就不会出现下一个新的连接</strong>。<br>可能大家会有这样的疑问，为什么 PAWS 检查要放过过期的 RST 报文。我翻了 RFC 1323 ，里面有一句提到：<br>_It is recommended that RST segments NOT carry timestamps, and that RST segments be acceptable regardless of their timestamp. Old duplicate RST segments should be exceedingly unlikely, and their cleanup function should take precedence over timestamps.</em><br>大概的意思：<em>建议 RST 段不携带时间戳，并且无论其时间戳如何，RST 段都是可接受的。老的重复的 RST 段应该是极不可能的，并且它们的清除功能应优先于时间戳。</em><br>RFC 1323 提到说收历史的 RST 报文是极不可能，之所以有这样的想法是因为 TIME_WAIT 状态持续的 2MSL 时间，足以让连接中的报文在网络中自然消失，所以认为按正常操作来说是不会发生的，因此认为清除连接优先于时间戳。<br>而我前面提到的案例，是因为开启了 tcp_tw_reuse 状态，跳过了 TIME_WAIT 状态，才发生的事情。<br>有同学会说，都经过一个 HTTP 请求了，延迟的 RST 报文竟然还会存活？<br>一个 HTTP 请求其实很快的，比如我下面这个抓包，只需要 0.2 秒就完成了，远小于 MSL，所以延迟的 RST 报文存活是有可能的。</p><p><strong>第二个问题</strong><br>开启 tcp_tw_reuse 来快速复用 TIME_WAIT 状态的连接，如果第四次挥手的 ACK 报文丢失了，有可能会导致被动关闭连接的一方不能被正常的关闭，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650783693946-a7e4db2b-4a58-4010-91e0-fbc487b0498c.png#averageHue=%23f5e9d3&amp;clientId=u83577f3d-fd36-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=458&amp;id=gb3Bx&amp;name=image.png&amp;originHeight=865&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=478765&amp;status=done&amp;style=none&amp;taskId=u9fdf4fed-b596-4611-923d-57c1d1faa47&amp;title=&amp;width=572.0000610351562" alt="image.png"></p><h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>tcp_tw_reuse 的作用是让客户端快速复用处于 TIME_WAIT 状态的端口，相当于跳过了 TIME_WAIT 状态，这可能会出现这样的两个问题：</p><ul><li>历史 RST 报文可能会终止后面相同四元组的连接，因为 PAWS 检查到即使 RST 是过期的，也不会丢弃。</li><li>如果第四次挥手的 ACK 报文丢失了，有可能被动关闭连接的一方不能被正常的关闭;</li></ul><p>虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。</p><h4 id="⑤如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#⑤如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="⑤如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>⑤如果已经建立了连接，但是客户端突然出现故障了怎么办？</h4><p>TCP 有一个机制是<strong>保活机制</strong>。这个机制的原理是这样的：<br>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。<br>补充在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651542221536-2e5fb538-0c41-4cf4-a2dd-242a1d9bf034.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=111&amp;id=qgKhC&amp;name=image.png&amp;originHeight=139&amp;originWidth=931&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=7730&amp;status=done&amp;style=none&amp;taskId=uddd4a79a-e471-473f-b4fb-92ae301f7ff&amp;title=&amp;width=744.8" alt="image.png"></p><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651542101709-cf167e94-e637-4f7a-a1bb-18f4119cd38c.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=194&amp;id=E4QIn&amp;originHeight=303&amp;originWidth=897&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8a57abe0-690b-4bf2-9128-7fbeb09b999&amp;title=&amp;width=575" alt=""><br>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。<br>TCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。<br>比如，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1651542101839-0479cbae-cac5-4621-a483-7201b7098db6.png#clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=362&amp;id=xzKk6&amp;name=image.png&amp;originHeight=947&amp;originWidth=708&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=77981&amp;status=done&amp;style=none&amp;taskId=ub4ba988b-c399-4030-86b2-9952e650f25&amp;title=&amp;width=271" alt="image.png"><br>如果开启了 TCP 保活，需要考虑以下几种情况：</p><ul><li>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，<strong>会产生一个 RST 报文</strong>，这样很快就会发现 TCP 连接已经被重置。</li><li><p>第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</p><h4 id="⑥如果已经建立了连接，但是服务端的进程崩溃会发生什么？"><a href="#⑥如果已经建立了连接，但是服务端的进程崩溃会发生什么？" class="headerlink" title="⑥如果已经建立了连接，但是服务端的进程崩溃会发生什么？"></a>⑥如果已经建立了连接，但是服务端的进程崩溃会发生什么？</h4><p>我自己做了个实验，使用 kill -9 来模拟进程崩溃的情况，发现<strong>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</strong>。</p><h3 id="ⅣSocket通信"><a href="#ⅣSocket通信" class="headerlink" title="ⅣSocket通信"></a>ⅣSocket通信</h3><p>实现跨主机的通信</p><h4 id="①针对-TCP-应该如何-Socket-编程？"><a href="#①针对-TCP-应该如何-Socket-编程？" class="headerlink" title="①针对 TCP 应该如何 Socket 编程？"></a>①针对 TCP 应该如何 Socket 编程？</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649900600934-cc696bcb-d2f9-4eb3-87b8-eb635bca2f90.png#averageHue=%23fbfaf1&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=490&amp;id=ub71f3599&amp;originHeight=1007&amp;originWidth=1188&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ufbd13c0d-6b73-4cfc-91e3-cc27cd55405&amp;title=&amp;width=578" alt=""></p></li><li><p>服务端和客户端初始化 socket，得到文件描述符；</p></li><li>服务端调用 bind，将绑定在 IP 地址和端口;</li><li>服务端调用 listen，进行监听；</li><li><p>服务端调用 accept，等待客户端连接；</p></li><li><p>客户端调用 connect，向服务器端的地址和端口发起连接请求；</p></li><li>服务端 accept 返回用于传输的 socket 的文件描述符；</li><li>客户端调用 write 写入数据；服务端调用 read 读取数据；</li><li>客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。</li></ul><p>这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。<br>所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。<br>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p><h4 id="👌②listen-时候参数-backlog-的意义？"><a href="#👌②listen-时候参数-backlog-的意义？" class="headerlink" title="👌②listen 时候参数 backlog 的意义？"></a>👌②listen 时候参数 backlog 的意义？</h4><p>Linux内核中会维护两个队列：</p><ul><li>半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；</li><li>全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649900600908-26eeca5d-cd55-4680-971c-3b17182080b0.png#averageHue=%23f2f0ea&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=518&amp;id=u1b0a2c17&amp;originHeight=842&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u30b55719-d2fe-451b-b725-e9b94ed2fbc&amp;title=&amp;width=555" alt=""><br>补充int listen (int socketfd, int backlog) </p><ul><li>参数一 socketfd 为 socketfd 文件描述符</li><li>参数二 backlog，这参数在历史版本有一定的变化</li></ul><p>在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。<br>在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，<strong>所以现在通常认为 backlog 是 accept 队列。</strong><br><strong>但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。</strong><br>想详细了解 TCP 半连接队列和全连接队列，可以看这篇：<a href="https://mp.weixin.qq.com/s/2qN0ulyBtO2I67NB_RnJbg">TCP 半连接队列和全连接队列满了会发生什么？又该如何应对？(opens new window)</a></p><h4 id="③accept-发生在三次握手的哪一步？"><a href="#③accept-发生在三次握手的哪一步？" class="headerlink" title="③accept 发生在三次握手的哪一步？"></a>③accept 发生在三次握手的哪一步？</h4><p>我们先看看客户端连接服务端时，发送了什么？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649900608877-b38c1723-ef5b-4a10-9a70-3349ed78dd35.png#averageHue=%23f5eccb&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=406&amp;id=u96a06730&amp;name=image.png&amp;originHeight=722&amp;originWidth=944&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=438841&amp;status=done&amp;style=none&amp;taskId=u21444a69-198e-4b1f-81d6-6a2f9de0216&amp;title=&amp;width=531" alt="image.png"></p><blockquote><ul><li>客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；</li><li>服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务器端进入 SYN_RCVD 状态；</li><li>客户端协议栈收到 ACK 之后，使得应用程序从 connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 server_isn+1；</li><li>应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入 ESTABLISHED 状态。</li></ul></blockquote><p>从上面的描述过程，我们可以得知<strong>客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。</strong></p><h4 id="④客户端调用-close-了，连接是断开的流程是什么？"><a href="#④客户端调用-close-了，连接是断开的流程是什么？" class="headerlink" title="④客户端调用 close 了，连接是断开的流程是什么？"></a>④客户端调用 close 了，连接是断开的流程是什么？</h4><p>我们看看客户端主动调用了 close，会发生什么？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1649900600837-ab98ec6a-dc20-4b9e-8b4e-69034efe56d5.png#averageHue=%23f2e6cd&amp;clientId=u25e7156c-5b63-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=446&amp;id=uec0d9f2b&amp;originHeight=794&amp;originWidth=753&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u8a41964b-f1ad-489e-8398-8bc29a17d0b&amp;title=&amp;width=423" alt=""></p><ul><li>客户端调用 close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；</li><li>服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。这个 EOF 会被<strong>放在已排队等候的其他已接收的数据之后</strong>，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；</li><li>接着，当处理完数据后，自然就会读到 EOF，于是也调用 close 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；</li><li>客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；</li><li>服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；</li><li>客户端经过 2MSL 时间之后，也进入 CLOSE 状态；<h2 id="二、TCP-重传、滑动窗口、流量控制、拥塞控制"><a href="#二、TCP-重传、滑动窗口、流量控制、拥塞控制" class="headerlink" title="二、TCP 重传、滑动窗口、流量控制、拥塞控制"></a>二、TCP 重传、滑动窗口、流量控制、拥塞控制</h2></li></ul><p>相信大家都知道 TCP 是一个可靠传输的协议，那它是如何保证可靠的呢？<br>为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。<br>那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。<br>今天，将重点介绍 TCP 的<strong>重传机制、滑动窗口、流量控制、拥塞控制。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958505784-76dcb14b-6583-498a-bc7f-3ae414103110.png#averageHue=%23f3f4f6&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=346&amp;id=ub3594d82&amp;name=image.png&amp;originHeight=741&amp;originWidth=1029&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=238018&amp;status=done&amp;style=none&amp;taskId=u51a181af-280d-465a-932b-680fc14cab2&amp;title=&amp;width=480" alt="image.png"></p><hr><h3 id="Ⅰ重传机制"><a href="#Ⅰ重传机制" class="headerlink" title="Ⅰ重传机制"></a>Ⅰ重传机制</h3><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。<br>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958505183-860ca435-e98e-46a7-a2b2-7bfbf5cd543c.png#averageHue=%23f7f7ed&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=456&amp;id=u090cadd7&amp;name=image.png&amp;originHeight=677&amp;originWidth=422&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=165059&amp;status=done&amp;style=none&amp;taskId=u4805b706-6f26-4919-a2ab-0b0e028fe3d&amp;title=&amp;width=284" alt="image.png"><br>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？<br>所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决。<br>接下来说说常见的重传机制：</p><ul><li>超时重传</li><li>快速重传</li><li>SACK</li><li><p>D-SACK</p><h4 id="①超时重传"><a href="#①超时重传" class="headerlink" title="①超时重传"></a>①超时重传</h4><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。<br>TCP 会在以下两种情况发生超时重传：</p></li><li><p>数据包丢失</p></li><li>确认应答丢失</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958505710-2f1cb2cc-d0e9-4892-81a6-19e9b90e764c.png#averageHue=%23fbf9f7&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=414&amp;id=u7440e3a5&amp;name=image.png&amp;originHeight=846&amp;originWidth=1092&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=317537&amp;status=done&amp;style=none&amp;taskId=u7fae3301-1586-4761-9064-a44e5a99b11&amp;title=&amp;width=534" alt="image.png"><br>超时时间应该设置为多少呢？<br>我们先来了解一下什么是 RTT（Round-Trip Time 往返时延），从下图我们就可以知道：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958505202-3d26ab91-3941-46e5-927c-828dd9bb4690.png#averageHue=%23f9f7f3&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=362&amp;id=u645fd671&amp;name=image.png&amp;originHeight=662&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=183750&amp;status=done&amp;style=none&amp;taskId=u375d16e4-b31c-409e-924f-5fe44b76592&amp;title=&amp;width=428" alt="image.png"><br>RTT 指的是<strong>数据发送时刻到接收到确认的时刻的差值</strong>，也就是包的往返时间。<br>超时重传时间是以 <strong>RTO </strong>（Retransmission Timeout 超时重传时间）表示。<br>假设在重传的情况下，超时时间 RTO 「较长或较短」时，会发生什么事情呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958505825-e184a20c-1d15-4460-a374-f08951167249.png#averageHue=%23faf4f2&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5e8dc257&amp;name=image.png&amp;originHeight=846&amp;originWidth=1412&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=360122&amp;status=done&amp;style=none&amp;taskId=u6fef6d01-1ff1-43ca-b007-e921c80f746&amp;title=" alt="image.png"><br>上图中有两种超时时间不同的情况：</p><ul><li>当超时时间 <strong>RTO 较大</strong>时，重发就慢，丢了老半天才重发，没有效率，性能差；</li><li>当超时时间 <strong>RTO 较小</strong>时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li></ul><p>精确的测量超时时间 RTO 的值是非常重要的，这可让我们的重传机制更高效。<br>根据上述的两种情况，我们可以得知，<strong>超时重传时间 RTO 的值应该略大于报文往返 RTT 的值</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958508594-bcc15069-8e97-40aa-b8e1-160583c744ee.png#averageHue=%23faf9f5&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=362&amp;id=u51b221b2&amp;name=image.png&amp;originHeight=482&amp;originWidth=617&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=104854&amp;status=done&amp;style=none&amp;taskId=u7909bb0c-4ef8-44a1-a6c0-fc8e582aa98&amp;title=&amp;width=464" alt="image.png"><br>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？<br>于是就可以用「快速重传」机制来解决超时重发的时间等待。</p><h4 id="②-快速重传"><a href="#②-快速重传" class="headerlink" title="② 快速重传"></a>② 快速重传</h4><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><blockquote><p>快速重传机制，是如何工作的呢？其实很简单，一图胜千言。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958508994-c7ca1595-a06a-407e-8e56-8cec624ad20a.png#averageHue=%23f8f6f3&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=408&amp;id=uf44dbbb5&amp;name=image.png&amp;originHeight=602&amp;originWidth=647&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=132601&amp;status=done&amp;style=none&amp;taskId=ued72dd2c-6f67-4c0f-9a2d-08190b3690c&amp;title=&amp;width=439" alt="image.png"><br>在上图，发送方发出了 1，2，3，4，5 份数据：</p><ul><li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li><li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li><li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li><li><strong>发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</strong></li><li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li></ul></blockquote><p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。<br>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。<br>比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。<br>根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。<br>为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。</p><h4 id="③-SACK-方法"><a href="#③-SACK-方法" class="headerlink" title="③ SACK 方法"></a>③ SACK 方法</h4><p>还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment 选择性确认）。<br>这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它<strong>可以将缓存的地图发送给发送方</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。<br>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 SACK 信息发现只有 200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958509375-6c601a7e-c94c-48dc-97ee-f75d494b4fc1.png#averageHue=%23fbfafa&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=365&amp;id=udf11bef6&amp;name=image.png&amp;originHeight=827&amp;originWidth=1413&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=376244&amp;status=done&amp;style=none&amp;taskId=u17d42399-1a2c-430f-acf3-88ad5de99a2&amp;title=&amp;width=623" alt="image.png"><br>如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）。</p><h4 id="④-Duplicate-SACK"><a href="#④-Duplicate-SACK" class="headerlink" title="④ Duplicate SACK"></a>④ Duplicate SACK</h4><p>Duplicate SACK 又称 D-SACK，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p><blockquote><p>下面举例两个栗子，来说明 D-SACK 的作用。<br><em>栗子一号：ACK 丢包</em><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659096945517-922a447c-3abb-43c2-83c4-26d3de3171d0.png#averageHue=%23fbf7f6&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1a0f4d96&amp;name=image.png&amp;originHeight=602&amp;originWidth=887&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=210448&amp;status=done&amp;style=none&amp;taskId=u2feecbc2-4152-4e33-802a-d297cf3cdc2&amp;title=" alt="image.png"></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><em>栗子二号：网络延时</em><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659096945722-daa81022-d0c6-4cce-88b1-96375a8237c0.png#averageHue=%23faf7f4&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u8d947282&amp;name=image.png&amp;originHeight=1082&amp;originWidth=962&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=443449&amp;status=done&amp;style=none&amp;taskId=u791fa3ac-bdc7-4cf1-be72-6c9674176ff&amp;title=" alt="image.png"></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li><li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul></blockquote><p>可见，D-SACK 有这么几个好处：</p><ol><li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li><li>可以知道是不是「发送方」的数据包被网络延迟了;</li><li>可以知道网络中是不是把「发送方」的数据包给复制了;</li></ol><p>在 Linux 下可以通过 net.ipv4.tcp_dsack 参数开启/关闭这个功能（Linux 2.4 后默认打开）。</p><hr><h3 id="Ⅱ滑动窗口"><a href="#Ⅱ滑动窗口" class="headerlink" title="Ⅱ滑动窗口"></a>Ⅱ滑动窗口</h3><p>滑动窗口解决了什么问题</p><p>大小是从哪里获取的</p><ul><li><p>TCP 利用滑动窗口实现<strong>流量控制</strong>。<strong>流量控制是为了控制发送方发送速率，保证接收方来得及接收</strong>。 TCP会话的双方都各自维护一个发送窗口和一个接收窗口。接收窗口大小取决于应用、系统、硬件的限制。发送窗口则取决于接收窗口。接收方发送的<strong>确认报文</strong>中的window字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将接收方的确认报文window字段设置为 0，则发送方不能发送数据。</p></li><li><p>TCP头包含window字段，16bit位，它代表的是窗口的字节容量，最大为65535。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。接收窗口的大小是约等于发送窗口的大小。</p></li></ul><p>接收窗口和发送窗口的大小是相等的吗？<br>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。<br>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。<br>引入窗口概念的原因<br>我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。<br>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。<br>为解决这个问题，TCP 引入了<strong>窗口</strong>这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。<br>那么有了窗口，就可以指定窗口大小，窗口大小就是指<strong>无需等待确认应答，而可以继续发送数据的最大值</strong>。<br>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。<br>假设窗口大小为 3 个 TCP 段，那么发送方就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142095187-9fe68662-8e62-4954-854b-056ca63c2a59.png#averageHue=%23f9f5f4&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=223&amp;id=uffe6e793&amp;name=image.png&amp;originHeight=602&amp;originWidth=857&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=227815&amp;status=done&amp;style=none&amp;taskId=udf358f0c-38c2-4714-9edf-76ade68aa66&amp;title=&amp;width=317.2857360839844" alt="image.png"><br>图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫<strong>累计确认</strong>或者<strong>累计应答</strong>。<br>窗口大小由哪一方决定？<br>TCP 头里有一个字段叫 Window，也就是窗口大小。<br><strong>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</strong><br>所以，通常窗口的大小是由接收方的窗口大小来决定的。<br>发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。<br>发送方的滑动窗口<br>我们先来看看发送方的窗口，下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142095249-3be72842-7b8a-4dae-aded-98d252891fe9.png#averageHue=%23c8dcc6&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1859f6ac&amp;name=image.png&amp;originHeight=483&amp;originWidth=1428&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=313054&amp;status=done&amp;style=none&amp;taskId=u59587a86-2638-4fae-bca1-bd025c8e02f&amp;title=" alt="image.png"></p><ul><li><h1 id="1-是已发送并收到-ACK确认的数据：1-31-字节"><a href="#1-是已发送并收到-ACK确认的数据：1-31-字节" class="headerlink" title="1 是已发送并收到 ACK确认的数据：1~31 字节"></a>1 是已发送并收到 ACK确认的数据：1~31 字节</h1></li><li><h1 id="2-是已发送但未收到-ACK确认的数据：32-45-字节"><a href="#2-是已发送但未收到-ACK确认的数据：32-45-字节" class="headerlink" title="2 是已发送但未收到 ACK确认的数据：32~45 字节"></a>2 是已发送但未收到 ACK确认的数据：32~45 字节</h1></li><li><h1 id="3-是未发送但总大小在接收方处理范围内（接收方还有空间）：46-51字节"><a href="#3-是未发送但总大小在接收方处理范围内（接收方还有空间）：46-51字节" class="headerlink" title="3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节"></a>3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节</h1></li><li><h1 id="4-是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后"><a href="#4-是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后" class="headerlink" title="4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后"></a>4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后</h1></li></ul><p>在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142095197-48a53cb7-033b-47c3-83b8-a3d5ee479c0d.png#averageHue=%23c8dbc5&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=163&amp;id=u30393f59&amp;name=image.png&amp;originHeight=393&amp;originWidth=1428&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=231266&amp;status=done&amp;style=none&amp;taskId=u7dcaed62-d90e-4bb7-902e-a9468eaab9a&amp;title=&amp;width=593.2857666015625" alt="image.png"><br>在下图，当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则<strong>滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认</strong>，接下来 52~56 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142095271-d6216631-c9d6-46ae-af3d-fc6daba00e74.png#averageHue=%23cbdec8&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=140&amp;id=u887fffae&amp;name=image.png&amp;originHeight=408&amp;originWidth=1608&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=348505&amp;status=done&amp;style=none&amp;taskId=u3fa259ee-0594-4d4e-9b7d-64119776507&amp;title=&amp;width=553.2857666015625" alt="image.png"><br>程序是如何表示发送方的四个部分的呢？<br>TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142097278-16ef5855-4d51-46e6-ae85-db9f70084ad1.png#averageHue=%23ccdeca&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=184&amp;id=u01f18b16&amp;name=image.png&amp;originHeight=513&amp;originWidth=1428&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=371816&amp;status=done&amp;style=none&amp;taskId=u27aab378-ae75-4a3e-b9a0-2afb34dfd3d&amp;title=&amp;width=512.2857666015625" alt="image.png"></p><ul><li>SND.WND：表示发送窗口的大小（大小是由接收方指定的）；</li><li>SND.UNA（<em>Send Unacknoleged</em>）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。</li><li>SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。</li><li>指向 #4 的第一个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND 大小的偏移量，就可以指向 #4 的第一个字节了。</li></ul><p>那么可用窗口大小的计算就可以是：<br><strong>可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）</strong><br>接收方的滑动窗口<br>接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：</p><ul><li><h1 id="1-2-是已成功接收并确认的数据（等待应用进程读取）；"><a href="#1-2-是已成功接收并确认的数据（等待应用进程读取）；" class="headerlink" title="1 + #2 是已成功接收并确认的数据（等待应用进程读取）；"></a>1 + #2 是已成功接收并确认的数据（等待应用进程读取）；</h1></li><li><h1 id="3-是未收到数据但可以接收的数据；"><a href="#3-是未收到数据但可以接收的数据；" class="headerlink" title="3 是未收到数据但可以接收的数据；"></a>3 是未收到数据但可以接收的数据；</h1></li><li><h1 id="4-未收到数据并不可以接收的数据；"><a href="#4-未收到数据并不可以接收的数据；" class="headerlink" title="4 未收到数据并不可以接收的数据；"></a>4 未收到数据并不可以接收的数据；</h1></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1668142096958-2033e646-8359-4e3d-8736-60ca00b48216.png#averageHue=%23d1e1ce&amp;clientId=u5c8b8f72-f3c7-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u2975fadb&amp;name=image.png&amp;originHeight=498&amp;originWidth=1429&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=312942&amp;status=done&amp;style=none&amp;taskId=u2670f4eb-2050-44b5-8f91-6204be83c5b&amp;title=" alt="image.png"><br>其中三个接收部分，使用两个指针进行划分:</p><ul><li>RCV.WND：表示接收窗口的大小，它会通告给发送方。</li><li>RCV.NXT：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。</li><li>指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向 #4 的第一个字节了。</li></ul><p>接收窗口和发送窗口的大小是相等的吗？<br>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。<br>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p><hr><h3 id="Ⅲ流量控制"><a href="#Ⅲ流量控制" class="headerlink" title="Ⅲ流量控制"></a>Ⅲ流量控制</h3><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。<br>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。<br>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong><br>下面举个栗子，为了简单起见，假设以下场景：</p><ul><li>客户端是接收方，服务端是发送方</li><li>假设接收窗口和发送窗口相同，都为 200</li><li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097970274-af4266ac-7783-4ad9-8dca-5b553522b3b0.png#averageHue=%23f5f2f2&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=950&amp;id=uf47cf8e7&amp;name=image.png&amp;originHeight=2417&amp;originWidth=1499&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=947215&amp;status=done&amp;style=none&amp;taskId=u3a213985-d6d9-4b73-9ecb-32350a56636&amp;title=&amp;width=589.2857666015625" alt="image.png"><br>根据上图的流量控制，说明下每个过程：</p><ol><li>客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。</li><li>服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 Usable 减少为 120 字节，同时 SND.NXT 指针也向右偏移 80 字节后，指向 321，<strong>这意味着下次发送数据的时候，序列号是 321。</strong></li><li>客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，RCV.NXT 也就指向 321，<strong>这意味着客户端期望的下一个报文的序列号是 321</strong>，接着发送确认报文给服务端。</li><li>服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。</li><li>客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，RCV.NXT 也就指向 441，接着发送确认报文给服务端。</li><li>服务端收到对 80 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 321，于是可用窗口 Usable 增大到 80。</li><li>服务端收到对 120 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 441，于是可用窗口 Usable 增大到 200。</li><li>服务端可以继续发送了，于是发送了 160 字节的数据后，SND.NXT 指向 601，于是可用窗口 Usable 减少到 40。</li><li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，RCV.NXT 也就是指向了 601，接着发送确认报文给服务端。</li><li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 SND.UNA 指针偏移了 160 后指向 601，可用窗口 Usable 也就增大至了 200。<h4 id="操作系统缓冲区与滑动窗口的关系"><a href="#操作系统缓冲区与滑动窗口的关系" class="headerlink" title="操作系统缓冲区与滑动窗口的关系"></a>操作系统缓冲区与滑动窗口的关系</h4>前面的流量控制例子，我们假定了发送窗口和接收窗口是不变的，但是实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会<strong>被操作系统调整</strong>。<br>当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。<br>那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？<blockquote><p><em>我们先来看看第一个例子。</em><br>当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化。<br>考虑以下场景：</p><ul><li>客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为 360；</li><li>服务端非常的繁忙，当收到客户端的数据时，应用层不能及时读取数据。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097970237-0a353490-f2f9-423c-a62e-961ff6f11ee9.png#averageHue=%23f3f2f2&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u437bc6d3&amp;name=image.png&amp;originHeight=2507&amp;originWidth=1614&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=957116&amp;status=done&amp;style=none&amp;taskId=u040f5eab-cb04-45b2-83ff-e2e16b9b60e&amp;title=" alt="image.png"><br>根据上图的流量控制，说明下每个过程：</p><ol><li>客户端发送 140 字节数据后，可用窗口变为 220 （360 - 140）。</li><li>服务端收到 140 字节数据，<strong>但是服务端非常繁忙，应用进程只读取了 40 个字节，还有 100 字节占用着缓冲区，于是接收窗口收缩到了 260 （360 - 100）</strong>，最后发送确认信息时，将窗口大小通告给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 260。</li><li>客户端发送 180 字节数据，此时可用窗口减少到 80。</li><li>服务端收到 180 字节数据，<strong>但是应用程序没有读取任何数据，这 180 字节直接就留在了缓冲区，于是接收窗口收缩到了 80 （260 - 180）</strong>，并在发送确认信息时，通过窗口大小给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 80。</li><li>客户端发送 80 字节数据后，可用窗口耗尽。</li><li>服务端收到 80 字节数据，<strong>但是应用程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗口收缩到了 0</strong>，并在发送确认信息时，通过窗口大小给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 0。</li></ol><p>可见最后窗口都收缩为 0 了，也就是发生了窗口关闭。当发送方可用窗口变为 0 时，发送方实际上会定时发送窗口探测报文，以便知道接收方的窗口是否发生了改变，这个内容后面会说，这里先简单提一下。</p></blockquote></li></ol><blockquote><p><em>我们先来看看第二个例子。</em><br>当服务端系统资源非常紧张的时候，操心系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097970239-9b9f03d1-77fb-4216-9632-f0b94ec57de1.png#averageHue=%23f5f3f3&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u4f8ac4a6&amp;name=image.png&amp;originHeight=1772&amp;originWidth=1757&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=773903&amp;status=done&amp;style=none&amp;taskId=u117053ba-e99b-4022-83fe-a7ea15d5b99&amp;title=" alt="image.png"><br>说明下每个过程：</p><ol><li>客户端发送 140 字节的数据，于是可用窗口减少到了 220。</li><li><strong>服务端因为现在非常的繁忙，操作系统于是就把接收缓存减少了 120 字节，当收到 140 字节数据后，又因为应用程序没有读取任何数据，所以 140 字节留在了缓冲区中，于是接收窗口大小从 360 收缩成了 100</strong>，最后发送确认信息时，通告窗口大小给对方。</li><li>此时客户端因为还没有收到服务端的通告窗口报文，所以不知道此时接收窗口收缩成了 100，客户端只会看自己的可用窗口还有 220，所以客户端就发送了 180 字节数据，于是可用窗口减少到 40。</li><li>服务端收到了 180 字节数据时，<strong>发现数据大小超过了接收窗口的大小，于是就把数据包丢失了。</strong></li><li>客户端收到第 2 步时，服务端发送的确认报文和通告窗口报文，尝试减少发送窗口到 100，把窗口的右端向左收缩了 80，此时可用窗口的大小就会出现诡异的负值。</li></ol><p>所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。<br><strong>为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。</strong></p></blockquote><h4 id="窗口关闭"><a href="#窗口关闭" class="headerlink" title="窗口关闭"></a>窗口关闭</h4><p>在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。<br><strong>如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。</strong><br>窗口关闭潜在的危险</p><ul><li>接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。</li><li>那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。</li><li>这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097969697-00f422a9-ad04-47a2-a27b-8992f05fc9d6.png#averageHue=%23f6ead1&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=388&amp;id=u9277062c&amp;name=image.png&amp;originHeight=827&amp;originWidth=1104&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=359182&amp;status=done&amp;style=none&amp;taskId=u67f4dd43-cfc7-4e58-9cd8-88ec53875bf&amp;title=&amp;width=518.0000610351562" alt="image.png"></p><p>TCP 是如何解决窗口关闭时，潜在的死锁现象呢？<br>为了解决这个问题，TCP 为每个连接设有一个持续定时器，<strong>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</strong><br>如果持续计时器超时，就会发送<strong>窗口探测 ( Window probe ) 报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p><ul><li>如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；</li><li>如果接收窗口不是 0，那么死锁的局面就可以被打破了。</li></ul><p>窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097969750-e5ae800d-3960-4d9b-ad0b-8cfca96a6bf6.png#averageHue=%23faf7f6&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=457&amp;id=u367b1000&amp;name=image.png&amp;originHeight=887&amp;originWidth=1184&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=349072&amp;status=done&amp;style=none&amp;taskId=ud8cfeaa3-5775-4560-88de-678e439e05b&amp;title=&amp;width=610.0000610351562" alt="image.png"></p><h4 id="糊涂窗口综合症"><a href="#糊涂窗口综合症" class="headerlink" title="糊涂窗口综合症"></a>糊涂窗口综合症</h4><p>如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。<br>到最后，<strong>如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症</strong>。<br>要知道，我们的 TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。</p><blockquote><p>就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家里有矿的大巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。</p></blockquote><p>现举个糊涂窗口综合症的栗子，考虑以下场景：<br>接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下：</p><ul><li>接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据；</li><li>在下一个发送方的 TCP 段到达之前，应用程序还从缓冲区中读取了 40 个额外的字节；</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659097972722-5ca980c6-7890-4d04-b487-b69fd78519ca.png#averageHue=%23f6f5f5&amp;clientId=u28900f28-0a01-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=601&amp;id=u0594cf8c&amp;name=image.png&amp;originHeight=1607&amp;originWidth=1653&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=773227&amp;status=done&amp;style=none&amp;taskId=u9f388cc9-521d-4ec3-b612-e323f8bf2b6&amp;title=&amp;width=618.0000610351562" alt="image.png"><br>每个过程的窗口大小的变化，在图中都描述的很清楚了，可以发现窗口不断减少了，并且发送的数据都是比较小的了。<br>所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：</p><ul><li>接收方可以通告一个小的窗口</li><li>而发送方可以发送小数据</li></ul><p>于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了</p><ul><li>让接收方不通告小窗口给发送方</li><li>让发送方避免发送小数据</li></ul><p>怎么让接收方不通告小窗口呢？<br>接收方通常的策略如下:<br>当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。<br>等到接收方处理了一些数据后，窗口大小 &gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。<br>怎么让发送方避免发送小数据呢？<br>发送方通常的策略:<br>使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：</p><ul><li>要等到窗口大小 &gt;= MSS 或是 数据大小 &gt;= MSS</li><li>收到之前发送数据的 ack 回包</li></ul><p>只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。<br>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。<br>可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (<span class="type">char</span> *)&amp;value, <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br></pre></td></tr></table></figure><br>TCP 延迟确认与 Nagle 算法<br>当我们 TCP 报文的承载的数据非常小的时候，例如几个字节，那么整个网络的效率是很低的，因为每个 TCP 报文中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，而数据只有几个字节，所以在整个报文中有效数据占有的比重就会非常低。<br>这就好像快递员开着大货车送一个小包裹一样浪费。<br>那么就出现了常见的两种策略，来减少小报文的传输，分别是：</p><ul><li>Nagle 算法</li><li>延迟确认</li></ul><p>Nagle 算法是如何避免大量 TCP 小数据报文的传输？<br>Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率。<br>Nagle 算法的策略：</p><ul><li>没有已发送未确认报文时，立刻发送数据。</li><li>存在未确认报文时，直到「没有已发送未确认报文」或「数据长度达到 MSS 大小」时，再发送数据。</li></ul><p>只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651544552208-a179133d-7f18-407e-914b-66233dff1676.jpeg#averageHue=%23fbfaf9&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=491&amp;id=hpuOs&amp;originHeight=678&amp;originWidth=836&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u298bae31-c424-491d-bc1c-45a4ca05333&amp;title=&amp;width=606" alt=""><br>上图右侧启用了 Nagle 算法，它的发送数据的过程：</p><ul><li>一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；</li><li>接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方；</li><li>待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去</li></ul><p>可以看出，<strong>Nagle 算法一定会有一个小报文，也就是在最开始的时候。</strong><br>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。</p><p>那延迟确认又是什么？<br>事实上当没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。<br>为了解决 ACK 传输效率低问题，所以就衍生出了 <strong>TCP 延迟确认</strong>。<br>TCP 延迟确认的策略：</p><ul><li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li><li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li><li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651544552235-88844107-1c33-4135-8391-7471ed4e8ea3.jpeg#averageHue=%23f5f2e9&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=473&amp;id=NzNK9&amp;originHeight=789&amp;originWidth=747&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u02000ade-0e5f-408e-8867-3becfea825f&amp;title=&amp;width=448" alt=""></p><p>延迟确认 和 Nagle 算法混合使用时，会产生新的问题<br>当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/21371548/1651544553236-252baf91-3f01-4cb4-b57a-284f2af302ae.jpeg#averageHue=%23f8f7f3&amp;clientId=uc8ddbc34-260f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=jClnc&amp;originHeight=617&amp;originWidth=483&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc25e615f-4af3-49d1-971c-2998c983fae&amp;title=" alt=""><br>发送方使用了 Nagle 算法，接收方使用了 TCP 延迟确认会发生如下的过程：</p><ul><li>发送方先发出一个小报文，接收方收到后，由于延迟确认机制，自己又没有要发送的数据，只能干等着发送方的下一个报文到达；</li><li>而发送方由于 Nagle 算法机制，在未收到第一个报文的确认前，是不会发送后续的数据；</li><li>所以接收方只能等待最大时间 200 ms 后，才回 ACK 报文，发送方收到第一个报文的确认报文后，也才可以发送后续的数据。</li></ul><p>很明显，这两个同时使用会造成额外的时延，这就会使得网络”很慢”的感觉。<br>要解决这个问题，只有两个办法：</p><ul><li>要不发送方关闭 Nagle 算法</li><li>要不接收方关闭 TCP 延迟确认</li></ul><hr><h3 id="Ⅳ拥塞控制"><a href="#Ⅳ拥塞控制" class="headerlink" title="Ⅳ拥塞控制"></a>Ⅳ拥塞控制</h3><p><strong>为什么要有拥塞控制呀，不是有流量控制了吗？</strong><br>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。<br>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。<br><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</strong><br>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong><br>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。<br><strong>什么是拥塞窗口？和发送窗口有什么关系呢？</strong><br><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><blockquote><p>我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。<br>拥塞窗口 cwnd 变化的规则：</p><ul><li>只要网络中没有出现拥塞，cwnd 就会增大；</li><li>但网络中出现了拥塞，cwnd 就减少；</li></ul></blockquote><p><strong>那么怎么知道当前网络是否出现了拥塞呢？</strong><br>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了用拥塞。</strong><br><strong>拥塞控制有哪些控制算法？</strong><br>拥塞控制主要是四个算法：</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复<h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？<br>慢启动的算法记住一个规则就行：<strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong><blockquote><p>这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子：</p><ul><li>连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958540138-6d49e386-0731-43cb-ab49-3faf2ebf0627.png#averageHue=%23fafaf9&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=368&amp;id=udd23a832&amp;name=image.png&amp;originHeight=632&amp;originWidth=1016&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=196358&amp;status=done&amp;style=none&amp;taskId=u5c0aaf77-ffe0-4bc0-86e0-f0235eab345&amp;title=&amp;width=592.0000610351562" alt="image.png"><br>可以看出慢启动算法，发包的个数是<strong>指数性的增长</strong>。</p></blockquote></li></ul><p>那慢启动涨到什么时候是个头呢？<br>有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。</p><ul><li>当 cwnd &lt; ssthresh 时，使用慢启动算法。</li><li>当 cwnd &gt;= ssthresh 时，就会使用「拥塞避免算法」。<h4 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h4>前面说道，当拥塞窗口 cwnd 「超过」慢启动门限 ssthresh 就会进入拥塞避免算法。<br>一般来说 ssthresh 的大小是 65535 字节。<br>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1/cwnd。</strong><blockquote><p>接上前面的慢启动的栗子，现假定 ssthresh 为 8：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了<strong>线性增长。</strong></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958540138-16ea3232-5c2e-482f-92b6-1626aaf18c93.png#averageHue=%23faf7f5&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u38eacc3b&amp;name=image.png&amp;originHeight=731&amp;originWidth=872&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=155543&amp;status=done&amp;style=none&amp;taskId=udc6dd46e-62b6-40b2-8ed6-528d68a7295&amp;title=" alt="image.png"><br>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。<br>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。<br>当触发了重传机制，也就进入了「拥塞发生算法」。</p></blockquote></li></ul><h4 id="拥塞发生"><a href="#拥塞发生" class="headerlink" title="拥塞发生"></a>拥塞发生</h4><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。<br>发生超时重传的拥塞发生算法<br>当发生了「超时重传」，则就会使用拥塞发生算法。<br>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li>ssthresh 设为 cwnd/2，</li><li>cwnd 重置为 1</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958540605-a981dafe-8f02-4b78-a070-f03a8d88899f.png#averageHue=%23f8f4f2&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0a98e41e&amp;name=image.png&amp;originHeight=873&amp;originWidth=1142&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=300269&amp;status=done&amp;style=none&amp;taskId=u2f938585-10b9-4e0d-9ae1-9e4dc47626e&amp;title=" alt="image.png"><br>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。<br>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。<br>发生快速重传的拥塞发生算法<br>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。<br>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下：</p><ul><li>cwnd = cwnd/2 ，也就是设置为原来的一半;</li><li>ssthresh = cwnd;</li><li><p>进入快速恢复算法</p><h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。<br>正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了：</p></li><li><p>cwnd = cwnd/2 ，也就是设置为原来的一半;</p></li><li>ssthresh = cwnd;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958540855-065f61d5-415d-454e-8989-43d9d8afb68a.png#averageHue=%23f7f3ef&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u193042c6&amp;name=image.png&amp;originHeight=873&amp;originWidth=1352&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=402224&amp;status=done&amp;style=none&amp;taskId=ue9a0f455-ce3e-4fbd-849f-e298d1f96ef&amp;title=" alt="image.png"><br>也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。</p><h4 id="拥塞算法示意图"><a href="#拥塞算法示意图" class="headerlink" title="拥塞算法示意图"></a>拥塞算法示意图</h4><p>好了，以上就是拥塞控制的全部内容了，看完后，你再来看下面这张图片，每个过程我相信你都能明白：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1652958555844-b622614b-6770-4192-badb-2759ecd736bb.png#averageHue=%23eef2f4&amp;clientId=uec7e2579-b299-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ude0e0a12&amp;name=image.png&amp;originHeight=407&amp;originWidth=800&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=221070&amp;status=done&amp;style=none&amp;taskId=u5f0d00fd-33d6-41ab-8e7a-a193068812b&amp;title=" alt="image.png"></p><h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><p>防止过多的数据注入到网络中。 几种拥塞控制方法：慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )</p><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。<strong>这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。</strong></p><h2 id="👌三、-如何优化-TCP"><a href="#👌三、-如何优化-TCP" class="headerlink" title="👌三、 如何优化 TCP?"></a>👌三、 如何优化 TCP?</h2><p>接下来，将以三个角度来阐述提升 TCP 的策略，分别是：</p><ul><li>TCP 三次握手的性能提升；</li><li>TCP 四次挥手的性能提升；</li><li>TCP 数据传输的性能提升；</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440631557-87acfd52-9012-474a-8272-beec928afc44.png#averageHue=%23f0f0f4&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u64ad6a5c&amp;name=image.png&amp;originHeight=918&amp;originWidth=1252&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=181348&amp;status=done&amp;style=none&amp;taskId=u33e03978-ec21-4a55-b56f-4b10b2b6099&amp;title=" alt="image.png"></p><hr><h3 id="ⅠTCP-三次握手的性能提升"><a href="#ⅠTCP-三次握手的性能提升" class="headerlink" title="ⅠTCP 三次握手的性能提升"></a>ⅠTCP 三次握手的性能提升</h3><p>详细内容TCP 是面向连接的、可靠的、双向传输的传输层通信协议，所以在传输数据之前需要经过三次握手才能建立连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440649297-4905ebf5-a8f4-4b6e-892d-3d5e2d81e83d.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=FoWWF&amp;name=image.png&amp;originHeight=549&amp;originWidth=437&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=47577&amp;status=done&amp;style=none&amp;taskId=ua6f33fcb-95eb-4af1-8d7a-bb1e01f6a82&amp;title=" alt="image.png"><br>那么，三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。<br>如何正确有效的使用这些参数，来提高 TCP 三次握手的性能，这就需要理解「三次握手的状态变迁」，这样当出现问题时，先用 netstat 命令查看是哪个握手阶段出现了问题，再来对症下药，而不是病急乱投医。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440649756-0f40d287-6c93-42b5-9991-e4cbf59dc559.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=385&amp;id=uBi04&amp;name=image.png&amp;originHeight=678&amp;originWidth=813&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=80594&amp;status=done&amp;style=none&amp;taskId=ua51783bd-55f9-43a6-b5c1-bae2421f608&amp;title=&amp;width=462" alt="image.png"><br>客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。<br>所以，客户端（主动发起连接方）和服务端（被动连接方）优化的方式是不同的，接下来分别针对客户端和服务端优化。</p><h4 id="①-客户端优化"><a href="#①-客户端优化" class="headerlink" title="① 客户端优化"></a>① 客户端优化</h4><p>三次握手建立连接的首要目的是「同步序列号」。<br>只有同步了序列号才有可靠传输，TCP 许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握手中的报文称为 SYN 的原因，SYN 的全称就叫 <em>Synchronize Sequence Numbers</em>（同步序列号）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440650111-2132b1f1-ea62-4347-8d21-2ec14ca7b062.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=309&amp;id=unPkY&amp;name=image.png&amp;originHeight=618&amp;originWidth=1053&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=82874&amp;status=done&amp;style=none&amp;taskId=u14ec8c77-f7ef-40e8-ae8c-22de1107e10&amp;title=&amp;width=526" alt="image.png">注意有个窗口大小字段<br>SYN_SENT 状态的优化<br>客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 SYN_SENT 状态。<br>客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包，<strong>重发的次数由 tcp_syn_retries 参数控制</strong>，默认是 5 次：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440653170-77a01e65-3324-4847-90ad-a2988e3e87f1.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=N6FIk&amp;name=image.png&amp;originHeight=220&amp;originWidth=906&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=33104&amp;status=done&amp;style=none&amp;taskId=u705b6013-e9fd-461c-85ec-4f07618fb23&amp;title=" alt="image.png"></p><blockquote><p>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，<strong>每次超时的时间是上一次的 2 倍</strong>。<br>当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就会终止三次握手。<br>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。<br>你可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。</p></blockquote><h4 id="②服务端优化"><a href="#②服务端优化" class="headerlink" title="②服务端优化"></a>②服务端优化</h4><p>当服务端收到 SYN 包后，服务端会立马回复 SYN+ACK 包，表明确认收到了客户端的序列号，同时也把自己的序列号发给对方。<br>此时，服务端出现了新连接，状态是 SYN_RCV。在这个状态下，Linux 内核就会建立一个「半连接队列」来维护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。</p><p>SYN 攻击，攻击的是就是这个半连接队列。<br>SYN_RCV 状态的优化<br>当客户端接收到服务器发来的 SYN+ACK 报文后，就会回复 ACK 给服务器，同时客户端连接状态从 SYN_SENT 转换为 ESTABLISHED，表示连接建立成功。<br>服务器端连接成功建立的时间还要再往后，等到服务端收到客户端的 ACK 后，服务端的连接状态才变为 ESTABLISHED。<br>如果服务器没有收到 ACK，就会重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态。<br>当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。<strong>修改重发次数的方法是，调整 tcp_synack_retries 参数</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440657280-95c61acb-7d1d-4b7f-8fe4-44b104f9e245.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Cem3R&amp;name=image.png&amp;originHeight=220&amp;originWidth=1024&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=36005&amp;status=done&amp;style=none&amp;taskId=u2a8eb744-77aa-4e5d-a73a-ee8ff15cb3a&amp;title=" alt="image.png"><br>tcp_synack_retries 的默认重试次数是 5 次，与客户端重传 SYN 类似，它的重传会经历 1、2、4、8、16 秒，最后一次重传后会继续等待 32 秒，如果服务端仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒。<br>服务器收到 ACK 后连接建立成功，此时，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。<br>如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440659605-b772ea71-bb37-4b94-ae59-26ad27cd6919.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=251&amp;id=jB77J&amp;name=image.png&amp;originHeight=347&amp;originWidth=839&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=41009&amp;status=done&amp;style=none&amp;taskId=uc804d5b2-1c32-4159-80e5-459c411234b&amp;title=&amp;width=606" alt="image.png"></p><h4 id="③如何绕过三次握手？"><a href="#③如何绕过三次握手？" class="headerlink" title="③如何绕过三次握手？"></a>③如何绕过三次握手？</h4><p>以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。<br>三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440663552-3c4b67f2-ec7e-45ce-bb55-6574f3799d78.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=458&amp;id=KMMQk&amp;name=image.png&amp;originHeight=647&amp;originWidth=518&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=47874&amp;status=done&amp;style=none&amp;taskId=ufb8d9a25-5e56-4ece-9204-de8d56fcc2a&amp;title=&amp;width=367" alt="image.png"><br>在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。<br>接下来说说，TCP Fast Open 功能的工作方式。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440664659-e0a1c15d-8c37-4278-93d2-a4b03e33abe0.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=805&amp;id=WuPGy&amp;name=image.png&amp;originHeight=1037&amp;originWidth=626&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=78372&amp;status=done&amp;style=none&amp;taskId=u18afab56-85d7-4d5d-91b0-ff47645b6c9&amp;title=&amp;width=486" alt="image.png"><br>在客户端首次建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</li><li>支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；</li><li>客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</li></ol><p>所以，第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。<br>之后，如果客户端再次向服务器建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含「数据」以及此前记录的 Cookie；</li><li>支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</li><li>如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，<strong>这就减少了握手带来的 1 个 RTT 的时间消耗</strong>；</li><li>客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；</li></ol><p>所以，之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗。</p><p>注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）。<br>Linux 下怎么打开 TCP Fast Open 功能呢？<br>在 Linux 系统中，可以通过<strong>设置 tcp_fastopn 内核参数，来打开 Fast Open 功能</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440665977-ae3f15bf-6e70-4ee1-85d7-043af9836c87.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=l7aP6&amp;name=image.png&amp;originHeight=220&amp;originWidth=854&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32216&amp;status=done&amp;style=none&amp;taskId=u617311f9-0626-41ee-8ba5-7e301807d4f&amp;title=" alt="image.png"><br>tcp_fastopn 各个值的意义:</p><ul><li>0 关闭</li><li>1 作为客户端使用 Fast Open 功能</li><li>2 作为服务端使用 Fast Open 功能</li><li>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</li></ul><p><strong>TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。</strong></p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440667875-7bdf3353-dbf0-4ea4-a2c4-081d57c50981.png#averageHue=%2373736e&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7c87dab0&amp;name=image.png&amp;originHeight=632&amp;originWidth=1037&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=102346&amp;status=done&amp;style=none&amp;taskId=u4e6954f9-c5dc-434b-b8ca-e30c04ffa76&amp;title=" alt="image.png"></p><h4 id="客户端的优化"><a href="#客户端的优化" class="headerlink" title="客户端的优化"></a>客户端的优化</h4><p>当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。</p><h4 id="服务端的优化"><a href="#服务端的优化" class="headerlink" title="服务端的优化"></a>服务端的优化</h4><ul><li><p>如果 SYN 半连接队列溢出情况比较严重,可以调整 SYN 半连接队列的大小。</p><blockquote><p>当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 netstat -s 观察半连接队列溢出的情况，如果 SYN 半连接队列溢出情况比较严重，可以通过 tcp_max_syn_backlog、somaxconn、backlog 参数来调整 SYN 半连接队列的大小</p></blockquote></li><li><p>服务端回复 SYN+ACK 的重传次数由 tcp_synack_retries 参数控制。如果遭受 SYN 攻击，应把 tcp_syncookies 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。</p></li><li>服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。可以通过 ss -lnt 查看服务端进程的 accept 队列长度，如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 tcp_abort_on_overflow 设置为 1 ，表示用 RST 通知客户端连接建立失败。</li><li>如果 accpet 队列溢出严重，可以通过 listen 函数的 backlog 参数和 somaxconn 系统参数提高队列大小，accept 队列长度取决于 min(backlog, somaxconn)。<h4 id="绕过三次握手"><a href="#绕过三次握手" class="headerlink" title="绕过三次握手"></a>绕过三次握手</h4>TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 tcp_fastopen 开启该功能，同时必须保证服务端和客户端同时支持。</li></ul><hr><h3 id="ⅡTCP-四次挥手的性能提升"><a href="#ⅡTCP-四次挥手的性能提升" class="headerlink" title="ⅡTCP 四次挥手的性能提升"></a>ⅡTCP 四次挥手的性能提升</h3><p>详细内容#### ①主动方的优化<br>关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。<br>如果进程异常退出了，内核就会发送 RST 报文来关闭，它可以不走四次挥手流程，是一个暴力关闭连接的方式。<br>安全关闭连接的方式必须通过四次挥手，它由进程调用 close 和 shutdown 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。<br>调用 close 函数和 shutdown 函数有什么区别？<br>调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong><br>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 shutdown 函数，<strong>它可以控制只关闭一个方向的连接</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440669015-2dabc965-06b1-4528-9106-08084be3fc8d.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=141&amp;id=UAJBy&amp;name=image.png&amp;originHeight=184&amp;originWidth=650&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=13898&amp;status=done&amp;style=none&amp;taskId=u8075ff1d-1841-4531-8f78-fd2414d3805&amp;title=&amp;width=497" alt="image.png"></p><blockquote><p>第二个参数决定断开连接的方式，主要有以下三种方式：</p><ul><li>SHUT_RD(0)：<strong>关闭连接的「读」这个方向（还能发送数据）</strong>，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。断开输入流。套接字无法接收数据（即使输入缓冲区收到数据也被抹去），无法调用输入相关函数。</li><li>SHUT_WR(1)：<strong>关闭连接的「写」这个方向（还能接收数据）</strong>，这就是常被称为<strong>「半关闭」的连接</strong>。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端。断开输出流。套接字无法发送数据，但如果输出缓冲区中还有未传输的数据，则将传递到目标主机。</li><li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，<strong>关闭套接字的读和写两个方向</strong>。同时断开 I/O 流。相当于分两次调用 shutdown()，其中一次以 SHUT_RD 为参数，另一次以 SHUT_WR 为参数。</li></ul><p>close 和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数也不相同。</p></blockquote><h5 id="FIN-WAIT1-状态的优化"><a href="#FIN-WAIT1-状态的优化" class="headerlink" title="FIN_WAIT1 状态的优化"></a>FIN_WAIT1 状态的优化</h5><p>主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变为 FIN_WAIT2 状态。<br>但是当迟迟收不到对方返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，<strong>内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制</strong>（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0。</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440670517-22d31415-7230-4924-b9da-a7d5bfd6f37e.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=mNnHj&amp;name=image.png&amp;originHeight=220&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=33122&amp;status=done&amp;style=none&amp;taskId=u83aeb9e2-ea74-4336-98de-f4c4cdb954f&amp;title=" alt="image.png"><br>你可能会好奇，这 0 表示几次？<strong>实际上当为 0 时，特指 8 次</strong>，从下面的内核源码可知：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440672762-09a29499-ed3a-4a3f-ba7d-a0401044f7ee.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=360&amp;id=r4h03&amp;name=image.png&amp;originHeight=724&amp;originWidth=1306&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=124629&amp;status=done&amp;style=none&amp;taskId=u41b2228a-e6d0-489c-9346-34f615c1c45&amp;title=&amp;width=650" alt="image.png"><br>如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。<br>对于普遍正常情况时，调低 tcp_orphan_retries 就已经可以了。如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：</p><ul><li>首先，TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文也不能提前发送。</li><li>其次，TCP 有流量控制功能，当接收方接收窗口为 0 时，发送方就不能再发送数据。所以，当攻击者下载大文件时，就可以通过接收窗口设为 0 ，这就会使得 FIN 报文都无法发送出去，那么连接会一直处于 FIN_WAIT1 状态。</li></ul><p>解决这种问题的方法，是<strong>调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440673347-03f098a7-7582-41b5-b16c-1514dfa18bdd.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=tMsBr&amp;name=image.png&amp;originHeight=220&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28433&amp;status=done&amp;style=none&amp;taskId=u8a8a8fc8-6f64-4256-8c48-8c95532a6a9&amp;title=" alt="image.png"><br>当进程调用了 close 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法再发送和接收数据。Linux 系统为了防止孤儿连接过多，导致系统资源长时间被占用，就提供了 tcp_max_orphans 参数。如果孤儿连接数量大于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。</p></blockquote><h5 id="FIN-WAIT2-状态的优化"><a href="#FIN-WAIT2-状态的优化" class="headerlink" title="FIN_WAIT2 状态的优化"></a>FIN_WAIT2 状态的优化</h5><p>当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。<br>这时，<strong>如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长</strong>，默认值是 60 秒：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440674038-c12e9703-f389-40f8-bc8a-fd2c1987f308.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=hB7Qn&amp;name=image.png&amp;originHeight=220&amp;originWidth=852&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=33472&amp;status=done&amp;style=none&amp;taskId=u9435aae6-172f-4b21-8edb-af188384906&amp;title=" alt="image.png"><br>它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。<br>这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的，后面我们再来说说为什么是 60 秒。</p><h5 id="TIME-WAIT-状态的优化"><a href="#TIME-WAIT-状态的优化" class="headerlink" title="TIME_WAIT 状态的优化"></a>TIME_WAIT 状态的优化</h5><p>TIME_WAIT 是主动方四次挥手的最后一个状态，也是最常遇见的状态。<br>当收到被动方发来的 FIN 报文后，主动方会立刻回复 ACK，表示确认对方的发送通道已经关闭，接着就处于 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。<br>TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p><p>但是你可能会说重新发送的 ACK 还是有可能丢失啊，没错，但 TCP 已经等待了那么长的时间了，已经算仁至义尽了。<br><strong>我们再回过头来看看，为什么 TIME_WAIT 状态要保持 60 秒呢？</strong><br>这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的原理是一样的，<strong>因为这两个状态都需要保持 2MSL 时长。MSL 全称是 Maximum Segment Lifetime，它定义了一个报文在网络中的最长生存时间</strong>（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。<br><strong>为什么是 2 MSL 的时长呢？</strong><br>这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。<br>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。<br><strong>因此，TIME_WAIT 和 FIN_WAIT2 状态的最大时长都是 2 MSL，由于在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。</strong></p><h4 id="②-被动方的优化"><a href="#②-被动方的优化" class="headerlink" title="② 被动方的优化"></a>② 被动方的优化</h4><p>被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。<br>当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 tcp_orphan_retries 参数的控制下重发 FIN 报文。</p><h5 id="如果连接双方同时关闭连接，会怎么样？"><a href="#如果连接双方同时关闭连接，会怎么样？" class="headerlink" title="如果连接双方同时关闭连接，会怎么样？"></a>如果连接双方同时关闭连接，会怎么样？</h5><p>由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。<br>此时，上面介绍的优化策略仍然适用。两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440677633-c5353360-1a7d-474b-b871-96bf210b9f1d.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=571&amp;id=dqm1i&amp;name=image.png&amp;originHeight=783&amp;originWidth=768&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=97819&amp;status=done&amp;style=none&amp;taskId=u81029070-8d78-4f10-88ed-0536124aef0&amp;title=&amp;width=560" alt="image.png"><br>接下来，<strong>双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态</strong>。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。<br>针对 TCP 四次挥手的优化，我们需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440677679-593cd333-6af5-4be9-8070-b71aa0ba0697.png#averageHue=%23f6e6d1&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=365&amp;id=u2442377d&amp;name=image.png&amp;originHeight=632&amp;originWidth=1037&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=124922&amp;status=done&amp;style=none&amp;taskId=u58e86060-9f19-40ba-9af1-ffce17e5bda&amp;title=&amp;width=599" alt="image.png"></p><h4 id="主动方的优化"><a href="#主动方的优化" class="headerlink" title="主动方的优化"></a>主动方的优化</h4><ul><li>主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 tcp_orphan_retries 参数决定。</li><li>当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：<ul><li>如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 tcp_fin_timeout 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，tcp_max_orphans 定义了最大孤儿连接的数量，超过时连接就会直接释放。</li><li>反之是 shutdown 函数关闭的连接，则不受此参数限制；</li></ul></li><li>当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，tcp_max_tw_buckets 定义了最大数量，超过时连接也会直接释放。</li><li>当 TIME_WAIT 状态过多时，还可以通过设置 tcp_tw_reuse 和 tcp_timestamps 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。<h4 id="被动方的优化"><a href="#被动方的优化" class="headerlink" title="被动方的优化"></a>被动方的优化</h4>被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。<br>当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 tcp_orphan_retries 参数的控制下重发 FIN 报文。</li></ul><hr><h3 id="ⅢTCP-传输数据的性能提升（了解即可）"><a href="#ⅢTCP-传输数据的性能提升（了解即可）" class="headerlink" title="ⅢTCP 传输数据的性能提升（了解即可）"></a>ⅢTCP 传输数据的性能提升（了解即可）</h3><p>了解在前面介绍的是三次握手和四次挥手的优化策略，接下来主要介绍的是 TCP 传输数据时的优化策略。<br>TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：</p><ul><li>如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；</li><li>如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；</li></ul><p>因此，我们必须理解 Linux 下 TCP 内存的用途，才能正确地配置内存大小。</p><h4 id="滑动窗口是如何影响传输速度的？"><a href="#滑动窗口是如何影响传输速度的？" class="headerlink" title="滑动窗口是如何影响传输速度的？"></a>滑动窗口是如何影响传输速度的？</h4><p>TCP 会保证每一个报文都能够抵达对方，它的机制是这样：报文发出去后，必须接收到对方返回的确认报文 ACK，如果迟迟未收到，就会超时重发该报文，直到收到对方的 ACK 为止。<br><strong>所以，TCP 报文发出去后，并不会立马从内存中删除，因为重传时还需要用到它。</strong><br>由于 TCP 是内核维护的，所以报文存放在内核缓冲区。如果连接非常多，我们可以通过 free 命令观察到 buff/cache 内存是会增大。<br>如果 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句，但这种方式的缺点是效率比较低的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440679360-cff4d50e-f0c7-4cfb-9cab-1d609ec18153.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=445&amp;id=JRpXs&amp;name=image.png&amp;originHeight=617&amp;originWidth=498&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48380&amp;status=done&amp;style=none&amp;taskId=ua426eced-8268-4ec2-bcd5-8ee5adae903&amp;title=&amp;width=359" alt="image.png"><br>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。<br><strong>要解决这一问题不难，并行批量发送报文，再批量确认报文即可。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440679910-75fbcc47-0e32-4099-95da-3d24b42b7a4e.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=404&amp;id=Cwo0Q&amp;name=image.png&amp;originHeight=602&amp;originWidth=857&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=78580&amp;status=done&amp;style=none&amp;taskId=u5d1b7e84-c242-4d21-b77b-607f3a0a173&amp;title=&amp;width=575" alt="image.png"><br>然而，这引出了另一个问题，发送方可以随心所欲的发送报文吗？<strong>当然这不现实，我们还得考虑接收方的处理能力。</strong><br>当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。<br><strong>为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来。</strong><br>接收方根据它的缓冲区，可以计算出后续能够接收多少字节的报文，这个数字叫做接收窗口。当内核接收到报文时，必须用缓冲区存放它们，这样剩余缓冲区空间变小，接收窗口也就变小了；当进程调用 read 函数后，数据被读入了用户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报文，接收窗口就会变大。<br>因此，接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的<strong>窗口字段</strong>，这样就可以起到窗口大小通知的作用。<br>发送方的窗口等价于接收方的窗口吗？如果不考虑拥塞控制，发送方的窗口大小「约等于」接收方的窗口大小，因为窗口通知报文在网络传输是存在时延的，所以是约等于的关系。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440679801-6e4d20c1-1d9d-466b-ae19-c64247a696a3.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=347&amp;id=WEqYn&amp;name=image.png&amp;originHeight=618&amp;originWidth=1053&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=80899&amp;status=done&amp;style=none&amp;taskId=u3e40ecbf-f614-46d6-8a60-32fdb5d75a8&amp;title=&amp;width=592" alt="image.png"><br>从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。</p><blockquote><p>这个窗口大小最大值，在当今高速网络下，很明显是不够用的。所以后续有了扩充窗口的方法：<strong>在 TCP 选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440679963-0fd93f73-b9a7-4d75-99ee-764d0d682397.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=453&amp;id=foRpn&amp;name=image.png&amp;originHeight=933&amp;originWidth=1263&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=205106&amp;status=done&amp;style=none&amp;taskId=u405f0134-1e0b-40a6-bb4f-031a87b3f44&amp;title=&amp;width=613" alt="image.png"><br>Linux 中打开这一功能，需要把 tcp_window_scaling 配置设为 1（默认打开）：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440679850-efdb89fd-14e0-4a39-a482-7a9935f21049.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=EFKez&amp;name=image.png&amp;originHeight=220&amp;originWidth=902&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28335&amp;status=done&amp;style=none&amp;taskId=u6d8e99ce-4972-4a54-88cf-7eea8ac2912&amp;title=" alt="image.png"><br>要使用窗口扩大选项，通讯双方必须在各自的 SYN 报文中发送这个选项：</p><ul><li>主动建立连接的一方在 SYN 报文中发送这个选项；</li><li>而被动建立连接的一方只有在收到带窗口扩大选项的 SYN 报文之后才能发送这个选项。</li></ul><p>这样看来，只要进程能及时地调用 read 函数读取数据，并且接收缓冲区配置得足够大，那么接收窗口就可以无限地放大，发送方也就无限地提升发送速度。<br><strong>这是不可能的，因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。</strong></p></blockquote><h4 id="如何确定最大传输速度？"><a href="#如何确定最大传输速度？" class="headerlink" title="如何确定最大传输速度？"></a>如何确定最大传输速度？</h4><p>在前面我们知道了 TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力。其中，窗口大小由内核缓冲区大小决定。如果缓冲区与网络传输能力匹配，那么缓冲区的利用率就达到了最大化。<br><strong>问题来了，如何计算网络的传输能力呢？</strong><br>相信大家都知道网络是有「带宽」限制的，带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:</p><ul><li>带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；</li><li>缓冲区单位是字节，当网络速度乘以时间才能得到字节数；</li></ul><p>这里需要说一个概念，就是带宽时延积，它决定网络中飞行报文的大小，它的计算方式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440681659-1a6dcf93-f2aa-4db0-93ca-9cbe14155307.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=lkKFl&amp;name=image.png&amp;originHeight=93&amp;originWidth=498&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=7949&amp;status=done&amp;style=none&amp;taskId=u04239cba-d058-46c6-a361-fc28d3c5d87&amp;title=" alt="image.png"><br>比如最大带宽是 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s <em> 0.01s = 1MB 的字节。<br>这个 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为 BDP，Bandwidth Delay Product）。同时，这 1MB 也表示「飞行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1 MB，就会导致网络过载，容易丢包。<br><em>*由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。</em></em><br>发送缓冲区与带宽时延积的关系：</p><ul><li>如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；</li><li>如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。</li></ul><p>所以，发送缓冲区的大小最好是往带宽时延积靠近。</p><h4 id="怎样调整缓冲区大小？"><a href="#怎样调整缓冲区大小？" class="headerlink" title="怎样调整缓冲区大小？"></a>怎样调整缓冲区大小？</h4><p>在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行<strong>动态调节</strong>。<br>调节发送缓冲区范围<br>先来看看发送缓冲区，它的范围通过 tcp_wmem 参数配置；<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440681844-5af2aaee-01f4-4aaa-8718-fd8373d5fc0d.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Zf9Nm&amp;name=image.png&amp;originHeight=220&amp;originWidth=1054&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32288&amp;status=done&amp;style=none&amp;taskId=udcf984eb-635b-42cf-abb2-435c6637bb8&amp;title=" alt="image.png"><br>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，4096 byte = 4K；</li><li>第二个数值是初始默认值，87380 byte ≈ 86K；</li><li>第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；</li></ul><p><strong>发送缓冲区是自行调节的</strong>，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。<br>调节接收缓冲区范围<br>而接收缓冲区的调整就比较复杂一些，先来看看设置接收缓冲区范围的 tcp_rmem 参数：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440681867-a0130191-df9a-483b-bfea-8fa1fbe48125.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=Mr2wy&amp;name=image.png&amp;originHeight=220&amp;originWidth=1054&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=32644&amp;status=done&amp;style=none&amp;taskId=u8abe2d20-d45d-40df-a55a-7a77e768649&amp;title=" alt="image.png"><br>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4096 byte = 4K；</li><li>第二个数值是初始默认值，87380 byte ≈ 86K；</li><li>第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；</li></ul><p><strong>接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：</strong></p><ul><li>如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；</li><li>反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；</li></ul><p>发送缓冲区的调节功能是自动开启的，<strong>而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440681880-60d0f4de-c3f9-47e8-ad30-8f9cbef278c0.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=UhnAC&amp;name=image.png&amp;originHeight=220&amp;originWidth=918&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=29278&amp;status=done&amp;style=none&amp;taskId=ue6e3707a-9d7d-49ca-81aa-6e77a2149c7&amp;title=" alt="image.png"><br>调节 TCP 内存范围<br>接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440682029-5fea369c-543d-4ec0-94b7-9a603c4e579c.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=WcWW0&amp;name=image.png&amp;originHeight=220&amp;originWidth=1054&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28161&amp;status=done&amp;style=none&amp;taskId=u8badf4ab-1196-410e-a3b2-d18e097606d&amp;title=" alt="image.png"><br>上面三个数字单位不是字节，而是「页面大小」，1 页表示 4KB，它们分别表示：</p><ul><li>当 TCP 内存小于第 1 个值时，不需要进行自动调节；</li><li>在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；</li><li>大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；</li></ul><p>一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 tcp_mem 最大内存页面数是 177120，当内存为 (177120 <em> 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP 连接分配内存，即 TCP 连接将被拒绝。<br>根据实际场景调节的策略<br>在高并发服务器中，为了兼顾网速与大量的并发连接，<strong>我们应当保证缓冲区的动态调整的最大值达到带宽时延积，而最小值保持默认的 4K 不变即可。而对于内存紧张的服务而言，调低默认值是提高并发的有效手段。</strong><br>同时，如果这是网络 IO 型服务器，那么，<strong>调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存，这有利于提升并发能力</strong>。需要注意的是，tcp_wmem 和 tcp_rmem 的单位是字节，而 tcp_mem 的单位是页面大小。而且，<em>*千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF，这样会关闭缓冲区的动态调整功能。</em></em></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_optimize.html#%E5%B0%8F%E7%BB%93-3"></a>小结</h3><p>本节针对 TCP 优化数据传输的方式，做了一些介绍。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650440683345-8ffc2ef0-26d6-4c28-a800-1f0e2e78302d.png#clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=KXVCh&amp;name=image.png&amp;originHeight=632&amp;originWidth=1037&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=94340&amp;status=done&amp;style=none&amp;taskId=u44fe419b-bc5f-4160-8507-04e94ef1a75&amp;title=" alt="image.png"><br>TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。<br>可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 tcp_window_scaling 为 1 做到的，此时最大值可高达 1GB。<br>滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。<br>内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。<br>Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。<br>但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。<br>有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。</p><h2 id="四、如何理解是-TCP-面向字节流协议？"><a href="#四、如何理解是-TCP-面向字节流协议？" class="headerlink" title="四、如何理解是 TCP 面向字节流协议？"></a>四、如何理解是 TCP 面向字节流协议？</h2><p>TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的「面向字节流」和「面向报文」该如何理解。</p><hr><h3 id="①如何理解字节流？"><a href="#①如何理解字节流？" class="headerlink" title="①如何理解字节流？"></a>①如何理解字节流？</h3><p>之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的<strong>发送方的机制不同</strong>，也就是问题原因在发送方。<br>先来说说为什么 UDP 是面向报文的协议？<br>当用户消息通过 UDP 协议传输时，<strong>操作系统不会对消息进行拆分</strong>，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是<strong>每个 UDP 报文就是一个用户消息的边界</strong>，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。<br>你可能会问，如果收到了两个 UDP 报文，操作系统是怎么区分开的？<br>操作系统在收到 UDP 报文后，会将其插入到<strong>队列</strong>里，<strong>队列里的每一个元素就是一个 UDP 报文</strong>，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442588335-4b187682-f339-4ce3-a51f-bfa0a7d5b331.png#averageHue=%23f4f4f4&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=249&amp;id=u1f673a1e&amp;name=image.png&amp;originHeight=302&amp;originWidth=782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=35439&amp;status=done&amp;style=none&amp;taskId=u71daa150-07dc-4474-8982-ced7e22fc6c&amp;title=&amp;width=646" alt="image.png"><br>再来说说为什么 TCP 是面向字节流的协议？<br>当用户消息通过 TCP 协议传输时，<strong>消息可能会被操作系统分组成多个的 TCP 报文</strong>，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。<br>这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。<br><strong>举个实际的例子来说明。</strong><br>发送方准备发送 「Hi.」和「I am Xiaolin」这两个消息。<br>在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。<br>至于什么时候真正被发送，<strong>取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件</strong>。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去。</p><blockquote><p>如果我们考虑实际网络传输过程中的各种影响，假设发送端陆续调用 send 函数先后发送 「Hi.」和「I am Xiaolin」 报文，那么实际的发送很有可能是这几种情况。<br>第一种情况，这两个消息被分到同一个 TCP 报文，像这样：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442588321-3d60f8cb-df8c-45a6-99ea-25994cabf5f8.png#averageHue=%23f3efe7&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u15fc8c4d&amp;name=image.png&amp;originHeight=189&amp;originWidth=356&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=8808&amp;status=done&amp;style=none&amp;taskId=u9d7c346b-599e-4cff-adda-4a83455693d&amp;title=" alt="image.png"><br>第二种情况，「I am Xiaolin」的部分随 「Hi」 在一个 TCP 报文中发送出去，像这样：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442588349-8ec989e5-e066-4ccb-b6c5-ee3529ac5416.png#averageHue=%23faedc5&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u6cf97aac&amp;name=image.png&amp;originHeight=152&amp;originWidth=407&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=10710&amp;status=done&amp;style=none&amp;taskId=u31e39d32-3764-4eb2-a9d2-1f33446245a&amp;title=" alt="image.png"><br>第三种情况，「Hi.」 的一部分随 TCP 报文被发送出去，另一部分和 「I am Xiaolin」 一起随另一个 TCP 报文发送出去，像这样。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442588260-963d71b8-4d13-4f98-be2f-ff1c23e31320.png#averageHue=%23fceec7&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ufc2e71e8&amp;name=image.png&amp;originHeight=152&amp;originWidth=437&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=10747&amp;status=done&amp;style=none&amp;taskId=ua50f524e-0933-4c21-926c-45c43821625&amp;title=" alt="image.png"><br>类似的情况还能举例很多种，这里主要是想说明，我们不知道 「Hi.」和 「I am Xiaolin」 这两个用户消息是如何进行 TCP 分组传输的。</p></blockquote><p>因此，<strong>我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议</strong>。<br>当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。<br>要解决这个问题，要交给<strong>应用程序</strong>。<br>如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP就会将其拆分为多次发送，这就是拆包，也就是将一个大的包拆分为多个小包进行发送。</p><h3 id="②如何解决粘包？"><a href="#②如何解决粘包？" class="headerlink" title="②如何解决粘包？"></a>②如何解决粘包？</h3><p>粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。<br>一般有三种方式分包的方式：</p><ul><li>固定长度的消息；</li><li>特殊字符作为边界；</li><li>自定义消息结构。<h4 id="固定长度的消息"><a href="#固定长度的消息" class="headerlink" title="固定长度的消息"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_stream.html#%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84%E6%B6%88%E6%81%AF"></a>固定长度的消息</h4>这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。<br>但是这种方式灵活性不高，实际中很少用。<h4 id="特殊字符作为边界"><a href="#特殊字符作为边界" class="headerlink" title="特殊字符作为边界"></a>特殊字符作为边界</h4>我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。<blockquote><p>HTTP 是一个非常好的例子。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442588354-acfc11f2-a671-43ae-b209-7561244ed8bf.png#averageHue=%23e3e2e2&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u48e7327e&amp;name=image.png&amp;originHeight=324&amp;originWidth=942&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=50889&amp;status=done&amp;style=none&amp;taskId=u19ab7612-2454-4965-aa30-fb054274588&amp;title=" alt="image.png"><br>HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。<br>有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。</p></blockquote></li></ul><h4 id="自定义消息结构"><a href="#自定义消息结构" class="headerlink" title="自定义消息结构"></a>自定义消息结构</h4><p>我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。</p><blockquote><p>比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650442666065-a81a450a-2d6f-4658-9a53-df9b5a15efe4.png#averageHue=%23282c35&amp;clientId=u8538f3f6-82e5-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=120&amp;id=u010f26c1&amp;name=image.png&amp;originHeight=150&amp;originWidth=916&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6501&amp;status=done&amp;style=none&amp;taskId=u5a739f0a-04a7-40c2-ab71-973cab08195&amp;title=&amp;width=732.8" alt="image.png"><br>当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。</p></blockquote><h2 id="五、SYN-报文什么时候情况下会被丢弃？"><a href="#五、SYN-报文什么时候情况下会被丢弃？" class="headerlink" title="五、SYN 报文什么时候情况下会被丢弃？"></a>五、SYN 报文什么时候情况下会被丢弃？</h2><p>接下来，我就给出我遇到过 SYN 报文被丢弃的两种场景：</p><ul><li>开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃</li><li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃<h3 id="坑爹的-tcp-tw-recycle"><a href="#坑爹的-tcp-tw-recycle" class="headerlink" title="坑爹的 tcp_tw_recycle"></a>坑爹的 tcp_tw_recycle</h3><blockquote><p>TCP 四次挥手过程中，主动断开连接方会有一个 TIME_WAIT 的状态，这个状态会持续 2 MSL 后才会转变为 CLOSED 状态。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650590508966-890d77e1-bddc-44f1-b227-13757d819e39.png#averageHue=%23f4e6cd&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=489&amp;id=ufa38debb&amp;name=image.png&amp;originHeight=794&amp;originWidth=753&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=89528&amp;status=done&amp;style=none&amp;taskId=u3bb9a1e8-7557-4d8e-a5e6-a423947d253&amp;title=&amp;width=464" alt="image.png"></p></blockquote></li></ul><blockquote><p>在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768~61000 。<br>那么，如果如果主动断开连接方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。</p></blockquote><p>Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：</p><ul><li>net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，<strong>内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用</strong>，所以该选项只适用于连接发起方。</li><li>net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；</li></ul><p>要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1)）。<br><strong>tcp_tw_recycle 在使用了 NAT 的网络下是不安全的！</strong><br>对于服务器来说，如果同时开启了recycle 和 timestamps 选项，则会开启一种称之为「 per-host 的 PAWS 机制」。<br>首先给大家说说什么是 PAWS 机制？<br>tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。<br>正常来说每个 TCP 包都会有自己唯一的 SEQ，出现 TCP 数据包重传的时候会复用 SEQ 号，这样接收方能通过 SEQ 号来判断数据包的唯一性，也能在重复收到某个数据包的时候判断数据是不是重传的。<strong>但是 TCP 这个 SEQ 号是有限的，一共 32 bit，SEQ 开始是递增，溢出之后从 0 开始再次依次递增</strong>。<br>所以当 SEQ 号出现溢出后单纯通过 SEQ 号无法标识数据包的唯一性，某个数据包延迟或因重发而延迟时可能导致连接传递的数据被破坏，比如：</p><blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650590509080-f6dd77c3-2c38-4f1e-807e-4876c7a9de4e.png#averageHue=%23f6f6f4&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=374&amp;id=u999af05d&amp;name=image.png&amp;originHeight=659&amp;originWidth=649&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=123619&amp;status=done&amp;style=none&amp;taskId=u72abcfa0-fed3-4039-b34b-e8179c3f07c&amp;title=&amp;width=368.0000305175781" alt="image.png"><br>上图 A 数据包出现了重传，并在 SEQ 号耗尽再次从 A 递增时，第一次发的 A 数据包延迟到达了 Server，这种情况下如果没有别的机制来保证，Server 会认为延迟到达的 A 数据包是正确的而接收，反而是将正常的第三次发的 SEQ 为 A 的数据包丢弃，造成数据传输错误。<br>PAWS 就是为了避免这个问题而产生的，在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时的时间戳，PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。<br>对于上面图中的例子有了 PAWS 机制就能做到在收到 Delay 到达的 A 号数据包时，识别出它是个过期的数据包而将其丢掉。</p></blockquote><p>那什么是 per-host 的 PAWS 机制呢？</p><ul><li>前面我提到，开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS 机制。<strong>per-host 是对「对端 IP 做 PAWS 检查」</strong>，而非对「IP + 端口」四元组做 PAWS 检查。</li><li>但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</li><li>Per-host PAWS 机制利用TCP option里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值。</li><li>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，<strong>客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包</strong>。</li></ul><p>因此，tcp_tw_recycle 在使用了 NAT 的网络下是存在问题的，如果它是对 TCP 四元组做 PAWS 检查，而不是对「相同的 IP 做 PAWS 检查」，那么就不会存在这个问题了。<br>网上很多博客都说开启 tcp_tw_recycle 参数来优化 TCP，我信你个鬼，糟老头坏的很！<br>tcp_tw_recycle 在 Linux 4.12 版本后，直接取消了这一参数。</p><h3 id="accpet-队列满了"><a href="#accpet-队列满了" class="headerlink" title="accpet 队列满了"></a>accpet 队列满了</h3><blockquote><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accepet 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p></blockquote><h4 id="半连接队列满了"><a href="#半连接队列满了" class="headerlink" title="半连接队列满了"></a>半连接队列满了</h4><p>当服务器造成syn攻击，就有可能导致 <strong>TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃</strong>。<br>但是，<strong>如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包</strong>。<br>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，<br>开启 syncookies 功能<br>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><h4 id="全连接队列满了"><a href="#全连接队列满了" class="headerlink" title="全连接队列满了"></a>全连接队列满了</h4><p><strong>在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650590512348-fe0c7307-9e54-4e7e-b172-5925ae8e7a2b.png#averageHue=%23faf4e7&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ub4127f10&amp;name=image.png&amp;originHeight=347&amp;originWidth=839&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=41446&amp;status=done&amp;style=none&amp;taskId=u8f692144-1f4f-4bae-a66a-0f788016c61&amp;title=" alt="image.png"><br>如果 Recv-Q 的大小超过 Send-Q，就说明发生了 accpet 队列满的情况。<br>要解决这个问题，我们可以：</p><ul><li>调大 accpet 队列的最大长度，调大的方式是通过<strong>调大 backlog 以及 somaxconn 参数。</strong></li><li>检查系统或者代码为什么调用 accept() 不及时；<h2 id="六、已建立连接的TCP，收到SYN会发生什么？"><a href="#六、已建立连接的TCP，收到SYN会发生什么？" class="headerlink" title="六、已建立连接的TCP，收到SYN会发生什么？"></a>六、已建立连接的TCP，收到SYN会发生什么？</h2></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650591094751-7b86406e-ec16-4e99-bff6-34d2e19a1393.png#averageHue=%23e5e5e5&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue3ddb71c&amp;name=image.png&amp;originHeight=348&amp;originWidth=550&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=92287&amp;status=done&amp;style=none&amp;taskId=u17a33188-774d-476a-a60f-a11ad1c3f3f&amp;title=" alt="image.png"><br>大概意思是，一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 establish 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？</p><hr><p>TCP 连接是由「四元组」唯一确认的。<br>然后这个场景中，客户端的IP、服务端IP、目的端口并没有变化，所以这个问题关键要看客户端发送的 SYN 报文中的源端口是否和上一次连接的源端口相同。<br><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong><br>如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。<br><strong>那旧连接里处于 establish 状态的服务端最后会怎么样呢？</strong><br>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。<br>如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。<br><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p><ul><li>如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，也就是处于 establish 状态的服务端收到了这个 SYN 报文。</li><li>处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。</li><li>接着，客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650591094839-bb3fa8a4-dd08-41c4-850a-476be1b5425c.png#averageHue=%23f9f8f8&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=545&amp;id=u04da54ac&amp;name=image.png&amp;originHeight=959&amp;originWidth=950&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=100026&amp;status=done&amp;style=none&amp;taskId=ud3ad0c61-b385-48f6-aa77-693422cda7d&amp;title=&amp;width=540" alt="image.png"></p><h3 id="如何关闭一个-TCP-连接？"><a href="#如何关闭一个-TCP-连接？" class="headerlink" title="如何关闭一个 TCP 连接？"></a>如何关闭一个 TCP 连接？</h3><p>可能大家第一反应是「杀掉进程」不就行了吗？<br>是的，这个是最粗暴的方式，杀掉客户端进程和服务端进程影响的范围会有所不同：</p><ul><li>在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接，这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。</li><li>而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。</li></ul><p>所以，关闭进程的方式并不可取，最好的方式要精细到关闭某一条 TCP 连接。</p><blockquote><p>有的小伙伴可能会说，伪造一个四元组相同的 RST 报文不就行了？<br>这个思路很好，但是不要忘了还有个序列号的问题，你伪造的 RST 报文的序列号一定能被对方接受吗？<br>如果 RST 报文的序列号不能落在对方的滑动窗口内，这个 RST 报文会被对方丢弃的，就达不到关闭的连接的效果。<br>所以，<strong>要伪造一个能关闭 TCP 连接的 RST 报文，必须同时满足「四元组相同」和「序列号正好落在对方的滑动窗口内」这两个条件。</strong><br>直接伪造符合预期的序列号是比较困难，因为如果一个正在传输数据的 TCP 连接，滑动窗口时刻都在变化，因此很难刚好伪造一个刚好落在对方滑动窗口内的序列号的 RST 报文。<br>办法还是有的，</p></blockquote><ul><li><strong>我们可以伪造一个四元组相同的 SYN 报文，来拿到“合法”的序列号！</strong></li><li>如果处于 establish 状态的服务端，收到四元组相同的 SYN 报文后，<strong>会回复一个 Challenge ACK，这个 ACK 报文里的「确认号」，正好是服务端下一次想要接收的序列号，说白了，就是可以通过这一步拿到服务端下一次预期接收的序列号。</strong></li><li><strong>然后用这个确认号作为 RST 报文的序列号，发送给服务端，此时服务端会认为这个 RST 报文里的序列号是合法的，于是就会释放连接！</strong></li></ul><h2 id="七、四次挥手中收到乱序的-FIN-包会如何处理？"><a href="#七、四次挥手中收到乱序的-FIN-包会如何处理？" class="headerlink" title="七、四次挥手中收到乱序的 FIN 包会如何处理？"></a>七、四次挥手中收到乱序的 FIN 包会如何处理？</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650591807398-b20fcc7f-cc54-412c-b457-354ba3534af2.png#averageHue=%23dddddd&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=524&amp;id=u55eaa44b&amp;name=image.png&amp;originHeight=648&amp;originWidth=565&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=263851&amp;status=done&amp;style=none&amp;taskId=u8f0baf51-56f9-430b-afc8-3e15275282f&amp;title=&amp;width=457" alt="image.png"><br>不得不说，鹅厂真的很喜欢问网络问题，而且爱问异常情况下的网络问题，之前也有篇另外一个读者面试鹅厂的网络问题：「<a href="https://blog.csdn.net/qq_34827674/article/details/117922761">被鹅厂面怕了！(opens new window)</a>」。<br><strong>shutdown函数讲解：</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650683980305-c565e298-4173-40cb-91a5-586eb2415369.png#averageHue=%23c7d292&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=132&amp;id=u1309c5c8&amp;name=image.png&amp;originHeight=165&amp;originWidth=220&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=27723&amp;status=done&amp;style=none&amp;taskId=u228e5755-6a3c-4d1e-8f37-3ec4ead80c7&amp;title=&amp;width=176" alt="image.png">关闭写端，还能接收数据，还能读<br>不过这道鹅厂的网络题可能是提问的读者表述有问题，<strong>因为如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个乱序的报文，此时客户端的 TCP 连接并不会从 FIN_WAIT_2 状态转换到 TIME_WAIT 状态</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650591807064-617365e4-bfcc-46a4-b6ad-8105a3067df3.png#averageHue=%23f0d966&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=538&amp;id=u38465454&amp;name=image.png&amp;originHeight=744&amp;originWidth=722&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=174388&amp;status=done&amp;style=none&amp;taskId=uc2b92a90-c7e7-4aa1-a493-8fd0c01aba2&amp;title=&amp;width=522" alt="image.png"><br>因此，我们要关注到点是看「<strong>在 FIN_WAIT_2 状态下，是如何处理收到的乱序到 FIN 报文，然后 TCP 连接又是什么时候才进入到 TIME_WAIT 状态?</strong>」。<br>我这里先直接说结论：<br><strong>在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。</strong><br><strong>等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。</strong><br>我也画了一张图，大家可以结合着图来理解。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650591807569-5368f413-9398-4874-93ab-8cd1fb4010aa.png#averageHue=%23dfcf6b&amp;clientId=ua42bb3c8-7eb4-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=620&amp;id=u4709fc20&amp;name=image.png&amp;originHeight=992&amp;originWidth=722&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=229545&amp;status=done&amp;style=none&amp;taskId=ue763deb2-3d2e-4c86-b48a-18a7fa7d768&amp;title=&amp;width=451" alt="image.png"></p><h2 id="八、在-TIME-WAIT-状态的-TCP-连接，收到-SYN-后会发生什么？"><a href="#八、在-TIME-WAIT-状态的-TCP-连接，收到-SYN-后会发生什么？" class="headerlink" title="八、在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？"></a>八、在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？</h2><p>所以，今天就来讨论下这个问题，「<strong>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</strong>」<br>问题现象如下图，左边是服务端，右边是客户端：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684585510-6251c19d-f24b-4624-af3b-7a741294e2e8.png#averageHue=%23f2dec0&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=523&amp;id=u8aea217c&amp;name=image.png&amp;originHeight=782&amp;originWidth=635&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=153672&amp;status=done&amp;style=none&amp;taskId=u0e0c2bf4-b316-4f43-9973-88030ec62db&amp;title=&amp;width=425" alt="image.png"></p><h3 id="先说结论"><a href="#先说结论" class="headerlink" title="先说结论"></a>先说结论</h3><p>针对这个问题，<strong>关键是要看 SYN 的「序列号和时间戳」是否合法</strong>，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会判断 SYN 的「序列号和时间戳」是否合法，然后根据判断结果的不同做不同的处理。<br>先跟大家说明下， 什么是「合法」的 SYN？</p><ul><li><strong>合法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。</li><li><strong>非法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。</li></ul><p>上面 SYN 合法判断是基于双方都开启了 TCP 时间戳机制的场景，如果双方都没有开启 TCP 时间戳机制，则 SYN 合法判断如下：</p><ul><li><strong>合法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>。</li><li><strong>非法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>。<h4 id="收到合法-SYN"><a href="#收到合法-SYN" class="headerlink" title="收到合法 SYN"></a>收到合法 SYN</h4>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，<strong>就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程</strong>。<blockquote><p>用下图作为例子，双方都启用了 TCP 时间戳机制，<strong>TSval </strong>是发送报文时的时间戳：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684585741-42322cbd-dba4-4ccd-9c48-f25ca920c163.png#averageHue=%23ecca71&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=624&amp;id=uf62766a8&amp;name=image.png&amp;originHeight=1221&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=588433&amp;status=done&amp;style=none&amp;taskId=u1d551341-6ad7-445e-a737-d942f9c5c47&amp;title=&amp;width=552" alt="image.png"><br>上图中，在收到第三次挥手的 FIN 报文时，会记录该报文的 TSval （21），用 ts_recent 变量保存。然后会计算下一次期望收到的序列号，本次例子下一次期望收到的序列号就是 301，用 rcv_nxt 变量保存。<br>处于 TIME_WAIT 状态的连接收到 SYN 后，<strong>因为 SYN 的 seq（400） 大于 rcv_nxt（301），并且 SYN 的 TSval（30） 大于 ts_recent（21），所以是一个「合法的 SYN」，于是就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</strong></p></blockquote></li></ul><h4 id="收到非法的-SYN"><a href="#收到非法的-SYN" class="headerlink" title="收到非法的 SYN"></a>收到非法的 SYN</h4><p>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端</strong>。<br>用下图作为例子，双方都启用了 TCP 时间戳机制，TSval 是发送报文时的时间戳：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684585781-af652337-3900-4ef1-a4aa-29dd77842fd6.png#averageHue=%23f6e6c9&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=606&amp;id=ud5839fe4&amp;name=image.png&amp;originHeight=1106&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=527992&amp;status=done&amp;style=none&amp;taskId=u3158984f-82f6-4398-8459-a9de3b2da8c&amp;title=&amp;width=592" alt="image.png"><br>上图中，在收到第三次挥手的 FIN 报文时，会记录该报文的 TSval （21），用 ts_recent 变量保存。然后会计算下一次期望收到的序列号，本次例子下一次期望收到的序列号就是 301，用 rcv_nxt 变量保存。<br>处于 TIME_WAIT 状态的连接收到 SYN 后，<strong>因为 SYN 的 seq（200） 小于 rcv_nxt（301），所以是一个「非法的 SYN」，就会再回复一个与第四次挥手一样的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。<br>客户端等待一段时间还是没收到 SYN + ACK 后，就会超时重传 SYN 报文，重传次数达到最大值后，就会断开连接。</p><h3 id="在-TIME-WAIT-状态，收到-RST-会断开连接吗？"><a href="#在-TIME-WAIT-状态，收到-RST-会断开连接吗？" class="headerlink" title="在 TIME_WAIT 状态，收到 RST 会断开连接吗？"></a>在 TIME_WAIT 状态，收到 RST 会断开连接吗？</h3><p>在前面我留了一个疑问，处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？<br>会不会断开，关键看 net.ipv4.tcp_rfc1337 这个内核参数（默认情况是为 0）：</p><ul><li>如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。</li><li>如果这个参数设置为 1， 就会丢掉 RST 报文。</li></ul><p>源码处理如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684933690-82148dd1-7b3c-4b24-a2fd-350ad398297e.png#averageHue=%23282c35&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=659&amp;id=u4ced7991&amp;name=image.png&amp;originHeight=824&amp;originWidth=916&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=48759&amp;status=done&amp;style=none&amp;taskId=ua09f9a2b-9eec-48dd-9aca-3a30882eb6d&amp;title=&amp;width=732.8" alt="image.png"><br>TIME_WAIT 状态收到 RST 报文而释放连接，这样等于跳过 2MSL 时间，这么做还是有风险。<br>sysctl_tcp_rfc1337 这个参数是在 rfc 1337 文档提出来的，目的是避免因为 TIME_WAIT 状态收到 RST 报文而跳过 2MSL 的时间，文档里也给出跳过 2MSL 时间会有什么潜在问题。<br>TIME_WAIT 状态之所以要持续 2MSL 时间，主要有两个目的：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p>详细的为什么要设计 TIME_WAIT 状态，我在这篇有详细说明：<a href="https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;mid=2247502380&amp;idx=1&amp;sn=7b82818a5fb6f1127d17f0ded550c4bd&amp;scene=21#wechat_redirect">如果 TIME_WAIT 状态持续时间过短或者没有，会有什么问题？(opens new window)</a><br>所以，我个人觉得将 net.ipv4.tcp_rfc1337 设置为 1 会比较安全。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？<br>如果双方开启了时间戳机制：</p><ul><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</li><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。那么就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。</li></ul><p>在 TIME_WAIT 状态，收到 RST 会断开连接吗？</p><ul><li>如果 net.ipv4.tcp_rfc1337 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。</li><li>如果 net.ipv4.tcp_rfc1337 参数为 1，则会丢掉该 RST 报文。</li></ul><p>完！</p><h2 id="十、TCP-连接，一端断电和进程崩溃有什么区别？"><a href="#十、TCP-连接，一端断电和进程崩溃有什么区别？" class="headerlink" title="十、TCP 连接，一端断电和进程崩溃有什么区别？"></a>十、TCP 连接，一端断电和进程崩溃有什么区别？</h2><p>这个属于 <strong>TCP 异常断开连接</strong>的场景。</p><p>这个问题有几个关键词：</p><ul><li>没有开启 keepalive；</li><li>一直没有数据交互；</li><li>进程崩溃；</li><li>主机崩溃；</li></ul><p>我们先来认识认识什么是 TCP keepalive 呢？<br>这东西其实就是 <strong>TCP 的保活机制</strong>，它的工作原理我之前的文章写过，这里就直接贴下以前的内容。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684992472-ebff6f4e-f3a0-4cf2-9c0e-a19082bff2ab.png#averageHue=%23f2f1eb&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=1110&amp;id=uf1cce5ff&amp;name=image.png&amp;originHeight=1905&amp;originWidth=750&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=772822&amp;status=done&amp;style=none&amp;taskId=u5ba89bd5-2863-4edb-a2e0-77fcb3158a4&amp;title=&amp;width=437" alt="image.png"><br>如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。</p><ul><li>如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p><p>知道了 TCP keepalive 作用，我们再回过头看题目中的「主机崩溃」这种情况。<br>在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。<br>客户端主机崩溃了，服务端是<strong>无法感知到的</strong>，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，<strong>服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态</strong>，直到服务端重启进程。<br>所以，我们可以得知一个点，在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。<br>那题目中的「进程崩溃」的情况呢？<br>我自己做了实验，使用 kill -9 来模拟进程崩溃的情况，发现<strong>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</strong>。<br>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p><hr><p>以上就是对这个面试题的回答，接下来我们看看在「<strong>有数据传输</strong>」的场景下的一些异常情况：</p><ul><li>第一种，客户端主机宕机，又迅速重启，会发生什么？</li><li>第二种，客户端主机宕机，一直没有重启，会发生什么？</li></ul><p>客户端主机宕机，又迅速重启<br>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。<br>服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p><ul><li>如果客户端主机上<strong>没有</strong>进程监听该 TCP 报文的目标端口号，那么客户端内核就会回复 RST 报文，重置该 TCP 连接；</li><li>如果客户端主机上<strong>有</strong>进程监听该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li></ul><p>所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接。<br>客户端主机宕机，一直没有重启<br>这种情况，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，一般就是 ETIMEOUT 状态码。<br>那具体重传几次呢？<br>在 Linux 系统中，提供一个叫 <strong>tcp_retries2 </strong>配置项，默认值是 15，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684992847-44192332-0097-4812-a164-8a389c391cbc.png#averageHue=%23f1f1f1&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uac770b39&amp;name=image.png&amp;originHeight=73&amp;originWidth=493&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=8787&amp;status=done&amp;style=none&amp;taskId=u83dcce6e-9b9c-4d82-89d0-1b23434aa80&amp;title=" alt="image.png"><br>这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。<br>不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核还会基于「最大超时时间」来判定。<br>每一轮的超时时间都是<strong>倍数增长</strong>的，比如第一次触发超时重传是在 2s 后，第二次则是在 4s 后，第三次则是 8s 后，以此类推。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1650684994943-6fb912ab-cd0a-4a45-bdce-03bcd03a976f.png#averageHue=%23f6f4f0&amp;clientId=ub5ecb47a-aa60-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=465&amp;id=ue69f1220&amp;name=image.png&amp;originHeight=720&amp;originWidth=848&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=286958&amp;status=done&amp;style=none&amp;taskId=u5549d503-ba3f-408d-9476-6255c4be885&amp;title=&amp;width=548" alt="image.png"><br>内核会根据 tcp_retries2 设置的值，计算出一个最大超时时间。</p><p><strong>在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传</strong>。</p><h2 id="十一、拔掉网线后，-原本的-TCP-连接还存在吗？"><a href="#十一、拔掉网线后，-原本的-TCP-连接还存在吗？" class="headerlink" title="十一、拔掉网线后， 原本的 TCP 连接还存在吗？"></a>十一、拔掉网线后， 原本的 TCP 连接还存在吗？</h2><p>今天，聊一个有趣的问题：<strong>拔掉网线几秒，再插回去，原本的 TCP 连接还存在吗？</strong><br>可能有的同学会说，网线都被拔掉了，那说明物理层被断开了，那在上层的传输层理应也会断开，所以原本的 TCP 连接就不会存在的了。就好像， 我们拨打有线电话的时候，如果某一方的电话线被拔了，那么本次通话就彻底断了。<br>真的是这样吗？<br>上面这个逻辑就有问题。问题在于，错误的认为拔掉网线这个动作会影响传输层，事实上并不会影响。<br>实际上，TCP 连接在 Linux 内核中是一个名为 struct socket 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。<br>我在我的电脑上做了个小实验，我用 ssh 终端连接了我的云服务器，然后我通过断开 wifi 的方式来模拟拔掉网线的场景，此时查看 TCP 连接的状态没有发生变化，还是处于 ESTABLISHED 状态。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653013676992-ab4a44ad-6ab7-4249-88fa-e647e003c5ff.png#averageHue=%23131f2c&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u7dbfb58e&amp;name=image.png&amp;originHeight=381&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=201375&amp;status=done&amp;style=none&amp;taskId=u1c299f94-94fb-4d76-9851-f2e9bc684a7&amp;title=" alt="image.png"><br>通过上面这个实验结果，我们知道了，拔掉网线这个动作并不会影响 TCP 连接的状态。<br>接下来，要看拔掉网线后，双方做了什么动作。<br>所以， 针对这个问题，要分场景来讨论：</p><ul><li>拔掉网线后，有数据传输；</li><li><p>拔掉网线后，没有数据传输；</p><h3 id="拔掉网线后，有数据传输"><a href="#拔掉网线后，有数据传输" class="headerlink" title="拔掉网线后，有数据传输"></a>拔掉网线后，有数据传输</h3><p>在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的数据报文。<br><strong>如果在服务端重传报文的过程中，客户端刚好把网线插回去了</strong>，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。<br>此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。<br>但是，<strong>如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去</strong>，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。<br>而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。<br>此时，客户端和服务端的 TCP 连接都已经断开了。<br>那 TCP 的数据报文具体重传几次呢？<br>在 Linux 系统中，提供了一个叫 <strong>tcp_retries2</strong> 配置项，默认值是 15，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653013676548-d09bc9d2-85bb-445b-a4e9-e70655f78164.png#averageHue=%23f1f1f1&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue57b1fd9&amp;name=image.png&amp;originHeight=73&amp;originWidth=493&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=8787&amp;status=done&amp;style=none&amp;taskId=ue0416a6f-ff81-4713-a1bb-a77b7930ee4&amp;title=" alt="image.png"><br>这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。<br>不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核还会基于「最大超时时间」来判定。<br>每一轮的超时时间都是倍数增长的，比如第一次触发超时重传是在 2s 后，第二次则是在 4s 后，第三次则是 8s 后，以此类推。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653013677016-eb6d943a-c17d-44f2-9969-68071f681a05.png#averageHue=%23f6f4ef&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc577bb1d&amp;name=image.png&amp;originHeight=720&amp;originWidth=848&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=283008&amp;status=done&amp;style=none&amp;taskId=ue079909a-36e8-4169-ba70-bfc1e7eeaa3&amp;title=" alt="image.png"><br>内核会根据 tcp_retries2 设置的值，计算出一个最大超时时间。<br>在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传，然后就会断开 TCP 连接。</p><h3 id="拔掉网线后，没有数据传输"><a href="#拔掉网线后，没有数据传输" class="headerlink" title="拔掉网线后，没有数据传输"></a>拔掉网线后，没有数据传输</h3><p>针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制 （TCP 保活机制）。<br>如果<strong>没有开启</strong> TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。<br>而如果<strong>开启</strong>了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文：</p></li><li><p>如果<strong>对端是正常工作</strong>的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</p></li><li>如果<strong>对端主机崩溃，或对端由于其他原因导致报文不可达</strong>。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。<br>TCP keepalive 机制具体是怎么样的？<br>这个机制的原理是这样的：<br>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><blockquote><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：<br>net.ipv4.tcp_keepalive_time=7200 net.ipv4.tcp_keepalive_intvl=75   net.ipv4.tcp_keepalive_probes=9 </p><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653013676745-35e0bafd-4517-460e-8f61-4126268d65c7.png#averageHue=%23f7f7b4&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u55b130fa&amp;name=image.png&amp;originHeight=303&amp;originWidth=897&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=25186&amp;status=done&amp;style=none&amp;taskId=u7ec09d3d-e21a-420d-9091-43312f38025&amp;title=" alt="image.png">图片<br>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。<br>TCP keepalive 机制探测的时间也太长了吧？<br>对的，是有点长。<br>TCP keepalive 是 <strong>TCP 层（内核态）</strong> 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。<br>实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。<br>比如，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653013676805-597be1e1-b2a6-4d7f-9a20-a16f33036030.png#averageHue=%23faf6f4&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=754&amp;id=u0cf2157f&amp;name=image.png&amp;originHeight=947&amp;originWidth=708&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=77981&amp;status=done&amp;style=none&amp;taskId=u52a8a481-6567-4c12-a835-890f1008adf&amp;title=&amp;width=564" alt="image.png"></p></blockquote><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。<br>有数据传输的情况：</p><ul><li>在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。</li><li>在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。</li></ul><p>没有数据传输的情况：</p><ul><li>如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。</li><li>如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。</li></ul><p>除了客户端拔掉网线的场景，还有客户端「宕机和进程崩解」的两种场景。<br>第一个场景，客户端宕机这件事跟拔掉网线是一样无法被服务端的感知的，所以如果在没有数据传输，并且没有开启 TCP keepalive 机制时，，<strong>服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态</strong>，直到服务端重启进程。<br>所以，我们可以得知一个点。在没有使用 TCP 保活机制，且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态时，并不代表另一方的 TCP 连接还一定是正常的。<br>第二个场景，客户端的进程崩解后，客户端的内核就会向服务端发送 FIN 报文，<strong>与服务端进行四次挥手</strong>。<br>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。<br>完！</p><h2 id="十二、HTTPS-中-TLS-和-TCP-能同时握手吗？"><a href="#十二、HTTPS-中-TLS-和-TCP-能同时握手吗？" class="headerlink" title="十二、HTTPS 中 TLS 和 TCP 能同时握手吗？"></a>十二、HTTPS 中 TLS 和 TCP 能同时握手吗？</h2><blockquote><p>前置<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014980942-073036f7-4324-4a12-82db-0bcb0b7c48a4.png#averageHue=%23e5e5e5&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=824&amp;id=u1be7069b&amp;name=image.png&amp;originHeight=1112&amp;originWidth=644&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=481646&amp;status=done&amp;style=none&amp;taskId=ub77ec13e-53cd-4c1e-8571-50cdc24b5db&amp;title=&amp;width=477" alt="image.png"><br>如果是我面试遇到这样的面试官，我直接当场给他抓 HTTPS 建立过程的网络包，然后给他看，啪啪啪啪啪的打他脸。<br>比如，下面这个 TLSv1.2 的 基于 RSA 算法的四次握手过程：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014980808-b0fc965a-101d-4d30-b14b-1c675d328491.png#averageHue=%23275689&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u688a8961&amp;name=image.png&amp;originHeight=406&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=261683&amp;status=done&amp;style=none&amp;taskId=ubd4c105a-9d81-47f6-9cac-0c2517adada&amp;title=" alt="image.png"><br>难道不是先三次握手，再进行 TLS 四次握手吗？面试官你脸疼吗？<br>不过 TLS 握手过程的次数还得看版本。<br>TLSv1.2 握手过程基本都是需要四次，也就是需要经过 2-RTT 才能完成握手，然后才能发送请求，而 TLSv1.3 只需要 1-RTT 就能完成 TLS 握手，如下图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014980791-96a59568-9dfd-47f4-b23f-24045f31e61b.png#averageHue=%23f7f9f4&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=393&amp;id=u7f824343&amp;name=image.png&amp;originHeight=685&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=262149&amp;status=done&amp;style=none&amp;taskId=u86e0b4f5-5ad8-41ba-be27-5fb62fa5516&amp;title=&amp;width=619" alt="image.png"><br><strong>一般情况下，不管 TLS 握手次数如何，都得先经过 TCP 三次握手后才能进行</strong>，因为 HTTPS 都是基于 TCP 传输协议实现的，得先建立完可靠的 TCP 连接才能做 TLS 握手的事情。</p></blockquote><p>那面试官说的这句「HTTPS 中的 TLS 握手过程可以同时进行三次握手」对不对呢？<br>这个场景是可能发生的，但是需要在特定的条件下才可能发生，<strong>如果没有说任何前提条件，说这句话就是在耍流氓。</strong><br>那到底什么条件下，这个场景才能发生呢？需要下面这两个条件同时满足才可以：</p><ul><li><strong>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</strong></li><li><strong>客户端和服务端已经完成过一次通信。</strong></li></ul><p>那具体怎么做到的呢？我们先了解些 TCP Fast Open 功能和 TLSv1.3 的特性。</p><h3 id="TCP-Fast-Open"><a href="#TCP-Fast-Open" class="headerlink" title="TCP Fast Open"></a>TCP Fast Open</h3><p>我们先来了解下什么是 TCP Fast Open？<br>常规的情况下，如果要使用 TCP 传输协议进行通信，则客户端和服务端通信之前，先要经过 TCP 三次握手后，建立完可靠的 TCP 连接后，客户端才能将数据发送给服务端。<br>其中，TCP 的第一次和第二次握手是不能够携带数据的，而 TCP 的第三次握手是可以携带数据的，因为这时候客户端的 TCP 连接状态已经是 ESTABLISHED，表明客户端这一方已经完成了 TCP 连接建立。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014980145-d50cc0f8-baf4-4e82-ad80-7981c191dd94.png#averageHue=%23f9f9f9&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u437a157d&amp;name=image.png&amp;originHeight=330&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=43840&amp;status=done&amp;style=none&amp;taskId=ub247a94f-4c73-47a8-be9a-a53808714b8&amp;title=" alt="image.png"><br>就算客户端携带数据的第三次握手在网络中丢失了，客户端在一定时间内没有收到服务端对该数据的应答报文，就会触发超时重传机制，然后客户端重传该携带数据的第三次握手的报文，直到重传次数达到系统的阈值，客户端就会销毁该 TCP 连接。<br>说完常规的 TCP 连接后，我们再来看看 TCP Fast Open。<br>TCP Fast Open 是为了绕过 TCP 三次握手发送数据，在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。<br>要使用 TCP Fast Open 功能，客户端和服务端都要同时支持才会生效。<br>不过，开启了 TCP Fast Open 功能，<strong>想要绕过 TCP 三次握手发送数据，得建立第二次以后的通信过程。</strong><br>在客户端首次建立连接时的过程，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014980350-03e77a47-4df7-475b-b8d2-b25499626459.png#averageHue=%23f7f7f7&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u221004a3&amp;name=image.png&amp;originHeight=310&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=47615&amp;status=done&amp;style=none&amp;taskId=ubf741a19-6161-4d9c-8a9d-4b7cb695431&amp;title=" alt="image.png"><br>具体介绍：</p><ul><li>客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</li><li>支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 报文中的 Fast Open 选项以发回客户端；</li><li>客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</li></ul><p>所以，第一次客户端和服务端通信的时候，还是需要正常的三次握手流程。随后，客户端就有了 Cookie 这个东西，它可以用来向服务器 TCP 证明先前与客户端 IP 地址的三向握手已成功完成。<br>对于客户端与服务端的后续通信，客户端可以在第一次握手的时候携带应用数据，从而达到绕过三次握手发送数据的效果，整个过程如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014981118-1c1dc246-ecd5-472c-a85e-60cc1d89d7b7.png#averageHue=%23f8f8f8&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u364e1f39&amp;name=image.png&amp;originHeight=365&amp;originWidth=600&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=53621&amp;status=done&amp;style=none&amp;taskId=u2922afa3-ec18-46df-a3c0-d78ab9f34c2&amp;title=" alt="image.png"><br>我详细介绍下这个过程：</p><ul><li>客户端发送 SYN 报文，该报文可以携带「应用数据」以及此前记录的 Cookie；</li><li>支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「应用数据」递送给对应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「应用数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</li><li><strong>如果服务器接受了 SYN 报文中的「应用数据」，服务器可在握手完成之前发送「响应数据」，这就减少了握手带来的 1 个 RTT 的时间消耗</strong>；</li><li>客户端将发送 ACK 确认服务器发回的 SYN 以及「应用数据」，但如果客户端在初始的 SYN 报文中发送的「应用数据」没有被确认，则客户端将重新发送「应用数据」；</li><li>此后的 TCP 连接的数据传输过程和非 TCP Fast Open 的正常情况一致。</li></ul><p>所以，如果客户端和服务端同时支持 TCP Fast Open 功能，那么在完成首次通信过程后，后续客户端与服务端 的通信则可以绕过三次握手发送数据，这就减少了握手带来的 1 个 RTT 的时间消耗。</p><h3 id="TLSv1-3"><a href="#TLSv1-3" class="headerlink" title="TLSv1.3"></a>TLSv1.3</h3><p>说完 TCP Fast Open，再来看看 TLSv1.3。<br>在最开始的时候，我也提到 TLSv1.3 握手过程只需 1-RTT 的时间，它到整个握手过程，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014988375-5bd169da-3aaa-4430-8b16-1143df3274a2.png#averageHue=%23041a34&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ue91eec5f&amp;name=image.png&amp;originHeight=570&amp;originWidth=585&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57350&amp;status=done&amp;style=none&amp;taskId=u8f8f052d-5d3a-42a6-a9ee-0a3338a9671&amp;title=" alt="image.png"><br>TCP 连接的第三次握手是可以携带数据的，如果客户端在第三次握手发送了 TLSv1.3 第一次握手数据，是不是就表示「<em>HTTPS 中的 TLS 握手过程可以同时进行三次握手</em>」？。<br>不是的，因为服务端只有在收到客户端的 TCP 的第三次握手后，才能和客户端进行后续 TLSv1.3 握手。<br>TLSv1.3 还有个更厉害到地方在于<strong>会话恢复</strong>机制，在<strong>重连 TLvS1.3 只需要 0-RTT</strong>，用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息，过程如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653014988645-d698ec43-f723-443c-b2b8-4485c35bbcc2.png#averageHue=%23f7f7f7&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=346&amp;id=u6ee1d823&amp;name=image.png&amp;originHeight=557&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=85510&amp;status=done&amp;style=none&amp;taskId=u7d16ec43-4ea5-44b4-b05b-5e947ea9607&amp;title=&amp;width=671" alt="image.png"></p><h3 id="TCP-Fast-Open-TLSv1-3"><a href="#TCP-Fast-Open-TLSv1-3" class="headerlink" title="TCP Fast Open + TLSv1.3"></a>TCP Fast Open + TLSv1.3</h3><p>在前面我们知道，客户端和服务端同时支持 TCP Fast Open 功能的情况下，<strong>在第二次以后到通信过程中，客户端可以绕过三次握手直接发送数据，而且服务端也不需要等收到第三次握手后才发送数据。</strong><br>如果 HTTPS 的 TLS 版本是 1.3，那么 TLS 过程只需要 1-RTT。<br><strong>因此如果「TCP Fast Open + TLSv1.3」情况下，在第二次以后的通信过程中，TLS 和 TCP 的握手过程是可以同时进行的。</strong><br><strong>如果基于 TCP Fast Open 场景下的 TLSv1.3 0-RTT 会话恢复过程，不仅 TLS 和 TCP 的握手过程是可以同时进行的，而且 HTTP 请求也可以在这期间内一同完成。</strong></p><h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><p>最后做个总结。<br>「HTTPS 是先进行 TCP 三次握手，再进行 TLSv1.2 四次握手」，这句话一点问题都没有，怀疑这句话是错的人，才有问题。<br>「HTTPS 中的 TLS 握手过程可以同时进行三次握手」，这个场景是可能存在到，但是在没有说任何前提条件，而说这句话就等于耍流氓。需要下面这两个条件同时满足才可以：</p><ul><li><strong>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</strong></li><li><p><strong>客户端和服务端已经完成过一次通信；</strong></p><h2 id="十三、TCP-Keepalive-和-HTTP-Keep-Alive-是一个东西吗？"><a href="#十三、TCP-Keepalive-和-HTTP-Keep-Alive-是一个东西吗？" class="headerlink" title="十三、TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？"></a>十三、TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015223369-68f66620-b9c2-4dfa-8fa1-c499efd1b750.png#averageHue=%23e8e8e7&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0795fabf&amp;name=image.png&amp;originHeight=382&amp;originWidth=607&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=146986&amp;status=done&amp;style=none&amp;taskId=u0fdb582a-059b-4a6b-8506-9a0026a5b13&amp;title=" alt="image.png"><br>大致问题是，<strong>TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗？</strong><br>这是个好问题，应该有不少人都会搞混，因为这两个东西看上去太像了，很容易误以为是同一个东西。<br>事实上，<strong>这两个完全是两样不同东西</strong>，实现的层面也不同：</p></li><li><p>HTTP 的 Keep-Alive，是由<strong>应用层（用户态）</strong> 实现的，称为 HTTP 长连接；</p></li><li>TCP 的 Keepalive，是由 <strong>TCP 层（内核态）</strong> 实现的，称为 TCP 保活机制；</li></ul><p>接下来，分别说说它们。</p><h3 id="HTTP-的-Keep-Alive"><a href="#HTTP-的-Keep-Alive" class="headerlink" title="HTTP 的 Keep-Alive"></a>HTTP 的 Keep-Alive</h3><ul><li>HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。</li><li>由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015223235-b136c390-1619-4a09-a6c7-1f2c32e1a132.png#averageHue=%23f9f2ec&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=473&amp;id=u49883dfa&amp;name=image.png&amp;originHeight=722&amp;originWidth=386&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=47822&amp;status=done&amp;style=none&amp;taskId=u0ee89f92-37c2-4575-88b3-49aa1cb3abe&amp;title=&amp;width=253" alt="image.png"><br>如果每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 <strong>HTTP 短连接</strong>。</p><p>这样实在太累人了，一次连接只能请求一次资源。<br>能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？<br>当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 <strong>HTTP 长连接</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015223280-dff21a88-1938-437f-b067-9efdfa4b48c9.png#averageHue=%23faf6f1&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3b7b8813&amp;name=image.png&amp;originHeight=1067&amp;originWidth=386&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61840&amp;status=done&amp;style=none&amp;taskId=uc56e599a-ae80-40a2-8741-2daf69f872a&amp;title=" alt="image.png"><br>HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。<br>怎么才能使用 HTTP 的 Keep-Alive 功能？<br>在 HTTP 1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的包头中添加：<br>Connection: Keep-Alive<br>然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：<br>Connection: Keep-Alive<br>这样做，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端提出断开连接。<br><strong>从 HTTP 1.1 开始， 就默认是开启了 Keep-Alive</strong>，如果要关闭 Keep-Alive，需要在 HTTP 请求的包头里添加：<br>Connection:close<br>现在大多数浏览器都默认是使用 HTTP/1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。<br>HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 <strong>HTTP 流水线</strong>技术提供了可实现的基础。<br>所谓的 HTTP 流水线，是<strong>客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应</strong>，可以减少整体的响应时间。<br>举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。HTTP 流水线机制则允许客户端同时发出 A 请求和 B 请求。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015229197-47d912a8-a9ce-46c3-916c-8357182449a5.png#averageHue=%23fbf7f3&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=593&amp;id=u7bc6687e&amp;name=image.png&amp;originHeight=1025&amp;originWidth=926&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=121263&amp;status=done&amp;style=none&amp;taskId=u946479b5-9be4-4a62-be76-ed93f676bcc&amp;title=&amp;width=536" alt="image.png"><br>但是<strong>服务器还是按照顺序响应</strong>，先回应 A 请求，完成后再回应 B 请求。<br>而且要等服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了「队头阻塞」的问题。<br>可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？<br>对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供<strong> keepalive_timeout</strong> 参数，用来指定 HTTP 长连接的超时时间。<br>比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015238130-5fc11c9d-bda4-406d-bb3c-079441f5efab.png#averageHue=%23f9f6f4&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=781&amp;id=u0b25fe8d&amp;name=image.png&amp;originHeight=947&amp;originWidth=708&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=76882&amp;status=done&amp;style=none&amp;taskId=u48cad40e-be43-453d-a2c9-58293065759&amp;title=&amp;width=584" alt="image.png"></p><h3 id="TCP-的-Keepalive"><a href="#TCP-的-Keepalive" class="headerlink" title="TCP 的 Keepalive"></a>TCP 的 Keepalive</h3><p>TCP 的 Keepalive 这东西其实就是 <strong>TCP 的保活机制</strong>，它的工作原理我之前的文章写过，这里就直接贴下以前的内容。<br>如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。</p><ul><li>如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015238186-2da88f6d-79ca-473c-be03-d25e406f3113.png#averageHue=%23fbfaf8&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=582&amp;id=uded7d232&amp;name=image.png&amp;originHeight=810&amp;originWidth=833&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=67650&amp;status=done&amp;style=none&amp;taskId=u55573612-28e4-45c1-852b-e1e25b8bd96&amp;title=&amp;width=599.0000610351562" alt="image.png"><br>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><p>HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。<br>TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。</p><h2 id="十四、TCP-协议有什么缺陷？"><a href="#十四、TCP-协议有什么缺陷？" class="headerlink" title="十四、TCP 协议有什么缺陷？"></a>十四、TCP 协议有什么缺陷？</h2><p>写的多了后，忽然思考一个问题，TCP 通过序列号、确认应答、超时重传、流量控制、拥塞控制等方式实现了可靠传输，看起来它很完美，事实真的是这样吗？TCP 就没什么缺陷吗？<br>所以，今天就跟大家聊聊，TCP 协议有哪些缺陷？主要有四个方面：</p><ul><li>升级 TCP 的工作很困难；</li><li>TCP 建立连接的延迟；</li><li>TCP 存在队头阻塞问题；</li><li>网络迁移需要重新建立 TCP 连接；</li></ul><p>接下来，针对这四个方面详细说一下。</p><h3 id="升级-TCP-的工作很困难"><a href="#升级-TCP-的工作很困难" class="headerlink" title="升级 TCP 的工作很困难"></a>升级 TCP 的工作很困难</h3><ul><li>TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。而升级内核这个工作是很麻烦的事情，麻烦的事情不是说升级内核这个操作很麻烦，而是由于内核升级涉及到底层软件和运行库的更新，我们的服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。</li><li>很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的，比如 TCP Fast Open 这个特性，虽然在2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，W indows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到。<h3 id="TCP-建立连接的延迟"><a href="#TCP-建立连接的延迟" class="headerlink" title="TCP 建立连接的延迟"></a>TCP 建立连接的延迟</h3>基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。</li></ul><p>现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。<br>TCP 三次握手和 TLS 握手延迟，如图：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1653015396604-ae4639bd-493e-4a03-91e5-e4f318368f95.gif#averageHue=%23f6f2ed&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=516&amp;id=u42f7e022&amp;originHeight=693&amp;originWidth=777&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u302e127b-8b9d-4ad0-9180-87ac842b171&amp;title=&amp;width=579" alt=""><br>TCP 三次握手的延迟被 TCP Fast Open （快速打开）这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。</p><p>还有一点，针对 HTTPS 来说，TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。<br>也正是 TCP 是在内核实现的，所以 TLS 是无法对 TCP 头部加密的，这意味着 TCP 的序列号都是明文传输，所以就存安全的问题。</p><h3 id="TCP-存在队头阻塞问题"><a href="#TCP-存在队头阻塞问题" class="headerlink" title="TCP 存在队头阻塞问题"></a>TCP 存在队头阻塞问题</h3><p>TCP 是字节流协议，<strong>TCP 层必须保证收到的字节数据是完整且有序的</strong>，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。</p><blockquote><p>如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/gif/21371548/1653015396605-c74b64a3-debc-4f43-84d5-f9d54febc96d.gif#averageHue=%23f6f4f3&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u11d4f2e9&amp;originHeight=502&amp;originWidth=521&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ucfbc39dd-357a-4bc8-83a9-2dab4af7f5f&amp;title=" alt=""><br>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据。<br>这就是 TCP 队头阻塞问题，但这也不能怪 TCP ，因为只有这样做才能保证数据的有序性。</p></blockquote><p>HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求，所以 HTTP/2 队头阻塞问题就是因为 TCP 协议导致的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015398784-2436db41-72f9-4afa-b65f-4451c52da937.png#averageHue=%23f8f7f4&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3d6226f7&amp;name=image.png&amp;originHeight=377&amp;originWidth=1011&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=191678&amp;status=done&amp;style=none&amp;taskId=u077fd1f6-b308-4a9b-85b2-c524c423058&amp;title=" alt="image.png"></p><h3 id="网络迁移需要重新建立-TCP-连接"><a href="#网络迁移需要重新建立-TCP-连接" class="headerlink" title="网络迁移需要重新建立 TCP 连接"></a>网络迁移需要重新建立 TCP 连接</h3><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1653015396597-46bb7bcd-11fd-4327-aff0-692571cdf222.png#averageHue=%23f1d6b8&amp;clientId=u4c6ab8ca-2b4c-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u1809f45f&amp;originHeight=228&amp;originWidth=821&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u9d33483c-b5e3-491d-82ce-edda7748aec&amp;title=" alt=""><br>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。<br>而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><h3 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h3><p>我记得之前在群里看到，有位读者字节一面的时候被问到：「<strong>如何基于 UDP 协议实现可靠传输？</strong>」<br>很多同学第一反应就会说把 TCP 可靠传输的特性（序列号、确认应答、超时重传、流量控制、拥塞控制）在应用层实现一遍。<br>实现的思路确实这样没错，但是有没有想过，<strong>既然 TCP 天然支持可靠传输，为什么还需要基于 UDP 实现可靠传输呢？这不是重复造轮子吗？</strong><br>所以，我们要先弄清楚 TCP 协议有哪些痛点？而这些痛点是否可以在基于 UDP 协议实现的可靠传输协议中得到改进？<br>现在市面上已经有基于 UDP 协议实现的可靠传输协议的成熟方案了，那就是 QUIC 协议，<strong>QUIC 协议把我本文说的 TCP 的缺点都给解决了</strong>，而且已经应用在了 HTTP/3。</p><h2 id="十五、TCP-和-UDP-可以使用同一个端口吗？"><a href="#十五、TCP-和-UDP-可以使用同一个端口吗？" class="headerlink" title="十五、TCP 和 UDP 可以使用同一个端口吗？"></a>十五、TCP 和 UDP 可以使用同一个端口吗？</h2><p>大家好，我是小林。<br>之前有读者在字节面试的时候，被问到：<strong>TCP 和 UDP 可以同时监听相同的端口吗？</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507775428-34acef40-df65-4dc1-a43c-dedb20d76b75.png#averageHue=%23f5f5f5&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u008e047c&amp;name=image.png&amp;originHeight=198&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61520&amp;status=done&amp;style=none&amp;taskId=u6ef64458-90b7-4ce9-9127-0265712cbe3&amp;title=" alt="image.png"><br>关于端口的知识点，还是挺多可以讲的，比如还可以牵扯到这几个问题：</p><ul><li>多个 TCP 服务进程可以同时绑定同一个端口吗？</li><li>重启 TCP 服务进程时，为什么会出现“Address in use”的报错信息？又该怎么避免？</li><li>客户端的端口可以重复使用吗？</li><li>客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？</li></ul><p>所以，这次就跟大家盘一盘这些问题。</p><h3 id="TCP-和-UDP-可以同时绑定相同的端口吗？"><a href="#TCP-和-UDP-可以同时绑定相同的端口吗？" class="headerlink" title="TCP 和 UDP 可以同时绑定相同的端口吗？"></a>TCP 和 UDP 可以同时绑定相同的端口吗？</h3><p>其实我感觉这个问题「TCP 和 UDP 可以同时监听相同的端口吗？」表述有问题，这个问题应该表述成「<strong>TCP 和 UDP 可以同时绑定相同的端口吗？</strong>」<br>因为「监听」这个动作是在 TCP 服务端网络编程中才具有的，而 UDP 服务端网络编程中是没有「监听」这个动作的。<br>TCP 和 UDP 服务端网络相似的一个地方，就是会调用 bind 绑定端口。<br>给大家贴一下 TCP 和 UDP 网络编程的区别就知道了。<br>TCP 网络编程如下，服务端执行 listen() 系统调用就是监听端口的动作。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507776266-fb931d68-c04a-40f5-ae07-37ba6979ee81.png#averageHue=%23f4e9c1&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uecfcc0fe&amp;name=image.png&amp;originHeight=722&amp;originWidth=407&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=84384&amp;status=done&amp;style=none&amp;taskId=u2e0f1917-1894-4649-aede-d460ac6d325&amp;title=" alt="image.png"><br>UDP 网络编程如下，服务端是没有监听这个动作的，只有执行 bind() 系统调用来绑定端口的动作。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507775560-5621ad7c-2eaa-4417-9b4b-65f7f78abf9d.png#averageHue=%2323241a&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uf65a9690&amp;name=image.png&amp;originHeight=396&amp;originWidth=464&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=65984&amp;status=done&amp;style=none&amp;taskId=ucdaf3cc7-4df0-4fc1-900a-5c13af57767&amp;title=" alt="image.png"><br>TCP 和 UDP 可以同时绑定相同的端口吗？<br>答案：<strong>可以的</strong>。<br>在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。<br>所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。<br>传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。<br>当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507776249-330e2330-975e-4da9-9cf2-f49bec2d52e8.png#averageHue=%23dddbc8&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=665&amp;id=uc9463f65&amp;name=image.png&amp;originHeight=1197&amp;originWidth=952&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=381631&amp;status=done&amp;style=none&amp;taskId=u6067bfe3-caaf-4559-80cc-c178b782ac6&amp;title=&amp;width=529.0000610351562" alt="image.png"><br>因此， TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。<br>验证结果<br>我简单写了 TCP 和 UDP 服务端的程序，它们都绑定同一个端口号 8888。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507775886-ec123d56-9114-4438-bdc5-9df152e8d1ba.png#averageHue=%23f1f0f0&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uc51d58c5&amp;name=image.png&amp;originHeight=878&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=427085&amp;status=done&amp;style=none&amp;taskId=uae7564e9-060f-497a-91dc-dc25db64554&amp;title=" alt="image.png"><br>运行这两个程序后，通过 netstat 命令可以看到，TCP 和 UDP 是可以同时绑定同一个端口号的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507776898-2c827c7f-4840-4ff0-b6b5-ab4b964d04b2.png#averageHue=%2313161d&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u0e426289&amp;name=image.png&amp;originHeight=85&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=79337&amp;status=done&amp;style=none&amp;taskId=ucc06f113-dee9-4f47-a96c-a27fc304b85&amp;title=" alt="image.png"></p><h3 id="多个-TCP-服务进程可以绑定同一个端口吗？"><a href="#多个-TCP-服务进程可以绑定同一个端口吗？" class="headerlink" title="多个 TCP 服务进程可以绑定同一个端口吗？"></a>多个 TCP 服务进程可以绑定同一个端口吗？</h3><p>还是以前面的 TCP 服务端程序作为例子，启动两个同时绑定同一个端口的 TCP 服务进程。<br>运行第一个 TCP 服务进程之后，netstat 命令可以查看，8888 端口已经被一个 TCP 服务进程绑定并监听了，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507777012-f8b12067-7132-496b-8fba-79139bfd6ed3.png#averageHue=%2314171e&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u401a0351&amp;name=image.png&amp;originHeight=50&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49643&amp;status=done&amp;style=none&amp;taskId=u4b1e9c81-bde1-48eb-a484-3986fe07ffd&amp;title=" alt="image.png"><br>接着，运行第二个 TCP 服务进程的时候，就报错了“Address already in use”，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507777365-24f2d7a3-093f-4125-bf37-9d582d56bb5e.png#averageHue=%230f121a&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=uece1ab47&amp;name=image.png&amp;originHeight=84&amp;originWidth=760&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62714&amp;status=done&amp;style=none&amp;taskId=u02c237b7-ed41-4898-9e61-6f85f2a372a&amp;title=" alt="image.png"><br>我上面的测试案例是两个 TCP 服务进程同时绑定地址和端口是：0.0.0.0 地址和8888端口，所以才出现的错误。<br>如果两个 TCP 服务进程绑定的 IP 地址不同，而端口相同的话，也是可以绑定成功的，如下图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507778013-24b34fe6-8d3c-4fa8-af95-fc25f07e1e05.png#averageHue=%2313161d&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=udb308949&amp;name=image.png&amp;originHeight=71&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=73343&amp;status=done&amp;style=none&amp;taskId=u6f3cd450-84cf-43a5-b343-0f6646e719c&amp;title=" alt="image.png"><br>所以，默认情况下，针对「多个 TCP 服务进程可以绑定同一个端口吗？」这个问题的答案是：<strong>如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”</strong>。<br>注意，如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。<br>这是因为 0.0.0.0 地址比较特殊，代表任意地址，意味着绑定了 0.0.0.0 地址，相当于把主机上的所有 IP 地址都绑定了。<br><strong>TIP</strong><br>如果想多个进程绑定相同的 IP 地址和端口，也是有办法的，就是对 socket 设置 SO_REUSEPORT 属性（内核 3.9 版本提供的新特性），本文不对 SO_REUSEPORT 做具体介绍，感兴趣的同学自行去学习。<br>重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？<br>TCP 服务进程需要绑定一个 IP 地址和一个端口，然后就监听在这个地址和端口上，等待客户端连接的到来。<br>然后在实践中，我们可能会经常碰到一个问题，当 TCP 服务进程重启之后，总是碰到“Address in use”的报错信息，TCP 服务进程不能很快地重启，而是要过一会才能重启成功。<br>这是为什么呢？<br>当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507779325-0b28ca1e-7207-4976-ba66-66a5eabed18a.png#averageHue=%23f5e7cc&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=589&amp;id=u57336329&amp;name=image.png&amp;originHeight=1031&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=366239&amp;status=done&amp;style=none&amp;taskId=uf2b189cc-a0b3-439a-888d-63739eb8ad5&amp;title=&amp;width=617.0000610351562" alt="image.png"><br><strong>当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误</strong>。<br>而等 TIME_WAIT 状态的连接结束后，重启 TCP 服务进程就能成功。<br>重启 TCP 服务进程时，如何避免“Address in use”的报错信息？<br>我们可以在调用 bind 前，对 socket 设置 SO_REUSEADDR 属性，可以解决这个问题。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> on = <span class="number">1</span>;</span><br><span class="line">setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, <span class="keyword">sizeof</span>(on));</span><br></pre></td></tr></table></figure><br>因为 SO_REUSEADDR 作用是<strong>：如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。</strong><br>举个例子，服务端有个监听 0.0.0.0 地址和 8888 端口的 TCP 服务进程。‍<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507780631-05874cf3-82fb-41c4-bd9b-58344f1f3da7.png#averageHue=%2314171e&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u16fb8cde&amp;name=image.png&amp;originHeight=50&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=49643&amp;status=done&amp;style=none&amp;taskId=u4f341515-4a53-4768-8590-9b0f8f4312b&amp;title=" alt="image.png"><br>有个客户端（IP地址：192.168.1.100）已经和服务端（IP 地址：172.19.11.200）建立了 TCP 连接，那么在 TCP 服务进程重启时，服务端会与客户端经历四次挥手，服务端的 TCP 连接会短暂处于 TIME_WAIT 状态：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">客户端地址:端口           服务端地址:端口        TCP 连接状态</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.100</span>:<span class="number">37272</span>     <span class="number">172.19</span><span class="number">.11</span><span class="number">.200</span>:<span class="number">8888</span>    TIME_WAI</span><br></pre></td></tr></table></figure><br>如果 TCP 服务进程没有对 socket 设置 SO_REUSEADDR 属性，那么在重启时，由于存在一个和绑定 IP+PORT 一样的 TIME_WAIT 状态的连接，那么在执行 bind() 函数的时候，就会返回了 Address already in use 的错误。<br>如果 TCP 服务进程对 socket 设置 SO_REUSEADDR 属性了，那么在重启时，即使存在一个和绑定 IP+PORT 一样的 TIME_WAIT 状态的连接，依然可以正常绑定成功，因此可以正常重启成功。<br>因此，在所有 TCP 服务器程序中，调用 bind 之前最好对 socket 设置 SO_REUSEADDR 属性，这不会产生危害，相反，它会帮助我们在很快时间内重启服务端程序。‍<br><strong>前面我提到过这个问题：</strong>如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。<br>这个问题也可以由 SO_REUSEADDR 解决，因为它的<strong>另外一个作用是：**</strong>绑定的 IP地址 + 端口时，只要 IP 地址不是正好(exactly)相同，那么允许绑定。**<br>比如，0.0.0.0:8888 和192.168.1.100:8888，虽然逻辑意义上前者包含了后者，但是 0.0.0.0 泛指所有本地 IP，而 192.168.1.100 特指某一IP，两者并不是完全相同，所以在对 socket 设置 SO_REUSEADDR 属性后，那么执行 bind() 时候就会绑定成功。</p><h3 id="客户端的端口可以重复使用吗？"><a href="#客户端的端口可以重复使用吗？" class="headerlink" title="客户端的端口可以重复使用吗？"></a>客户端的端口可以重复使用吗？</h3><p>客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507781329-2ec6b2b6-6aa2-4987-9357-b280551173e8.png#averageHue=%23fcfbf0&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ubd1db415&amp;name=image.png&amp;originHeight=915&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=229314&amp;status=done&amp;style=none&amp;taskId=ua040c1e0-944b-4094-b99c-fa68f8a14ab&amp;title=" alt="image.png"><br>所以，客户端的端口选择的发生在 connect 函数，内核在选择端口的时候，会从 net.ipv4.ip_local_port_range 这个内核参数指定的范围来选取一个端口作为客户端端口。<br>该参数的默认值是 32768 61000，意味着端口总可用的数量是 61000 - 32768 = 28232 个。<br>当客户端与服务端完成 TCP 连接建立后，我们可以通过 netstat 命令查看 TCP 连接。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -napt</span><br><span class="line">协议  源ip地址:端口            目的ip地址：端口         状态</span><br><span class="line">tcp  <span class="number">192.168</span><span class="number">.110</span><span class="number">.182</span><span class="number">.64992</span>   <span class="number">117.147</span><span class="number">.199</span><span class="number">.51</span><span class="number">.443</span>     ESTABLISHED</span><br></pre></td></tr></table></figure><br>那问题来了，上面客户端已经用了 64992 端口，那么还可以继续使用该端口发起连接吗？<br>这个问题，很多同学都会说不可以继续使用该端口了，如果按这个理解的话， 默认情况下客户端可以选择的端口是 28232 个，那么意味着客户端只能最多建立 28232 个 TCP 连接，如果真是这样的话，那么这个客户端并发连接也太少了吧，所以这是错误理解。<br>正确的理解是，<strong>TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。</strong><br>比如下面这张图，有 2 个 TCP 连接，左边是客户端，右边是服务端，客户端使用了相同的端口 50004 与两个服务端建立了 TCP 连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507781475-2532ca35-e276-4f83-833a-e574b7c1553f.png#averageHue=%23282828&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u5881bd3b&amp;name=image.png&amp;originHeight=125&amp;originWidth=1080&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=83518&amp;status=done&amp;style=none&amp;taskId=u64b17c69-9050-4de4-acc3-e1cd06c5b4c&amp;title=" alt="image.png"><br>仔细看，上面这两条 TCP 连接的四元组信息中的「目的 IP 地址」是不同的，一个是 180.101.49.12 ，另外一个是 180.101.49.11。<br>多个客户端可以 bind 同一个端口吗？<br>bind 函数虽然常用于服务端网络编程中，但是它也是用于客户端的。<br>前面我们知道，客户端是在调用 connect 函数的时候，由内核随机选取一个端口作为连接的端口。<br>而如果我们想自己指定连接的端口，就可以用 bind 函数来实现：客户端先通过 bind 函数绑定一个端口，然后调用 connect 函数就会跳过端口选择的过程了，转而使用 bind 时确定的端口。<br>针对这个问题：多个客户端可以 bind 同一个端口吗？<br>要看多个客户端绑定的 IP + PORT 是否都相同，如果都是相同的，那么在执行 bind() 时候就会出错，错误是“Address already in use”。<br>如果一个绑定在 192.168.1.100:6666，一个绑定在 192.168.1.200:6666，因为 IP 不相同，所以执行 bind() 的时候，能正常绑定。<br>所以， 如果多个客户端同时绑定的 IP 地址和端口都是相同的，那么执行 bind() 时候就会出错，错误是“Address already in use”。<br>一般而言，客户端不建议使用 bind 函数，应该交由 connect 函数来选择端口会比较好，因为客户端的端口通常都没什么意义。<br>客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？<br>针对这个问题要看，客户端是否都是与同一个服务器（目标地址和目标端口一样）建立连接。<br>如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。<br>但是，<strong>因为只要客户端连接的服务器不同，端口资源可以重复使用的</strong>。<br>所以，如果客户端都是与不同的服务器建立连接，即使客户端端口资源只有几万个， 客户端发起百万级连接也是没问题的（当然这个过程还会受限于其他资源，比如文件描述符、内存、CPU 等）。<br>如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？<br>前面我们提到，如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。<br>针对这个问题，也是有解决办法的，那就是打开 net.ipv4.tcp_tw_reuse 这个内核参数。<br><strong>因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。</strong><br>举个例子，假设客户端已经与服务器建立了一个 TCP 连接，并且这个状态处于 TIME_WAIT 状态：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">客户端地址:端口           服务端地址:端口         TCP 连接状态</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.100</span>:<span class="number">2222</span>      <span class="number">172.19</span><span class="number">.11</span><span class="number">.21</span>:<span class="number">8888</span>     TIME_WAIT</span><br></pre></td></tr></table></figure><br>然后客户端又与该服务器（172.19.11.21:8888）发起了连接，<strong>在调用 connect 函数时，内核刚好选择了 2222 端口，接着发现已经被相同四元组的连接占用了：</strong></p><ul><li>如果<strong>没有开启</strong> net.ipv4.tcp_tw_reuse 内核参数，那么内核就会选择下一个端口，然后继续判断，直到找到一个没有被相同四元组的连接使用的端口， 如果端口资源耗尽还是没找到，那么 connect 函数就会返回错误。</li><li>如果<strong>开启</strong>了 net.ipv4.tcp_tw_reuse 内核参数，就会判断该四元组的连接状态是否处于 TIME_WAIT 状态，<strong>如果连接处于 TIME_WAIT 状态并且该状态持续的时间超过了 1 秒，那么就会重用该连接</strong>，于是就可以使用 2222 端口了，这时 connect 就会返回成功。</li></ul><p>再次提醒一次，开启了 net.ipv4.tcp_tw_reuse 内核参数，是客户端（连接发起方） 在调用 connect() 函数时才起作用，所以在服务端开启这个参数是没有效果的。<br>客户端端口选择的流程总结<br>至此，我们已经把客户端在执行 connect 函数时，内核选择端口的情况大致说了一遍，为了让大家更明白客户端端口的选择过程，我画了一流程图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/21371548/1659507782182-5ae43043-bce1-4f92-9368-c845b61f5427.png#averageHue=%23fbf8f8&amp;clientId=u45feb1e7-5ce6-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=1183&amp;id=u7670d086&amp;name=image.png&amp;originHeight=3400&amp;originWidth=1549&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=823549&amp;status=done&amp;style=none&amp;taskId=ua60241d0-c953-4a70-b781-d1406483418&amp;title=&amp;width=539.0000610351562" alt="image.png"></p><h3 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h3><p>TCP 和 UDP 可以同时绑定相同的端口吗？<br>可以的。<br>TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。<br>当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。<br>因此， TCP/UDP 各自的端口号也相互独立，互不影响。<br>多个 TCP 服务进程可以同时绑定同一个端口吗？<br>如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”。<br>如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。<br>如何解决服务端重启时，报错“Address already in use”的问题？<br>当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。<br>当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。<br>要解决这个问题，我们可以对 socket 设置 SO_REUSEADDR 属性。<br>这样即使存在一个和绑定 IP+PORT 一样的 TIME_WAIT 状态的连接，依然可以正常绑定成功，因此可以正常重启成功。<br>客户端的端口可以重复使用吗？<br>在客户端执行 connect 函数的时候，只要客户端连接的服务器不是同一个，内核允许端口重复使用。<br>TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。<br>所以，如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。<br>客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？<br>要看客户端是否都是与同一个服务器（目标地址和目标端口一样）建立连接。<br>如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。即使在这种状态下，还是可以与其他服务器建立连接的，只要客户端连接的服务器不是同一个，那么端口是重复使用的。<br>如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？<br>打开 net.ipv4.tcp_tw_reuse 这个内核参数。<br>因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态。<br>如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。</p><h2 id="other"><a href="#other" class="headerlink" title="other"></a>other</h2><h3 id="1-DNS-的解析过程？"><a href="#1-DNS-的解析过程？" class="headerlink" title="1.DNS 的解析过程？"></a>1.DNS 的解析过程？</h3><ol><li>浏览器搜索<strong>自己的DNS缓存</strong></li><li>若没有，则搜索<strong>操作系统中的DNS缓存和hosts文件</strong></li><li>若没有，则操作系统将域名发送至<strong>本地域名服务器</strong>，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向<strong>根域名服务器、顶级域名服务器、权限域名服务器</strong>发起查询请求，最终返回IP地址给本地域名服务器</li><li>本地域名服务器将得到的IP地址返回给<strong>操作系统</strong>，同时自己也<strong>将IP地址缓存起来</strong></li><li>操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来</li><li>浏览器得到域名对应的IP地址<h3 id="如何解决udp不丢包问题"><a href="#如何解决udp不丢包问题" class="headerlink" title="如何解决udp不丢包问题"></a>如何解决udp不丢包问题</h3><a href="https://blog.csdn.net/GoodLinGL/article/details/116780880">https://blog.csdn.net/GoodLinGL/article/details/116780880</a><h3 id="粘包"><a href="#粘包" class="headerlink" title="粘包"></a>粘包</h3><a href="https://github.com/Zeb-D/my-review/blob/master/network/%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90--TCP%E7%B2%98%E5%8C%85%E4%B8%8E%E6%8B%86%E5%8C%85.md">https://github.com/Zeb-D/my-review/blob/master/network/%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90—TCP%E7%B2%98%E5%8C%85%E4%B8%8E%E6%8B%86%E5%8C%85.md</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
